{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data is imported as csv file to Dataframe\n",
    "defdir=\"D:/Mobile proje/alllar\"\n",
    "os.chdir(defdir)\n",
    "all_=pd.read_csv(\"all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36707 entries, 0 to 36706\n",
      "Data columns (total 80 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Querylength                      36707 non-null  int64  \n",
      " 1   domain_token_count               36707 non-null  int64  \n",
      " 2   path_token_count                 36707 non-null  int64  \n",
      " 3   avgdomaintokenlen                36707 non-null  float64\n",
      " 4   longdomaintokenlen               36707 non-null  int64  \n",
      " 5   avgpathtokenlen                  36427 non-null  float64\n",
      " 6   tld                              36707 non-null  int64  \n",
      " 7   charcompvowels                   36707 non-null  int64  \n",
      " 8   charcompace                      36707 non-null  int64  \n",
      " 9   ldl_url                          36707 non-null  int64  \n",
      " 10  ldl_domain                       36707 non-null  int64  \n",
      " 11  ldl_path                         36707 non-null  int64  \n",
      " 12  ldl_filename                     36707 non-null  int64  \n",
      " 13  ldl_getArg                       36707 non-null  int64  \n",
      " 14  dld_url                          36707 non-null  int64  \n",
      " 15  dld_domain                       36707 non-null  int64  \n",
      " 16  dld_path                         36707 non-null  int64  \n",
      " 17  dld_filename                     36707 non-null  int64  \n",
      " 18  dld_getArg                       36707 non-null  int64  \n",
      " 19  urlLen                           36707 non-null  int64  \n",
      " 20  domainlength                     36707 non-null  int64  \n",
      " 21  pathLength                       36707 non-null  int64  \n",
      " 22  subDirLen                        36707 non-null  int64  \n",
      " 23  fileNameLen                      36707 non-null  int64  \n",
      " 24  this.fileExtLen                  36707 non-null  int64  \n",
      " 25  ArgLen                           36707 non-null  int64  \n",
      " 26  pathurlRatio                     36707 non-null  float64\n",
      " 27  ArgUrlRatio                      36707 non-null  float64\n",
      " 28  argDomanRatio                    36707 non-null  float64\n",
      " 29  domainUrlRatio                   36707 non-null  float64\n",
      " 30  pathDomainRatio                  36707 non-null  float64\n",
      " 31  argPathRatio                     36707 non-null  float64\n",
      " 32  executable                       36707 non-null  int64  \n",
      " 33  isPortEighty                     36707 non-null  int64  \n",
      " 34  NumberofDotsinURL                36707 non-null  int64  \n",
      " 35  ISIpAddressInDomainName          36707 non-null  int64  \n",
      " 36  CharacterContinuityRate          36707 non-null  float64\n",
      " 37  LongestVariableValue             36707 non-null  int64  \n",
      " 38  URL_DigitCount                   36707 non-null  int64  \n",
      " 39  host_DigitCount                  36707 non-null  int64  \n",
      " 40  Directory_DigitCount             36707 non-null  int64  \n",
      " 41  File_name_DigitCount             36707 non-null  int64  \n",
      " 42  Extension_DigitCount             36707 non-null  int64  \n",
      " 43  Query_DigitCount                 36707 non-null  int64  \n",
      " 44  URL_Letter_Count                 36707 non-null  int64  \n",
      " 45  host_letter_count                36707 non-null  int64  \n",
      " 46  Directory_LetterCount            36707 non-null  int64  \n",
      " 47  Filename_LetterCount             36707 non-null  int64  \n",
      " 48  Extension_LetterCount            36707 non-null  int64  \n",
      " 49  Query_LetterCount                36707 non-null  int64  \n",
      " 50  LongestPathTokenLength           36707 non-null  int64  \n",
      " 51  Domain_LongestWordLength         36707 non-null  int64  \n",
      " 52  Path_LongestWordLength           36707 non-null  int64  \n",
      " 53  sub-Directory_LongestWordLength  36707 non-null  int64  \n",
      " 54  Arguments_LongestWordLength      36707 non-null  int64  \n",
      " 55  URL_sensitiveWord                36707 non-null  int64  \n",
      " 56  URLQueries_variable              36707 non-null  int64  \n",
      " 57  spcharUrl                        36707 non-null  int64  \n",
      " 58  delimeter_Domain                 36707 non-null  int64  \n",
      " 59  delimeter_path                   36707 non-null  int64  \n",
      " 60  delimeter_Count                  36707 non-null  int64  \n",
      " 61  NumberRate_URL                   36707 non-null  float64\n",
      " 62  NumberRate_Domain                36707 non-null  float64\n",
      " 63  NumberRate_DirectoryName         36697 non-null  float64\n",
      " 64  NumberRate_FileName              36697 non-null  float64\n",
      " 65  NumberRate_Extension             26577 non-null  float64\n",
      " 66  NumberRate_AfterPath             36704 non-null  float64\n",
      " 67  SymbolCount_URL                  36707 non-null  int64  \n",
      " 68  SymbolCount_Domain               36707 non-null  int64  \n",
      " 69  SymbolCount_Directoryname        36707 non-null  int64  \n",
      " 70  SymbolCount_FileName             36707 non-null  int64  \n",
      " 71  SymbolCount_Extension            36707 non-null  int64  \n",
      " 72  SymbolCount_Afterpath            36707 non-null  int64  \n",
      " 73  Entropy_URL                      36707 non-null  float64\n",
      " 74  Entropy_Domain                   36707 non-null  float64\n",
      " 75  Entropy_DirectoryName            28239 non-null  float64\n",
      " 76  Entropy_Filename                 36471 non-null  float64\n",
      " 77  Entropy_Extension                36667 non-null  float64\n",
      " 78  Entropy_Afterpath                36701 non-null  float64\n",
      " 79  URL_Type_obf_Type                36707 non-null  object \n",
      "dtypes: float64(21), int64(58), object(1)\n",
      "memory usage: 22.4+ MB\n"
     ]
    }
   ],
   "source": [
    "all_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of None-Empty Rows for Each Feature')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4gAAAMACAYAAABmU0l7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdebhsVXkn/u8r1xgSBSdQBBUVko4aJUqIibZxSEccQUHFWZsWpHFINB2H2A5Jk47t1CFGHAIydKIiKKJCR+OAbYKQGxtFNMabqIGAcBNU0Fb8ge/vj1oHi+O5dc6FW3X08vk8Tz1n19pr7Xp31UHP9669V1V3BwAAAG6y3gUAAADw40FABAAAIImACAAAwCAgAgAAkERABAAAYBAQAQAASCIgAvxEqqrjq+q/rdNrV1W9o6q+UVXnrkcNzF9V7VhVH6iqb1XVe9a7ni2pqk9U1X9a7zoAthcCIsA2UFVfrapLq+pnp9r+U1V9Yh3LmpcHJPkPSfbo7v2W76yqZ1ZVV9V/WdZ+UVU9aEE1Tr/uV6vqu1X17anHm+b0Wl1Ve13PsQ+qqh+M+q6sqi9V1bO2dY1b4eAkt0tym+5+/A092LLzm3786g0v9QbV8IFtcNx1+wcbgG1tw3oXALAd2ZDkBUn+cL0L2RpVtUN3X7MVQ+6c5Kvd/Z0ZfS5P8uKqemt3X3HDKtwmHt3df7XeRazBxd29R1VVkocnOb2q/qa7v7QOtdw5yT9099VbO7CqNmxh3MXdvccNL+0G+XGo4TpmvF8AC2cGEWDbeW2S36mqWy7fUVV7jtmlDVNt114aN2bd/rqq3lhV36yqf6qqXxvtF1bVZVX1jGWHvW1VfWTMNp1VVXeeOva/G/suHzNRT5jad3xVHVNVZ1TVd5I8eIV671BVp4/xm6rq2aP90CR/luRXx+zLq7fwXnwxydlJfnulnVV1s6r6n1V18Xj8z6q62dj3oDHb+KJx3pdMz6SNsa+rqn8es7Zvqaodt1DHTFv7vo/37i0rve9V9cnR7bPjvXliVX2+qh49Nf6mVfWvVbXPrLp64oxMgva9psb/WlX9bU0u+/zbqvq10f7gqjp/qt9f1dTlv1X1qao6cGy/uKr+ZWqW8qErvC+vTvKKJE8c53JoVd2kql5eVV8b78uJVbXz6L/0+31oVf1zko+t/VO49jWfVVVfHHX9U1Udvmz/AVV1XlVdUVX/WFX7T+2+8/gcr6yqD1fVba/H69+kql4yjv1vVXVyVd16av97qurr473/ZFXdY7QfluQpSX63pmYka9lsck3NMk79jr+4qr6e5B2j/VHjHL9ZVX9TVfcKwIIJiADbzsYkn0jyO9dz/K8k+VyS2yT5iyTvSvLLSfZK8tQkb6qqm0/1f0qSP0hy2yTnJfnzJKnJZa4fGcfYNcmTkrx56Q/a4clJjkpyiySfWqGWdya5KMkdMrnU8A+r6qHdfWyS5yQ5u7tv3t2vnHE+/zXJb0//kT3l95LcL8k+Se6dZL8kL5/af/skOyfZPcmhSf60qm419r0myc+NsXuNPq+YUcdqtsn73t0PHPvvPd6bdyc5cRxjySOSXNLd580qaISVx4zX2DTabp3kQ0mOHrW+IcmHquo2mYTxvarqtjX5R4h7Jtmjqm4xwvN9k/yfqvr5JM9N8svdfYskD0vy1eWvPz7XP0zy7nEuxyZ55ng8OMldk9w8yfJLdX89yS+M426ty5I8KslOSZ6V5I1VdZ9x7vtl8l7+lyS3TPLAZXU/eYzZNclP5fr9N/j8JAeOc7hDkm8k+dOp/Wcm2Xu8xmfyw8/9bWP7f4z36tFZm9snuXUmM7WHjXM9LsnhmXy+b81kBvlm1+NcAK43ARFg23pFkudV1S7XY+xXuvsd43LPdye5Y5Lf7+6ruvvDSb6fSWhZ8qHu/mR3X5VJ4PrVqrpjJn9kf3Uc6+ru/kySUzMJekve391/3d0/6O7vTRcxjvGAJC/u7u+NMPNnSZ62NSczxn04yYtX2P2UcW6XdffmJK9edvz/b+z//8ZM2reT/HxVVZJnJ/nt7r68u6/MJMgcsko5p41ZmaXHs6f2bav3fSX/K8kjqmqn8fxpSU6aUecdquqbSb6b5H1JXtjd/3fse2SSL3f3SeNzfWeSv8/k8tnvZfIPFA9Msm8mgfdTSe6fSRD/cnf/W5Jrktwsyd2r6qbd/dXu/sfZb921npLkDd39T9397SQvTXJITc2KJ3lVd3+nu7876/yWPX42Sbr7Q939j2P29KxMfnf+/Rh3aJLjuvsj43f2X7r776eO+47u/ofxuidn8o8HW7K8hqXZ9cOT/F53XzQ+21clOXjp/Lr7uO6+cmrfvZdmUK+nHyR55fg9+24mv9dv7e5zuvua7j4hyVWZfH4ACyMgAmxD3f35JB9M8pLrMfzSqe3vjuMtb5ueybpw6nW/ncnliHfIZEbiV6b/CM7kj/vbrzR2BXdIshS+lnwtk5m6rfWKJEdU1e2Xtd9hHHP6+HeYev5vy+7J+n+ZnPsuSX4myd9Nndv/Hu2pqjPrh4uPPGVq/IHdfcupx9un9m2r9/1HdPfFSf46yUE1ufT44RkzT1twcXffMpNZtKOTPGRq3/L3LLnu53JWkgdlEhLPymQ2+9fH46xRz6Ykv5VJwLmsqt5VVSvWvoKVPrMNmSxks2TW71Uyzm/Z4ztJUlUPr6pP1+Sy5m9mMtu6dKnoHZPMCrJfn9pe+l1Zaw0nj/Y7J3nf1O/VFzMJ1Lerqh2q6o/G5adX5Iezl1t9KeuUzcv+cebOSV607L/bO2YLv1sA8yIgAmx7r8xkNmA6UC0t6PIzU23LQ9PWunbWalwCeeskF2fyR/pZy/4Ivnl3HzE1tmcc9+Ikt66qW0y13SnJv2xtgWOW571JXrbCa9x56vmdRttq/jWTwHaPqXPbubtvPl7v4eNcb97ds4LYDbGl931LTsjkMtPHZ3Jp7qrv45ilenGSX6xx72B+9D1Lrvu5LA+IZ2VZQBzH/ovufsA4Vmdyye5arPSZXZ3rBuxZv1dbNC6jPDXJ65LcboTkM5LU6HJhkrtdn2NvhQuTPHzZfzc/PT6vJyc5IMlvZHLp855LpY+fK533/8vs/96Xj7kwyVHLXv9nxkwxwMIIiADb2JileXcm9zQttW3O5A/5p47ZiP+YG/4H7yOq6gFV9VOZ3BN3TndfmMkM5s9V1dNqsijKTavql6vqF9ZY/4VJ/ibJf6+qnx4LZRya2TNfs7w6k/vDphfveWeSl1fVLmNBkVdkcjnmarX9IMnbM7k/bdckqardq+r63PN2fW3pfU8mYemuy/qfluQ+maxwe+JaX6S7v5/k9fnh/ZVnZPK5PrmqNlTVE5PcPZPPO5l8Zj+fyf2c53b3BRmzyUk+mSRV9fNV9ZARyL6XSdhe6wq278zkntK7jGC8dI/itlh986cyufR1c5Krq+rhSX5zav+xSZ5VVQ8d92fuXlX/bhu87rS3JDmqfrjo0C5VdcDYd4tMLvf8t0xC3/KVilf63M9L8uTx3/v+mQT1Wd6e5DlV9Ss18bNV9chl/1ADMHcCIsB8/H6Sn13W9uxMFtn4tyT3yOQP+hviLzKZrbw8k0VInpIk49LQ38zkvryLM7n87jWZ/AG+Vk/KZJbk4kzuhXtld3/k+hTZ3V/J5L676ffjv2Vyz9znkpyfyaIfa/0euRdnsnDLp8flfn+VSTCa5QN13e++e9/WnMMyK77vw6uSnDB9b9u4v+zUJHfJZDZ1axyX5E5V9ehxD+Gjkrwok9+h303yqO7+1/E638nkfbxghMtksnjN17r7svH8Zkn+KJOZ2K9nsuDK8tndWbWclEnY/EomAfN5W3k+d6gf/R7Eg8bv7PMzuX/wG5nM2J2+NKi7z81YuCbJtzKZEV0+m3pD/fF4zQ9X1ZVJPp1JuE4mwf5rmfwjzxfGvmnHZnJf5zer6rTR9oIkj06ydIn3aZmhuzdm8r8Rb8rkPdiUyaJAAAtV3dfrahAAuNGpquOTXNTdL1+t77Jxr0jyc9391FU7A8A62rB6FwDg+qrJ11Mcmq1cBRYA1oNLTAFgTsbXaVyY5Mzu/uR61wMAq3GJKQAAAEnMIAIAADAIiAAAACS5ES5Sc9vb3rb33HPP9S4DAABgXfzd3/3dv3b3Livtu9EFxD333DMbN25c7zIAAADWRVV9bUv7XGIKAABAEgERAACAQUAEAAAgiYAIAADAICACAACQREAEAABgEBABAABIIiACAAAwCIgAAAAkERABAAAYBEQAAACSCIgAAAAMAiIAAABJBEQAAAAGAREAAIAkAiIAAACDgAgAAEASAREAAIBBQAQAACCJgAgAAMAgIAIAAJBEQAQAAGAQEAEAAEgiIAIAADBsWO8C1sPmY/7Xqn12OeKpk75vOW52v+f8x9HvmNWP+ZwjkiSXveUNM/vt+pwXXrv99WP+YGbf2x/xX1d93eUuetOhM/fv8dxjkyRf+ZMDVz3WXZ53WpLki396wMx+v3Dk+5Mknz3mMase895HnJ4k+du3PnrVvr98+AeSJH/9tkfN7Hf/wz6YJPn42x+56jEf/OwPJUk+fOwjZvb7zUPPSJJ86NiHr3rMRx56ZpLktONW73vgf5z0fc879p/Z7/HP+t9Jkr84/mGrHvPJz/zLJMkJx//mzH7PeOaHkyR/duLqx/xPT58c8y0nrd73OU+b9D36z2f3ff5TJv1e987Vj/k7T5r0/cN3z+77sidO+r3i5NnvZ5L8/hMm7+nvnDK77+sO/t/Xbh/+vtl93/rYSd/HvX/113/vAZO+D3//U2b2O/OAPx/9nrvqMc884E1Jkkec9uKZ/c448DXXbj/ifa+c3fexrx79/nDV1z/jsS9Lkjzyva+b2e9Dj/ud0e+PVz3mhx73gtH3T1fpd+S124889a2z+x50+Oh37Oqvf9Dkf0MfderxM/t98KBnTvqdsvr/53zw4KeOvu9cpd+Trt1+1Cknr9L3CUmSR59y6qqv/4GDD0qSPOaU98/sd/rBB4x+H1r1mKcfPPnf2wNO+cuZ/d5/8A//Gz7wlI/O7HvawQ9Nkjz21E+u+vrvO+iBSZLHnXr2zH7vPehXkyQHnbpx1WOeetC+SZLHn/q5mf3ec9C9kiRPOPVLqx7z5IN+PknytPd+bdW+Jz3uzkmS33nfRTP7ve6xeyRJjnrfJase8/ceu1uS5Oj3fX1mv+c/9vZJkmPfe9mqxzz0cbsmSf7i1M2r9n3yQbskSd53yr/O7PfYg2+bJPnQu2f3S5JHPnHS96/eOfv1f+NJk9f+5P9avc4HPnXS99PHz+57v2fucu32Z46d/V7d59DJ+/T5t1666uvf8/Dbrdpn2tfeOPvzTJI7//bkM73kNbN/T3Z78W7Xbn/9tV+Z2ff2/+Uuk36vX/13//Yvmvzuf/0N58/u98JfTJJc+j8/s+oxb/db95n0/eNzZvd7wa9cu33p0Z+a3ff5D0iSXPYnH1/19Xd93oNX7XN9Xfanp81+7SN/+Hf7ZW9+z+y+//nxM/ebQQQAACCJgAgAAMBwo7zEFAAAYD1d9qbVL9ff9bmr3x61rQmI24mL3/y7q/a5w3/+HwuoBAAA+EnlElMAAACSCIgAAAAMAiIAAABJBEQAAAAGAREAAIAkAiIAAACDgAgAAEASAREAAIBBQAQAACCJgAgAAMAgIAIAAJBEQAQAAGAQEAEAAEgiIAIAADAIiAAAACSZY0Csqp+uqnOr6rNVdUFVvXq0v6qq/qWqzhuPR0yNeWlVbaqqL1XVw6ba71tV5499R1dVjfabVdW7R/s5VbXnvM4HAABgezfPGcSrkjyku++dZJ8k+1fV/ca+N3b3PuNxRpJU1d2THJLkHkn2T/Lmqtph9D8myWFJ9h6P/Uf7oUm+0d17JXljktfM8XwAAAC2a3MLiD3x7fH0puPRM4YckORd3X1Vd38lyaYk+1XVbkl26u6zu7uTnJjkwKkxJ4ztU5I8dGl2EQAAgK0z13sQq2qHqjovyWVJPtLd54xdz62qz1XVcVV1q9G2e5ILp4ZfNNp2H9vL268zpruvTvKtJLeZy8kAAABs5+YaELv7mu7eJ8kemcwG3jOTy0Xvlsllp5ckef3ovtLMX89onzXmOqrqsKraWFUbN2/evJVnAQAAcOOwkFVMu/ubST6RZP/uvnQExx8keXuS/Ua3i5LccWrYHkkuHu17rNB+nTFVtSHJzkkuX+H139bd+3b3vrvssss2Oy8AAIDtyTxXMd2lqm45tndM8htJ/n7cU7jksUk+P7ZPT3LIWJn0LpksRnNud1+S5Mqqut+4v/DpSd4/NeYZY/vgJB8b9ykCAACwlTbM8di7JTlhrER6kyQnd/cHq+qkqtonk0tBv5rk8CTp7guq6uQkX0hydZIju/uacawjkhyfZMckZ45Hkhyb5KSq2pTJzOEhczwfAACA7drcAmJ3fy7JL63Q/rQZY45KctQK7RuT3HOF9u8lefwNqxQAAIBkQfcgAgAA8ONPQAQAACCJgAgAAMAgIAIAAJBEQAQAAGAQEAEAAEgiIAIAADAIiAAAACQREAEAABgERAAAAJIIiAAAAAwCIgAAAEkERAAAAAYBEQAAgCQCIgAAAIOACAAAQBIBEQAAgEFABAAAIImACAAAwCAgAgAAkERABAAAYBAQAQAASCIgAgAAMAiIAAAAJBEQAQAAGAREAAAAkgiIAAAADAIiAAAASQREAAAABgERAACAJAIiAAAAg4AIAABAEgERAACAQUAEAAAgiYAIAADAICACAACQREAEAABgEBABAABIIiACAAAwCIgAAAAkERABAAAYBEQAAACSCIgAAAAMAiIAAABJBEQAAAAGAREAAIAkAiIAAACDgAgAAEASAREAAIBBQAQAACCJgAgAAMAgIAIAAJBEQAQAAGAQEAEAAEgiIAIAADAIiAAAACQREAEAABgERAAAAJIIiAAAAAwCIgAAAEkERAAAAAYBEQAAgCRzDIhV9dNVdW5VfbaqLqiqV4/2W1fVR6rqy+PnrabGvLSqNlXVl6rqYVPt962q88e+o6uqRvvNqurdo/2cqtpzXucDAACwvZvnDOJVSR7S3fdOsk+S/avqfklekuSj3b13ko+O56mquyc5JMk9kuyf5M1VtcM41jFJDkuy93jsP9oPTfKN7t4ryRuTvGaO5wMAALBdm1tA7Ilvj6c3HY9OckCSE0b7CUkOHNsHJHlXd1/V3V9JsinJflW1W5Kduvvs7u4kJy4bs3SsU5I8dGl2EQAAgK0z13sQq2qHqjovyWVJPtLd5yS5XXdfkiTj566j++5JLpwaftFo231sL2+/zpjuvjrJt5LcZoU6DquqjVW1cfPmzdvq9AAAALYrcw2I3X1Nd++TZI9MZgPvOaP7SjN/PaN91pjldbytu/ft7n132WWX1coGAAC4UVrIKqbd/c0kn8jk3sFLx2WjGT8vG90uSnLHqWF7JLl4tO+xQvt1xlTVhiQ7J7l8LicBAACwnZvnKqa7VNUtx/aOSX4jyd8nOT3JM0a3ZyR5/9g+PckhY2XSu2SyGM254zLUK6vqfuP+wqcvG7N0rIOTfGzcpwgAAMBW2jDHY++W5ISxEulNkpzc3R+sqrOTnFxVhyb55ySPT5LuvqCqTk7yhSRXJzmyu68ZxzoiyfFJdkxy5ngkybFJTqqqTZnMHB4yx/MBAADYrs0tIHb355L80grt/5bkoVsYc1SSo1Zo35jkR+5f7O7vZQRMAAAAbpiF3IMIAADAjz8BEQAAgCQCIgAAAIOACAAAQBIBEQAAgEFABAAAIImACAAAwCAgAgAAkERABAAAYBAQAQAASCIgAgAAMAiIAAAAJBEQAQAAGAREAAAAkgiIAAAADAIiAAAASQREAAAABgERAACAJAIiAAAAw4b1LgAAAGB7cdmffHjm/l2f95sLquT6MYMIAABAEgERAACAQUAEAAAgiYAIAADAICACAACQREAEAABgEBABAABIIiACAAAwCIgAAAAkERABAAAYBEQAAACSCIgAAAAMAiIAAABJBEQAAAAGAREAAIAkAiIAAACDgAgAAEASAREAAIBBQAQAACCJgAgAAMAgIAIAAJBEQAQAAGAQEAEAAEiSbFjvAgAAgNX9w5sunbn/5557uwVVwvbMDCIAAABJBEQAAAAGAREAAIAkAiIAAACDgAgAAEASAREAAIBBQAQAACCJgAgAAMAgIAIAAJBEQAQAAGAQEAEAAEgiIAIAADAIiAAAACQREAEAABgERAAAAJIIiAAAAAwCIgAAAEnmGBCr6o5V9fGq+mJVXVBVLxjtr6qqf6mq88bjEVNjXlpVm6rqS1X1sKn2+1bV+WPf0VVVo/1mVfXu0X5OVe05r/MBAADY3s1zBvHqJC/q7l9Icr8kR1bV3ce+N3b3PuNxRpKMfYckuUeS/ZO8uap2GP2PSXJYkr3HY//RfmiSb3T3XknemOQ1czwfAACA7drcAmJ3X9LdnxnbVyb5YpLdZww5IMm7uvuq7v5Kkk1J9quq3ZLs1N1nd3cnOTHJgVNjThjbpyR56NLsIgAAAFtnIfcgjks/fynJOaPpuVX1uao6rqpuNdp2T3Lh1LCLRtvuY3t5+3XGdPfVSb6V5DZzOAUAAIDt3twDYlXdPMmpSX6ru6/I5HLRuyXZJ8klSV6/1HWF4T2jfdaY5TUcVlUbq2rj5s2bt/IMAAAAbhzmGhCr6qaZhMM/7+73Jkl3X9rd13T3D5K8Pcl+o/tFSe44NXyPJBeP9j1WaL/OmKrakGTnJJcvr6O739bd+3b3vrvsssu2Oj0AAIDtyjxXMa0kxyb5Yne/Yap9t6luj03y+bF9epJDxsqkd8lkMZpzu/uSJFdW1f3GMZ+e5P1TY54xtg9O8rFxnyIAAABbacMcj33/JE9Lcn5VnTfaXpbkSVW1TyaXgn41yeFJ0t0XVNXJSb6QyQqoR3b3NWPcEUmOT7JjkjPHI5kE0JOqalMmM4eHzPF8AAAAtmtzC4jd/amsfI/gGTPGHJXkqBXaNya55wrt30vy+BtQJgAAAMNCVjEFAADgx5+ACAAAQBIBEQAAgEFABAAAIImACAAAwLBVAbGqblVV95pXMQAAAKyfVQNiVX2iqnaqqlsn+WySd1TVG1YbBwAAwE+Wtcwg7tzdVyR5XJJ3dPd9k/zGfMsCAABg0dYSEDdU1W5JnpDkg3OuBwAAgHWyloD4+0n+Msmm7v7bqrprki/PtywAAAAWbcMa+nygu9+z9KS7/ynJQfMrCQAAgPWwloD4+aq6NMn/SfLJJH/d3d+ab1kAAAAs2qqXmHb3XkmelOT8JI9K8tmqOm/ehQEAALBYq84gVtUeSe6f5N8nuXeSC5J8as51AQAAsGBrucT0n5P8bZI/7O7nzLkeAAAA1slaVjH9pSQnJnlyVZ1dVSdW1aFzrgsAAIAFW3UGsbs/W1X/mOQfM7nM9KlJHpjk2DnXBgAAwAKt5R7EjUluluRvMrn38IHd/bV5FwYAAMBireUexId39+a5VwIAAMC6Wss9iN+vqjdU1cbxeH1V7Tz3ygAAAFiotQTE45JcmeQJ43FFknfMsygAAAAWby2XmN6tuw+aev7qqjpvXgUBAACwPtYyg/jdqnrA0pOqun+S786vJAAAANbDWmYQj0hywtR9h99I8sy5VQQAAMC6WMv3IJ6X5N5VtdN4fsXcqwIAAGDhZl5iWlU7VNVtk2uD4feq6tlV9cWFVAcAAMDCbDEgVtUhSS5P8rmqOquqHpzkn5I8IslTFlQfAAAACzLrEtOXJ7lvd2+qqvskOTvJId39vsWUBgAAwCLNusT0+929KUm6+zNJviIcAgAAbL9mzSDuWlUvnHp+8+nn3f2G+ZUFAADAos0KiG9PcosZzwEAANiObDEgdverF1kIAAAA62vm11wAAABw4yEgAgAAkGQNAbGqdlhEIQAAAKyvtcwgbqqq11bV3edeDQAAAOtmLQHxXkn+IcmfVdWnq+qwqtppznUBAACwYKsGxO6+srvf3t2/luR3k7wyySVVdUJV7TX3CgEAAFiINd2DWFWPqar3JfnjJK9PctckH0hyxpzrAwAAYEG2+D2IU76c5ONJXtvdfzPVfkpVPXA+ZQEAALBoawmIT+/uT003VNX9u/uvu/v5c6oLAACABVvLIjVHr9D2J9u6EAAAANbXFmcQq+pXk/xakl2q6oVTu3ZK4rsRAQAAtjOzLjH9qSQ3H31uMdV+RZKD51kUAAAAi7fFgNjdZyU5q6qO7+6vje8+7O6+cnHlAQAAsChruQdxl6o6P8nnkpxfVZ+tqvvOuS4AAAAWbC2rmB6X5D939/9Jkqp6QJJ3JLnXPAsDAABgsdYyg3jlUjhMkvGVFy4zBQAA2M6sZQbx3Kp6a5J3JukkT0zyiaq6T5J092fmWB8AAAALspaAuM/4+cpl7b+WSWB8yDatCAAAgHWxakDs7gcvohAAAADW16oBsapumeTpSfac7t/dz59fWQAAACzaWi4xPSPJp5Ocn+QH8y0HAACA9bKWgPjT3f3CuVcCAADAulrL11ycVFXPrqrdqurWS4+5VwYAAMBCrWUG8ftJXpvk9zJZtTTj513nVRQAAACLt5aA+MIke3X3v867GAAAANbPWi4xvSDJ/5t3IQAAAKyvtcwgXpPkvKr6eJKrlhp9zQUAAMD2ZS0B8bTxAAAAYDu2xYBYVTt19xXdfcIK++4037IAAABYtFn3IH5iaaOqPrpsnxlFAACA7cysgFhT28u/97Cyiqq6Y1V9vKq+WFUXVNULRvutq+ojVfXl8fNWU2NeWlWbqupLVfWwqfb7VtX5Y9/RVVWj/WZV9e7Rfk5V7bmGcwYAAGAFswJib2F7pecruTrJi7r7F5LcL8mRVXX3JC9J8tHu3jvJR8fzjH2HJLlHkv2TvLmqdhjHOibJYUn2Ho/9R/uhSb7R3XsleWOS16yhLgAAAFYwa5GaXavqhZnMFi5tZzzfZbUDd/clSS4Z21dW1ReT7J7kgCQPGt1OyORS1heP9nd191VJvlJVm5LsV1VfTbJTd5+dJFV1YpIDk5w5xrxqHOuUJDyLEJcAACAASURBVG+qqurutQRYAAAApsyaQXx7klskufnU9tLzP9uaFxmXfv5SknOS3G6Ex6UQuevotnuSC6eGXTTadh/by9uvM6a7r07yrSS3WeH1D6uqjVW1cfPmzVtTOgAAwI3GFmcQu/vV2+IFqurmSU5N8lvdfcW4fXDFriuVMaN91pjrNnS/LcnbkmTfffc1uwgAALCCWTOIP6KqPrOV/W+aSTj88+5+72i+tKp2G/t3S3LZaL8oyR2nhu+R5OLRvscK7dcZU1Ubkuyc5PKtqREAAICJrQqIWcPqpdd2nEwVHpvki939hqldpyd5xth+RpL3T7UfMlYmvUsmi9GcOy5DvbKq7jeO+fRlY5aOdXCSj7n/EAAA4PqZtUjNSj60FX3vn+RpSc6vqvNG28uS/FGSk6vq0CT/nOTxSdLdF1TVyUm+kMkKqEd29zVj3BFJjk+yYyaL05w52o9NctJY0ObyTFZBBQAA4HpYU0Csqjsn2bu7X15VOybZ0N1XzhrT3Z/KlmccH7qFMUclOWqF9o1J7rlC+/cyAiYAAAA3zKqXmFbVszP5Com3jqY9kpw2z6IAAABYvLXcg3hkJpeLXpEk3f3l/PCrKQAAANhOrCUgXtXd3196MlYLtRAMAADAdmYtAfGsqnpZkh2r6j8keU+SD8y3LAAAABZtLQHxJUk2Jzk/yeFJzkjy8nkWBQAAwOKtuoppd/8gydvHAwAAgO3UqgGxqu6f5FVJ7jz6V5Lu7rvOtzQAAAAWaS3fg3hskt9O8ndJrlmlLwAAAD+h1hIQv9XdZ869EgAAANbVWgLix6vqtUnem+Sqpcbu/szcqgIAAGDh1hIQf2X83HeqrZM8ZNuXAwAAwHpZyyqmD15EIQAAAKyvVb8Hsap2rqo3VNXG8Xh9Ve28iOIAAABYnFUDYpLjklyZ5AnjcUWSd8yzKAAAABZvLfcg3q27D5p6/uqqOm9eBQEAALA+1jKD+N2qesDSk6q6f5Lvzq8kAAAA1sNaZhCPSHLCuO+wklye5JnzLAoAAIDFW8sqpucluXdV7TSeXzH3qgAAAFi4LQbEqnr6FtqTJN194pxqAgAAYB3MmkH85RXaKsmjk+yeREAEAADYjmwxIHb385a2azJt+JQkL07y6SRHzb80AAAAFmnmPYhVtSGTBWlelOScJAd395cWUBcAAAALNusexCOTvCDJR5Ps391fW1hVAAAALNysGcQ/SXJZkgck+cDS4jSZ3IfY3X2vOdcGAADAAs0KiHdZWBUAAACsu1mL1LikFAAA4EbkJutdAAAAAD8eBEQAAACSzAiIVfXR8fM1iysHAACA9TJrkZrdqurXkzymqt6Vyeql1+ruz8y1MgAAABZqVkB8RZKXJNkjyRuW7eskD5lXUQAAACzerFVMT0lySlX91+7+gwXWBAAAwDqYNYOYJOnuP6iqxyR54Gj6RHd/cL5lAQAAsGirrmJaVf89yQuSfGE8XjDaAAAA2I6sOoOY5JFJ9unuHyRJVZ2Q5P8meek8CwMAAGCx1vo9iLec2t55HoUAAACwvtYyg/jfk/zfqvp4Jl918cCYPQQAANjurGWRmndW1SeS/HImAfHF3f31eRcGAADAYq1lBjHdfUmS0+dcCwAAAOtorfcgAgAAsJ0TEAEAAEiySkCsqptU1ecXVQwAAADrZ2ZAHN99+NmqutOC6gEAAGCdrGWRmt2SXFBV5yb5zlJjdz9mblUBAACwcGsJiK+eexUAAACsu7V8D+JZVXXnJHt3919V1c8k2WH+pQEAALBIq65iWlXPTnJKkreOpt2TnDbPogAAAFi8tXzNxZFJ7p/kiiTp7i8n2XWeRQEAALB4awmIV3X395eeVNWGJD2/kgAAAFgPawmIZ1XVy5LsWFX/Icl7knxgvmUBAACwaGsJiC9JsjnJ+UkOT3JGkpfPsygAAAAWby2rmP6gqk5Ick4ml5Z+qbtdYgoAALCdWTUgVtUjk7wlyT8mqSR3qarDu/vMeRcHAADA4qwaEJO8PsmDu3tTklTV3ZJ8KImACAAAsB1Zyz2Ily2Fw+Gfklw2p3oAAABYJ1ucQayqx43NC6rqjCQnZ3IP4uOT/O0CagMAAGCBZl1i+uip7UuT/PrY3pzkVnOrCAAAgHWxxYDY3c9aZCEAAACsr7WsYnqXJM9Lsud0/+5+zPzKAgAAYNHWsorpaUmOTfKBJD+YbzkAAACsl7UExO9199FzrwQAAIB1tZavufjjqnplVf1qVd1n6bHaoKo6rqouq6rPT7W9qqr+parOG49HTO17aVVtqqovVdXDptrvW1Xnj31HV1WN9ptV1btH+zlVtedWnTkAAADXsZYZxF9M8rQkD8kPLzHt8XyW45O8KcmJy9rf2N2vm26oqrsnOSTJPZLcIclfVdXPdfc1SY5JcliSTyc5I8n+Sc5McmiSb3T3XlV1SJLXJHniGs4HAACAFawlID42yV27+/tbc+Du/uRWzOodkORd3X1Vkq9U1aYk+1XVV5Ps1N1nJ0lVnZjkwEwC4gFJXjXGn5LkTVVV3d1bUycAAAATa7nE9LNJbrkNX/O5VfW5cQnq0vcp7p7kwqk+F4223cf28vbrjOnuq5N8K8lttmGdAAAANyprCYi3S/L3VfWXVXX60uN6vt4xSe6WZJ8klyR5/WivFfr2jPZZY35EVR1WVRurauPmzZu3rmIAAIAbibVcYvrKbfVi3X3p0nZVvT3JB8fTi5LccarrHkkuHu17rNA+PeaiqtqQZOckl2/hdd+W5G1Jsu+++7oEFQAAYAWrBsTuPmtbvVhV7dbdl4ynj02ytMLp6Un+oqrekMkiNXsnObe7r6mqK6vqfknOSfL0JH8yNeYZSc5OcnCSj7n/EAAA4PpbNSBW1ZX54aWbP5Xkpkm+0907rTLunUkelOS2VXVRJjORD6qqfcbxvprk8CTp7guq6uQkX0hydZIjxwqmSXJEJiui7pjJ4jRnjvZjk5w0FrS5PJNVUAEAALie1jKDeIvp51V1YJL91jDuSSs0Hzuj/1FJjlqhfWOSe67Q/r0kj1+tDgAAANZmLYvUXEd3n5bVvwMRAACAnzBrucT0cVNPb5Jk32xhtVAAAAB+cq1lFdNHT21fncm9gwfMpRoAAADWzVruQXzWIgoBAABgfW0xIFbVK2aM6+7+gznUAwAAwDqZNYP4nRXafjbJoUluk0RABAAA2I5sMSB29+uXtqvqFklekORZSd6V5PVbGgcAAMBPppn3IFbVrZO8MMlTkpyQ5D7d/Y1FFAYAAMBizboH8bVJHpfkbUl+sbu/vbCqAAAAWLibzNj3oiR3SPLyJBdX1RXjcWVVXbGY8gAAAFiUWfcgzgqPAAAAbGeEQAAAAJIIiAAAAAwCIgAAAEkERAAAAAYBEQAAgCQCIgAAAIOACAAAQBIBEQAAgEFABAAAIImACAAAwCAgAgAAkERABAAAYBAQAQAASCIgAgAAMAiIAAAAJBEQAQAAGAREAAAAkgiIAAAADAIiAAAASQREAAAABgERAACAJAIiAAAAg4AIAABAEgERAACAQUAEAAAgiYAIAADAICACAACQREAEAABgEBABAABIIiACAAAwCIgAAAAkERABAAAYBEQAAACSCIgAAAAMAiIAAABJBEQAAAAGAREAAIAkAiIAAACDgAgAAEASAREAAIBBQAQAACCJgAgAAMAgIAIAAJBEQAQAAGAQEAEAAEgiIAIAADAIiAAAACQREAEAABgERAAAAJIIiAAAAAwCIgAAAEnmGBCr6riquqyqPj/Vduuq+khVfXn8vNXUvpdW1aaq+lJVPWyq/b5Vdf7Yd3RV1Wi/WVW9e7SfU1V7zutcAAAAbgzmOYN4fJL9l7W9JMlHu3vvJB8dz1NVd09ySJJ7jDFvrqodxphjkhyWZO/xWDrmoUm+0d17JXljktfM7UwAAABuBOYWELv7k0kuX9Z8QJITxvYJSQ6can9Xd1/V3V9JsinJflW1W5Kduvvs7u4kJy4bs3SsU5I8dGl2EQAAgK236HsQb9fdlyTJ+LnraN89yYVT/S4abbuP7eXt1xnT3Vcn+VaS28ytcgAAgO3cj8siNSvN/PWM9lljfvTgVYdV1caq2rh58+brWSIAAMD2bdEB8dJx2WjGz8tG+0VJ7jjVb48kF4/2PVZov86YqtqQZOf86CWtSZLuflt379vd++6yyy7b6FQAAAC2L4sOiKcnecbYfkaS90+1HzJWJr1LJovRnDsuQ72yqu437i98+rIxS8c6OMnHxn2KAAAAXA8b5nXgqnpnkgcluW1VXZTklUn+KMnJVXVokn9O8vgk6e4LqurkJF9IcnWSI7v7mnGoIzJZEXXHJGeOR5Icm+SkqtqUyczhIfM6FwAAgBuDuQXE7n7SFnY9dAv9j0py1ArtG5Pcc4X272UETAAAAG64H5dFagAAAFhnAiIAAABJBEQAAAAGAREAAIAkAiIAAACDgAgAAEASAREAAIBBQAQAACCJgAgAAMAgIAIAAJBEQAQAAGAQEAEAAEgiIAIAADAIiAAAACQREAEAABgERAAAAJIIiAAAAAwCIgAAAEkERAAAAAYBEQAAgCQCIgAAAIOACAAAQBIBEQAAgEFABAAAIImACAAAwCAgAgAAkERABAAAYBAQAQAASCIgAgAAMAiIAAAAJBEQAQAAGAREAAAAkgiIAAAADAIiAAAASQREAAAABgERAACAJAIiAAAAg4AIAABAEgERAACAQUAEAAAgiYAIAADAICACAACQREAEAABgEBABAABIIiACAAAwCIgAAAAkERABAAAYBEQAAACSCIgAAAAMAiIAAABJBEQAAAAGAREAAIAkAiIAAACDgAgAAEASAREAAIBBQAQAACCJgAgAAMAgIAIAAJBEQAQAAGAQEAEAAEgiIAIAADCsS0Csqq9W1flVdV5VbRxtt66qj1TVl8fPW031f2lVbaqqL1XVw6ba7zuOs6mqjq6qWo/zAQAA2B6s5wzig7t7n+7edzx/SZKPdvfeST46nqeq7p7kkCT3SLJ/kjdX1Q5jzDFJDkuy93jsv8D6AQAAtis/TpeYHpDkhLF9QpIDp9rf1d1XdfdXkmxKsl9V7ZZkp+4+u7s7yYlTYwAAANhK6xUQO8mHq+rvquqw0Xa77r4kScbPXUf77kkunBp70WjbfWwvbwcAAOB62LBOr3v/7r64qnZN8pGq+vsZfVe6r7BntP/oASYh9LAkudOd7rS1tQL/P3tnHr/bVD3+97rXPGauzGRIIkKkr6Loq1CSUCLJkOmWSqlkqChRGSqRoUgyZCrKdJGZyzVTMjWXCjeUsH5/rH3uZz/72eecvZ97/Xxvd71fr/P6fM551tn77DPsvfbea63tOI7jOI7jzBS8JDOIqvqH8PcvwLnAOsCfg9ko4e9fgvjvgCWj05cA/hCOL5E5nsvveFVdS1XXWmSRRaZnURzHcRzHcRzHcf5r+P/eQRSRuUVk3uZ/YBPgLuACYMcgtiNwfvj/AmBbEZldRJbFgtHcFMxQp4jIuiF66Q7ROY7jOI7jOI7jOE4lL4WJ6WLAuWFFilmA01X15yJyM3CmiOwMPApsDaCqd4vImcA9wHPAnqr6fEjro8ApwJzAxWFzHMdxHMdxHMdxRuD/ewdRVR8EVs8c/xvw1pZzvgx8OXP8FmDV6X2NjuM4juM4juM4MyP/l5a5cBzHcRzHcRzHcV5CvIPoOI7jOI7jOI7jAN5BdBzHcRzHcRzHcQLeQXQcx3Ecx3Ecx3EA7yA6juM4juM4juM4Ae8gOo7jOI7jOI7jOIB3EB3HcRzHcRzHcZyAdxAdx3Ecx3Ecx3EcwDuIjuM4juM4juM4TsA7iI7jOI7jOI7jOA7gHUTHcRzHcRzHcRwn4B1Ex3Ecx3Ecx3EcB/AOouM4juM4juM4jhPwDqLjOI7jOI7jOI4DeAfRcRzHcRzHcRzHCXgH0XEcx3Ecx3EcxwG8g+g4juM4juM4juMEvIPoOI7jOI7jOI7jAN5BdBzHcRzHcRzHcQLeQXQcx3Ecx3Ecx3EA7yA6juM4juM4juM4Ae8gOo7jOI7jOI7jOIB3EB3HcRzHcRzHcZyAdxAdx3Ecx3Ecx3EcwDuIjuM4juM4juM4TsA7iI7jOI7jOI7jOA7gHUTHcRzHcRzHcRwn4B1Ex3Ecx3Ecx3EcB/AOouM4juM4juM4jhPwDqLjOI7jOI7jOI4DeAfRcRzHcRzHcRzHCXgH0XEcx3Ecx3EcxwG8g+g4juM4juM4juMEvIPoOI7jOI7jOI7jAN5BdBzHcRzHcRzHcQLeQXQcx3Ecx3Ecx3EA7yA6juM4juM4juM4Ae8gOo7jOI7jOI7jOIB3EB3HcRzHcRzHcZyAdxAdx3Ecx3Ecx3EcwDuIjuM4juM4juM4TsA7iI7jOI7jOI7jOA7gHUTHcRzHcRzHcRwn4B1Ex3Ecx3Ecx3EcB/AOouM4juM4juM4jhPwDqLjOI7jOI7jOI4DeAfRcRzHcRzHcRzHCXgH0XEcx3Ecx3EcxwG8g+g4juM4juM4juMEvIPoOI7jOI7jOI7jAN5BdBzHcRzHcRzHcQLeQXQcx3Ecx3Ecx3EA7yA6juM4juM4juM4Ae8gOo7jOI7jOI7jOIB3EB3HcRzHcRzHcZyAdxAdx3Ecx3Ecx3EcwDuIjuM4juM4juM4TsA7iI7jOI7jOI7jOA7gHUTHcRzHcRzHcRwn4B1Ex3Ecx3Ecx3EcB/AOouM4juM4juM4jhPwDqLjOI7jOI7jOI4D/Bd0EEXkf0XkfhF5QEQ+81Jfj+M4juM4juM4zozKDN1BFJHxwLeATYFVgO1EZJWX9qocx3Ecx3Ecx3FmTGboDiKwDvCAqj6oqs8CZwDveomvyXEcx3Ecx3EcZ4ZkRu8gLg78Ntr/XTjmOI7jOI7jOI7jVCKq+lJfw8iIyNbA21X1I2H/g8A6qrp3IrcrsGvYXQm4P0lqYeCxwmxfDNkZJc2XOn8vk9+n6ZnmS52/l2nGyN/LNGPk72Xy+zQ903yp8/cyzRj5z+hlWlpVF8lKq+oMuwHrAb+I9vcH9h8hnVteStkZJc2XOn8vk9+n/6b8vUwzRv5ephkjfy+T36f/pvy9TDNG/v+NZWq2Gd3E9GZgBRFZVkRmA7YFLniJr8lxHMdxHMdxHGeGZJaX+gKmBVV9TkT2An4BjAdOUtW7X+LLchzHcRzHcRzHmSGZoTuIAKp6EXDRNCZz/EssO6Ok+VLn72V66dJ8qfP3Ms0Y+XuZZoz8vUwzRv4zSpovdf5ephkjfy/TjJP/jB2kxnEcx3Ecx3Ecx5l+zOg+iI7jOI7jOI7jOM50wjuIjuM4juM4juM4DuAdxCLCeou9xxzHcZwXDxH52HRIY+7pcS0vNiKyfsmxyjRnLzz2YuRd3I6KyLIlx14MXsq8nReH/ys63IxS98SIyCtf6mt4KZkebc4Ief6feE9mah9EEXkjsAxRsB5V/UFG7lZVXbPvWDj+VVX9dN+xyvwXAXbJyH64Rk5Ehq43RlVv7fpdRBYAllTVO1p+nwv4BLCUqu4iIisAK6nqTyOZY4DWl05V98mkW1T+WkRkaWAFVb1MROYEZlHVKSOks2DX76r698w544HFGCzPoy3p974nIrIYcCjwSlXdVERWAdZT1RMz6e2byeYJYJKqTk5kZwe2yuR/yChylWVaEfgUsHQit1EuzVJEZPFMmlcnMlXlCefMBqwYdu9X1f9kZJYAjgHeBLwAXANMUNXfZWRnBT4KbBAOXQUcl6Zbk2aQ3yJOU1UvHLU8Qa73u49kNwMuUtUXcmn1ISKPqupSmeNvwr7lk0N9MY+qPpTIvBH4XvhtKRFZHdhNVfeYxjKdqqof7DsWjk9Q1aP6joXjRe2OiFyuqm/tO1aZ5nRv8yrTzMlOUtXXZ2SL7n/pfarJu5bSNn96p/litaEh7Tmx7+T+zG/VbeOLQc2713L+j1V1m2nIv7juCfK99VmQq9EjimWT87J1bvitty2NZHv1rUo9plQ3mSY9oqPNKdXLa8pU9Z6UMuqzn+GjmI6KiJwKLA9MBp4PhxX4QSSzKfAOYHEROTo6fT7guZakNwbSzuCm6bGS/CPOB34JXBbJ5uiTOzL8nQNYC7gdEGA14EZMwRxARK4EtsDelcnAX0XkKlXNdTJOBiYB64X93wFnAbFSdUvH9bdRVP4wwn0QYxWBAKqqy2VkdwF2BRbEnsMSwHFATqmawnCn9gmsLJ8ALg+/S+ayFBjIX0T2Bg4E/owp9I3capm8S9+TU7D7/7mw/yvgx8BQJYQ9+7WApmPwTmxN0d1F5CxVPTySPT+UdRLw70xatXI1ZToLeyYn0P3c3wN8FVgUewbNc58vI/tVYBvgniTvtFErLk9I9y3A94GHQ/5LisiOmcbyZOB0oBm93j4c2ziT7HeAWYFvh/0PhmMfGTVNETkMWAf4YTi0j4i8UVX3H7E8Tf59333DtsBRInIOcLKq3puR6WLoGxORA7H3eaVwLbMCpwHpjNc3gLcT1spV1dtFZAPy1JTpNcn1jAfaOhM7Amln8EPxMRFZD3gjsEgymDMftpxTIzcHMBewcBi8k0huYNRfRF4OLA7MKSJrJLJz1ead0Nnm1bSjIrIydj/nD991LDtHS/6d97/0Po2St4isi9XlaZuzYka2uM0vrdMq0uxtQ0XkTroHb3Pt0+bAEcBswLIi8jrgEFXdIohMoqJtDGmWlr23vR9Rh8uxXu5ghc5RXPeU1meVekSxbO6SWq6ztC2t0bdOoVyPKW2ji/SIDrLlp1wvP4XyMtW8J0Xv3jQ9e1WdKTfgXrAZ1A6Z1bEG/ZHwt9neAyyQyH4UuBN4Crgj2h4CThsl/0h28nSWOwN4bbS/KnBKi+xt4e9HgIPD/3e0yN4SnxP+vz0jNx74WsWzKi3XfZhisiiwULO1pYk1avG13tkiezCwGzAv1rDsCnwBqxyvDDKCjaKWXOcDbdc16nsC3Jy599n7hq0bOk+0Pw/wc2BO4J5E9q7C6yySqyzTpIr7+epC2fuB2adneZprxWaYmv0Vc9efeyYdzyn37eSO1aR5BzAu2h+f+55LyxN+K/ruo9/mC9/TDcD14Xuat/A+P5ora/j+4vxzZbqx9DpLygTsD0zBFM0nwzYF+BtwWCK7HTYg8w+s8W+2icBlieybsQb9j+Fvs+2LjcA3chOw9uXfwIPh/4ewgb+9kjR3DHlNCX+b7QLgPbV5B9miNo+6dvRdmDL1t/C32Y4G3jjK/S+9TzV5R+fcC2yOdTQXa7YO2dI2v6hOK02TgjYUUzSXBg4P22vD9hXgCy3nTALmp+Pbo6JtrCx7b3tf8+715DVU75ReQ5CrqXtK67MaPaJYtqLsRW1pVKZefYs6PaZUNynSI0Yof6leWlOmmvek9N0b+dnPtDOIwF3Ay7GGMIuq3g7cLiKna4t5VcTpwMXAYcBnouNTNG9G0Zt/xE9F5B1qaz5OD7mVVfXOZkdV7wojfzlmEZFXAO9jbASkjWeD6YC1CiLLkxnZUdXnRaTGXKe0XE+o6sWFaf5bVZ8VscEhEZmF9tHT/1XVN0T7x4vIDap6iIh8FmzYRkTOpX3mIOa32MhXCaXvyVMishBj937djjyWAp6N9v8DLK2qz4hI+ryuE5HXxu9LC6VyUF6mC0VkD+Bcovco8z39Wctnoh7ERmT7ZgVrygMwq0YmVqr6KzET0ZTHRGR74EdhfztMIc3xvIgsr6q/ARCR5ciPVNakCfAyoLmH87fIlJYHCr/7KK0nwwzinMDHgC2BT4nI0ap6TMuMPZjSNGcu//D9Nfm3+W/8NpjwqJj57D6Ygj1SmVT1MOAwETlMkxnYDNdh7/vCjFlygHVoBkz2VfUq4CoROUVVH2lLUM0s9SgR2VtVj+nKXFW/D3xfRLZS1XM65IryDhS1eTXtqKqeD5wvIuup6vU9skX3v/Q+1eQd8aS2mGhnqGnzS+u00jR729DmeYvI+qoaz1Z9RkSuBXLm9c+p6hNNO9qSbk3bCOVl723va949aXfBEazNGOkaAlV1T2l9Rrke0Skr7a4/grUXOUrbUijXt2r0mM42WsbMm3v1iBHaHCjXS2vKVPOeFL97Hfl1MtP5IIrIhdiDmhd4HXATgy/NFplzik0Xg3yvva+ITKzIfwowN6bUPxvln5pclMr9CBv1PS3ci+2xGaXtMnlvDRwAXKOqewQl9WuqulVGdmPg88AqwCWYScSHVPXKjOyRwArY9P9TUfl/0lH+f2OdmYFyRRX7+7AZkZ8weE+HfCtF5HDgcWAHYG9gD2z2bKgTLCLXY1P/Z4dD7wX2VdV1RWSyqr4uyH0Lm4m9OU0jSe9EzHzkZ8l1fj2SqXpPwz04BpsNvgtYBHivZvxFReQATCk/PxzaHJtJOBI4XlU/EMneA7yKsRH45t6vFn5vzJJmwZ7ngzm5Ecv00PDdG/7uROQoTEk6L0kv9y6dg40qX57I7pPIdZY7k+5JoWynhkMfwHwsdkrklgKOxUyWFOs4TMgp4yLyVmwG48GQ/9LATqo6cRrS3A6bEZgY0twA2F9VzxilPEG25rvfAtgJMzM6Ffi+qv5FzOfvXlVdOj2nDxH5JPbubYx1Vj4MnJ52BkRkYcyU822h7JcA++QG8GrKFOSLfXEqyrUi8EmGfVyGfGek3J+9xm+nKO8gX9Lm1bgAVPnMld7/kvtUkreINPVA02ambc4dkWxxvSdjpq1vpqNOK00zUnyFjjY0Kf9kbGb1muiefbtp5xLZE7G69DPYe7UPNri0eyJX1DYG2c76fMT2vsQcdWJ6XoyqbphJ9ysl19BS90xQ1aGBvIr6rESPaMzEX9MlKyI79pT9+5nrLGpLg2yRvlWpx/TpJg/RYd7cpr+X0qeXjlimmvek890rffadZZwJO4hv7vpdbQQ1Pec+4OOYOcXzNbyAjgAAIABJREFUkWzuoe2FVUQD9r6pYtl2Hbn8pzdiPhlx8Iurge+o6r+mQ9oLAetiL/cNqvpYi9zJmcPapgD05NlVsWuLQjUO2BnYJFzrL4DvaeaDCJ3ioxhTwG/A3offA6+PGtJ7MFO8R7BOb7ZTIeZjkLvQgyOZUd7TWbCKQOgIKhJkX4/5nArW+c/6hoo5lufyf6Tr91QuyFaXqYSad6mtIUwbwL5yZ9KdHdiTsXt6NaZUlYyuthLSbZ7pfdOaXkjzFcDaIc0bVfVPLfkWl6fiu/8B9p3llPe3qurlHdf9MmBPVf1y5reNib5lVb00I7O+ql7bd2yEMn0F860c8MVJBzyCbI2/7O2Y70za7kxK5LJ+aC2K2s8Z89uJ0zwykSvKO8iWtnk17eh1mH9PKjs0+1l6/0vvU0neIvLL9DoiVFU3iGSL672WuixOtwk496LUpSHtNbGBqfmx9u4J4MMtHa+5MMuiuB39YqpLlLaNQbazPh+xvS9+92pouZbsNVSmW1KflegRWZnoOluDrkVpLJ1r90rb0iBbo28V6TGlbbSIzJF5H4eOteTR2ubUUKObVaTZ+e5Nl2c/s3UQG6Qu2uiNOmhi2JXuA8AbSioeGYzqNBcwXjNRNEVEsBH8ZVX1iyKyJPAKVb1pFLnCcowSbXRL4ApVfSLsvwx4i6qeV5t/OH9lVb1PWkw/MqN0y6nqg33HKq9hPDbL8I0C2apORWH+pRECx2PBZpZhcNT764ncOMyfYdWKayiJEFkTybG0THNhvk9Lqequ0hFJsgbpiLqXyBVFkivMcz9VPbztu4q/JxHZSFWvkMFAGbFsM5Jek2bVt1RYpuqoyCXPPtRbB2B+XedhpoxfxEafT1fVCS3XMx+D7/7fk99romhmAwO0dGzvB1Yr6byH9mFzLTChk8LImSJyL7BKTtnKyN5V8u2X5h1ki9q8ynZ0qmVGgWzR/S+9T5V5DynPHQp1jc5RNJhRUZeWRnAdh81unBm+J2na82nhRWobi9v7mncvc+7GwH6qmgskVprGstjM2TIM1lFDg0jROZ31WSQ3r/2s/+xIa2tVPavrmFiAqsWBq9WsOlbDZob/R1WX7C7h9KFUj4nkVwf+J+z+Us2kOJXprfdr2pwR9NLiMo3ynvRR8uzbmJl9EIuijQYmisjXKDBloNDeV4ajOi1OSxRNLIrhC8BG2Ev7T+Bb2CxAsZzURSkbJdrogap6bpTe42EUY6iDGEYJc0ptPOuzL3aPjkzlwrnpKN3ZQPrRnkXG90Es3P4XGTY5GRjJV/OXfBdmYtpHn+LxTVX9mIyZBw2enK8ESt/TC4F/YUEjWpcQUNUXROR2EVlKy0JcH0hZhMiaSI6lZToZG/F9Y9jPRpIUM4f7DhYcYtXQsG2hql/KlKcv6l4jV1RuETlTVd/X9m1F31TTISj5rt4MXIGZ/g4lidVDtWkWfUsV5aElraE0E0qe/Q+wJT3OAf4Xm7G/GwuslZvt3A3zj3oGe/cl5L9c+H2UyJyfiv6fA4v8OqmlTDW+ODX+sqU+uDW+baW+taV5Q7mPS007WurfA+X3f7r560Wcy3CbkzsGdTrHMZk0csf6IsjOgZnB9Ua6hantw17Amar6ZOa6COlm27AoncbEtfEDawa+FXg810mvGfAKFLf3FLx7IrIRpoM1nYRDsbpIgIEZJBHZXlVPk/ySUTnl/zwsauWFdLTPIe3O+iySWxUz018w7D8G7KCqd2eS3R+7N9lj4d5shs2uf1pEfoqZgR6KmbjG+da0Ec05RfoWhXpMSHMCZgretIenicjxGkxxpTByc6CmzanVS4vLRN17Mj8WQCxeBuuQzIBO57PvYqbrIIrIR7EXfzkRiW2A5wWypkZAM/K0VnSsTQF6ELhSRPrsfffElI4bw++/FpFF2/JX1TVF5LYg+w8xB9Zauc2wj+RwBhWg5thY4YZN7uZW1afoZlzmWNs7Fiv5c2A+cX9IrmHX8HfI9j+5tlFCo38Ti2R2Z8HI+7UiciwWmjj2l0wVm58xZvM+B7AsFumr6Tw1/lxH9OTX955elzlliVzF3MIrgLtF5CYGy5ProG4JrAHcGmT+EEYsm+vcH/gsVgk3CoVgPrDHV5Qp9+0tr6rbiPnNoRZEJ+dPcAL2Pn83yN0hIqcDQx1EzBRuHeDKIDtZ8otgd5Y7ohlZ3Czz21R0LJDF07nRvES2MQ05RIdnapeN5GrS3DX8u6lmzG1qyxPS7PwukzyaZ798wbNfUFUPCv//QkT+DKzdMUP0SeA12mICig0GzIPVRfEzfBLzJx5CVQc652GE+fCcLPA0MFlEen1xgFtE5McU+Mti0RZhsK4eUhSxwDf3hO+5058dMxn+kJh/TpdvbWneUN7m1bSjE4DPigXN6vSZo/z+l96n3rzDoNSrsTYnPn+ozamp90oHMyrS3A0LBPVKQl0WeBIbPM5xqZgfXNrexYMDvW1YILfMxTxiJswfUdWHo+NFA14jtvcl796RmOJ/PdbJvgE4QDNrlGKdbhisT7r4l6oe3S8G9NdnDcdjsRAmAogtTXQCYwOqSPkyH+8E1lDVf4WBhD9gs/K/zuRb3EZElOpbNXrMzpjO+xTYzDn27BpfzbdjSwgtAcR10RRMZ4kpbnNK9dKImjLVvCcnYYNe7wv7H8QGs98DVc++lZmug0h9tNEqRQh4NGyzha2Nmiia/wkzMk0UpEXIjy50yumY39irdNgsZuVcxqHBOhFTsPoW7rxFRL6ONTyKTZUP+ayEaxnwJRELnHNZTjb8vioWMGJqA6BjwQVWwiqrlzE46zIFG2HK8VssTHKJjXVT4cY220OKjaq+NrnmNbEGuvl9Uvhb4h9S+55eLCKbqOolBWkf3C8ylc6IaloXybG2TKXRMedS1ZuSvmNbBZiLupd7B4oiyalqMxuxh2ZMvRge3a8ZzTuH4RHysxkeIa9J87pMmlOPjVCepoO5B9b5UMx/67ikI1r17JPZjj8BczXPICP/G6yTkEXrInO28TssyECOZsmKEubDrnWT+BIZGwUfO6iaG7jIcVChHJji20tF3lDY5tW0o6paqnhD+f0/aDrm/RpMEXsZY+uPgrU5uyWyNe9+6WBGaQTZ4ki3Ec2M0Z7RsYHBAR30m5wNWDnI3K+qz0Zy2fcodOyOw2ZrGtkLw98hH7aE6va+8N1THQtCdZ6I/LWlc4iqNoORpW3pUWJWKZfQP3veWZ9FzK1RwDJVvTLTTv0B63BvwaAuNgXzyWx4pqmvw8TC/S2dw6ltRGVdWqpv1egxwmBU7+eJBiK0MHLz1MTq2pzmnC69tKGmTDXvyfI6GCzyYLEAUw2lz76VmdkHccHM4SmacR4VkS/k0tACJ8+O/GuiaH4AW3NvTWzx6vcCn8/MGnTKxaOOWCXUMC9wrapun8n7xpDOBaq6RjiW9WMJH9MBDEZg+pL2zzwiIisBP1PVV2V+OxB4C/YhXoQpOdeo6nsTueLw5CKyNmbycBWVkZ3C+Yup6p8L5HL27ytgDXtasbRG1Qqzy7FsGiFwS8wEchz9I+5p2usD71fVPTO/5SKq/Sgd5ZK8Pf4TwCOqmi6GXfTtSWEkSRG5GNgLOEttBv29wM6qOqQMS3nUvaJyR/K553yHjkVUa0bz3oeNzDfMh/lFrROd14yQpzP98wGfUtXXjJBmY25zGvB+Bs1tjlPVgQGivvIkx8/EGp3TwqHtsDXGtk5lg3xnxEsReZgx06oUTb8TMfOhkzFrjK7ItIsA+2H3Nv6WckEtYjO3cVikyIdzdeSLhYjskDueUUBq0lyqJc20Pnkx8i5uR6XCB3R6U5O3iLxJQ5CygnRrdI6lSxTwiro058/8BDaj85e+fDryfyfW0fsN9r0uiw0g94bfz9Ux4fgi2EBU2j5ulMjVtPe9756IPIjN3jUcEe9rPir2HNhMVlqnpGaZh2EzPL9hMJBTru4prc/OxWaFG8uk7YG1VPXdmTRnzb1n0e+PM7jA/QbxvuYDbq2Lzda9GhvYGA88ldM5SvWtGj1GbIZ9R8ykG+DdWKTcb2Zk38nwM4qf/cNUtDnhnFK9tKZMNe/J9Zg+0ARJXB84QlXXS+Q6n30XM+MMYsOtwJLYwsWCjUb9UUT+Auyig9Ha4g7OHNjoVdaPRCyyUM4uO33An8EqljuxEceLgO/l0lTVH4rIJMw/UYB3a8aPpUCuevY0pPvbZMYltxYboSP4mdxvKTK87syfyPtigHVQV8cWD91JRBYjf69uE5E96amsA1/GfDTnoHumN77m+bFOxfuxSnHx5PfYJGgc1lH/ayapkzHb8W8AG2Jh/3MVE2I+c1/HTIT+gtnw30vi84eZx6xHmcksYr5378c6Fw9hs1VDqOoRoaP2JDZy+wXNRFTD/F/XxNZ0E2yB5duBhURk92T0rOjbU9VLReRWxiJJTiD/rPbEzG1WFpHfh/J8ICMHNhjzOayROp0QdW/Ucku5qVfNaF7pCHlNmkXmNhXlGbheVV092p8oZkI2hLREvASmdjxVdZmWfNr4Luaz2efj8UOsI70ZsDumXOS+Txg0c3sOGxxoi3bahFMfoEWpKPG9boh9zOfA6vVbMX+ZOM24Lp0N88fLKmr0m8FX5R3yL23zittRKnxAS+9/xX2q8T/dKtP5egK4RVV/lhyv0TmOlWC9kKYLfFfHZudL09wZax+aGae3YCaUK4rIIaradDIQW+80jnJ+Zcgzp2QeCWyoqg+Ec5fH3rHODqKIzEPeJQXGvtN30v2d1rT3Je/eVQzWt/F+dpYf65zdh9Wvh2DtTu6d3hJYTqPZ1Q5K67MPY9ZAP4GpkaZ3apFdJnQ+2gal35XId/mXNxyLRQ8+CzPd3QFbdiJHqb5VrMeo6tdF5ErGIm3vpKq3pXIichzmc7ghpje+F1sWJk5rma68WijVS2t0s5r35KPYDOn8WPn/jrXxKX3Pvh1VnSk3bNTr7dH+JpjitC4W+r3r3Nmx0MO5314fbeuHNA8f8RoX7Npq5Ua8hrMxE8tbsQ/7k8AZLbKLAF/DOrtXNNuI+b4m+v+m8HcSNuMhwN2Zc87ClP3fYI3KJcBRLenfUngdc2KzsudjZhKPY43ruIzsgdH2OayxmCMjNyn8vTM69suW/G8HFsIqIbBK7viM3C9y15TIrAh8AWvArsE6S4+M8GyuzRw7I3lmq2Ad4eWAyYnstHx7j3b8Njcwb/h/q4ryHDEN5Z4fizj2I6zz3mzZ7w6brSy9rvUK5WrS7LwvteUJ55wCrBvtvwFbEiMn+wCwUM81rJlsawBLdshfV1j25ru7Izp2Vem960h3oWhbHPP5OqTt/kfbB7D69ejCfObHLDn65N4NHFqY5pqY8j9y3ozY5tHRjmZkl8Q66dN0/0e5Tz15n4ANnHw8bL/EAmb9DDgykS2u97BllU7HOiibYzMQR2DuG6fWpokFvVgs2l8M61gsiJn+xXl/D7NA2ihsJ2NLEuTKf3WyL/ExLKBHun0Ra9d2aUmz6Dulor2flnevJ53b4mvFBh2GdB6sw7toYZpF9VnldV6DDfLcgdXnBwEHT2Oat2SeU/baKde3SvSY+cLfIn03ejbN33mASxKZqjYnnFOql/aWaZT3JL4fzT2Z3s9+Zp5BXEsjszJVvUREDlXVfcXWAOtiLvLO+ujwOlHXikhsr18TSTTn4N3sa3QNpXKjsDvWWC2O+eFcwqBvQkzNCH0fpzLmK3WL2JIZJ2Bl/SfJCFDgVaq6tYi8S1W/Lxao5Bct6V8mPXbhIvJDbBT1Emy07ArgAW1ZLFt7/BFE5BhV3Rv4l1g48V+HGZXfY+ui5fiPqv5NRMaJyDhVnSjmC5byRyxQxMW0m3Dchykwm+vYiG+RLXpCzkxtZY2ip6nqPSKyhqo+KMNxZabl28vOtIZ04lHib9AyK5rhfQyaFrUxVG61iGFPEBbMljFT4HlEZB4djhRbM5pXOkJenKaqntNlblNTnqgumxXYQUQeDftLY2vS5SiJeJkbvV5QzNdpO1WdnPw2UUR2xZTgroibzQzIH8M9+AM2ozqVjvq5dd02HV7e4Zsicg02GJPKVvleJzyNmT13oqrniUiRJYeq3hrMv0bOu6/N66C1Hc3Q6gNac/+T80rvU5f/6fLYUk7/ARALZvZzbEbpduATkWxNvbeGRmspYlFlr1bVDUQkjlJZmuYyOugS8RdgRVX9u4ikM4Nr66BFwBWpRUA0a3q3iFwEnIl9N1sDN0eiqT+nYtZC22t7JN3e7zRQ096nDL17MhyRVIHHMLPBh3qu9XExf7Q/YQNsKYsB94nIzfQHkuqsz2S0aOhzqurlIiJqpssHia3leWBIM633mrJPxAZQc2sGPh3q5MliLlN/ZCx4T0qvvhUo0WNOx3TMRu9taNN3n4mu95XA3zDLiZjaNgfK9dKSMjX0vifSEkG30bMy6XY++y5m5g7i30Xk09jMB9gs0T/E/GMGpvWTj2c8NlOW9T+UQZ+Acdio6sujY8WRn7QwUECp3Ij8U1XbzPVSFlLVE0Vkgo4FhihRFHLEzsZNQJzjxBZ6nk9V78icU1pZg3Vy95PuKHmrYqY792KLlD+fMfupoVki4WNYA7UPNgK6EWNRA1MeD+Y4vwR+GEyHcgFYHgpbV6CIrTCTkInhPp5BR4erg9w9uF9EvsPg9/SroKSkCkjxt1eYd46acpXKtuYt5abAJ1NoXky5+VJxmiXmNhXlKa7LosasN+KltgSUEJG1gKMZM31reH/4GwdJyikKXwrmOJ/AfGfmY9gUtyYyX3NdsR/VOMzcqjTIygrkB1xIFMDxmFn7mRm52MSxyT/7rkqhGXxp3kG2r81r5Gra0ZwPaJvZctH9L71PNXkTwugzVsfNCSyuqs+FtiWmpt5bRKKliMR8RxcOv8XmZ6Vp/lJs6YImbsFWwNVicQMeT/J+XkSWV9XfhLyXY9itJDbF/DO2NA/Yu7RA84OqHhyu5SuqGpvudlHynUJFe1/47uW+2WWAz4nIQap6Rub348WCmxyABUqah/zARK8yHtFXnxVHQ4/oG5TO1XsLYnrJMeSD/3wQu5d7Yc9nSey9ylGib0GBHqOqm4W/pXrvT0NH7muYJZxinbo4zdo2p0YvLdHNGkrek+oIuj3PvpWZOUjNwtjDaOyXr8HsuZ/AFtF+IJJdOjr1OWwtq2yURBnzh5Ag+xBm7lLkyN5xvYsztoYM0Oo0XyRXke8DWAPwS8zG/VptWThXRG5Q1XVF5BfYR/UH4GxVXX6EfNOFTFdjePHQnyTnfASbNVoNU5rnwcJUf7c2/yjNlbEKextMUV6ZlvXYCtLKOuX3nDM3toaOYB2E+YEfZkbNa9N8NzZLtBFmTnRuPLonLYu0h+s4TlUXSdKck7FIls339O1w7XNptIhv37eH+Rq2zeLsmGlUcmV8VFWXivZzwRyaNG9X1SWCXFW5o/Rvx+7lZaq6hohsiI087prITVLV14vInRqi3orIL1X1fzJp3hbSukNVVxPzDfqFDgdrqEmzSav5Ow/wE1XdJJErKk9yTmsgJTGH/la0MBrgKN9QT3oly/f0pTEx2n0OeBgbdb8/I9v4wTWj3X8C9k9nFoPsm6Pd5zBz8N9l5E7O5H+CZoKPJM+hkT0nnSEozTvIFrV5le3ojonsw9ruA1p0/0vvU2Xeu2G+85dj5X8LpoieBnxRVfeNZGt0jncwHPxlD8wfcBcNgThK0xSbXtgKG6Rs5M7RjAIoIm/F2s8Hg+zSmH/XxFS2FBG5XFVzazyPTE17X/PuZc5dEKsHp1u9M70JndQlWzooiFkJ3Iv5qH4R63R/TVVvKEj7Ng0BCv8vIRaUZbKqPiUi22ODXd/UjvWdw4D1HG06bMs5rW1OiV76UpN59vNjLgD9z35m7SDWIra8Q6NwXd32IVak9x7gq1hPXmgfUUHMpHAbzGyrGcnT1JSgVG6Ea10KK/v6WNTEx1X1dRm5zbCO5JKMjfwdrKqlIeDjtKZ+lCJyEtYI3M1gZKecM3pNHgtgI/ixUtvamQ6jSdthZjS/U9U3tsm2nH+rWpTNtTAfxbQjn10rRywC5TqYEnZzrnMqFREak/MWDOXZJpZNlKkhVLXNGX6aSRS0XN7fD3Jd5oArqupUE6tEic2luWyQG6ncInKLqq4VOlZrqC04fZNGkUSD3LXYt3Q2ZrL8e2x0faVMmjep6joicjWmHP4J83tITaNq0rxRVd8gIjdgYfr/hvkgrZDIFZUnyG6BmegMzDZqiLY6vRALAnCRqg4thC094cbDwNkrMD+UZ0Nn9mNYVNyhBcOlIkLfi0koc2MCelOu0zdiuvNideg/O2Sme9417aiYedeKYfd+HTES3yjU5C0iS2B+t4L5/f12Ol3D7NiApGAWLDkzvxeFkPdKUd7ZNUilPIrnkVhbexaDayvmIoMui/nHL8Ng+ziteszIOlxbJ0lsZmqHzLWmEUer6pO++izIXIkFKJsFW+D+r5ivZmp6uAhWJz+gqulscS8icrsOmhw3xzfDOhyNHtMZOb1E36rRY8SCqK2O6YanYsuxvUdV35zIpcswXQN8p+R76mlzivTSyjLVRIY9HFvr+RnMrH114GOqeloqG+TnC9c3pafYU5lpTUzFFrr9JMMfdu6hTcCm2JvK7Icicrxm1hWS8ghgh2O+YG1R3GLejUUKbFsoulaumND4rY9VrKtjH0N2NlRVfxr+fQIzYZsWYjOadVV1lb4TRGQhzAF3fZi6HtsXNTPbFkYfJ2C+DZMxp/7ryUfJW19Vr1XVWzC7808xvNBqCU3n5IdYpLy+KGXNdX4BU/wFOEYs6txJiWix/6eInKqqH4Spfg3fFZE3xTK1HcAwmncQw53eXCTHzm9PzZ+kxCzpxTDXHrXj25gCX023KXCNeXFjvvR5us2XatLMmdvkIq+VloeQ57oks405Qcn7zQxEZ5RBE7+GBbFgWROS482s2FtIwo0TIm6KyMewAZkHgNlF5CjMfPYHDK8p2VAcoU/MHO5Axur8q7AZtDZLiy0i2SujejOVex/2nK5k7Nv/lKqencgtgSkVTb13DTBB87ONq2LK1IJh/zFsVv6uUfIOskVtXmU7+hbMsuHhkP+SIrJjbgCv9P6X3qeavAPPYb61swTZJVX1usx1FuscgddHsquJSK6TUJRmyYB0GAy6BlsX9drCDlSpGfyC2GBUfF1KPjLoeZiyfyEd7WNle1/87mXO3QhzNclxERYNtq8tz9UnWZ/evvosYn5VfTLoCCer6oEyGHm60R8OxWailxWRXXMD9pJfpmoBbOmMtvf+m9ggY290zgp9qyaOxXOqqiLyLiw40Yktg8s/wKJ1N896O+y9nboMU22bEyjSS6krU/F7AmyiqvuJLaPxO6w8ExlbbgqYOrFxMsEkVUSeAD6sw77jw+h0jpY0o2yYT8FHsZmZqVHYWmTvwBYlbfbnJorclMgWRQAjExGx41ovBuaZXnKV9+kFbD2edxXILodV6o9hMwnnYyF7Y5k0WtTA1pLuidi6bn35X4r5Aiwbts9jSmtO9k5sNGdy2F8Z+HGL7K0lxwqu70Ph7zUV59xPFPURi9R3f0auOEJjeu3YKNXdybFc9LmpWybN+7CGbFGiqIIt+Rd9e1REwMU6pm8L/89JiGaakbu88Fiu3DsDr2tJd27MX2kWrAHYp638uWuvfZemR5pYJL/5p7U8jEWzu50QrY0Q4S0j2xudMeQXbztgIe+z0d3CtzwOMxUGc/S/MPr9HkJ0O8yE+VmiqKs9ZSqJ0HcOZta3XNgOxMx2c7JfwcwRPxy2S4HDOr6TRaP9RZoyJnKXYn6ns4TtQ8ClLWlehy1L0Oy/JVeu0rzDb6VtXk07Ogkb7Gz2VyTUcaPe/9L7VJn3ocCjWHCUi8N2UcfzLNU5Tg3P6tuYYnsMmWi3pWligyOv7nnnVwV2xaIS/wqzRDgL8y97Q8s5RVE8azZ6Ilknz7O0ve9997B65I5k+x3mo71yS7pFegB19UlnfZbIvQILord2mn7YvwtYJPy/HHB9S54Tk+2K8Oz3pCVKdpArjc5ZpG9Rp8dchflp/grzeR5PFBk+/kb6jlHZ5oRzSvXSmjLVvCd3h78nAP/bUdY7gP+J9t+Uvidt20w7g4iNPnynUFYYdNJ+nhZTNQoigAVuEZEfY6NlcbCG3Ija01ikqMvpWDi1Qq6GNbAX6v1iEd9+jb3cJ2ZkT8cUvS3D/rZYuPw3RDJd6+so+bWmvg9cLyJ/wsrVFlFwQVWN17T7kogMLRob+JfabAUiMruq3iciAyZ5IrIeNoK0iAwGd5gPq4wauWw0samFCqYxqnpKOHSgiHwPUxT7nv3vsNGvhinYaHVKSYTG/bGZzzlF5EnG3uFnSZy2KXeAbnhCCxZHDpR+e7eJyAX0mCWJyC6YYrMgFlVwCcx/562RzByYUrBwmJVryj4fZhqZslbYLgz778Si8+0uImep6uGxsI75sb2ArU00Hnv/fxhdw3pYUIurVfUvYv4Ln8Fm55dMyjQeW2z+sbA/G9Zw7auqrx4lzRRV/beIbCAi+6nqxrXliaiZbeyNzqjBhLiCZ9RMYJ8LZjR/YTBAzb80RABU1UdF5Ffa739RE6FveVWNgzMcLCK5qHdgJvqvU9UXAETk+8BtDAakaBing2adfyO/dtwiqnpytH9KmDXNMbdGvmSqeqWYT/KoeUN5m1fTjs6qkQ+hqv4qzFTmKL3/pfepJu+tMHP2EvPPGp1jLUz5bG1XKtP8s/ZYK6nNIt+FrSmLmH/jtpiFwhFEbV5EUaAYKTRFDRwVZtEuYbB9vDWRq2nvS9691CJFgb9p4qMsIguoajOjeGpof35KdwTlmvqkrz5rOAQbmLhGVW8WCyb060TmWVX9a7imB6UlSri2BGlJCTPpTf28H3CRWCDCvuicvfpWoDSCLZg71fuOrCBtAAAgAElEQVSBnVX1T2KuUF/LyN0mIus2db6IvIFkTd/SNkdEzonqmlK9tKZMNe/JhSJyH2ZiuoeYKWuuHpqiqr9sdlT1GjFf+F5m5g7ihSKyB3Au3R822IjojSJybth/NzZ6kKMkAhiYYvo0tm7R1OzJm1xcELY+SuWKUdXbReQ3mInC/2AmBxuQL79otOAucJpY1KQ4vVFMT0/CImb1mXFMFJFtGYu2915sPaocvxMztTsPuFRE/oF9uDGzYWZ9szDYYXoypN3QRBN7DzaS1Uzxb4eZKaXshI2gzcrgYuG5Z/977N07P8i8C7ip6bBGlXFv5DdVPQw4TEQOU9WcQhrLHhw6Bfuo6je6ZAMTReRroQxdjTqUf3ulZkl7YiPoN4Z0fi3mYxazG6bovBKbIWiUgyexQY2UhbAZ7X/CVLOfs7F3fxJmIt7Y9e+JddIuwEa198RMiCcTOlTh3mwWjn1aLKLgHtgMROqzsC22WPJTIvJrzIzqVKyD+oFIribNjbBO8yuxd/5QzPRGsEWMG7mi8iS8C2ukPs5YIKW2oDOl0RlzZstNA5wqS33hxpcQkaOj/UXj/ZYBtA9iHaKSCH3PiMibNARlCdf9TIssWLCA5l2fv0Pu52IBv34U9rchvwD5Y2JBGhq57bDvJseDInIAY5EQt8eCyoyaN5S3eTXt6C0icmJynW0mUaX3v/Q+1eT9EO0d55QaneMurC3543RKs3dAOtT3a2CDoutjg22/x2aIr2/JvzSKZ6kpKsBrse9vIwbbx3TwuKa973331JYAKOFyxpbgehbrlHyOsUFiZbhDV1OfFC2foKpnMRaVFlV9MJNmWvctUVD3dTEB6xiBtRv/xDr8fdE5S/QtKI9gi1oshjj69aMMm+GCTVA0yzCBWZHcKyGGQaZD10X8XEv10uIyUfGeqOpnxOKOPKkWYf8prC1OuUlEvovVe4rV5VdKMCtu0dEAZt4gNWJBK1JyykcjvyZjkcKuVtXbWuSmewSwkO6cWFSyoch4o8hV5HsLZop2HWYHf3VbRSoiX8FCZp/B2Is4O0EBV1tzqS1KJEEm57R+hfYEWwlyU7DRlkY5Gc/YzJNqu/P0mzFF7eeq+mzm96VV9RHpiXgoYSak4NjUaJMFZTqw63ctjP6YpDkOG3lbVlW/KCJLAq9Q1dxyBxNLOvUyGEkwurysT2/Vt1eQdxN4pYn6OQtm+jNU8YvI3lrmd3IvsHrzPoSR18mq+mqJAhaEjvs/MAXqrZjfxmyYb9PkKL17sA7nv4JC9QdgNVVNR3wRkbuAd6vqA6HeuR7YVlXPTeRq0rwNa3Cux0yBf4BF/DsqkSsqT3LOV1X1033HwvGi6IxB9r5wzZOIOhzaEcFXRJYhCTcuhUGPguwnMdOn4kAjYsEvfsBYZ+8fmDn50CyaiGyHmZlOxMq/ARbFNBdCv/Edi9udczMyS2G+K+th9e512PMaqqfDe3JwSBNs1vfgaEakKu8gV9zmVbSjs2MDE43sVVhgiSH/+tL7X3qfKvM+CwtUcRmDHa90Tb2qei/Up6/DOgat6+aVpin54Fuq0QxeUDDvxdrrK7V97b9qpDAic5C9D6vHhtriRK6qvS9990rLEv7/DWZ++9goaRXktQwtyyeIzRjtwrD/afxMi+u+wuuJy36Lqq5Vc344r1PfqkinKNCjDEawHaJiYAAZDJ5YpJe+mIjIGxl+/qmfclffI6ujTT13Zu0g1iAWWehuDdF/xCLAraKqN7bI90YAE3Mu/w6wmKquKmYatoWqfikjuzk2SzWbqi4rIq/DnPDTxqJIrrLsi2gwUSiQ7WpQVFWXixqqRbGRyivC/oZYozTUgRSRb2Oj7unCsVXhhEXkNRot5h5GTBdj8OMaCpEsZsZ3IubfuVRQSHbTsXVwGrl7gXeGkTzEorFdpJFJYDh+AvANVW1bTLymTMeo6t4ljUV0znewEa+NQodnAeASVR1aMFtEvoxV5j9m0MyzddRpWhEzeTxc8o7jQ6OeYqYYj2N+A3tjHY57VPVzmbS/CBykqs+H/fkwB/edErkDMFPp88OhzbER8iOB4zWsDSqDS0uMx/xvl9IkUpiEpSii/cmaiQQcfkuXeLlPVVfOyE1Lmr/RzPIzpeXpSjscuyPXQQ+/FUVnbDr+Hflm1w9sSL9lEVlVk2AsmTS/gc1EPISNuJ5VqvyFdwlVfbJH7hVYdNAm6uWfkt9fhbUL1ybHNwB+r2GmrgYxE79507pcLErfE80zGDXvwjavtx0N9dgiad0oZr745662qPT+d5xfnbeI7JxLS/MuGDXX8uaWdK+alnR78twO6zy/Hut03YwNFF2vqr9PZLOLdUfX+fVEvigic5D9MbC3TmPUXBF5DRa8a2FN3B/EAkX9XksCdQynG3cSLsAG755ukZ1Iu/uJarT0xwj12XVYYJ50AO2cRK52HcpWkrJ/BfM3vaTntPg6svqWiORmnSOxAVPiJr0H6An0KDYYfoeqrlpyjX0k5e/US0csU02wv1OxWf7JDK5asE8kMw54r6pm17DtY6Y1MRWRubDAE0up6q4isgLmmJ6LKPcdxkwKwBTl9FiT7p7YOnV3hP0FRGRnVf12InoCZrb1XQBVvUNETsfC1qYchJnQXRlkJ4fOx6hyNTwrIl+nIEKfFkSKbBRxMXO4VVT1j2H/FeRN/cCCjvybMnPcLk4lPDMR2RsLZvBnBs1YckrtNzHTmAtCGW4PClPKx7Gp+wfD/jKYaWPKm4AdQ4e6y3a9hPXD3/OxxuIy8uZdMW9QW27jNizjf4jZvedolvJoZiqFjLlPUDQPBV6pqpuKyCrAejlFqeDbayr8W3rK0fAZzL/lTux+X0Q+MifYKPNNIrITZsLVBIAYQG1m9SLGRpx3V4tiC5GZJ2P+BaiZeTzU0plaPigTDcvE+8kgzqKJ4jVPvB8pXzVpvkwGZ+8l3o8GW0rLg4h8FFP2lpPB6Hnzkvh4iMhGqnqFDFsQLCcWnTH3LfeZLf8MhpYuUSygyqIM+0wdF97zU4DTNRPyXVU/Hu71Bpj/1QFi/nQ/wtYKnXovgtwTzTvedExC3TJeB2dD34510M4Odd4F4fgHROQvqnppdBnfJB8l+enw2+bh3MOBB1X1uFhIRD4OvFwHZ3CPxkKhp/f5bdg7/tGavEM+22ODzKeGDmHT5u0iIk+p6ulJGiXt6DHhWMri4bqaRcSL73/FfSrOu0EtcuJsJOsY5qjROVT1KrGZjxVU9bJw7pAPYGmaUjAgrao/IpjfhnTXwdqXw0RkNlWNZ2JqF+suNUUF60TcJyI30zF7WsCpmAvBhzK/3YP5Wk7rDNDzmL/YRPJxHz6ZOWddzH8v7QDX1mdzacZKIyXU423RmmuJr21PYD8ReZaxdkM1vyRDn76Vs8yaG2vXF8IiZaeU+NW+ICK3S+TWMI3E5e/TS0cp04lkrGZa6PVTDuXfizEz7Cpm2hnEMEo1CdghVJhzYiNlufX9hkbmpWWEvEV2aA0dEblZVdeWwSn77AyAJCZ0bfmXytUgIudg/hCNKcIHMdO73EzfeCyYxzIMjn4MOS2LyF3xqM70HunJkdyXB7COUu+C8y33tW1toGZ2BNpH0rMmD1ph6hCl1ayt2Dp7lDnnRqzjd3M4dxFsBjG3zlPOxFVV9ZBE7mLMzOxzqrq6mJnnbZoxpa359l4MRORt2KjfP4ANUsWu5l0UkecZawgEazSehkFzF2mZEWjQaGag5Z7HsgePkGbOxCwStZnm0vIE2fkxE9TDsE56wxRNfKBE5GC1MOy9pm7ROcVmy0F+GWzR8rdhER9zyyesgPlnbo2Z752iHSPgoU57G2YWupKqzhX9dhdm4pv6Ts6OfVurRcduwEa70xm8l2Mdz/XidNvePRmc4b0HWFVDwJtIZuj9FZF7tCUku4jcrWHNytK8w/5t2PeTzpbPB0zUZO2wknY0vpZM/mmbUXT/S+9TTd7R8XdiflCx1c6BqrplRrZG55gaeEtVlw/v7XGaLDZfmqZYIJFPYcuPNG3YUJnEAha9gTE/xLWxoGjXqupeiWyNj3oxbfWaVs6ehvdzllwbFH7PtuEl6Ub3MGvCqRnTzVCuAzC3m0O1J6hbX30mIl/CIlxeVHDNRetQisiympgWx8dE5Nj0PSihUt+aF/N13Bnr2BypmdlkseWKXk5PoEcRuQJ7j29isOxDAw5iaztelNYV0e+bdLUX06FMnVYziexZ2PfX6acsZg31DMNWYDnf5wFm2hlELPLZNmJmFajqMyLSFlHtQRHZh7HRxT0wf4sc40REml59qERzszOPicjyBPMDEXkv7Q7pd4nI+4HxoaHYB/OfGFWuhpoIfRdiUZR61/fDZtqaIAiKjdZnbaWlYp2vHuLRkN9i66+V8FsxW28VGy3eh8jBXtr9KpeXzOyImj9jvGjvLzXjr1TJT0XkHSWNBTabcC42U/VlzKTu8y2y8ULac2BBUXKjdgur6plikVJR1edCZyNH77cXGt4JmNkaIc+jNbGvD7LFC/aKzfwehQVKeC1wrIh8WFWnOsxrxaijquYi++XkipUbLfQrrUyzaH3H0vIE2SeAJ0QkHcWeR0Tmie+dqh5Ycx1BtjSy3gpYkIg3YCbA+2jLwuZqAYw+j81OHw2sEd69z2YUi9di9dI2WDCTdGZN085JOPjvTFsyV9o5DLJ/kuEoonOkchFzJvkP1bPh/U3zb2vbYDDISmneYLN0Q7PLamuz5aJ+lrSjbdFCc7+V3v/S+1STd8Mh2Hs3MaQ5WcxMN0eNzlESeKsmzblU9abkp4FIw6FDtRRjpqVHAjdoCNSVojYztQXQ20EMnfatGB48PiSVVZs9XQxT6sFMUUcxN1WG39mYtuiQiK0LvIKqniw2gDpP1HGa2klXW7N3NmwpFLAlqNL1P9+OdQz/BXxZe+JRVNRnE4DPis3gPUtHu0d5wLdzGLaMO5uwXmxmkKBoTVcK9C0RWRCbDf8ANiGxpmZ8oyNKAz3WxGnYFouiew62tuSArhN3Dkv00hHKVBPsb2HgHhHp9FNmLGDdnnFRyEfGHWBm7iA+G0bbmg7a8kQ3OWF3TJn4fJC/HBvdy/EL4EwROS7I7o6Z9qTsiZk4rCwiv8d8XrZvSXNvrML4N7aUxCXkp6dL5WqoidC3hBbOVqrqXqFj1XSSjteWIAjYzNTpjC1sun04tnGLfAkPYp3Un9Efonl3rFOxOLbsxCUMfmybM2ga0nREG3PMVPFMF+09TQoX7c3Q5FncWKjqD0VkEtbQCRYQJWuqoaoDy5KIyBHkI+U+JbZwcfM9rUt7g9D57YnIDljE0X2xxdwFa7S+JpnFoqlYsBfz0d1ag59ReAevYGzWt+EVwN2h8o0DHwxECQsNQCvNKJ2EiGkdcjlrhE6/0hHTLFbUpNBHl0HTqDmAZbH1O6fOxojIN1X1Y+H/CRoFxxGRU1T1Q9F+kX+TmG/Y50I+h2PhzlvNcsTM6nbCrBwuxWb0bhWRV2IK8U+CcrYtFuHyeSzg1iYa/IozaS6mqn9Oj2VE5xCRWVQ1VcpnZViJvVlEdlHVExLZnRmMpvm0iKygSVCiUIa0jv6LiKyjSSAqEVmbwUWbS/MGmFUygbvERstzg6Il7eivcwNdIrIpmUHZwvtfep+q8g78R1UfTzpebd9kjc7xb1V9tklXzCIjl25pmiUD0jtSVofGXCcix9Lvo34+1h5Marm+qYjI+7DIoFdidcoxIvIpVT274roaLguDoJ+PyyUiBzMW/yDN/0DMfG8lTM+YFYtMvj4MzryIyFswxf/hcK1Lii0FcXX4/WbMRPRrhEiwEi1KH9+n2vpMVYuXouobmBORlUO+88vggPd8tAwaifkgrs1YZOsJQVf8TEa8U98KnaL3YDrxa9sGJWrKFMldJQXm2kF2ezELiO2Ak0VEsXfgR5nBsE69dJQyMbYkXBz8JxfBF8ylrBctcP1qY2Y2Md0Ya6hWwRT+9bHIZ1eOkNb+aksINGYru2JmARLS/l76oYutBfNvsdHjcao6RUQW1My0r4gso6oPJ8fWVtWbR5GrLNvrsAowjhC3o+ajan0VW3S8egq+5xpypknFJpXROTeo6rrh/6wZn44WFfQTcRIkHcW00ynmr7Veo1iFd+D60s51ktaHdGx9xdJzcp2aKS2jlOm5C2Ajuiskx9fERtNWJSzOizlH596Tzm9PzBxv28y7vAxwRvMMo+MTgbfmZgkyeY/PfIsLaWL6IoNmToL5aW2niQmamB9p6jfSoBqcy2WESGrSE4RgxDR/zpiiFqeZDgRkfUZK3tHwLuymqrtFx2Ln/jRgTrq/m6p+t+8bFZuh/i3WQR1SpHQ4mNHVmO/32ar6TPLbB1X1VDH/4R9h79mdPeXcAbMm+AQ2kAE20n448C0djI76FayzvVfy3R8NPKaRL1Ho4JyLDfQ0nbK1sE7XlhqC2oSOyzGY33ostz/wsbijIyLrYKZNpySyO2Df2o01eQfZT2KDTB9tvtXwjTZRMHNrkrUiZn1wDram3HVJ/usBm6nqryL5ovtfep/E/PSK8o6u4WRs+Y/PYUsnTMBm64YGkGt0DikMvFWaptjSI8djpqP/wAakP9BSR9T4kxeZgUuH6XImzduBjTXMGooNlF2mkTmoWM95Ce2INhzakbdi/ujrYME8AFbHLAg+klPaxSyk1sAiYXe66ogNtL5fQ9T48A79SIN5tYhcSfuAwcB9GqE+E2xmqiQaeacPqoi8C3t/t2BwAHgKVhcOWaIFPSZe03U85laSu099dfkLWMfxOQbvV5c1UFGgRyk0107OWRjr8H0Ms156FYmZb59eOkqZasl1fNOOrNTFWxlEVWfaDXMUfSdmNrfwNKRza4XsOeHvzzD7+Ob4y4FJbekDi0f7G2AjfSPJVZZtfPg7HxZuuUt2S2wU8RnMOXwKtkZLLDMl/JZuQ7LROZdhH+v4sG2PdUSb39fs2nquee6Ce3B0Zvsi8K7w+4FhOx1bqPYIzDTkV9jgQJrencAc0f4c6XPCzHUvaNsyaUq4LweE/SWBdVrK8zDWAD2GmZ08j82M3gq8PnOtd4Ttbsyxfq+WdGfBRiFXxRabLv72MGWk+e2ejvOGfsNGMX+OKXz7Nlsi883o/wnJb6e05PU6TNl8GDMh27tFTrDKt/dbwhSd0m9v8ouQ5l2Fcg8AC5Wmmzn/1mT/ttz/OdmKPHbs2jLyH8scm9CR/tLA28L/c2JBZlKZTbHAXX8L39NVwKYZuVkwP8bHsM7HJGzm7itt3woW2XnvsG3UIrMqNoDXpPl9bLQ6J7soZm51TtgOARYdNe8gtzvwSFT+R7AO48jvDOajtRNWhx6JmUjN0XJO6f0vuk81eQf5ubFQ+7eF7SvAnB3yrfVeIjcOsx44CzPx22Va04yud97w/1YtMhcD7wNuj97dadUjmlmUEtm0LRyXy58WfaklzeUwS5/NgeUyv78m+v+m5H2cG/NVzaU7dLxNtuAaa+uz72CDMfeG/QUw39tc2ldhneS4Hh5qC7CBgNLrvQPrdDX7C3bcp1Wn5f2ZxjJNxga4Yrns+xzej3ND2T5FqB+xaLiPJLKdeumIZVoMC1RzcdhfBZtJzsnugpmD/ybsr5DLH5vd36+5N1hb1qtbqOrM10FkGjoTHWneVisbHu554cVaJryQm7Scs3Z4EV4OvCO88EuOKldZtkexyv2thBnnDtkHsahUnXIjXMNSWMfor1gH5Txg6ej3iR3bFS1prodFMns07K8OfLtF9nhsvbBGYboSq5gvYLDjcQmREolFePt5Jr19gdsxE4GDwnP6WCLz5rAdFT7wpnE7HXNwT9OsaSyOA94e7W+CBVpYFwu7H8suHW2LEw1qhN/f07XVvGfR/60Nf+63cN9/gim/BzZbInNr7v/Mbyti0fXuxXwK9iZpGEqvq0XuAmD+QtkvAe+YzmkWKWrh25mlMM19o+2T4R39RSJze3gnF4r+XzBst7ekezg2MDUrZo74GLB96TuVSW+oI0pL3U1h4xt+e1Pm2PotsnNhvq+vJXQkgNlbZE8tPLZ1ybFwfKhD3HKsKO/ot3nIdKDDbzsWPp+mbSwe9Aiy+xbKfa1QrnjApSWNr1TIPloh++PpmWabHKHdYFChblUosc7pfqHe/ALwhei3ZoDxHizS5f1h/07aOxNfw1x1PhS2i4GvZuS+Baw9Lc8qSituAz6JRZd/MNQD12N+gLnzTsIU+reE7QTMdy2VuwWbBV6g4po6B68Z68DGz6mtLi16ppjlz2exduKkZmtJcztsQOgUbMDlIcwaISd7DRYkZg/gZT3lehO2jirYgMey01imG2M5bMCj7d37ARZ4K/fbW5P9Tr00kjsCizZa8syLB2co7PgCt5S+J+k2M/ogHtnxmzJa2GOtlVXVE8Scm88jLIegmWn8IHuzmHP/JZij88aaD3hQJFfJSljHZE/gRLHlKc7Q4JOY8GtslKLmfvSi5vfUGuJaC4NZJJQuXQFmXrCRBv8hsXUEL8FszWMztKUw06yGZ7Fnm17v14PpSbOEwk6aLNqrIQCJiHxRVePrujCYyqXULF2xlqruHuV1iYgcqqr7ivmoxdfRF1l1847flPKlSGITzVfL4LIJsUzOsXpBVd0kc7wt/a6AHfdhZp2ba4huKhYOv48bCs25/wXcKSKXMuizs09GtvEr/TemXLWZptSk+SbgQ9KyxIqM+f3V+OjGvjDPYdYR5yQy82MzN829L1lHcxNV3U9EtsRmuLfGOq6nxULB1OiTDPtVbhR+3w5bomBZGVwWZF5s5ilHaZAQMIuCNLDDMZljANdosmYkpoDmZFNz5lkIwSIS9sdmmvqOgc1GHJUc+1DmWGneAGi3f80ExqJgd9G0jc+LyNMiMr9mllNK8n1ebP3f3HuZyuXucU6uKO8O3s9gVN8uuuqilPX6RarSbJMr9icXi7UwFzbj/D0s4Fls4rhZ4bVMRVU/JeYH17SPbfEJNgR2F5GHsXpvoC6rZOq9UNUjgunuk5j+8wUdXIYm5qNYXbFPSONqIF3SDMyveSfMx/cWzFftkpyuJNG6y0DrusvAf4JZZ/OcFqE9OGBpUMTi5bJU9UdBj2nWdP20Jmu6RrJvCvX0TsAtYr79p2jijiTD/p+zEfl/jlimq0Tks8Cc4bnugVlo5a5zBxF5uVjwHcU6oX8Kv12eyHbqpRH3ASeEOvRkzAS5rW6pCfY3vf2Uh5jpOogjdib6qKnk4zXOBDMFnAysKyLrxgqYiFzI4AOfC6uoTxQL1rFFjdwoqPnqnIkF3lkAUySuIu/k+0dMqbyYfqWyF2lZKD1Kd58g1xZFtJHLdlJU9bcyGFyg7UNcHDMzaT7quTEznueD8t5wKrbG3rnhurckUoxk0Pfv4bBN/U3zYYcXEZHlNATJEFvXcpGMXE1j8XexyJNnhP1tgH+E83v9+GK0IiplX1LR/6+uPPcy6Q8/PS68v+Oi/5uHH7/LWxEi6or5651B2fe9IbCbiDxCt7Lys7D1ouVBCIrTxEzyumjyfDRsszEWcCT7LWqB366qLlN4fTFN5Mh3YI3q3yUf9PEsbFb8e+S/4euwumlhBgcIpxDW7svQ2/gGRe6N2DcaB9SZj6R+FFvOYnFMSVmDsXdqPqy+jmX3x0bx5xSRJyPZZ7GR/UZuU+zeLC4iRyf5p8FwijrJpXlXMkqHpWbQozRQyuRQ9s5Q/5V595Wjj+k6mFqZZpvcJ7CB0+VF5FqCP3mL7BtVdTUxH72DxZZTmHo/mwHG0Mm8W4N/lFggo1WwGagBRORlmC/ej4BfdSjTfXVZDVPvhYh8Vc0n+NLMscGTLI7EqdjseutgfBhs/JzYkgObYTNzL4jIScBRSdtfOnidi0Z+QMsl5IIifiAjV7S2YqgPN2UsuNu9mIVHK6r6K+mPIL0lwf8znPOH8K5MS5mG1knWJAhXVK6dMQukK2BqgKRDVPWkRK4xwY+jrB+rGX9iVf0e8D0RWQnrIN8RvqsTdDiibU2wv9KO70GYC86SIvJDrLNdpLfNdB3EhjCKcxKmeHSFnS0hN1LbxngGR9ybkbHcR3BEYZqlciMhFrBjG6xCuBmbAs/xUNhipXJaaBYmXx9rTH4c9rdmMKJeM4u1KKawNdHJNsTMQXMdxM6lKxIOx5SLK7FKYwPgULEgE5c1Qqr65dA5biKzpjODkxgLaLIUFixAgJdhyngu2tTHsU53E0VvGaySS6lZuuL9WCV4Xti/JhwbT/uz7UQKomN2dPibe9Cc80h0zsuxmZyB0byEZsHerpm2rhmsqdcURqrPDc/23dj9X0xs1vjcjk5okbKimfWxuggd2RWIIslpiJBXk6aIzKe2kHh20fsorSZowNaqOlCvicjWuXOCIr21hoXnwzWfoapvz8hersNruQ0dC1woIvdhPs17hEGPf2XknlPV3ALnTZkewRTR0hkYKGt8Z8NG+WdhsP5+kmGF+u3YTN0SDM52TSFZPkMt4NlhInKYqu7fcY1/wOrILRisD6dg721MUSe5Iu8aVMrWzIvft5pBjzeGv3Ek3pw1UGmo/968xSIdZn/KyBbVe0G2bZZTiJbaKE1T2iMdC+bvNISqTgpt/kpBbmjphogm2NPTYtGA/0a+HfsOg7PkT6XHQjt8PFbvPogN5i0dBlx312RJE7XlooaWo2i5zho2xtYfjNk0PhY6NgcCe2H3SMRmeo7RTETocE4TRfkdmIXFD7FZ0iswf/e4bL2D11oRjdzE9W0yGBQx95x6l8sKz3kiVp/cFvLeDDhSRDbUaMmoTNlbI0gH0WdVVcWihzaBvNooLdPealGzp3YKJYmkHbEfsIaGoHWhs3Yd1ldozn0ncCxW3xwcyr8mcJKI7JW7d6H+Wzlsj2FuFvuKBWTbNhLdl/LBmaKOr5qF2CTMhUgwl4LOzvzU66caI1gAACAASURBVM7McM8UiK1VtBPW8emb8u8MN1+Z78BMRxgdUe0JgSuF6wKVylVc70PYDOeZWHCUp3pOKS5TxTVMxMzN/hP2Z8We1YaJ3E8xZ/4/hv1XYNHshmYYxaJUHcVgtNkJ2rKQa0hrnSB7U1wJishrVPXuivIch93LJnreplgwjE+0yM/O2EjdfaqaNQ8QC1XdNBaXdzQWfdd3jKruXXlOb3RMaVlUOJId6OiIyEcwn5ZmNO/NwNBo3ouN2Mzv1sA22r5I+1K54xqWhcgoaoo1FBOBI1R1qOMTyj8B61RMxir463XMdLI4TRH5qapuJvmoq6oh2mokPxBZtO1YOJ6L5jZ1MemwPwc2834F5qsTz6BdrKpDs8bhvZ8LC171fFAE5tHhZQ0OwnxAzmXQcqFZYuQaNROnKZRHyBuHNb6bBLlfYAGncu3D0tpvit3IbqUhCm2HzMqqel9bZ0GTmTHJLJ8xKrV5F6Z5m6quISJXqupbKs6bEwv+dH9tntNKX94i8luGv6OpqOqSkWxxvSf5qKCx7IY1acpokY5vxwZjf6yqv+k6X2xG7Bis3fkWdk9OUNUvJHK5OmIgMqiIHAIsj3UG45nGb2F+4Ack5081R1TVFUNn4yxVXT+RE8oinn4fGwhaDojLPS9wrapuH8l/HOvo7apji8gvh3V6f54OhAQF/XHMdPScuA0XkZ/EOoqInI0NIh2L1fn7YG4h2yZpnqqqH+w7Fo7n6vNJGqKtRsemYPV062CriJyC+fp9Mzl3HyzI3dC7KQURpMP/n8QGRDcGDsOCRJ2umSXAKsqUkxton6Ljl2NBrp4N+7NhHa+3RTJXYrri7cm5q2EDBG9Ojn8dm8S4AjhRoyizInK/qq6UyM9CweBMrpPbcqxmUHYwj5m1g9gQFIHNsA/7BWykYGDKX3rCzSfprY9N6S7N4KLdqQK2KmaS2JgdPgbskOtoyPC6QP8DDK0LVCpXg4zNPJTIFpep8hrux6JrNQrfAtgCvumHNRBKOzzbO7QwvPY0XF9Wce6Qz1Vit6jqWtF+kdmsFK7DV0NtecI5xWHMK9K8HzNhGhjNS597+K13pi3ICYOhwZcCXq6Z0OCV19p01oRoLUANy2K0KGoLYj5hc6vqLi1pro29668LAwAHq+o2o6ZZUI7GbPF9jM3Yg3XkVlHVdTLnTMKWQGg6w0tjs63x7MAELGT4K4HfM6ZYP4kplMdm0i3qpIZOb8pQnTu9kbC2owyb+DcXsEUk26zt+IkW2di14Hi1cOS5zoJGAwRnqur7MgMFjWCsfBd1kkvzjtIdhy1nc2ZGvpE5Vm3d2y9jM/l9pqCI+RUeAcymqsuKLbd0iGbcJaRwWQYpD4tfnPd/I+H73SZsL2DP60zNr4Eanzc7FvF1yCRORH6C6SXNTP8ewIaq+u5I5i4s8vbTybnzYHXgqsnxquUo0jY3IzM/FjzrMAZ9SKek7aiYr//GmszEiE0mXKKDg2PjgM+o6qFd+UfyRYPXaV0oNkt1p6quEh1r1jc8HIvK2TAfphsO+BoXXt99qpquG9z8luvwjAd+oKo5889cGhsTDcxp4v/5/9j7znBJqnLrtYYMAoIgJuIoSclJwE+SICIIiCRBUEBUQEZQERBJBoKgIF6JEgW94CDJQGYQGNKQs5K8qJckYUSQtL4f71und+3eVbV3n3OA65z1PP2c09W7d1V3V+1641q5n4m9svqPwOz3CrMDeC10+oK5T4cRiJ0PWyc3hvXUPgCg4o9o+/y119ze2A/AkfF57a/PKem5XHsvem+r40sLys4KCxivCXQHZWNMsyWmwJDHn5Pyz6rLdvwcVt5TcyYTOAHGvnalH8uasAjLaomx34axddV0gWD014OMK8E8tLrlD8MumMkA9lBaOLrkM5XgUAC3BkbLGkiLhF5F8mJY74LgvWThAGb2NRaipOcEsObq/WDN14LRI8eZy41Qj1BXx0zUy6KmROMQPBfSpC6jgetILqUO7ThgyFBrJBUJ8BjqJZFTYb0p8XzJTBvShFM/gxk9a8OkSqbCrv2VEmOzIWmp6JiWR1AKrHSG6VHYeX1r4jUAeEnSSyRB0029j9bHMJw5u5zpkrLFCt8GcA3JSf78o4gE0CUdTesT21fSd5uOzY8vu1/P506VFaXmbc3y+pimkrxqbGh8nuF/c0r8q1KpzhI4uYaeuvvlJ/jfTiIQSR/xv619rQX7rsa/TnI3WIVJ05jd/N/cUlDA1veVYU4FJN3GdPkYYCyKp8DOQ8CMuf+G3YtDnAgzKI/3Oe8geRaMLXjQfVfn6wKor2XXBa8nAwjB2DCQkBsYzJozERCIx/Vlz31dORzA4TTNtO/ApDz6eAfYn21sIr/4MqwNomp7uAzRGgHg9ZQRLemf9JLDCCXliJ0kYu7YPgdj5wSNlGpmAG8j+bbIQZ4hdg59jidpFU7httdJrg8LYnTC5210ptjfJwzYGvkygjJKx2Kw9eHtqBPKTYVVxcVzJ4n6omDri6kxjtTv9xrJd5CcUVGZcMO+LkXQ/5lA7me6BeW95w+inj0+3/+G62ZbFV3tNT8/N2m65wXBlGyyP+aTrn0JvaBs2F7zPCwr34lp1kFkPeW/t3op/xtoWcAQnXXZAZ6T9PuMcbMpaFCVdFXLAjdO9VLRp2H1+YOOK8FZsJNpU3++FcwBWyUxtuQzZUPWX/D7YJ97qy7Y/EFJd3uU+tPo9QCm2M9uxsijNA2/Nax/oSKzudq3hbgrmj92FO1JpnH8BqCVHTNCK6kIe4Qff4Vdj3E0L8YE9DJta3mEsYk4pYTtdWDI+itync6ma/QxGmHDeQAuJfkMzIEbeM4uZ1pWNnM7ybPU3HdUg6Q/uENc9Tjs0WA8vUZyA5hj3oasfj2Sa0u6osmoTkRdw76yoSwv6oyd2ayLkqb430kZYyunpJPQp0LD53oOliV4Ql5K3xAoaJozVXEwNf6tu/Ydbb+UVhoWZwZrWZdcp9PxqkfWa1M0jM1l/ptV0o3RnKnS3Ox9k/wBLMB3H3prmWBB5wpVAOHTMAmqioV3awREZY7cfvqsOauAAK18839hQY2qiqIxWEByIVgVwZb+ufZqGPopH3M2TRg8mW30c2arxPtrw1gnDwuRIk87m+TxAN5OE0PfAXZPSWEtZDKesseK+x5Y6fqCMH6CcJ1oc3RSr3VeI7nBa5X1Ca8m6Qsk91dDb2SEMCM3MyxQMgX1IM6cDesDYUG8FB4FcK07NOHn/xHQGsjoK3GVdD6A80muKmlybXD9Xv5Lv9c/mLNG+9xVD35bm9T4yDELjzUVkM8JTmSRxjhySdf+JquA2F1SSGKWjWnSQaSl/CeqIeWv/p61im7+ZdjF39i7AmM//CFsIQ/7YeIymodo9ftVFHpbGMFLCn8IMmOALcgpJzR3XAkorw93/MIjximUfKYiuEN4fsPLZ8Cb3d0obJRWUCFJyGjAbwoTml73G0VlYC8Gc37Oh513G8EcymrsiPcMoTwjCpQxyrWSiqBnuDRF82K0ZtoilLC9ZoN1FstxsPPxyeD11O8zF+waScmWQFIVlDnQs+dzwtjIBp4T+c70QiQPgZFDhZnGvhsgzZJeHyZAfTDJBUiurHTZ7iUkNwNwrpTub/Br9DR29+utATOgU9HXPvIRdWR5fUwpQVJT1vE5WDDqewpKw1hnG62NdcMnxI4wYp0q6LYmgOsBLEpj1qv6dlLGVbX/r6te7XELjDk7JMj6O8knYP3bVdY4a9+Oqhd/12BbX/UCM0tBHXeR/CyA6TyLtTvMMEohl/kvlxa/ZN+bAVhUiR7iCiqQLKoMRVo//ZKK+ukHmdPxcUlhUPdYkjfAMoU1+PYZYIG8zZWuFqqOIyvbSOvPOxrtlUgxkVhtV4l9l8hRlNyfvufHeZmsd3Yt9AdwlwmydyGqFoMYOddIafD6z7Ud231tvygItQGtWmkT1DP3SUiqraUk50f/OTIJzRmvpvvO3/wxDonAhPIZu0McQvLzkh7xY10JFiBYxl+fkdaru2rKoU0EEMGoTYpkqk1q45ZjSlWTrIUOhnP2WhD2TLy/1oLg19yjJHeUdE90/GvCKx/Qkzr6PCx7X4xp0kFUecq/5OStFuEVg22pMpodYIZZdZJeDfshU/vP0gXKHVeIK0nuDaP7F8zp/G0ViY6ixKnPVBIZGRRti3XNkWdB31ABOssmCrG6vLac5CUAllevaf9A1Nn+9oSV6qT0PZvKt7qQYvdKgpnsmD62yl5cSHIXNJCKlGRZHCWZthK21xJ0aQHGv49gGf6r0CIf4BH1+WHf71QAH0KPgXWQOXOd6VNgWe4fw25wX0Bz4CAs2z0Y7WW7e8LKLV8j+SLag22X0xr8KwN4EqwX7DnYmw7wvwOtMWrJ8rKfIClJd+74PSzLcpY/38rf8xys/DE0pmaGEU5V1/BmAO4GsCONAfBrwdjXASwhJ+VxB+tY2D3mavQCcT+Cne9n+X63gmWV7of11K8ZzPkHWH/oxT7nejDn/mzY71jdv3L3XVLFcCrySkEBo5D/Nmx9OAtGEtSUeU4x/6UYd3Np8Uv2/TDyq3RyJYsAYKHKOXQ8DmDRYcz5Gslt0LuPb43mFpjtJd3X/XEMzMs2dlYiKVMKh14xxDI5ikeZz3j6iqSnSY4jOU7SlSQPi+ZLyXyljnUuSc/kXCMDBK/X8WDbjrBs0smwNTLEH2DB5tkiG6lt3Q3xGOyeEx5n1npLcvvqM3Vl5io7gg2cCkpzKRwCS4r8BNaSsAHq9uaXYdd3XIoKJAKIjs42qdxsJMmJkjZDXnCiqrQr8TXOpvVM/hB2Xzkc5ndUbN1Pe2B5YSYynjm27jRLUkPLdL2IjrIYHxsTW8wP4N0NEfLc/Sdp5ONtvr1v0RvOtsLjbMsAKpVReKPBAlIVksu7YbhG6vXw4meHsPKA2blOhJ+HRvO/jLwEmkYEcLu8Ebo6Z0IjoWXe7F6YgmPNZsdsGJMc6+OvTB2vGphE/T1rwDNtauh34AixvY42SH4XFjR6CL0sp9o+f8acv4HdRL8Gc+iegfXTbBCNmyJpBZJ3yjNvJP8o6f8l5rxFXrarXoP87ZKWiccWHutEWKl1ZTh9DnYtpFiJPwkrAQuznQdHY1JZ3ncoLcdRQpB0rfqZE6+VtHr4/fn2K2CMzK/68+lhJBTrop9gIn4vfcyHou/6BtWzQyB5vaQPx78DIzKscBsDpsncfftrs8KctAVkBDcfgDFLXhTt5yZJK0XH3sdu6dtL7o8zwRyTIeY/WLvFv6NxC0t6mBEtvpyFcsB9nwNgaVhPXRjs6ssE0ILSJ8CuZ8B6sHdWQjqH1q/7AdT76f+siF06d0534o6GSUYJwLUAvibPvviY7CxG8J4q23g2rLQ0eQ9qO0dT49sQrDcpko4mkposxlMfexks43YIzPF6AsbtUMylEBzrDAC+gl6w6yoAxyso7eYAwWuSW8Ic738B2FrStQ3Hcb6ktsxXNS4scx0H4+J4RAGDay4iO6aVwLDEjoj2sSYsQPAUTJ6ir8qDlmmLCatmUKKFInXfGvReFq1zy6DX+vRHRQyog8DXscMArABzLM8EcJik1/31GWH3uDMA7BS/P8fRnSYziI6sshhHTGzxT9hF2Rd9Zn4ZTZX+7doGZOjyFI7Lhgp63Figh/Ym4ocw52CDDMc5lZWrMGh2rhRnALjRDXvBIrBhpLE6Z36Nus5UCiW9MFmQtKH/zYmQLgwAJGdWVJJFY9yK8Y3g/5lh2ZZWOv+mRS+KTD6BXhk2SM7dEKHMBjOJdxqMr+cATJF0W7R9CwDjmxzdYM5ODcpgW2vZaoCXaKX4f6KVlP8V1heVQlHZLslPITCUYkciwHhZBLbCQTTmwni+42DkNWvBSow+g3SvaleWN0QWQZLjbSRXkXSDH8/K6GUn4vP1vbBocVUCORvsXvEaTcczxB9ppYZhtvFqNwyeDca9TmOwrsjIQt2s2ND8B8lvwTJJgGV9nvHfL/zNcvcNWFZwCnpR9sf8ffHvWiICXXJ/nOyG6FAZGMlb0L8eToRVY4REEr+GGViD7vsPSF8/Nfi19DzM6euULJL102+K3nXSVw2UO6f/tptmOAhtWYymwOL2ask2spdFKqlE6sK8tLLuRUiGPVezwxzfFEoE2DeGJQ/2gCUG5kRGeWYDKkfnWJgj/TN//jnfFhruJaRX8EDMBNh5vQSAz7lTkiKK2Th67+oAPitp12hoWOb6KqyPr+k77TzE4P/WzFyJHTE0uSV5toBdI0vDSAq/LqmmYVrZ3h7kWgtG8LIR0jqgI9kmVa1zE2DkOVXG8hc0tugh6Q6Sl0haz//fR9Zn2oVXYOfpLDD76OHKOQQAtxuuJ7mapLDdZWa0k+IMYZp1EEtORJQRW5yKljIa9mjk38t6P8ociIwJkl+B6/K0LYS54waB31w+iX7jsy+aCCMLeDYY8wyNCWy0UVLi+W5alulTJH+FKJulICuoMlKFkcTQMUn6Po2gp4o+fUFSyFCZXUag8r6VsoPOlJqA9fPExlvfNvX6oSpcyx5TJtjrvapFG2Hn6YySwvVttNleW4l3Aqzoj0p0/ZMAboIRKJwjKez3uAtWHtOlZXo+ehqUTSyCQ2B72WqFr8Gcrt1hQbG1YPIZKWSX7ZI8FBZYO9M3TSD5EUl7J4a/6K9d4+9dHWkGvdUkLe3Zg4NIHolE+ZAySpdZTpAEmJF3Mo2OnzCjfSd3puIb/eEAbqNpaRFm3PzAx14Wjd0V5pit7mNPh/XOC/Z7VNgGlh36mR/r9QC2pWn5xf3in4WVDp/nc17j26aDGVul+wbMkd+Sxq4HSS+6MRajsxS08P6YxXbLHi1+TK4xB4K1qmTfFST93G2BBST9OTXGx71O8khJq8JEshvh99yLZTT8jS0iuXN68GFjWLl4I+RESrDeu5rdwH7ivuo9XaWoE2ABzS39+ZfQczYJC9SXrr9Po5fha5WjCJDNeBoEEF6H9UJPB8vgntn0nhZUn3WlKAt1BY0BNsSTvv+sEkbYPWRXSZf79bYn7F6SlK6gybV8FnadP4z0Gnman89VOfNwNEjDoEIrgSFNYP6n/n+urvQ8MFmUFwFMpmkxn4Q6GRlIrgL73JvCMpi7ok7GE2I02qR2hPkQL/jxHAbrwQ21HcOy8M3Rf99I4SbYvX8lAO8AcDzJz0gKA4SQMetOB5MO2RpGAvdHpANeNUyzDiIzy2IcJRHyLka1Ehr5s2D9LV0LYe64QXAhgJcA3IluMo/XSS6guh7awDXMzCzxVFmZyv6w7+h9sAxh7DAMZXw4gDbNCKHWA+ifs6mc9ZPolRG0ZTxDlPTCZIEZUhO5Bl0wPsz6jYM5Vu+qNijqDfaI8C4wI6RmWBUGhAZBF/FOhXfAshj/BIZKn34NcxSmoE4IcAhMsuIu1MvX4lKj90laP+cg2VC2ivrvNK9vm17SY+i4QUo6k8YKXZXtbqLmst0NACwblMGcBuBW1NetCl+BGWhz+rz/QNpJrZzGf9FKx54G0Pd7My/LW0qQBBk73VLVcYZBMkTyD+5Q/A5GfkOY7EfVL/vNaKxg50arTJFfx00R4WuisU/BeuxS+HMwLmvfjpfdGa3uj+ORDlTcDSMWqpWCRmNK7o8h2224lj+PgO0W+bT4xRIvtNLmHwGYERakWxbAAUGmPkQnQRMw5ND9i66R1jSuZE5YcO2nyNCghBmu8b03tS0H1W/yLVjZ//OeoVkewHcb9t+F12WlsVuz3lc4DxMlw45OxlOSc8Cch/fCAhmXoudM3IbBHMQKr5EcL5MCAY20Jw4kngf/jtnrX2vDynKNav/tj4yDxL7mbQVzDJ6G/f5sCn7TMnunwSqKCGB+WhZ4kAByaFt1ZeZ2AFBp4Q6RDrZB0oTo+aN+PdrOLVi5BYC/wCqGDoaRgSV7Pd3G31eDSZ0lpwz+hr/1a6h/N8BgdvKOkqqM7/8C2Jjk52oHYLIln4XZiTfCAn4LK5FlTkLSNPmAXSh7AbjLn88C4LaGsdvAFozHAHwfdmPbomHsVTAj8BZ//mEAkxLjZig83ulgtMsLVI/hjCvY7x0FY9eHXYxn+ONRGHvaoPu+suVxxTA/13c6Xv8gLBN8Ciwi9QyslGMizFA9d4B9XujnUfIxzM8zb8frxyR+p6v88chwfief805YNP42f744TBsrHLO9/3ZTo9/yAgCfTsz5MMyReRiWib8EwEcS494O0y57CMZA947EmMX97/KpxzA+99z+OBDmnL472DZ3Yvy9sOxm9XwmAPf6/7dGY++GZfDWghnWawBYIzHnCQCWyjze+8P9J17fCZaxnAy76XwqY86PJbZt3zD2jvB78e+pdY2BBRDmaHn9O34ObObH/HeY8RmPux3mdK4MKytcAcAKw/jtt/W/e6Yeg55/AK7xv1Nhzk71mArg+WDcXv73GFgWt/aI5jzK/ybXoNJ9R3OvByPHeBJmRD8CE0GPx92Ssy38bNG2CQVjF05s+2hi2+rD3PcUP/duDbbd2TB2Kiwo80rGd3o2bI3+edNvWjInMu6hMHKLr8NKqcNz+UBY3/sg10hlB93hfz8Cy8psDOCGxHgCmL9jzuv97wF+Pj/gz98D4NqW960LazE5AiZyH79+PqwC7Ev+/V/q5/Wyg3x2n/NW/7sOevfcSX6NrJ0aG//fdn7CWnrC134QPX/d9/f+YNtDLXNPgSVKqueLwtofUmNT19jCwf8/Df6fy8/hKth9FIC3x+dJ12f3168J/j8jdb75/0/CAmSfATBz12f317PtSljQaVzL6+v53z1h954D/XEbjME3HPssbC2+MPg/aRuG5038GyCwo2D+ynWwcubZfdvDJefvNJtBRH5ZDFQWIU+V0XwmMW5lGiPlgrBodsUqlaKR3w12Yj2OetR/6UHGFeL3JNdTopE+2jdhBu3y6NBDy4VGscRTHWLdsIWniua1Uo4XYMR7ACsoqDFvwFCJkEy3LqsXpgCd7JjKly+okIo6D0W+SM4DM2i2hDG4LafmiPtosL0C/aWrYRZI6C+dOgvWF1BlpDYC8Esvt7knGvuU8vSLSjQou8pWvwbgg7KylEVgBn9f6XKE/T2L8Q1Y791JfhypSG2VFb0SvRLLPi0vP3d2Ru8cvZfWt/FAPDa4lif6tTpzw3mQm+Wtsqh7oZ/4JjxPSpjnss8/ZYraw4INQB49flZ/U8G+w/dc4vfHat2fEK77pZUDjq3QT6//eaQZllNjU72FRyEvM1ay71ckPcsMzcSS7xQWlPxt16DcOTPvpTPCrt/pUT+nn0fahslB9cVUGZRPAjhO0vlu/8THKZLnof+3C8dUFUPZfYXMYzxdRD1CrpNgxCcLyBnEGz9ggh1VvSzmOv73Glj7RZU9T5XmquH/GOH5GffGro969nwzH3+ll2D2tdVEmEHSUFmppAdoBDspTET/tTN03UkKy9s/pigzR3Lz4NjfTuu5HQdgjrh6S/VqrbA8OC6nDT/bu9ArqzzK7zmzkJxeThKWwK2ehT0H9Ux7qlpsKwBH08jUTol9gspmlvQjWktBpS4QtwkBdemMrh7UI9D73uPfYD/0ymMnwkqxt4RlsKt2iWxMyw5ibllMyIJ0X7DtUCX6ZtRjyGwrowEsMrgHzMBs61kCzGhbTIGe1jDHleB6AL+hNcS/gp7xWaNHrhZ2SSugn5xgILyJJZ5AfaFZSHmU463QKPcAdqHl+xxPcrjfZ7bUhKSJzGCdhGk6ne034HVhxnVFtQ9YhvpJWJb3XzCpgHA/YZ9sZRjsqA621xKokHhHxoL8O/RuFl9Wr0wkptyfQtMivADtmqolGl9dZasvV8EGSQ/RCHC6sAbMUa8IZPaX9MvUQEm/9JvlSrDP/y1FzHMkV4Xd5I6HZUcJMwSvIvlpSddH4/v6pP18jvukW+VVIpwJqzLZEEaXvj0CXUt/3/H+t7O3UdLO/jc76EVyKfQc5HsU9eVIutD/dtLjy/t5JU1yI7Y1qNS172js5ZLWQeDQBNuA/FJQeMD2s+jvqZ4dViIXjs3tLVwVRoYxL+skUXMg0Osr2XeAe2kEQeNopfoTYPfMJJhJ0KREL5gSrIu5c9LKnw9Ag2SM73MSgEkkT1WgBzpMVL2Mf/USz48BOMzXlSZ5kE5hcUd2XyHyCPyGvl9Zme/DGc7hAXB2VNh9aAZY4Hd1n6daWyoipTuC98ZESpVcF2GOzPPVUNRtrtA2iZ29mFPhNzD7bTaYs7AHgPlIHguTu4kD/zeT/DnqpaA1LoDc6y5CF/HTJFhpN2AZ5rAUXKj3S7Y5OUOvSXoN1nr1e78XbwgLSP3V16fPJt4/N+xaDwOB8f6r+bellSVvDeAUPw9PgRH7DJ03JM+Q9DkEbULBtmqurL5Td0azfn9JE0h+DVaBtDUsez6Hr1e/UyQ1ksK07CAeAGMfm5/kmbAL+vMNYz9D8iVJZwIAyZ/BSsP6QPJkSTvAGdX8wrwAvUhSheck5YrY/w+a2d4GGVeCI2GlJ3dK6oo+5C7suagWiXfCbvBX+PO1YKUao+kghp/1KpIXo045fuUw5h7xHsBMbIR6tqv6jBVRy8Dfp/LZMcF81smuqPMPg8/QFUkvYXsdBJ3EOx5kuUPShxDddBtQSQmEPbZD2SYWaFAGOA1Gjd3UU/w+1gk6as/jKLBjLpjT/iDMCViQJMP1gkZWtS+A9/u+D/FjT2F/GGX7VcG282gSEQeg3yHO7ZPe3v92ZXkBK1P+OckJgeHcdxOniWjvhiDTCSutuiox9h0wByQce1bsoLoxfz6sReB22PW5FMm/ANg4/N5oQtATYAZqNedPJJ0ezUnYd7ebzzeO5Kuw0vODg3El+54Zdh3PQyM+CjOD76nGqVc5sJfqJEzV2hfiOliJ8DyoZ1unIjCuHbm9hbmZsZJ9V9gNdr6+Dls/L0bk9FZguQtVpwAAIABJREFUAUETM3vBCuY8GVY9UBERfQ5mzA4Z+HSZBQA/rZyuEErLLEzweabC1vLlAOwdZE+qLNIWsOzWEbKM67vRTBSyFoy06xE0CIs7Un2FJ0bHV0LgFzpoQM9JSwbFHa1ZTBZkz5WprYi6Yx3/Tk3Z6xdg58iZtN7+zWF935f4cc4l6RlYCf6usNYGwhy3uOoi97rLJn5SgbYi6tnGtwdOKmF2R+rzvwTvqXanbqhHmIFeI4CTlEnQ5PM+707bLLAEzaYAvknyJ+qxlNaynB7QbMyQd2ARtGeaa8/9HnwFjBRpBtg1uDWM0Gyerp1NszqIwNANuyqLuV4N5ZC0TOMFsEX2EwD+obqgcTj2uzCimq/4TfO3AE6UdEo07lBY9PJctGcH4BGdxXyucOyP/PUqKvrBtnGDwB2jTyigz20Zew8s4vko2hf20mO4CMAXFZV4KqGHNlJgpLHki1DFJHq1IsrxwrlT2lVfkotXjwZoDLy/CDb1OYrDOU98HxU7ZkgAkjqf71CPdXJpGvvjuXKa52DcRTA2yY/BFtQXAdyowTSJLvXjWhbG4FVDyvjJnLcyAH4BM/5DA+A4uV5lMP5MAPvIiZyGAw6gHUVykqQ1Wubcvuk1n7QvW0XyAQCHSjrZ18rDAKyoQDeMVt40BRYd3hDWE/H5hmN4QFIyQ0/yfkVahGzQPhsO2NMRvBjWO/M3AL+WND4Y80kYscLBMAORsIDAfgB2k/S7YOwSsBv1xTBSniorui6spySsTvkJjJl5L/XIfMYBOBTALHItPJLbwTICe0b7/yGAo0MnkeQeMENtZ3n5G62E+FhYGfePS/bt2yfAjKL3wK7TMDN4opyVMBif0q2bIqs6Sf0GC8JK9y7z82r6VEaH5KqSJqfmiOeTEVnMprrUxXD2PUTKFmxbvmndQ52gaTpYv1VKt28KTIbgfn++KCwzscIgczKhNxlvI7mCpCnM0AgO3nO7pGVIfhzmWHwHVm43cBDOv/vU/vuymiTXhZUREsb8emn0+pywANZoEPiB5I2SVmZP73A2WLZwaX99e1jiYUXUS8GfB3CaBqjaced9KjzTiF7bBWHl9U0loW1z3gFgK0n3RNs/BOBxJaoNcq47mv7fsrA1cv/gpakArnSntOQ4b0EHC3CusxnOqV47UWqNSupsk9wIFpQYD8u4nibpCRoB5r0wVvN90f8bvQyTrelrrcg5VpiTeLXP9f/8/2ruj0iaK2OeWWTsr2ALIdI0m0GksfsAvej7krSypKuDMXMHb9kJVj53LYCD2aCdJuk7JA+jZUlWgBlOqX6rqkwuFC1u6oX6iz9m9EeM2VvGDTcC8HdYBu336HY6S0rdSjAiJZ6FqEln+EI+IhlLjU4PYBeOhvW7AhZEWAmWKSAsCjisEldmsGMGyGKdRGbU2Y2nYwHMJxPyXhpGrvK9YNggbK85CMvnwmtiKtKZhHcDuJvkjej1OEgJjTJ2lIVpAO0odJStphzADHwMwBok95d0MMkjYEGPEO+SVEn/XOw3uia0ZURThn1rnzTJtSVdwYYS6wYj7Xv+/X8d1qc2B/qZLL8J60cPDZbbSN7s7/ldsP27sN68GqsprXfz+7BeoQofA7C06ppWr5PcF5YlrbALTN/ukWDbFT7nr2DSFBW2gxFzDAVBZSXE28KyCJUEQu6+IeloWA/O7op6ZRmUJnOAkjRaRmhnWMnXeNj1dRz6K3EAk/q5HO3XPwC8x+9jbwOwgBuvX5K0yzD2fS7JjYLg5eqw0ugPpT4XLOtS2Q3JbIejpBcsZ85OyRgFZcjVtiroJ6kpg1oFBTaAOYa3k2kuh1y4E9/X19cw9lKSN6BXWl6zy3ytfA6ZjKesV3nkoJUdVeV99zm4TS7A3gb2soI5mB/pKqb3wu5jqXLMP/u6sBDqQeEdgv9vB3A7Tcf5BVnZZxXIyGlfiMFcB5D1zGDH0Lwy9AibA/ixoqy+pH+R3EHS5QAOIXnIIM5gC9r6FbM0NCvn0NEoMTPNOoioG5ozw5jtpqBu0IYEFNXfT/qjVpoU3fhuhEXSbgQgWt9MzQhRQS+KOnpcqtdJbi6pVudNawQeDh72R5NzGh7Ho77Pd6K5Fn0QXMURKvFkgXQGezp7fdOgueSkbd8j3gNI8sKGYwTQy4xJOjV4zyUw5sSp/vxAZGjidCBL1N1xEa1f8XD0Si1PigfJqJjPDZ7/HRawiHEi7HquesLuIHkWjNG0em9SNHa4GMAACK9lwnoRt24Y21kWNjRRvgZla9lqMF/qvHoOFgU/XvV+y31gQYG1YZHiqTAnfKX6lLUyxOnC51GwbX7Wy5GG5oAZLDG6+qTXgGXvUlIQTf0lVR/Xc+jX/avwrsg5rN57B8lYhHkpRfpUPnYiyR9Em19WgkRBJpkUBpLmiJzDatwjtDKqEDMoUSEjIyMKHY/cfYf4PCzLGmIyeuXV2SVpAXaF3ZNv8P3/ic2aup3Xv+MoWEDnAh93exAoHnTfuwI4n+SGsGvrcJh9kEIWQZMj7gXbBumy9Nw5Q8kYwFi5k9UCtB7hT8Hsw9sAPEmrPNgzMXyK308WBrAPrbyys9qoDezo6wvGfQm23rzo+6zstFTlRDznjKk5PRhyOxOZ4RQkHUHLYj7vc++vKIvpWIHW9/asH89cAL4uKakX27XbzHGXI7+dYmYlMsSSLqbpyqZwPqwa5zJ082hcAgs+VX1vs/i21RrfkUZJwqPS4MyZs5igSdJ2JN9F6wEWgJvk/fTuHFa4kYFkjds+a0o6r+CzVGDqd0oOzJNKAVq+02nWQZRUMxZIzo+IuawwMh8bH7fCFraq7+tc38+2kn4RRSnCfQ5lIeg9AU1OgPrL4roagYsROJ+z29Pmxla/UI6ElRw9ActY3YsG4daCY9iN9RLPEzR4iWdb9ihmEyxhncvBaPQADsKMugDqGdKX0Z/xKUWuqDtgx/wV2O85GXaTyWKXbMCskm6MAtdNwtapUpmdJZ0wjP1Xhn4n8Y6MJCQWLD6uYdrx0QJ/EMnb4kHM0KAM9p8bmHoIFlGuyGa2RC9zfyLMWa2wiqy86lbfxzM0go0Qc8IM3PBHqrKIsVHX1JsEpBk7W/ukJR3g/x6cyBgsHD3fS9LhJI9Bes0NezDbyhTj10rGzsx6v9LQ4aEedX8RzYhfawvchK/l7jssr27tr5J0PsyJyioFdfxb0svVNU1yejQbMiXX//9E41KGbfa+Jd3g9/JLYd/jepIebxjbSdAUIO4FuxrWNzTQnJJug/XYzeHPm/p/AWBOWW/VTrCs4AGs9++F2BFWQviQZ07egeELi+eyk34Dxricw5SezXiKdJVHUw9mDjsqYG06QxUlvkZuACtHHy2UZHLbxjZlrmdNfM4mzBzajpL+SSvFLMVIfabaOA1A0ERyR1iFzxW+r2NIHizp5GjoAaG9KquGOgBWkRjPuSGMQKYpyJL7fQMtmcFcTLMOYgKPoaEsxCOsX0HAFAaLooesV7mLYgk1ehY1OTMbgQcBrQb9DFi5DUg+BWA7pVntvgszTi+TtByNwKEpO1IEjVCJZ0nmdhRwV/B/ylEshgZjRj0DFtX6je97U+RF2tqQK+oO39dU9LIOW8PK4bZIjM3BUzQW4orN7jNIZxqbMKySKN9nK/EOCwWLHZ1lYY4JMAPxeklr0Ur6klUHzGAzdCyXOp8kfZRkfO2/QisZqr7/eRFlESQt1PI5Y3xM0udoBDEpaYEYf4Lp2XZdR6207I4S6YjxjISpHUT/zfmdDUFBor+06++olyuHCI3/JRoM99T+KwKO1Niw2iN330BzeXUfO6kjtxQUMGNtX5jzuS6snPbChuPKvf7/h+RqsKqeGWHOV0quqnPfwdpZYVaYftmxtGqQkPzlfJjMwXWwLEOjbAzJTQBcJ+kJ2Hea/C1y5yT5NCzDfh2sPeZGdYtkT08r598CwLc7xgrAkrAM8cEw+2a41UO57KQPIpA9GqE5gYa1swE57KiAVUzMJG8lofW1DlJiCeTfr0rsin+T3EBB3zQwZFs2sX5flHpPA15g0JtLsuIUqIHpst9wW0ws1Ibqty6ZcyaSJ6C/bDbVKrMX7D75tM/5Dth1FjuIKbbeJt8rSzojE7m/f+P5NM2S1EQR4nGw6NLDkrZNjD0JFkWpjOjPAXhN0k6Jse+D9Z+s7vNfA+s9eWzEP0RvnyPaCBzNfR2Ab0u60p+vCRNj7SsNIHmzpBVJ3g67cF6nN3EPuO8RLfH0Od806QyPGgENPYCp86lg7nsBfFJ1ZtTfSVqiYfzyqJPuxLo8pfu/G1biVWOSVAuxQde2gn0vAiP9WQ1WOvUwTMT8kUHmG/AYWol3SL4Oy5TuKOnPvu0hJYhkgjmXha05c8LOk3/ABOjviMbdJGklWnZxFUn/ZoKUwsdOhAUqwrVsGUWET34+fVxeZkVyARiZyZIkb1XQA0NyG1iGcXmf9zMwiZK+ygV3cm+T9AKt/215mIj7X4Ix98CMrAsArInoBqZ+1s9TYQ5Rsk+avR64w1HPTs4B4JuSUixzh0pqy2SCDWQewf7DXq4DOsaWGKXVnNvA7i9Nc2ZFwqM5s/qWSK4rL6VjZnk1jQX2m7Dg6nK+7S4l+r1o5cI7ok5AcmI8zsemrv9t4s9P0009GlbqRliJ2+6J86lz3yRT/YhDUFBi5lmB1fyxNEwu61qYMXmdgowjyV/DsuH/CsZcGwdkc+ekZQw/HIxdAWbwV/PWemL9PZvDWmSukbSLf78/VKJcjSaX8DqMaGkJWunkJZJWisfmguQ3YOXy68ICjzvACHriPtflYOWiN6B+3fcxLTfMeZZ6TJPx+JCkaFYA06kuXTDEjgpzVCvMDvtet43m2wtWtnsKzKbZASaAHuttVuMbtRXZwH+RmCMm2mubs2LCvQ69UuYVYefihkroz7p9Nhvsu2+UQAvm/xV60lfvBrClvO+16Zh9WyORVcfnv9UTFdlzuu16HCL5ufg4fezlsMzwy/58RpjN9bFo3Mmw4NF/wX77rwKYS80kbZV0xhd8/CmIpDNywB5xUmtWkm0655KmyQd65Ru7w+r7V28Ze3vONt9+qf+w0/vj8wAuTYyb2Y/hZ7CIw8kATm6Y8wOwSPc9sMX9IVhJRzxuhlH4nko++2WwOu5jYKVpR8NuVm/67x0c4yn++C3MmJjoj3/ADPo34hgugbE4Vs9nhxnfw5lzfRhB0VX+eARm4L9R3+ukgrGnAvhw8HwVAD8bgWOYLfxeG8ZMgDkGhGmR3gIrCxvuvm/wv9fDSqxnAvCn4PVNYVnD/4GVaK4DC0jlzD0HrN+s6fXfwMp7D4SVop0PuyGkxt6WuW0DP5+u9PPpUVhv1WwAvpYYv7ivZ7sBWKLlWO/w734Z/39CfO6gl9n5t691DweP1Lp3QOoRvL6xX/NPB9f/KbAM9moNx3nFCF4bEwvG7lMw9pbMcZNHYc5bgv/f5dfS7/35krBASPyem/zvrW3nXss+/7vj9aHrH8BmmXP2ncul+4bRxa/vj3k65pkOZnh/A8CfYYHm1LiFYGXoP4UZq0+2XNNZcwbf0W5d40rPl+g3TdoHhfOuC2PjPQJGrpQacyMsw/oFWD/l9rAA2sBz+rgvArgJwIP+/AMALo/GzOm/0S9hrTTVY+6Wedf3fR+Jlnuzr18XAnjAn78H5nSWfoe3lswJu2d9wY/vSJgTO/Nwf8tg/hlgVXpLIbJVYfePzWDO9qeDx+cB3N0w38Jt22DtNqVzTin4PKfDWskO9O/3FphzuSeAPYNxs8FYoG/2xw8AzNYx9zwwhuhHYIHPPwH46iC/v38PD8ICpI335tRjmisxpZWL/hDG6vYIzFh5J8ypuZbkcurPprxGcrykB32ORdDclDuv6pIWp9LEKmOcAYv6fRyW+dsG6XIXwIyZA2BMc2vBLuJUWnghGkPhkqj3QQ2nFvkhkt9BXTj14YaxG8P0yPaAfZ45YZ/tLQN5KTBNQmFJRdIZb9BhjHgPoN4cZtQQuaLugDmE29G01QD7Pu4leae9JU+ygA19vPTeIaWZdneQdDSNln1e2LV0ClwPahhoJd5RoWAxycVgTIpDmnkkT1AikqsCDUpklK16BuVZmGG0OGytuU89YpqjEsdwH2w968KrkkRyY5gUw88ZSWvIMgU/IXmspK90TaiOPmkN1gN3K6189BzU+5AGqTAoWX83h2U4cpBbalZS8pfdtxP8XzncVTniA7BgyM+j9wy3FHzVthdVl674MSzw14U9kTifc/dNY4z9Maw6gACOI7mHoh55z15WWbwPw36Ty2C9wn2QEQ3NDCPzmMXHz1I6J40luhpTZfWmwHrfkvv27NIX0cJOGaCzvLwUzO/re1Vp4pwk1MF4GqCTpEgBO6rPVRHzvY3k25QmuLnXj/kykrOSnF3prFB2v2RbVhB11t3OOd1eCG3XVjBN8AQlyNE8C7sngAUlfZHkB0guph4Z2CBEVl0tA+fA7rUlc15IchdY0DW0Y1LnyYOoZ4/P97/x9/oCgL39vGgVp2e/dMbKqktnHBOMzepXlLRtkJU8hVZmnZWVnOYcRFhkZFbYiVqxOM4B4Ag31tYH+ij3vwngSpIPwW4CC8J+xBSe8tKpityh6jmK8X5Jm5PcWNJpNNa1Jh28WSRdTpKyspkDSf4R5jSGyHUkS7ADrCa/MoyuRkMTenSDHm5P22hjIb3x0hkVRqwHkKPAjDogstgxHeuP0D4HIRGqrocRo2V3ZBHvqEOwGABolNvnwkp2T/BjXg7G5vtpSdf3faieBuVUf3wIPRKYECGb4VDZanSMr5M8UtKq6NCcGgBTSe4DCzR91I3LJAmCTEt2GdRLoft67pjfJ91Jyx5gbti6HZ6/wmB90CoYW3Iu5s5bsv9B5pxH0tn+u0LGeJoKoO4KO58XJ/lXeCl4wbGVYBBHdxDsD2Al9Uo654Ndy0MOIsk/wZyJibB7/PeaDEU/P1eFBa/uh1Uk/BSmX/laMC53zsdg68CPYQL2OSzTJeyUP4F91neS/D68vDxjH23I7eu7kuTOsMxYqzHPAsZTFJAUuUH/I3QQ87FfOuW9aJZOyeqXZAfba/Q9tM7Jwdp5cpQAKpzir1WBlsdgDtxFfqzZQTxmyuYMGBis7oXhZ0ueJ12ByeB4V4MFi1vldRyt0hnR2Ox+RRnp1ERYkOlrMJvzmyR/ooYya2DadBA3gEVchi4G//K+AuAppLX8roFF0xeDR9Nb5t8BtqD/GHZiXYe0Q1UR3DzrBs7/ojmL9JJH9f9EcjeYKHGKdjvXkcyGrB+lr6Y/Bb9YD/NjI9oXlzcbV3GEpDNKIen7ND2uyvD9QiJrnYvRYEYthspkW4p7oxrmKe7bwijQsjuKiXf8Bn68P0LsD2BrSVcF284jeQXsWq6tUSzQoFQ+m+Elnh05N1wrRwBbwkrndpT0v7Texh+mBpLcHWZUVefwmZ5FjW9oJ8BKeq70960JK+ON+6SzDV8Vii2PIEbyu36j8AKNoKEyPj8Mc15qkPVHf8yN03Gp6DWbZYiIZjbFFIod3QH3PU511tIn0U9KcTIscLYZrLzuQyQnw0rA4vNwO5gUwEUw2+EG9RNIlcy5Oswo3xTAniQfgQWwJgO4Wekqk2x2SklnkpwCc3QI0wVtqoRqBYO+PtbJl2ZHmpyk0uYLZT2anL4SxtNJzCdI+h7yiPlKpFNatRUDlDCzduk1FgdblaEEEGC8pC1Jbu3vfbEhMJsTxCvNNmYHBlWgXFAQmPwx8uR1oHzpjOzMYElWMsa06CC+njJ4JL1G8slUdB7Ww7E8rGcGgDWAIq0xM78i5kZaGVdccnCCR/2/Aztx3oY6wUyIr8GynrvDmELXRlrDKNeRzAbJSwFsrrp+z68kfTwx/HAAGw16g3gjoZGVzhhk/7cgneEpxYgzow4C5rNjjuQ+SyQJKowGLTsALKY6yc6VtIb3QTA+cg4BGOkJjWEtRpYGJQvKVmHlQLMBeJXkSxihYI/f7H4UPP8L6oLuIXaCke684Md/GMywjW9os1XOoc95VUPUPdvwpZX37Yh+2ZKmypHW6UZp7CNv4v7Dfe8Ju4eNJ3ktLPs1pB3GslLwNhmiWmCWXpKemhrAfMG4tuxIWLaZve8Al5D8HYCz/PlWiCqBJA2VDNPYjFeDGbL/z22ONYKxi9MqC1aDETTtTSO8uh3Wz39KyZyeOZkMv+ZILgQzqk+Dsc+myo872SlJzuGB9blhmbNfBq9lkagkcBas3+oQWFVFhamp+UqMeZQxnu4Nu/bvBPAlAL9D2kEDgFckPU1yHMlxkq70dSpGiXRKrrZiNjNrwZxgRtVGAxqVAAC8TGNurY51PIKsb4DOIN4AmcHOOStbwv+v6YmT/IECiZIAuYFJKE9eB8yXzqjmzckMlmQla5gWHcR7SG4nqWaU0MpC7422Zek8RTgG/Y5j3zZJ1YIzCR09KpJu8n//iXZjNteRLME8lXPox/JMS+Tr8f8LzmEFjZB0xpuMt/nfJDPqG3gc2aLuI4hvwYISD8IIhxpBcnFZn1zF7LlIOoA5MG4l+eEqwERyFZRRcodo6wtI6el1alCysGxV0uxu/H0Aw6etB8lrJH0kYay3OZ5E/Ub6GtIOTG6fdAkte0mPeP+Bk/8taUt/+q1g++qSro3GhttCw+Rm2DV0lhLMoqpLKSyIHuviLACmD6LIoWYlaGW986EeTa8CmOuU7lvSLTRG16rC5n7U73fZ2QllViK4sbth5py5+/906rOm9h0Y19+AGWAfgX3202B9UKn3LQLLIq0CyzrNi4SEgDtDF5H8A6yf6qMwR2UHRD1iOXPSSvKqPsTVAcwFcxqb9FcnANiX5Muw/vjUNXoW7PufgsT1jAE02BT09bHeWzcPA1kCkmtLuoIN7RVKt1XsA+A6Wg9iK+OprMT+NFi2TwDuTyUVHM+6A381rMLhCaSlxbKzkszvwczNNGbPSXICLNDQVbUB9isBLIvmloQDYH3x85M8E3Yefj4xrkRbMTczmDPnVuhlP2Pt8PWRlu3JDUzmyusA+dIZ2ZnBkqxk3z6az/v/TJB8L+zkfxG9xW0lmAe+qaS/BmO3h53EK8JYrSrj5HkAp4ULkRtgq8GctB8Hu5zD541p/d8OKydZCPWTO0XRvCKMAGDBaGySzIOWdpYKaXEb5prix1/R3S8II9UI6ZOrhXoNGKPdeagvwm8ZJ6wjmjzsDMmbBVrZ5Gbq9dXODuAcSSPV79e1/z5ZhdS2Ed5nKIfQZ1iGUWe/ye1MI3FJDE3qHJUcy70wA7lGvAMr+VTTtdow1xMwSvC+lwBsIWm+aPyKsMBAowYlraT5MEWZSTfs95YUl63uBDMU3wfgNpjxeZ2kVnr/kYRnnrZHr59rEwCnSjoqGjcXrE+6MtInATgoNvbZo2V/Gb0S/+Q1zx5FeiVbMgNM7iDrPCH5F0kLJLanKNf7tvn298MCglvC2O9OgUkIKBo31N8kaTyNrOq41G9F8qswY+1xBOXI8fmZu+/Sz9/xnn0UZMY6xia/s4axk2X9tCMyJ6166Cm5hE3G+N/Arp/n0dMjvE7SPYmxn0LPkfsggLv9PZV8xZMlc9LK3v4ezHGtXGZnuKBF2OZXmpBlOPMO9dZJWpRGtHOOpNX99YMkHUAyRaiihIMAmuj9NeiXYerr/Sf5SZjz/CBsPVkY1jP2+8TY2WC25Dj0iPnOrAz8YFyfdAqAk1LXU8MacUfqHuLOZijH0pQVzJqTVtq7qnpVG7PBKuhS+w6TD68CeCQOfvk4wu4j/4Kds4Rp9vaV+5L8Huw87gzi0STY/oh+SYqJ0bjOORlIN7Ffxqn2PNj+G1gVWBiYXFHSJtG4lLzOhPgc8bFZ0hn+2umwcyhFCrRO5fyxPyu5Bqy6K5mVrM0zrTmIFUiuDVuACaO8bfSk2aHz5BfKI7CSkC+jHpmbCuBCSX+K3nMdrAE9Z8G6H9Y0G4+NdZ5WhN3Iq4jpczDWxj4Nl1yQXB+WcZjkmz4Ka5i/OBhTLdRhiWNwmAOVZY2hACTvg+nZVUK8M8Hoxhdvf+eI7X8yTFMuZMc8IscwG8Y+v4qeFtVfw5dg591w2HtLj2XBttfja7Vjrtasf7xGMEODkuQDkpIkTCTvl7RYtO1OWODseknL0rIQB6mXFXtDQOsLqxy/Yet1Fuz3Rkkrk7wado79L0xkPOucih2k0gBiNNc4WLam0pw7GcYA+w9//TZ4f1Ng5NwpaanEXH+Gle2miNOK993yvv+RNH/OPoL3lDh9SaNtOGNLxgFAwf4/BXPO/qkeE3D12pB4uj8/Fz2Hb4oaysZz5yQ5p6Tn2J25DrcT5uwsLOm7tN6yd0u6MTF2II26Nvj5vBxMQqM6n5MOUsGc1ymh3dww9j6Y9l+lVzsewG9z7qW07PxWks6Mtp2mhMZ29N5SbcVUBrC2bYA574SRLr3kz2eGZZz61hJ/fUb0yP3ul/RKw7is84Rl2opZAeicOcO1J16HWgJ4YWASsCxyLTDpv/3ukn4cv7/hWE+H9RSfD7OnN4bJuTwA9JXjg1bluDKizGA05n6YnFMtKxnf81OYFktMAQCSroB51Dlju+iyJ/gJNInkqW3GIMljJH0Vpi+TS9H8pKQLMsadDGAXSX/0fX0E5jAOtLD6jeJuWLlQFfnZI478qCcdcRrsuwj7Fdv6OsYwchgxZtQB8WUAp9N6EQEr+RxueXMrZGUvxzBTDqECrdxjIdSz8U19cLnHMiLEOz5X6e/2lCIR6QRKy1ZfkvQSycrgvI/Ww/iGwB2TO2Qi6o29uu5MT4BlbwHL2v6k6fd0w7rqk71KPZr1GFWP+H7o9Yh/J5qrhNRkRp9jetRLLp9H0K+XON6lYZm8DWCMlWfCDJIr0CuXzu5vgulwZvUFZ+67CYNEnkeDwbVkbMm4t7OZQbpWNVPdu5lWjokaAAAgAElEQVTmLZgcbpOX7rqhX+uvCo3/3DnV6wHPan1x/AwWDFgb1qryT5gE1EqJsdeTXEm9NpiRQBfjZqvdFBvRjmzGUwBPqJ5lfQhR+T6tSmtXWAvSBbDSzV1hgfzbYNdKtY/XSM5LcsYmh99R1IOJPLbX0jlPAXCD2xGEOSixXA0AgNZzdxp6cnHzk9w+ldFC5nmiMrKcrJaBzDmXIfk87HPM4v/Dn/e1WLjjt6/SPAfhvl+jSTplOYjIlM7wY8jtV3wM9fv/VNh9oBPTrIM4whi6sWUYiqv73zNopUEXoXvBOoDkSQAuR3vp5tTKOfTXr/HoyUDwRfo8j/w0GVIhllZ/v2JWlHUMw4NGlhk1G9HN+nRYpA4wp+NjCIidRguFzuEZsJr929ArSxGaiVLeNJC8EP1G63Owkr/jg8xBjgbl/CRTTiRhRk6Mx2hl8OcBuJTkMwD+NtgnKYesD+h2kguooYSN5HawjNyeMCeSMIP3hzSJl7jP/FCYkVsZbxNompB7B2Pmk/S4ej3iV6O5nyqb1ESWza0FEN0JfpsamGRp5f3Pwgy0vYNM0w20DH2FScxnXXwI1nf6W9TPlTgy3bnvhvMTsN/hHQ37b8P/pXKmOWGZ1ZRTW2OP5mBcBq3Gf+6c7GWu543W6jkATNew71UkLR9kSp/xTFEKawH4Mo0d9QX0sjMDZ/uQ7q07MXh9EHmjTsbTwOG/m0Y8dLaP2RzWYhTiDFgQdDKMTOubsCDQxjKm6BiPwHS2L0BdVzUk7MrSVmQB22vunOHxkLwKvaxYmx1xJID1JN3vcy8KIytKZQrXAvAlko+i5TxhgbYier2yrdnGnDklNV0LSbjjl5s5v5bkT2HasOFv3xf4VKZ0hiO3X/GvsHW7lpWs1oOGgAqAMQdxpDDIje1lGL37t4P3NzV3fwHGPDgD6jT2sYN4oy+slXTDljBjoIomDsKaWRIhHEdyrirFTiO5GDvH3iBo5JhRS1DdrGOSnG3xxpLk5GJFAEtK/ydq6x+CkU5UDIFboqfXeSJ65CM5GpShrlOMm+MNkjb1fw+k9W3OCSMZeCPxbpixdiPqN9aqt3IXWHnmI8F7rqDJc/wK/U7/BgCWlQsLe8XDrahH1m+nlVn9EsBEtbDwqkDaJcAhJL8MC05MgWl5/UhSTerDnceJkn7QsO8we1XCuvgXf8zojz4U7PuIhn10vdaE0WBwLZm3iMFV+a0TH4dxGbwPZlRX+5mKiPwiMP7Hdxj/uXMOkrl+xTMkVQZvXjRLAaVkwYYFdTBuagB5I+UxnoaSCY/DerUAky6ZKxq7iLzs0oP3TwFYQM28D3/zxzh0OLjs1lYszQrmzNn3FvT0IpswQ+UcAoCkB2i92inknifZ2ooF2cYSvcYS3OoO/zmo359iu7wqbT442JaUoWK+dAaQnxnMzkr2Hc//DTvprQ2W9UPc4tG5B2GRuk5dHjb0kyTGten4SQMQcdCIQBYF0Br58bHbwSJ0v4ZdAFsA+L6kM+KxY/jPAt9kkpxckDwH1hPw9zf7WLpA8mpJH01tI3m3pKab+38EaAQ6ffBsHEjeI2nJhvf2veYG95rq9e7NDSszXToYMx0s870VzKGcDHMWL5D0YuZxrwtgL0nrJl67TdbTuQ0s0v4tWK9Zaj3t+/1HCl0R6pHcN8mJkjZjRx8cyX0rp5QdLKqJfTSyuJL8kKS7/P9GBle6PEPOvkvu+cF7WrkMfMycMGcky/jPmdPHLViQud4GFoxaHlZC+BkA+ymg/o/Gh4yj8/rcKRbhItDKOMPf6R/R64vCemPnk/QhWkn0pyR9LxgzCONpzrFl9akNOPftMOehpq0oaeeG8VVWEEDvfB5kTpL7wzKmE2G23iaw+/j3EnOeDLPzQpKW6RRoyLIuh9KHJoc2eP/8AA6X1KctWZhtzJqzBCwgSSqY8zoA31ZdOuMHSvTPsrxfMScrWcNYdmdkUEJnX0Vk7ka+Ls/1JJdUgvUsxIAR7S5kRwglne4317Vhn/PTXcc8hv8YLADLild4Gdbn95YAe+Vws8Okbm5EA+PnWwjzMiixpInKz+OvDX3XLNCgdKPqG+jvwRxuNHXEIdN9DA3/WVEvi2tz2FKvHQKL+l4JW58+inrJGWQi4xcDuJhWVvcJmLN4NMnLJW1TjaURnR0Hi8qfB+AHsKwlAXy/4bhm8Cj7JgB+KukVeq9VApeS/Ab6S5NiQ3lDWK9YxXLdRuyQG6HO2ncmqqqY1j64KGO5Faxy5qbAYUuyqDJgcYWVj78P9rus4/NWzmGSwRXeox98tpx916RDMvE+d3qmwioAloeV715SDfBr9jmS+wH4X0n/diNxaZKnK2jhyJ3TkZW59mM4k1ZivA7cSVCDfBUDxlHY9zQDgF+g10pTDJJfgmVbXkQvi5WqrjoRlh063o/7DpJnwcTrK6wB69HaCP1IVWGB5MIAvor+NTK8R4Q9a0Cvb6127ZE8StLX2FCO3XDfydJWLMwK5uo1bg0rW6xIag6FVSX1OYgAvgLru9zdP/ckmMMeIpZDCTOSOXIobdqKg2YG2+YswUmpgFfw/7aSfsGGntnYgXPkSmcAmZnBwqxkDWMOYgZojJCboX/BONj/7lYw3dH+9zUAt7mx0qrLA6sH357kwz62qX47dSI+B4tQp+riOxFEHWtRqpbx9wAYcwqnPbzZJDldOAJ23RwGM84rVNveivg6gGto1QYV3foufsMIv9sSDcpzYMbzSWgQ632rIGH4vxeB4Q9gCdbL8IbeioThIemXtP6alXzMt5RgfQvGv0yroLgXlu2Ls5VH+vFNhjmS1wP4jqSj0YzjYSWKtwO42h3gZCYH1nsFmBE2dFiJz3YU7Le+M+VARcgVd87ddw5mJfl1FPTByUhCvk3Tt9wQdo6/7lmLmEV1VziLq7/3T0xr9U6ASSe0Mrjm7DtwOj8NWz/eCTun2uSSdpB0NMmP+/gvwJ3PxNiJAFakyY38HNZffBYsqz3InEt6JmcbWAnyt2DGdJ+DSGPtfFjSf/n5sS7JvyecU8DW+eXgrQ2S/uaZiuHgGwA+qO7qqlkl3ci6nm1Ng1DSAf73C8jHebDv/EI0lNYqv2etyq6VlFznait+D9ZWUMsKDnPOR2B2XtXfPhPqTkhVcjyv23o/8kfliMwBK8kFAEja0P/mlPiCBdqKkmpOf5UZHM6chegifqocu5LrIVfTt6RfMXfN78OYg5iH8+GOFgJnLgWP0H8T/ZqFa/vfU33Tef7IQW6Z3or+qAgKPglrrv4yyXMk9V08XaCx/h2J/Nr1MUyD0JtEkpML9coSZ1Ag/+DbZnlzjqoZtDKwZ2FC9YvDDM/71COmCbUAx0vaLHh+EI0qPoVXJcVR3rcqugz/JXImceN5dkm/lpUWVwyQ25B8QpF2mGdqt/LHbLB+xo0TWRSppyt5HsknO5xDyNhmQ7KgR92wS43NMqpgfSd3ZTiHQGaEumDfOSBGj8EVyGdxHQ0G18MBbNSUYYun9b8bADhF0u2MvJsAr0t61R3QoyQdQyeNGXDOksx16JyeBLMnUs4p0ME4OiAeRF511VPuzFb7/gxM83EITdmbCg1ZnJfUzQpdrdEV03LT/FP87yR3rCDXsmzBxrDs6R7oaSsenBiXmxXsnDNwov4N6/u+1J+vC9OPDHEM+jOFgAXw9kWPEKiae3pYAK2SCbkHptmYclDDfvhXAfwyztK1oCkzOJw5+8BM4idJVWa7pGd2B5h0RpXZvhq2DqWOIzczWJKVrGHMQczD+5TfS1VF6E9ES4Re0mnM1JCR9CjJZdAzvv8oKRUBeQeA5atIgpd//BpWSjUFiehKBr6L/CjVGKZh6M0hyckCC5jf3gqQsXgeKdOR7Ip2vkhj4ww1KGslluz1gFxIcheY+HwXe/KbjVbDX/nSIgchXWJ2Oex7GHIQaT0g74Wt4ztL6iPwCRBLHTB8rkR/ExvKgZFwXNyg/0ow9ioYe218n9gLwO9ITkILM6kjK0JNK+fdE0a8sTPJD8Cybzls1jFekHQQR4fBFchncR0xBtcAj2c6h4CxDV8CqwTYxyP/TeQvr5DcGsB26J27KQKQ3DlLMtehc3p0i3MKdDOODoJ9AFxH8ga0V1ftCsuOLE7yr7DzeJtozCDZzKPddroEzazQuUzLhF3vu8Gc+XEkXwVwjLwCLYZcpB72O55G11ZEIJ3hyM0K5sxZrXNTYGtihasS0y0VB1l9HxeTrDE7k3wPgCthjvutsO9gQwA/IrmWpL9Fc/TZxanP43NnZQZL5sxENvGT28u7oecc3wsL0FwVT8pM6YwAuZnB7Kxk3zHlBR2nbZA8AXZB35kxNlcQdE1EGjIAtleiwZbkBABfRC+qsCmAE2Q6cOG4e2Fi6S/785kA3CZpCQ7QVO9z3CxpRVqT83K+KN4oaeXSucYwhjcLLCR/eCuA5EEwmZBz27JDHjw6HRYVBlyDUtIdwZiH0d8DUkHKFIB/I0HycJihvh2sJ2gXAPdI+nY0rrXMjy0i2/FrNGKcq2HCwq3C4jSSgvB3qfXXKEFWQHIirBy4KhH+HGzN7isHprEjzhCNfU3STtG4S2BadXcicA5SkWvWxZ3pn/VARWQsJP8bZixuJyMAmQXAZGUIU1fvl7Sl/7+epEto/WG1PjgATQyue6uBRTWxr3EwFtf1/DNdDOsPUjTugNT7w+8pd99BIGANAO+CVQO1SVBVcy8L4CFJz9Jo6d8bXqfB2CVh39VkWWn0wgC2lHTooHMm9jF9KovjjtlRMIb1jSQ9TPKupkyZO+VD372ijHwpaP3h16D/fD7NX4+zgrPAHIQXfFwjbX/m/g+BXWsPBvuXEn3aJK+AlawnmZZJ7gHLvO4sJ+4huQgsA/cHBQLq7NBWlLRxtO/ZYIHAcehlBc9UUEJdOmfm9/OApEUbXrtfgQA7yVN9P0dF43YHsIKk7aPtayLfLg7f+yqAR1KZwZI5S8CA+Knh9U8C+CksABjKMO0HYDcl9BtJXpE6zxrmv13SMhnbwjUfsDX/oHjNT+5jzEHsBq0P5f0wrzvZA8hehH53WClma4Teo5SfVaQhk3IuaRmPVasokC8Mk2Ojx6MEm6LXrLoRbFE4EuZQxtG1nM9+Gaws5RAYQcYTAFZSglVpDGMYw8iBpmE6G+zm9xL6HZ/QUCLqGpRKGUokZ1avTLVx21sBBYb/n9FS5kfyAVgP1qvR9hlgDucHEu/pYyWMt9H66kK8DqO7v0YNLI50FtOubb491wC4WdKKqf0NiiAwOBRYTO275f1/kbRAtO0/hsGVaQbDCk3BAcIM+UUkHUwrZX6XpBsb9jELLIPblkXJmpPkfDASpfdI+oQ7oKtK6hNBz3VORwskr2uzLwJHP5ZW2gjA1XEAxd/TyXgajL0PpuncJmpfje1iWr4VwLqK+ilp5aaXhEF7mk5dpa24DiygOSOACcrgkPAM1FaSzgy2Fc3JDMIrWgb+v2IHh+QnYAzhnwi23SdpcSQQO5O+Ldsu9tc7q/BK58wFOwjfaP3uExRV+/m5d4ykvnOHloH9ALqlM0Dje7gF9czgipI2CcZMB+BQSW0yV40YKzHNQw6TZ8zSFP4gqeb+Eg0Zol6u+lqwn95OpO/SBF6r6PCX1SuRKnYOHRvDjNOuevgxjGEMIwhJs3vg6QNIE0QNokF5Hfob61Pb3nTIqhVOg/UgCmYApCKaXWV+5wI4keRuUZDtJ4hYDEl+GMbAmEOo8rbEvhaCEZwcKOlXidc7y4EDvEZyvKQHfewiSLctXFZl6RrmAcvZFF92B6Xq7xqPjv77DIw4g6sfWxaLK0eQwVVOesIG6Y6Gz/QzWBBhbdg9dCqs32+lxGfaCEZsMiOAhUkuC2Mmjn+n3DlPhZHXVNn3B/zz9TmIMvKR3YPnDwMYcg7psiX+/1T0zqcZYRnvF+LvvhBXktwZVibcF2RXj5zjElhLTSVnciDMsE4hh/G0wu0A3g4LhrdC3UzLM8TOob/vyYS9l6Wt2JUVRL0UtVSvMYfwag8AF5HcAmb3AsZ9sSqsfDREG9N0qs802y5OZQZJbq/+zGCJrV2CLsK3d8XOoe//Dg/YpDA3gKdRZ2JNsu0io19R0mskB3aExxzEFtA1XFAXo0xC3tTfFKFPvOVmkj9Hz/vfBr2LLcYpsP6HqjZ8EyQWdpJHA/hvdRAllEC92nXgrcVKOYYx/EeD5E4w5sX3wW78H4Y5cxV9f7ahRPJdMINiFpLLoRdgmgPArKP9WQYBrUTnOFipF2GG8pck/T4aejOtJLKpzG8/mCH4KMmqJGgB2Br6nWiumZDZX6IG8gF36i+DkdvE+AqsB6hWDpyaB2bwXUnyIdjnXxA9dtEQuwLYi+S/AbyCtINUyqZ4AIA/wIyuM2FO8+fDASSbggpEul9uNBhcgXwW19FgcO1iMgyxikwD+VYAkPSMZ0BSOBBG0HSVj73NM3mDzjmPpLNJ7uPjXiU5KIvx0PegSKyc5CZ+3MNBRXISStCkvv8SaaVOxtMA8wG4j+RN6JBCYjfTclsWMn5tKPvlhv3DDY7cGehlBXeCrRMzwoi04qxg7pwVOgmv3MFaCvY7VWXHkwB8KbZ9YXIqKTZtwu49MWK7eFs028VHAlgvzgzCqhMGnbMEXYRvLwzwWqt0RrCtpF/xVpIXICMrGWPMQWzHIBouuRH6WEPmalg0sA+SfuTp6ioz2MQQeQuA/fxC+Q3MWWwjWegEy2i8xzCGMYwcJsAyAddLWovk4rCIYYwcQ+njMAP/fXBacsdUGPPcWxFHAlhLJjtQZbF+CyB2EOeARaPXC7YNRV3dGN7X31tR9f9ZCeF7Lw2bxAJClcQc/yAb2SnvhZGFjYdlKZ6DBfxSPWPXwLLHi8HW3fsa9tdJxKGATbHaRutNmV+JfjVJl5K8BRaUIKxUKs6EHBm/L0DfsWp0GFyBfBbXEWNwZSaTYYRX3LCrsrLzopmk5lVJz0WnUerz5c75Aq0/sRr3YWQyuibQ5jycR3LvptezJs//7UuklToZTwMke1Ub0MW0XOklxiD6q0KytBVRlhXMnbNCFuGVjLiprcy6wiSkCcKAdJVLjrZihdzMYMmcJegifBvvjlkMolkuKCvgVJgZLMlK1jDmILZABRoupRF6v8CGNGQa5pw7ePqIP4Zei8ttZE3cp/n7NgNwGI1hq6/HpgAlNN5jGMMYRg4vSXqJJEjOJOk+koslxnUaSsHasJmkiaN/6COCJyrn0PEQEmVfytA4k5WrHi5jhc1BtrB4DJJrwyL8KZwPc1JvAfDXjqkmy3oeQ7KhW5DITrmzVytFTpRaVX0xn4Ld+28D8CTJSZL2jMZVPXiV0bkkydqckpLOXRM4OgyuQD6L60gyuGYzGQb4CcyYfCfJ7/u4/RrG3kXyswCm8/3vDgs0DzrnnrByxPEkrwUwb8txZiPKDo2DlRoORGxBcm1JVzRknPoyHiqTVsphPK3m7WPobEEX03KWXiLJuXLHoiArWDBnhe/DCK9mhp3jqWMNy4prLyFyOnPWZp9zNwBXKENbMUBrZpAFeo0Doqr8aGonayMAqlVyDBhwys0MZmUlUxhzEDORcQPOitCTvBPtEbiwYT/MXC4AMzoIizz/BUCT4/p+GK3uQhi+aH0JjfcYxjCGkcNjJN8OK528lOQzAP4WDyoxlCRNpJVufhD1tewt01ccGIh303qqz4atg5vDdF2rcSHNeR8S5TeXkNwMHaywjk5h8Ya1fG7Yb7Rdw7ydkkmlwUamS5Enox4xrjCnf66dYLp5B7Au+1IhNHpmhmVJpjTMGR/PugD2krRu9NLJMAbXLfz552BZiJRDcCysTPVnwdhjYSV1MTqNWkfYs1NV7aQM2FNgn7UqPX0MZoQNOYipTHMXJJ1JI8xYx/e/Scu99auwfsF/w8rmLob1WQ40p6RbaIQqVTa6UVYrA2FaM8wOvQoLYhczYzrWgOlMpjJOyYyHOqSVImP7dzDJhYrxdDMkAvQs66ucxDyJlS5cDmB5ZmgrojArmDlnhbklrdc2IKdiYQAcDGOtjZHUVnR0ZQaL9BpL0ZU4yg000Jitf4LygFNuZrCkDL5+bN33yTE03YCVpj1ujdDT+i6AXn9D2IP4r5ShRvI4ABfIWaNobFEfk/T1aNxhsJvtg7AG9N9IejaeLwccgMZ7DGMYw+jAjbs5YdTonex6LfMcB3My1oI1138GwI2SdhyRAx0BMJMhknWa89TAWhaVPVbY12DkCY3l8iTvhskHnAUjVJnEiMUzWMuHdgngadX7tuN5OyWT/HN9HpaNCVsEngdwWrz2uqNalSIvSy9FlstMJMauB8swf1vSTWyRAQneNz+AwyVtHWxbG9Zv9R7Y/eEHMLkVAvh+4jhHnMHVt48oiysLGFw9S7EX+gMuKdtg7ngbTGZnUEcte86GrNxzsL7NTjIWJmRLBjrgNxgcgPE0MccmAFaW1FeKz0ym5Yx9hOfamQD2UYO24iDInZPkobBMXtbvy7o+99XKkFdpmOdFSbM0vFaTWIkyg+G4D8ESGk/687slfTBnzsJj3UvS4f7/5pLOCV77Qeo86Zgv/O0XzA04sYEgq9oWZCW/BuDHwbA5AGyaWs9ijGUQ85DbC9QZoVevr2V1SWGad28v/UhF8leS9OVgrt+T7IsmwsomVoOluGcCsDSjsqACVFE8oaW/ZwxjGMPoo7DsqQ2rSVranYKDaLTab6lrObcsKXYAgfZ+wcLIdyehSu6N3I+ryjZOD+ALNOKZpGSSysuBc0uRAbu/XAyT4riJxoz6p4x9PIYeIUWFI2EEHZNhTN/XA/iOmknSRoPBFehgceXoMrieCQvGbgiThtgezaVrt8A02MJKoL/TBM6/KO8T9X2mjvU5WMDgePXIQHLn3BHGMln1YK4J+70WJXmwpCpQ3YSh0uzqeya5Mcw5XsJfuhnGtHoNyTklFfU4sl/fsAYNoG+owRhP4zka+yqVz7TcuZvg/3fDqieS2opAcVYwa05HDuFVdQyxPveZJPv0uTPR1LMN9BNe5WYG25hKh8NiuhWs9QowIqXwPFof5T394W8/kwcRF0JCOiNCV2ZwkDL4GsYcxDxk34CbIvSJobNFN8vV0NMxi/EUyf0A/AJ2Mm0LSy3HeA1WopFTatQK9Wi8T4MRFDzrz+dCOznBGMYwhrcuKoP8XyTfA1tHSghB3jDQWBu/iv6b5aeicX0C7Ez0C5JDmnELyySB5gfwbiV06FRAqJKJmP49ByuQvDxae78uKe4xyypFBgCPdp8TPH8IVmpXA+vlu+MALAdzlqPpdJX/fx7JJ1ucQ2B0GFyBbqN2xBlcA7xD0s9JTlCv7LQpmPMHWFXPxYBl4mAG5dmwUtpVgrEPwfoEf+nPtwTwOEzz7URYyW3JnK8DWELS4z5uPpiRvQqs1LbLQayBRs6xA8xBrLLcKwI4nMamvi+ALM3MAKNRulghm/GUBX2VzGdaLkEy+RDCHdPbaRwTOZnGzjl93pLfYEcYi24lHXQYzN4cxEH8N8kNlNZWfCgau1QqYCrpYg94VvhTwZwlYMP/qeel6JLOyO5X1ABl8DHGHMQ8ZN+AkR+h3xHAycHN8lk03wC3ht20KpmLq31bjN2RmekswNIKylRlNNrLtb1hDGMYw1sWF/ladjh6Df0nvYnH04bzYFIUF6KZ7RHI6Bd0hJpx34X1rf0X0jp0SWFxJOSFcjDgDfoTYbmSr70bICIhkbSp/3sgySvhpcipCWnlWV9Ev9Md33vuQ8/YeBomLH1tNObtkTHN8Ln62xBGnMHV99Nq1Gp0GFwrVKWcf3dn4W+wAG0KK0aVQJfQStL2JDlTNHY5SR8Nnl9I8mpJH6WVP5fOuVDlHDqeALCojHH3FQBgmWzJVwGsrjpR3hU0/cbHYKQ4RVCDbMwIoYTxtKSvMpdpuQtDjoW6tRUr5GYFs+ck+WtYr/AfJLWtudUxd+pz+7wLy/Q0m7ZdCOAo5mkr5mYGS/QaS6CG/1PPcxB+Z13SGUB5ZrAkK1nDmIOYgZIbMDIj9H7TWoYmesq2cgxfhCdkHGpJqVEuxtEYtp4Bhnoexs6bMYzh/yaOgGVy/h8s2vtHjAzl92jgJc/kdSFXgL1Eh+5UZAqLjyKm83X83wBAK3uMHQn4a9PB9Nsqg+tdMCKzGOfDfvPLkIhQ+/f4QxjJziMw4+WdsKzAtSSXU48AaRLqhlZIaZ9qQxgVBld/rZPFlSPI4Brgex7k/TrsO5oDZpim8A+S30JPH3NLAM/4bxcb4/OG2SGSCwCYx18LM2G5c/6R5EXoZY83g5VOz4ae9EupbMk/EtueJvlohpHbCJpM17EA5pP0IZJLA/iUpJSofRZURuSVVeLuyGJaBgCSH4E5aKd4oOZtgYO0TjCuS1uxQrZDXTDncTDipmNIngPgVElNwZlQn5swJ7ppfZyI/mv313DNQknbekAjR1sxKzOoMr3GEoQkQRVBEPx5n+Y5yQ0B/K7F4f5W8H+XdMYgmcHOrGQTxgz9TFQRR9hNYyrshEuxZ2VF6KPUMGg0yc8BmKJI7JT5/Qglmc5cHAngOo8sCcZA9/1hzjmGMYzhzcFpsPWrcry2hhGLbNH4jjcPR9NIJi5B/WYZr7u5AuwlOnQjKSw+KH4B4HIaaY9gFSapvsuvwipMHkfv8whAinhmVknfSmyvcCSsRWJB9fq15gBwBMljYeWLVcDzrui9r8M02a6JswWOEWdw9ffksriOBoPr9R7cfQ7WVtKGz8J+p/P8c13j26ZD//X3dQDXkBwqXQSwizt04TmQO+euMKdwdR93OoCJklQdt8pkS54nuYykWtkxjbRkUH3FCifCfoPj/bjuoJWRD+wg+jxdjKf7t79d3w3GZjEtB+MPgGWvFoM5VjPAru/VffLQ2e7SVqwOKDfTWDLnZbCe3jlh94ZL+daS1WQAACAASURBVP/bu/Mw2arq/OPf9zLLpCgiDqCggMikggzyiwyiUSGIiArihMYxgmIkGhxwxDFqcEQJICoKAQQHZBAEhCDcy6yCUUBBYxgigigi8P7+WLu4p06fqj6nu6u7q1mf5+mnu07t2rW7u7r67LP2Xku6gfidfM2V5Efur88NDZNuxSq2JxHL/qurDVajNply+9qKrSODHfpszd1Lh7yE+F92AvG+05dl2P17pycrnVHVNjLYJirZKCeILSgSwrySuDpR/Qfc9A+j7RX6LctHLyXy84g3ltdLOt4lS1LRaj9Cx0hnK7a/Kmkx8b0KeIFr2aNSSmNjQ/dnLztbUn1v2XyxKfHethND3nfdfr9gU824dw947pksLD4ltj9WJjDPJN57P+Cy16zmAOL32rQvve67TVffK55LnHBWa7ndLukNxOTvOZW2qzQ8/rHAwZIOsf3N2n0XSNrUQzK4Mrhc1O0MTv7QNoncspLWJiZOBzfcD4DtvjILKhlca8d2I5bi9S4cvMh2U53Car+3EEszm/yy1vb7ivqHG1GW2FYuBH+6a5/l9/mf5aMTNZcteRtwSrl40SvHtRVxgrtv1+eoeZDti8pF8557ptlnG03Zh1cmtgM9lP4yI9XXyP8S2d4hEhQ9pKGfPYh9vJcA2P6dpEFLo4fWVuzpEBVs3We576HE7/BlwKVEIqbtid/tDk0PId6fm5aXbkhM2h5M/8/sDmKpe+85u9RWbBUZ7NLnKJXo6GrEhPvIsrrlSGLZ/h21tl3yAbSNDE4alRw2+PyY5AO4Bli+ZdvjiDD7juXjcOC4hnanEUsMerdXISZzKwE/q7U9t+Hx55bPP53rn09+5Ed+jMcHsXRym8rtrYHPz/W4Boz16jbvu8QEYTXiH/8RxEnYswa03Yi4mv5PRNKOQX0+BTifmBSeTywx3WwOfgbrEiWNICJoqza0ORtYtmV/dxAnc3cRk647gNsr9/9iyGMH3ldrtwZwSeX2lcRS0Z8Re/auKbevJDIxNvWxZ4ef0cXl82XACr2vG9rtVZ738+X2ekQUbbL+RZSDqB67AtiofL01cE6LfjYo5wOnE8nkziJKCgxqvx1xEvzy3sdU+yTKX/13eT1P+L2XNjuV1/mfiOjWxsQqpSXEheF6n2sRWXFPIJYTfwB4xAy85k8lJjyXlNsvBE6dbr8dx7Aqsdf3OuCjwMOn2d9F5XPve1p5yGv/Y8TFkKuBXYgT+w81tLuM2I92aeXYldPs88Tyd/rO+u8SWFy7/Z7yN3wIcUHmcuBdA55/29n8/c3HD2KJ+FuI1S6nlr/HN5f7Dqq026v2uA8P6G9Jy+e9ruHj2jaPzTqILZTQ8Bvcrl5Qq/pNkn4ObO5S06ysv77M9hNVqYtSafts9+9H+IHtjettU0ppkPJesiFL96etQyQPuY9auYW5JulbxD/Qoe+7vfdXSc8mJn/vJpbyPKXW7hjbL5vsWOW+ZZmZwuJTUo0Q2F6/RJS+aHvnWrsjyji/R/8V4s5lASR9GzjR9ldrx/clTlxaFUFXrbbXsLZu2Ecj6cNE3cXJMrhS9kC9ijj52onIjrqc7ee2GWtDf00ZXK+zvW+lzSXV11f99oB+Lyeu+C+hcsXflfIWlbbHEJOkyyptbXv/qfQp6ZfAbq4tb6u1uZRYvtcrW/JVhpctGdTP/TUTp0JR0uRwYoL8B+KE9qVNr5OZpsixcCCR7fho4DMu+RcGtG+bafmfiT2yuwCHEsvFj3XDHmu1rK0o6Se2t+79rZX3q0ua3sMn61PSVkRyoSfaPktRi/UFwK+BQ9wQbSr/S57sErVT7JG+xPYTG9q2TY7VW6Y8sLbiVCKDk/U5SmW1wX7E3/MxRC3bm8qS4J/bXrf6/tH2vUVRquUmphIZbCmXmLZzKHCppKvo/0VMyBZV2m1j+0IASVsTV6DrvgFcKOnkcns34Niyx6C+hLPtfoSUUhpm6B6weWYt4GpJFzP8fbe3tOm5xMTwctXWpxV9RZMV+xGf2vTEmlhYfANJrQuLz5BW+4aIyf5viGjCoKQ7AG1KfbwJOFHSfvQvHVyJWCY3KUm9SRpl3CPL4Frua7W1osNJapsMrg9Xfx6BvtsDJudd9gJtSWTnnewKfts+/3fY5LCwu5UtGWTbyZtMVPt5fp+IjC8iln7uSf+S4xkn6ePEpOhwopTCn1o8rFWmZdufKEt1bycu5rzH9hkD2ratrXiOpH8l9uvuAryRpVuWuvb5JWKlwlmKJE2HEhPfLYifR1N2zOuJfYS9ZZ0rEOU+mgxNjtWjFrUV3a0UR6s+R2wv4FOuJbmy/efyPgv9y3Pbls4Yul9R0kEuW9Uk7eUocUS5/eHq++sgGUFsQZFW+ktEOP3+NwE31GLpcoVe0lOJtd0iNvYvZoASYWzaj5BSSguOpGc0Ha+/75Z9UI8iLpxtTpzc/8j2U8v97ySWV60E/Ln3MCIb5OG239nw3N9jQGFxohh4p7pxU9ElQjBJP4fZfnP5+guUUh9ltcpDgNNtb1V7zE7EhFrENoYfNvR7JROv5K9BJEZ7uQdnP2wz5iuArdyfwXWx7ScNaN/L4lqd+P2m1uYC4iS1Hm07odw/MIOr7Y+oksFVkXRkENt+f8MYD6HlFX9FBsn9bf/PkOdp3aeiNuEjiAlNtd2JlTbXAv9cedgnqrc9sWzJoDH9xvY6bdrWHtf7mW5IXJQ4mfgd7EZEfV7Ttc+Oz38f8bO5h/7X9bDI1E9sb10/3tDuo64lh2o6Vo5PqK1I7K87tdauVaSxTZ+qrHKT9DngZtuHlNuX2d6i0lcvwr4O8Xs6o9zehTiPfUnD8/f1MeTndAWxHLVXW3FlIqNx43tem8hg1z5HQZF862nEz+li27+v3d85gtjiOafdZ04QW1Ckwm48WWlo22o5TXnD/pYn2dhe6Xc7Jl75/OrAB6SU0gNAOVHagthXcZsiycKjGpYmHdo0GRzQ53eA13hiYfHXECcimwx7/EyQ9DGiBMHLiav5byT2pw9MsDKgnwknCupfAjphC0TLfuv/6wzc2jsRmw5JBxElKY5kaQbXU9yfvK3XtjGLa/0EcLKTVEn/TuzzfKtrGVyJCeXfu5ZEQtLT69HFpmPl+HUNT2vbEzIUlkjoFsBFDImet+2zXERpardfrU19YjSo7bCaid+1vfaA+ycl6XRiD2rvd7AqcLwnyYA7FyTtQywdHZppuemEXFEru2k56NXArq7VVrS9UUPb5YnAQS8qeHe9TZs+FavjtnBka74aeG0v4iXpqur7nWL56UC2mzItfxC4wIOTY/XaXUlcGOotW12RmFBt2tC2Hhncg7jgd1itXes+R0HSq4n3p7OIv49nEBcZ/6PS5l4iUi4mXshc0fZylbatIoO19/j6trVWW9NyiWk7SyQdCpzC8HTrXZbTXAK8S1Hz5yRistgYQdSA/QjEHoGUUlpw1L/XZHkiNfydDVfyTSTU2JVImrEyDfWoiELZq7vUnFWUBNrB9rcb2j7WkxQWnwXvICIEVwKvI5bdTSiZ1FGXUh9DdfhfN5W+22ZwhfZZXGcyg2vPYUys79Z0jPrkchKHtGnUtk+3q+3XpWxJp5qJHa1Df63Hu4mL4/PR0EzL5bXzRmA99ZdUWZXmrUfQsrZiU1RQ0oRIY8s+jyWWrN5C1PI+rzzH46llb26aALZwAPCvkv5KJKoaFJU9kva1FV9N1LbtRQY/SuyfrS8d7dLnKBxE7NW8tYzzocAFRBZkoHPpjJewNKvyO1la2xRiC0lv6Wj1Yk89EtgqMpgTxHZ6M+1tKsfufxOYivJHdrRiU/SewEcVhXGf0NC87X6ElFJaEFzbayLp+cQynbrPU5ZNEhPEO4jMilvV2r3X9kmV/m8ry9qaJohtCouPTJnEHe1IjPLlGey6S6mPufZzYo/dmZIeJGlV19LCFzfQrgRJ7yT1bmLSUT9Jva/pf6ztexX78S7sHZO0LZFEZU31751bjQG16BRLWN8A/F059COijvGECw6OGndrsfQ1fJEb9r627VPSo4kT56cT5y4/Bg6wfWOlWeuyJe5WM7GrY4iLOSeVse7B/M21sAew3qDIHZFr4lRiT987Ksfv8MRlwJ1qKxKT9B3rUcHyfJ36tP0hST8E1iaWnFeTNDWWUVEUgP8AkWl5WYYsxa2/lw/iFrUVq0Ogfz/jvTBxv17HPkfhRuJ/Us8dxHvWVLXdr7i5pNvLsZXK1702TRdQJ8gJYgsjfjN8PLFE4LFMTE7TcxWxf2DofoSUUlqobH9b0jsa7tq6t2yytPtDWXpVt6jh2KD/gZMWFh+lMilZU9LyQ04+27r/pMH21yUtIWqlCXi+J09eMuvUrcbbtcCPFPtGB2ZxbXGS+jNJL3dzBtf6z2h5YkK1LBEN6rmd5oQeEEuUlyMuaEBEnnrLlvsoioB/nJjwCThM0ttt1+sYtu3zSGKysle5vW85dn9tQ9tNtSMpF7HPBOp1LZvaNtVM7KRMVk5l6d6y2T6h7+JyosZfY+Kqslrhj0QNPBRJplYEVpG0ivv3yXatrdgm0ti6z+oFkMqxXzQ8b8+niaQ+V04WvFAkvpnAtcQt1YcwuLZiT9fIYJs+R+G3xDhPJibnuxMXQA6EKWWbbhUZ7BiVbJR7EFuQtDqxhrj3Ij+HWEM85cLJJRz+AmJ5wLeAk1xSeje0bbUfIaWUFgr1ZxJdRKykeIbtbWvtfkJEcy4uE8U1iavgT661+w8i+vc54h/pm4GH2H7l6L6LqZP0JWKp4ilUingPOqGQtLIb9v9JeqXto8rXnUp9zBVJl1EyuFb20Vw5YC9SY8KY+oRHGp7BVdKjiP1Mf6Ehg6vt3zY897pemldgEVHb+PZ6u3J/qxJYvePALr2oYXlNn9nm8QOOTdh/2XRskIY9TDsRE/ZHEhH4DxMXUUTU12uV0GbclcjUZkQ0bthe0d2ILKyPJCZx6xIlDhqTLk3ynL33xV1KP9Wo4DW239b5G5mCcl66s+1Jl6gr9nT3rEj8bS+xvVOt3XuI7+MEygUsYv/pBwf0+xSWRgbPa7qQ0LXPmTbo/aln0IWZIf213q84XRlBbOc/iCjei8rtlxFXL+qp0Lu4jjipWY9ID7yZpEFXVA6ZxvOklNI4ql79vofILNlUh69p2eSEcgjEhPDdxAU5EYkl3tT0xOUk7KNEFksxZPnUCP2ufCyiP0rVR5HA7CtERGsdRWa/19l+I0Bvcli0LvUxx/5q+26VaiWKDK6NV7N7J1iDJsgV1aXIHyAKwn+OsoyzTAC3Vn8G11PdkMG14lBJryeWty0BVpf0b7Y/3tD2Xknr2/5VGe96DE75v6i2pPRWmiPgbfu8pURCjy239y59Tkq1siXFJ4kIb69m4oVMoWbiAjD05L/ig8QWpTMdGYl3pEQV6zR5bcWukcY2fU7FQcD3JZ3DJPVXbVfHTLk4MyHhFPEzqdZW/AiRr2PYZG6yyOBU+pwxlfenVeNmq/Ipw/qbdmSwrZwgtrO+7T0rt99XrnBOx71EVqNHE8lntiHebCfsa2y7HyGllBYKt0us0XrZZJk8NC1RbfIxJiksPmodrix/Cng2EWnEUQeyb0mXKqU+antR7mZm9zjOlHPUssZb2Q94BAMmyBWtliLbPov439zGxo5ENi8lkgj9CzFRbJogvh04W1FOQkT0Z9Br/AeSTmPphO7FVPaWTaHP/YDPEq8VE0ky+tppkrIlteP2zNRMHGtuKHU2wN9s3yppkaRFts8uq8iaDK2t2PZ9sUufU/Qh4iLLikxSf7XBjUBTJujraVlbsSEyeKSkpshg6z5HQdImxL7aNcrtW4gyQD+drTFMVU4Q2/mLpO1t/xhA0tOJZSjTsT8x4bvQ9o6SNgIG7QFoux8hpZTGWvnHP4htf6DSdhFwhSMN+9DsiWWZ3kFEdOj+Tfr1ZU5Fm8LiIyHp07bfUpZlNSVNmXDV3/YNvWhbcW/t/kOJaFfrUh9zrEsG108zyQS5mLEMrhXLKRLFPB/4rO2/SRoU6fyhpCcQdf5EvF4bl3jafnuJYvfqJB/uSoKlrn2WvW71ZY9vIX52PbvWH8bgsiUPri0BV/X2A2iJadtMy7dJWgU4lyjUfhOxKqLJXbb/vcVzd4kKtuqzozVsP6tNQy2tnQgRCd+C2L9Zv/+vREKdvtqKA7odGhmcYp+jcDhwoO2zy7h2IC7KbTeLY5iSnCC283rgq4q9iBDLLYbWgmnhLtt3SULSCravlrThgLYHE3Vc+vYjADlBTCktNE0npCsTE4aHEssDAbB9n6TLFRmgf9PwuKqvE8tLdyXe019BLMtqsljStxhSWHyEjimfP9Gy/Q1lmalLRGx/JiZV6akmtegtMX1X130wo6QpZHCdbIJcjCKD65eICMXlRJbbdYlENYPG+Vfg/nIHko4nyjo0tT2RpTXekHS+7adPp8+aA6lMEN2tbMk59E8oz2Hp0kdXx72QuX2m5d2JoMJbiX2wqxMZl5t8puxbG1pbkW5RwbZ9dnGmpGfZPr1F22oJt3uAY91fK7R3/xLib7TnR0P6vJ7hkcGp9DkKK/cmhwC2f6TIhj3v5QRxCPWnr/4qcZICcQLzTCpvylNwo6IO17eBMyT9gVjK0aTtfoSUUhprtu+vsVb2bRxALIf7Js3119YmrhBfRH8yl/qV9IfaPkLSAWVp2Dll/0yT1YjN/9Ur5LNy4mt7Sfl8TrkYiO1BE1mIye5niEyfNzJkbyWws6Q9icn2w4j99W2Xyc0Kd8/g2mqC3HYpcsex/jsx8ez5ddlf1laXjIptJn1d+pxONscuNRMfMDwg03IlCnsfUd5sGaKe3dcbuhlaW7GiS1SwbZ9dvAk4SJPXNsT20eVvc4Ny6Jr6/W2ftG1ksEufI3atpHez9MLfvkQOknkvJ4jD9a4ObUgsBz2Z+CPYl1gqMGW29yhfHqLIBrU68IMBzZv2Iwwq9ptSSmNNkVr/QOJq+9HAU2zXE2X0tI1+9WrD/Y+iyPTviD3gE0xxn8+MUITC3gv8E/H/ZpGke4DDbE+IOti+hfg5Tcr2PpJeTCzd/DOwd+1K/nxxPXC+pDYZXFtNkLU0W+vVDcempOQG+DDwSNvPkbQx0NsT2UaXNPJt2850uyatayYuZGrOtOzK/asRr8VHEUugzyi3307knmiaIE5WW7GnS1SwbZ+t1aOnw5RllUcTf9cCHiPpFa4lZVS72oqdIoMt+xyl/Yj/Ub2Li+cyeO/xvJJlLlqQdDqwp0uR3nJV+3jbfz+LY6jW5Dq3aT9CSimNO0kfJzJEHw58brpZ3yr97gqcBzyGKBq+GvA+26c0tG1TWHwkJL0VeC7w2l40RpGd8gvAD2x/qhyr7uuZwPb+DX0/gThRuxJ4IlF790Dbf663nUtqWbqiY5+X2H5K5fYyRA23jafR56lERvODbW+uyLZ6qSvlOAbtJSX+l+9ke+VK20GZ0QV80faaXfqs7ZGrt1vJ9owGCcqFnTOrP+eFTNKRlZu9TMtfrmwHOpnYkvRfROT6IcRexQNsNyY6LEvb3+xJEhFKOpSICv6KSlSwaU912z67kPSfxAqEH3iSUhclcr+P7WvK7Q2IZaZPrbX7JS1rK3YY54z32eG5lwE+Yvvts/m8MyUniC1IuhrYvKz1R9IKwOW2N5rbkaWU0sIi6T7iivg99J/c9l35HXLyC9Hw/ivE5R/1/r3JVYsxnEEUFq8uC3qpp1EAvC1Fls1dSmSweryvvqOkofvgm5ZYlf9lbyrJTUREaffzFOqxzbW2E2RVMrjSXzPsbuJkvm1m26YxXGx7K1XqBKpWX1DSMwb30J8JszbhaGr7qq59tiHpIUMi9J2oVjPxgUyV2p3lPegWYJ1esGHAY35Eu9qKVwObtYkKtu2zC0nPJCJh2wDHA0fZbkwUJukK25u1ONaltmKryGCXPkdB0llNk/ZxkEtM2zkGuEjSScQ/pD2Iq7AjNcnVv9kMkaeU0qyw3Wp/dW+Jk6T3A78n3qd7xdBXrbW9V9I/EGn+21jTdvVk/ShF1sfZsFx9cgixD1GRMbN3eyr/g57mUsi9XE3/ZFnGOS+oWwbXxfX7m3i0GVzvlPRQlmZG3Qb4Y+35W03WJJ3g/nJawzy2ze+/Q58/BKYd9VNzzcQFR+0zLf+tcvBeSdcNmxwWbWsrXg48GGgTFWzbZ2u2zyQS1axOZBQ9Q9INRGKpr9n+W6X5YklH0H/BbUlDt61rKxIJltpEBrv0OQqXlvfY4+lfLj/vEznlBLEF2x8qS0n+Xzn0KtuXzsLztl7jnVJKD1DPtr115fYXJP2EiYWYL5D0WSKTafUfddOenSkXFp8BwyIC99/XZTIl6SDbH3PU7NvL9vGVpq8iImzzQesMrlOYII8ig+uBxN6y9SWdD6xJZEedivU6tD2Adhep2/bZKWGNutVMXIjaZlreXFF3tPfzXalyu/Eif4fo71rA1ZImjQp2jSi3VS6O7Essdb2U2FO5PZEheodK0zcQey/3J773c4gl83VdaiveAFzVYtnodOo1zoQ1iP8d1SjiWGT6zSWmKaWUxpakC4DPEVlOTUzm3mR7u1q7sxsePmjPzjpEYfFtWVpYfH9PXkpj2iTdS/MJqIAVbS9X2j3V9pJByw1rSxfv33/XsBev7/Z8oUkyuHaMNiLpG0TEpS+Dq+1/nuY4l2VpHcJrapGTLv20/j20XcbZts+urwFFOY+qYTUTFzQtzbT8auA44JPT2eunlrUV2/zdd+2z4zhPBDYiLuocafv3lfsW296y/A2vaftntcduQtSavbl2fLHtLVs+/1bERHxoZLBLn6Mg6emuJQJrOjYfZQQxpZTSONuHyGL5GeIk6PxyrI/t1uUH3K6w+EjYXqZl05tL+zbRAQ34uun2nCn7IttmcO1UL9IjyODakFRmA0l/JJa9zVhCkAZzemXf3WomLkhqmWlZ0iLgCtubtOm3vnJMA2ordokKtu2zjTIxuxH4rO2zyl7oL0n6NXCI7f+rTMgOozlS+Chi1UL9fbpLbcW2kcEufY7CYUxcvt10bN7JCGJKKaUHBEV5iycRJxUANEw8Bj32N7bb1qIbuVpUcOhes3GJIKplBtdyfJ0uEV2NIIOrpO8RUeZedHoH4EKi3tv7bR8z4KFNfbVO7tIhgjij7VJQx0zLkr4OvHOqKxAkXWh7m9qxaUUFm/ps+bhLgGfa/j9Jf0es3HgzsAXwRNsvrLT9qQckwJJ0VX3SXL6nlYmI4NDaim0jg136nEmStgW2A95C/9731YA9bG8+yuefCRlBTCmlNHbUscyDpC8CDwJ2BL5C7BW7qMtTTmGYo1Qdz2R7zap7oXr7oHp9rDj4YbPu5dQyuNq+tuwHPZ3+E61vU67Ct0zG8h0mZnC9mLhgMFX3ESfF/1vGsRYxmd2aqHfWeoII/EuHtueX59sV+L4HZ2j8l9JufeBG239V1KTbDPiq7dtKu507PHeCtxETjncRtR97xwdNPtYmirpfRP/+5wn7BTVJbcXKY1tHBdv22dIytv+vfP1i4HDbJwAnSKqX7liOwSbc1zHvRqvI4Bzm8lieqBe6LP1J025n6vuUZ1VOEFNKKY2jXhbLpwMbE8lnAPaiOUPedrY3U6RXf5+kT9ItUcB8W27jAV9PbNh+2epca5XBtegyQYbRZHB9bG9yWNwEbFCiK317ESU9HTiEiWn51ytjOr3SdgVgT6L4/P3nab1ot+1/KodeQhRMP4HYB/bz6nNW+jwB2FLS44EjiMQ63yCitVRO+FMLbplpuaJLIqTdKl/3aivu3mJM35Y0qGTLlPocYBlJy9q+h7iw8NrKffU5xX9Leq7t71cPSnoOcG29Y3WorUgkvTlI0tDIYMc+Z0xZAnyOpKPGdUl2ThBTSimNHZcslpJeCezYSw5SIoVNV5X/Uj7/WdIjicxyj6s20CSFxWdm5DNmWFRw5EuoRqRVBtei1QRZo83gep6k7xIp7CEmdedKWhm4rdb2COCtxMWLeyfp92SiXMYSKgk46mzvK2k1IjHTkZIMHEkUIa+WU7jP9j2S9gA+bfswRb3NNAtsn1MS+zzB9pmSHgQ0XrRxqXU5mS5RwbZ9tnQsMfG5hXhPPa+M5/HUSrwQr/fvSnoRSy/abUksy961oe8vEn+Th0kaWluxQ2SwdZ8jsoKkw5l4sWfe10bMPYgppZTGlqRrgG17URBJDwEutL1hrd27ieQAOxNZTw18xfa7Z3nIaQC1zOBaa9ubvP+50vb+CfIo91+Wpap7ElFsAT8GTnDDiZWkn7i/HMuwfifsz5qk/cOIcgNvAX4OPB74d9uH9Z6bSLB0MLCb7eu6PkeaOkn/SETa1rC9ftkP+0XbO1fatK2t2GtfrdPaiwp+2ZXkSF37bEtR73Nt4HSXzLWSNgBWca1sUImG7wP0Xms/Bb5h+64h/fdqKx5MlLOYUFuxa2SwTZ+jIOlyYpLad2HIdtMql3klJ4gppZTGlqRXEUv3eolCngG8z/ZRQx6zAjHhqF/xTgtMNQFLPRnLbCZnkfQRImp0Iv1p+SfU4SwRh8NsXzlJn/9AREfWJ/Y7Hm37phKh+rntdUu7jYHXA/9l+1hJjwNebPsjM/PdpWHK3rynAT+pvBavtL1ppc3bGh56f21F26tM4XlnvM9RU39txd+xtLbiprZ3qLR7JvHa34aI4A+MDLbtcxQkLbH91FE+x6jkEtOUUkpjy/aRkk4lEoMAvMOVmlxVkrajstRHEra/OisDTXNl2FLUaV0hL8v8Pgo8nIggDlve23t9VjMvmkoBbS0tQL8s8CpJ1xKTyV6/m9X63BP4lO1zqwdt/1nSfpVDu1STNpUI4l9Is+Wvtu/uJbNR1M7se+3Z/mTvay2trfgqIkto9b7WUcG2fY7KJEv2m/YLVmsr7lp5H/+WpMXVtrbPJBLV9CKDZ0iah36yjQAAE6NJREFUEBns0ueIfEfSG4GT6L8wNO/3/WYEMaWU0oJQsjXuDbykvnxO0jFEpOUyli71sWvZTtPCMslS1L5lq1Po+5fEks2fT9q4XX/1AvR9qskuJC0DnGb7mS36nbCUdjajpw90kj5G7El9OVES4o3Az2wfXGtXr634GddqK3aNCrbpc65paW3FJ3ppbcUXAPfXVhzwuIGRQeDtU+lzpkm6ruGwXZJTzWc5QUwppTS2JK1NpFvfh0jffyhwYn15nqSfAxs37Q9LaSoknW/76ZO02df21yQd2HS/7X9reMwxtl/W4tgpwMsGLZWWtDfxd7E9JZlIsSpwb5vJZZo+SYuICdyziAsTpxH7n11p06m2YnlMLyr4auA44JO1PYid+xwVSZsD/6/cPNf2FZX7WtdWrDymGhk8srpqpEQGF3XtM/XLCWJKKaWxUxI/7A08mjg5Og442fbjBrQ/Htjf9v/M3ijTQibpM8AjiJqM1eVjJ1bavM72lyS9t6kP2xNKIDQk01kGuNL2xrV2xxF7sM6gv77e/uX+dYlMvYcC1RIIdwBXOEoVpFkgaXliQmPgGtt31+6/j3gN3UP/sswJyzHbRgW79DlKkg4A/pGlZYX2IOon9pIoXe5SOF7S54CbbR9Sbl9me4tKX62ijV36HNH3fJDtj5Wv+7InS/qw7elkT54VOUFMKaU0diTdDfwX8Dbbi8uxa+tLdyR9hzg5WpW4enwR/SfzE4pVp9RGLZNkj23v13C8TX/vJMpu1JfC3k2cUL+z1v4VTf24lIBJ84Ok5xGZLH9F/D4fB7zO9qlT6GveRAXbknQFkWm6l/F0ZSJh0mbl9lXAFo5SLFcDr+3tq61n220bbezS54i+55FlT54tmaQmpZTSOHoksBfwb5LWIiKITfvJTgHWon+JHUS209+OdIRpQXOH+nKSViSWAj4JWLHSx36Vrw8FDpV0aH0yOOD5jy6RqQ3KoWvckLa/YzKdNPM+SdRq/SXcv1f6e0DnCSLwNuIC17uAg3uJb5jfv1PRX/vz3nKsp0ttxWUq+wdfTFw4OQE4oWSLnUqfo6ABXzfdnpdygphSSmns2L4F+ALwBUmPBl4C3FT2Gp5UWcKzO/Cv1T0vAJLuBN5LFDBPqbPyujuMqINoog7iAbZvbGh+DHA18Gzg/cTywMbkNrbfqajn+QT6J5N92Uol7UAsMbyeOOl8jKRX1NsBH2MGk+mkzm7qTQ6La4GbBjUexvaimRnSrDoS+Imkk4jX6e5U3ndtf0jSD1laW7G3tHERER2sWkbSsmV59M5EfcmeaiH6Ln2OwsiyJ8+WXGKaUkppwVAUbN67t7dr2HIi1WqRpdSFpDOAbxCTP4iMii+1vUtD20ttP1nSFbY3k7QckYV0p4a2ryGSjzyayLq7DbEkb6dauyXAPravKbc3AI51re5am2Q6aeaVyC3ALsC6xCoHEysfrrHdlJF0QZL0FCJZEsB5ti+dYj8HA88FbgHWAZ5i2yUyePR8eZ2PMnvybMkIYkoppbFVlu69kTj56EVxPlppsmLT44qVRji0tPCtabu6D/EoSW8Z0La39PM2SZsAvydqcjY5ANgKuND2jpI2AiYkswGW600OAWz/okw86xZL+hZDkumkkdit8vX/EsvaAW4GHjL7w5lzAu5jGkss50FksBXby8z1GKYrJ4gppZTG2VeJrIyHldt7l2MvKrcvlvSPtr9cfZCkVwNLZm2UaSG6RdK+xH4niNferQPaHl6Wjb6b2Be7CjCo6Pldtu+ShKQVbF8tacOGdoslHcHSCOZLaX5Nr0ZEMJ5VOWaWZpVMI9Blj+pCJuk9RNT0BGJyeKSk421/cCr92b6w4dgvpjfKVJdLTFNKKY2tajrzpmMlgc1JRCbI3snzlsDywB7V+lkpdSFpHeCzwLbEhOsCopTKb6bZ70nAq4C3ADsBfyCihc+ttVsBeBMRPRdwLpHZ8m7SvCHpcUR067H075N7QGRQLvvCn2z7rnJ7JeAS20+c25GlYXKCmFJKaWxJOgr4Yu+qsqStgVfYfmOt3Y5Aby/iT22fNasDTQ8Ikt5i+9MNxx8MvJyJk4T9J+nvGcDqwA8aaucdYPszLY5tQCR0Wsv2JpI2A/5hqhGc1I2ky4mkLFcSSywBsH3OnA1qFkk6ldgXflu5/WDga7Z3nduRpWFygphSSmlslavTGwK9qM06RHbI+4i075vN1djSA4+k39hep+H4BcCFTJwkHF1psyLweuDxpd0RHlLMvqmeWi8ZTu3YOcDbgS/17puNWnApSPqJ7a3nehyzTdJhRGR9HWJP7Rnl9i7Aj22/ZA6HlyaRexBTSimNs7+f6wGkVDEoAceKtg+c5LFHE8lszgOeA2xMJKzpfwJpb2Af4HGSTqnctSrNeyAfZPuiSs08gIETzzTjPiPpvcDp9CcJumTuhjQrFpfPS4hl/j0/mv2hpK5ygphSSmnsSFqjfHlH0/2VYsopzaZBy7KOkfSPwHfpnyRUX6cb98qulOQzFw3o6wLgf4CHEUXYe+4Armhof0spzu7S9wvL49Ps2BR4GbGftBc9drm9YFWj42n85AQxpZTSOFpCnGQ1RWwMrDe7w0kPFJLuoHki2Kt51uRu4OPAwZXH1l+nvVIY2L6nFvGjct+vgV9Leinwu1ryj0cD19ce8ibgcGAjSb8FriNqNqbZsQew3gM1eZCkXYEPELUglyX+Tmx7tTkdWBoq9yCmlFJKKY2QpF8BW9u+ZUibXnFt6C+w3XhCLWkxsF1v4iFpeeB821sN6H9lYJHtxqh7Go1Sg/LNtm+a67HMBUm/BF4AXOmcdIyNjCCmlFIaO5LWBW6z/cdye0fg+UT0JFP9p/nmp8Rkb6ApFNdetvo6t313mST2qWdQ7UUmJ8ugmmbMWsDVki6mf3nxA6LMBXADcFVODsdLThBTSimNo+OIpVt/lLQFcDxwKLAF8HngNXM4tpTq7gUuk3Q2/ZOE6UzSbpb0D7ZPAZC0O9AUofw+DRlU06x571wPYI4dBHy/ZNOtvvb/be6GlCaTS0xTSimNHUlX9EpYSPoEcJ/tgyQtAi7L8hZpPpH0iqbj00nkURLPfB14FLGf8Ubg5bZ/WWs3oRxGSrNF0unAn5hY4uV9czaoNKmMIKaUUhpH1QweOwHvBLB936DkHinNFdtHl+WfG5RD19j+27DHtOjzV8A2klYhLvgP2lvYJoNqGpFaUqPlgeWAOx9ASVrWsP2suR5E6iYniCmllMbRWZKOI9L1PwQ4C0DS2kTGyJTmDUk7EHUOrycubjxG0itsnzuNPtcCPgw80vZzJG0MbGv7iFrTNhlU04jYXrV6W9LzgafN0XDmwpmSnmX79LkeSGovl5imlFIaO4ow4YuBtYHjbP+2HH8y8HDbp83l+FKqkrQE2Mf2NeX2BsCxtp86jT5PBY4EDra9uaRlgUt7tRQr7SbNoJpml6QLbW8z1+OYDSWCujIRvf4bWeZiLGQEMaWU0tgpGfG+2XD80jkYTkqTWa43OQSw/QtJy02zz4fZPk5Sb3n1PaVURt2kGVTT6Eh6QeXmImBLmutoLkj1CGoaDzlBTCmlNHYmKVaeV6fTfLNY0hHAMeX2S4El0+zzTkkPpfwdSNoG+GNDu1FkUE3t7Vb5+h5imfHuczOU2SfpP4H/AH5gO7PojolcYppSSimlNEKSVgDeBGxPXMQ4F/i87b8OfeDwPp8CHAZsAlwFrAm80PYVtXYznkE1pbYkPRN4FbANUY7oKNtXz+2o0mRygphSSimlNGKS1gSwffMM9LWIOOG+CNiQmHROOzNqmjmS3jPkbtv+wKwNZh6QtDqwN5Es6Qbgy8DX8jU7P+UEMaWUUkppBEoypfcC/0RM4kQs+TzM9vun2fd/2d62RbvraFiObTuzmI6QpLc1HF4ZeDXwUNurzPKQ5kxZCr0v8DLgd0T9zu2BTW3vMIdDSwPkHsSUUkoppdF4C/B0YCvb1wFIWg/4gqS32v7UNPo+XdKewIkefrV/y8rXKwJ7AWtM43lTC7Y/2fta0qrAAcRSy28Cnxz0uIVG0onARsT+211t/77c9S1Ji+duZGmYjCCmlFJKKY2ApEuBXeolJspy09NtP3kafffKB9wD3EWHBE2Sfmx7+6k+d2pH0hrAgURSoqOBz9j+w9yOanZI2gq4EXii7bPKXtgXAL8GDrH9f3M6wDRURhBTSimllEZjuab6g7Zvnm6Zi7blA0oym55emYUsPTBikj5OTIgOJ5ZS/mmOhzTbvgQ8s0wO/w44FHgzsAXxM3nhXA4uDZcRxJRSSimlEZB0ie2ndL1vkj43sn11beJ3P9uX1NqfXbnZK7PwiWpdxjTzJN1HlBW5h/49oA+IUjySLre9efn6c8DNtg8pty+zvcVcji8NlxHElFJKKaXR2FzS7Q3HRewHnIoDgdfSvI/NwE59B+wdp/g8aRpsL5rrMcyxZSQta/seYGfiNduT8495Ln9BKaWUUkojYHuZEfT52vK51cRP0oENh/8ILLF92UyOLaWKY4FzJN0C/AU4D0DS44nXX5rHcolpSimllNIYKWUD9iGyQwL8HPhGU+IPSd8g9h1+pxx6HnBxeezxtj82+hGnByJJ2wBrEwmZ7izHNgBWqS+FTvNLThBTSimllMaEpCcCZwGnAZcSy1WfDOwC7GT76lr704A9e0lSJK0C/CewBxFF3HgWh59SGgO5xDSllFJKaXx8ADjA9nHVg6Um4oeAPWvt1wHurtz+G7Cu7b9I+utIR5pSGks5QUwppZRSGh+b2p5QIsD2CZI+3ND+G8CFkk4ut3cDjpW0MvCzEY4zpTSmcolpSimllNKYmErpDElPBbYnlqP+2PbiEQ8zpTTGMoKYUkoppTQ+Hj4gM6mANfsOSIuAK2xvAiyZjcGllMZfThBTSimllMbHl4FVB9z3leoN2/dJulzSOrZ/M/qhpZQWglximlJKKaW0QEk6C9gKuAi4sxy27d3nblQppfksJ4gppZRSSmNskn2Jz6jeJPYi7m37SbMyuJTS2Fk01wNIKaWUUkrTokF32D4H+CPwPOAoYGfgi7MzrJTSOMo9iCmllFJK4+179QOSNgBeAuwN3Ap8i1g5tuMsjy2lNGZyiWlKKaWU0hiS9AjgaYCBi23/vnLffcB5wKtt/7Icu9b2enMy2JTS2MglpimllFJKY0bSa4jEMy8AXghcKGm/SpM9gd8DZ0v6sqSdGbIUNaWUejKCmFJKKaU0ZiRdA2xn+9Zy+6HABbY3rLVbGXg+sdR0J+Bo4CTbp8/ykFNKYyIjiCmllFJK4+dG4I7K7TuAG+qNbN9p++u2dwUeDVwGvGN2hphSGkcZQUwppZRSGhOSDixfbgFsCpxM7EHcHbjI9uvnamwppYUhs5imlFJKKY2PVcvnX5WPnpPnYCwppQUoI4gppZRSSimllICMIKaUUkopjR1JZxNLS/vY3mkOhpNSWkBygphSSimlNH7+ufL1ikRZi3vmaCwppQUkl5imlFJKKS0Aks6x/Yy5HkdKabxlBDGllFJKacxIWqNycxGwJfCIORpOSmkByQliSimllNL4WULsQRTwN+B64NVzOaCU0sKwaK4HkFJKKaWUOvsXYAvbjwOOAe4E/jy3Q0opLQQ5QUwppZRSGj/vsn27pO2BXYCjgC/M7ZBSSgtBThBTSimllMbPveXz84Av2j4ZWH4Ox5NSWiBygphSSimlNH5+K+lLwIuA70tagTyvSynNgCxzkVJKKaU0ZiQ9CPh74Erb/y1pbWBT26fP8dBSSmMuJ4gppZRSSimllIBcipBSSimllFJKqcgJYkoppZRSSiklICeIKaWU0lCS7pV0WeXjsVPo48GS3jjzo0sppZRmVu5BTCmllIaQ9Cfbq0yzj8cC37W9ScfHLWP73slbppRSSjMjI4gppZRSR5KWkfRxSRdLukLS68rxVST9UNIlkq6UtHt5yEeA9UsE8uOSdpD03Up/n5X0yvL19ZLeI+nHwF6S1pf0A0lLJJ0naaPSbi9JV0m6XNK5s/sTSCmltFAtO9cDSCmllOa5lSRdVr6+zvYewKuBP9reqtSfO1/S6cANwB62b5f0MOBCSacA7wA2sb0FgKQdJnnOu2xvX9r+EHh9KWWwNfB5YCfgPcCzbf9W0oNn9ltOKaX0QJUTxJRSSmm4v/QmdhXPAjaT9MJye3XgCcCNwIcl/R1wH/AoYK0pPOe3ICKSwHbA8ZJ6961QPp8PHCXpOODEKTxHSimlNEFOEFNKKaXuBLzZ9ml9B2OZ6JrAU23/TdL1wIoNj7+H/m0e9TZ3ls+LgNsaJqjYfn2JKD4PuEzSFrZvnco3k1JKKfXkHsSUUkqpu9OAN0haDkDSBpJWJiKJN5XJ4Y7AuqX9HcCqlcf/GthY0gqSVgd2bnoS27cD10naqzyPJG1evl7f9k9svwe4BXjMzH+bKaWUHmgygphSSil19xXgscAlirWfNwPPB74OfEfSYuAy4GoA27dKOl/SVcCptt9eloZeAfw3cOmQ53op8AVJ7wKWA74JXA58XNITiGjmD8uxlFJKaVqyzEVKKaWUUkopJSCXmKaUUkoppZRSKnKCmFJKKaWUUkoJyAliSimllFJKKaUiJ4gppZRSSimllICcIKaUUkoppZRSKnKCmFJKKaWUUkoJyAliSimllFJKKaUiJ4gppZRSSimllAD4/+oQevGjPrBKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b=all_.describe()\n",
    "c=b.iloc[0,:]\n",
    "a=b.columns\n",
    "c=pd.DataFrame(c)\n",
    "c=c.iloc[:,0]\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.barplot(x=a, y=c)\n",
    "plt.xticks(rotation= 90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Number of None-Empty Rows ')\n",
    "plt.title('Number of None-Empty Rows for Each Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useless Features are eliminated\n",
    "all_.drop(columns=['Entropy_DirectoryName', 'NumberRate_Extension', 'argPathRatio'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nan-Values replaced with mean values\n",
    "all_.fillna(all_.Entropy_Extension.mean(),inplace=True)\n",
    "all_.fillna(all_.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Number of None-Empty Rows for Each Feature')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "b=all_.describe()\n",
    "c=b.iloc[0,:]\n",
    "a=b.columns\n",
    "c=pd.DataFrame(c)\n",
    "c=c.iloc[:,0]\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.barplot(x=a, y=c)\n",
    "plt.xticks(rotation= 90)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Number of None-Empty Rows ')\n",
    "plt.title('Number of None-Empty Rows for Each Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'URL Types Table')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "aaa=all_[\"URL_Type_obf_Type\"].value_counts()\n",
    "plt.figure(figsize=(15,10))\n",
    "ax= sns.barplot(x=aaa.index, y=aaa[:])\n",
    "plt.xlabel('URL Types')\n",
    "plt.ylabel('Amount of Each URL Type')\n",
    "plt.title('URL Types Table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Defacement</th>\n",
       "      <th>benign</th>\n",
       "      <th>malware</th>\n",
       "      <th>phishing</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36702</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36703</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36704</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36705</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36706</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36707 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Defacement  benign  malware  phishing  spam\n",
       "0             1.0     0.0      0.0       0.0   0.0\n",
       "1             1.0     0.0      0.0       0.0   0.0\n",
       "2             1.0     0.0      0.0       0.0   0.0\n",
       "3             1.0     0.0      0.0       0.0   0.0\n",
       "4             1.0     0.0      0.0       0.0   0.0\n",
       "...           ...     ...      ...       ...   ...\n",
       "36702         0.0     0.0      0.0       0.0   1.0\n",
       "36703         0.0     0.0      0.0       0.0   1.0\n",
       "36704         0.0     0.0      0.0       0.0   1.0\n",
       "36705         0.0     0.0      0.0       0.0   1.0\n",
       "36706         0.0     0.0      0.0       0.0   1.0\n",
       "\n",
       "[36707 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_cate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class Names are encoded in two different formats \n",
    "target=all_.loc[:,\"URL_Type_obf_Type\"]\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "target_label = enc.fit_transform(target)\n",
    "from keras.utils import to_categorical\n",
    "target_cate = to_categorical(target_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy to Dataframe conversion\n",
    "target_cate = pd.DataFrame(target_cate)\n",
    "target_label = pd.DataFrame(target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming classes\n",
    "target_cate.rename(columns={0:'Defacement',\n",
    "                          1:'benign',\n",
    "                          2:'malware',3:'phishing',4:'spam'}, \n",
    "                 inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Orginal Target Labels are replaced with One-Hot-Encoding Target Labels\n",
    "all_.drop(columns=['URL_Type_obf_Type'],inplace=True)\n",
    "all_[\"Defacement\"]=target_cate[\"Defacement\"]\n",
    "all_[\"benign\"]=target_cate[\"benign\"]\n",
    "all_[\"malware\"]=target_cate[\"malware\"]\n",
    "all_[\"phishing\"]=target_cate[\"phishing\"]\n",
    "all_[\"spam\"]=target_cate[\"spam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=all_.corr()\n",
    "b=b.loc[[\"Defacement\",\"benign\",\"malware\",\"phishing\",\"spam\"],:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3600x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#correlation matrix is extracted \n",
    "f,ax = plt.subplots(figsize=(50, 10))\n",
    "sns.heatmap(b, annot=True, linewidths=0.5,linecolor=\"red\", fmt= '.1f',ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Querylength</th>\n",
       "      <th>domain_token_count</th>\n",
       "      <th>path_token_count</th>\n",
       "      <th>avgdomaintokenlen</th>\n",
       "      <th>longdomaintokenlen</th>\n",
       "      <th>avgpathtokenlen</th>\n",
       "      <th>tld</th>\n",
       "      <th>charcompvowels</th>\n",
       "      <th>charcompace</th>\n",
       "      <th>ldl_url</th>\n",
       "      <th>...</th>\n",
       "      <th>Entropy_URL</th>\n",
       "      <th>Entropy_Domain</th>\n",
       "      <th>Entropy_Filename</th>\n",
       "      <th>Entropy_Extension</th>\n",
       "      <th>Entropy_Afterpath</th>\n",
       "      <th>Defacement</th>\n",
       "      <th>benign</th>\n",
       "      <th>malware</th>\n",
       "      <th>phishing</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36607</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>5.166666</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.694218</td>\n",
       "      <td>0.879588</td>\n",
       "      <td>0.795418</td>\n",
       "      <td>0.893417</td>\n",
       "      <td>0.924957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36608</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747232</td>\n",
       "      <td>0.879588</td>\n",
       "      <td>0.862184</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36609</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>12</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780851</td>\n",
       "      <td>0.796692</td>\n",
       "      <td>0.958425</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36610</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.770675</td>\n",
       "      <td>0.807835</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.898227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36611</th>\n",
       "      <td>849</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4.333334</td>\n",
       "      <td>9</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>3</td>\n",
       "      <td>96</td>\n",
       "      <td>85</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578298</td>\n",
       "      <td>0.863489</td>\n",
       "      <td>0.576876</td>\n",
       "      <td>0.576187</td>\n",
       "      <td>0.575277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36702</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>5.750000</td>\n",
       "      <td>12</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.690555</td>\n",
       "      <td>0.791265</td>\n",
       "      <td>0.690227</td>\n",
       "      <td>0.656684</td>\n",
       "      <td>0.796205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36703</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>8</td>\n",
       "      <td>8.461538</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665492</td>\n",
       "      <td>0.820010</td>\n",
       "      <td>0.674400</td>\n",
       "      <td>0.674671</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36704</th>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>6.666666</td>\n",
       "      <td>16</td>\n",
       "      <td>3.375000</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.656807</td>\n",
       "      <td>0.801139</td>\n",
       "      <td>0.713622</td>\n",
       "      <td>0.717187</td>\n",
       "      <td>0.705245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36705</th>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>4.333334</td>\n",
       "      <td>9</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725963</td>\n",
       "      <td>0.897617</td>\n",
       "      <td>0.745932</td>\n",
       "      <td>0.758824</td>\n",
       "      <td>0.790772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36706</th>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>6.666666</td>\n",
       "      <td>16</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>31</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.674351</td>\n",
       "      <td>0.801139</td>\n",
       "      <td>0.730563</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>0.769238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Querylength  domain_token_count  path_token_count  avgdomaintokenlen  \\\n",
       "36607            9                   3                 8           2.666667   \n",
       "36608            0                   3                 8           2.666667   \n",
       "36609            0                   4                 3           7.250000   \n",
       "36610            3                   4                 9           4.000000   \n",
       "36611          849                   3                 6           4.333334   \n",
       "...            ...                 ...               ...                ...   \n",
       "36702           29                   4                14           5.750000   \n",
       "36703            0                   4                13           3.750000   \n",
       "36704           58                   3                27           6.666666   \n",
       "36705           35                   3                13           4.333334   \n",
       "36706           40                   3                25           6.666666   \n",
       "\n",
       "       longdomaintokenlen  avgpathtokenlen  tld  charcompvowels  charcompace  \\\n",
       "36607                   4         5.166666    3              12           11   \n",
       "36608                   4         4.125000    3               8            5   \n",
       "36609                  12         4.000000    4               3            3   \n",
       "36610                   7         3.800000    4               9           10   \n",
       "36611                   9         2.500000    3              96           85   \n",
       "...                   ...              ...  ...             ...          ...   \n",
       "36702                  12         3.666667    4              20           24   \n",
       "36703                   8         8.461538    4              24           23   \n",
       "36704                  16         3.375000    3              41           34   \n",
       "36705                   9         3.600000    3              15           13   \n",
       "36706                  16         3.250000    3              35           31   \n",
       "\n",
       "       ldl_url  ...  Entropy_URL  Entropy_Domain  Entropy_Filename  \\\n",
       "36607        0  ...     0.694218        0.879588          0.795418   \n",
       "36608        0  ...     0.747232        0.879588          0.862184   \n",
       "36609        1  ...     0.780851        0.796692          0.958425   \n",
       "36610        0  ...     0.770675        0.807835          0.916667   \n",
       "36611      125  ...     0.578298        0.863489          0.576876   \n",
       "...        ...  ...          ...             ...               ...   \n",
       "36702        3  ...     0.690555        0.791265          0.690227   \n",
       "36703        0  ...     0.665492        0.820010          0.674400   \n",
       "36704       20  ...     0.656807        0.801139          0.713622   \n",
       "36705        7  ...     0.725963        0.897617          0.745932   \n",
       "36706       19  ...     0.674351        0.801139          0.730563   \n",
       "\n",
       "       Entropy_Extension  Entropy_Afterpath  Defacement  benign  malware  \\\n",
       "36607           0.893417           0.924957         0.0     0.0      0.0   \n",
       "36608           0.875000          -1.000000         0.0     0.0      0.0   \n",
       "36609           1.000000          -1.000000         0.0     0.0      0.0   \n",
       "36610           0.000000           0.898227         0.0     0.0      0.0   \n",
       "36611           0.576187           0.575277         0.0     0.0      0.0   \n",
       "...                  ...                ...         ...     ...      ...   \n",
       "36702           0.656684           0.796205         0.0     0.0      0.0   \n",
       "36703           0.674671          -1.000000         0.0     0.0      0.0   \n",
       "36704           0.717187           0.705245         0.0     0.0      0.0   \n",
       "36705           0.758824           0.790772         0.0     0.0      0.0   \n",
       "36706           0.731481           0.769238         0.0     0.0      0.0   \n",
       "\n",
       "       phishing  spam  \n",
       "36607       0.0   1.0  \n",
       "36608       0.0   1.0  \n",
       "36609       0.0   1.0  \n",
       "36610       0.0   1.0  \n",
       "36611       0.0   1.0  \n",
       "...         ...   ...  \n",
       "36702       0.0   1.0  \n",
       "36703       0.0   1.0  \n",
       "36704       0.0   1.0  \n",
       "36705       0.0   1.0  \n",
       "36706       0.0   1.0  \n",
       "\n",
       "[100 rows x 81 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 36707 entries, 0 to 36706\n",
      "Data columns (total 84 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Querylength                      36707 non-null  int64  \n",
      " 1   domain_token_count               36707 non-null  int64  \n",
      " 2   path_token_count                 36707 non-null  int64  \n",
      " 3   avgdomaintokenlen                36707 non-null  float64\n",
      " 4   longdomaintokenlen               36707 non-null  int64  \n",
      " 5   avgpathtokenlen                  36707 non-null  float64\n",
      " 6   tld                              36707 non-null  int64  \n",
      " 7   charcompvowels                   36707 non-null  int64  \n",
      " 8   charcompace                      36707 non-null  int64  \n",
      " 9   ldl_url                          36707 non-null  int64  \n",
      " 10  ldl_domain                       36707 non-null  int64  \n",
      " 11  ldl_path                         36707 non-null  int64  \n",
      " 12  ldl_filename                     36707 non-null  int64  \n",
      " 13  ldl_getArg                       36707 non-null  int64  \n",
      " 14  dld_url                          36707 non-null  int64  \n",
      " 15  dld_domain                       36707 non-null  int64  \n",
      " 16  dld_path                         36707 non-null  int64  \n",
      " 17  dld_filename                     36707 non-null  int64  \n",
      " 18  dld_getArg                       36707 non-null  int64  \n",
      " 19  urlLen                           36707 non-null  int64  \n",
      " 20  domainlength                     36707 non-null  int64  \n",
      " 21  pathLength                       36707 non-null  int64  \n",
      " 22  subDirLen                        36707 non-null  int64  \n",
      " 23  fileNameLen                      36707 non-null  int64  \n",
      " 24  this.fileExtLen                  36707 non-null  int64  \n",
      " 25  ArgLen                           36707 non-null  int64  \n",
      " 26  pathurlRatio                     36707 non-null  float64\n",
      " 27  ArgUrlRatio                      36707 non-null  float64\n",
      " 28  argDomanRatio                    36707 non-null  float64\n",
      " 29  domainUrlRatio                   36707 non-null  float64\n",
      " 30  pathDomainRatio                  36707 non-null  float64\n",
      " 31  argPathRatio                     36707 non-null  float64\n",
      " 32  executable                       36707 non-null  int64  \n",
      " 33  isPortEighty                     36707 non-null  int64  \n",
      " 34  NumberofDotsinURL                36707 non-null  int64  \n",
      " 35  ISIpAddressInDomainName          36707 non-null  int64  \n",
      " 36  CharacterContinuityRate          36707 non-null  float64\n",
      " 37  LongestVariableValue             36707 non-null  int64  \n",
      " 38  URL_DigitCount                   36707 non-null  int64  \n",
      " 39  host_DigitCount                  36707 non-null  int64  \n",
      " 40  Directory_DigitCount             36707 non-null  int64  \n",
      " 41  File_name_DigitCount             36707 non-null  int64  \n",
      " 42  Extension_DigitCount             36707 non-null  int64  \n",
      " 43  Query_DigitCount                 36707 non-null  int64  \n",
      " 44  URL_Letter_Count                 36707 non-null  int64  \n",
      " 45  host_letter_count                36707 non-null  int64  \n",
      " 46  Directory_LetterCount            36707 non-null  int64  \n",
      " 47  Filename_LetterCount             36707 non-null  int64  \n",
      " 48  Extension_LetterCount            36707 non-null  int64  \n",
      " 49  Query_LetterCount                36707 non-null  int64  \n",
      " 50  LongestPathTokenLength           36707 non-null  int64  \n",
      " 51  Domain_LongestWordLength         36707 non-null  int64  \n",
      " 52  Path_LongestWordLength           36707 non-null  int64  \n",
      " 53  sub-Directory_LongestWordLength  36707 non-null  int64  \n",
      " 54  Arguments_LongestWordLength      36707 non-null  int64  \n",
      " 55  URL_sensitiveWord                36707 non-null  int64  \n",
      " 56  URLQueries_variable              36707 non-null  int64  \n",
      " 57  spcharUrl                        36707 non-null  int64  \n",
      " 58  delimeter_Domain                 36707 non-null  int64  \n",
      " 59  delimeter_path                   36707 non-null  int64  \n",
      " 60  delimeter_Count                  36707 non-null  int64  \n",
      " 61  NumberRate_URL                   36707 non-null  float64\n",
      " 62  NumberRate_Domain                36707 non-null  float64\n",
      " 63  NumberRate_DirectoryName         36707 non-null  float64\n",
      " 64  NumberRate_FileName              36707 non-null  float64\n",
      " 65  NumberRate_Extension             36707 non-null  float64\n",
      " 66  NumberRate_AfterPath             36707 non-null  float64\n",
      " 67  SymbolCount_URL                  36707 non-null  int64  \n",
      " 68  SymbolCount_Domain               36707 non-null  int64  \n",
      " 69  SymbolCount_Directoryname        36707 non-null  int64  \n",
      " 70  SymbolCount_FileName             36707 non-null  int64  \n",
      " 71  SymbolCount_Extension            36707 non-null  int64  \n",
      " 72  SymbolCount_Afterpath            36707 non-null  int64  \n",
      " 73  Entropy_URL                      36707 non-null  float64\n",
      " 74  Entropy_Domain                   36707 non-null  float64\n",
      " 75  Entropy_DirectoryName            36707 non-null  float64\n",
      " 76  Entropy_Filename                 36707 non-null  float64\n",
      " 77  Entropy_Extension                36707 non-null  float64\n",
      " 78  Entropy_Afterpath                36707 non-null  float64\n",
      " 79  Defacement                       36707 non-null  float32\n",
      " 80  benign                           36707 non-null  float32\n",
      " 81  malware                          36707 non-null  float32\n",
      " 82  phishing                         36707 non-null  float32\n",
      " 83  spam                             36707 non-null  float32\n",
      "dtypes: float32(5), float64(21), int64(58)\n",
      "memory usage: 22.8 MB\n"
     ]
    }
   ],
   "source": [
    "all_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=all_.iloc[:,76:]\n",
    "X=all_.iloc[:,:76]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values,target_cate.values,test_size=0.2,random_state=4, shuffle=True)\n",
    "#X2_train, X_valid, y2_train,y_valid = train_test_split(X_train,y_train,test_size=0.25,random_state=4, shuffle=True)\n",
    "\n",
    "list_=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout,Input, BatchNormalization, MaxPooling2D,AveragePooling2D,GlobalMaxPooling2D\n",
    "def get_model( no_outputs):\n",
    "    m = Sequential()\n",
    "    m.add(Input(shape=(76)))\n",
    "    m.add(Dense(76,activation='tanh'))\n",
    "    m.add(Dense(76,activation='tanh'))\n",
    "    m.add(Dense((no_outputs), activation=\"sigmoid\"))\n",
    "    print(m.summary())\n",
    "    return m\n",
    "\n",
    "m=get_model(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 76)                5852      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 76)                5852      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 385       \n",
      "=================================================================\n",
      "Total params: 12,089\n",
      "Trainable params: 12,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "(29365, 76)\n",
      "(7342, 76)\n",
      "Train on 29365 samples, validate on 7342 samples\n",
      "Epoch 1/3000\n",
      "29365/29365 [==============================] - 3s 113us/sample - loss: 0.0936 - accuracy: 0.6856 - val_loss: 0.0643 - val_accuracy: 0.7882\n",
      "Epoch 2/3000\n",
      "29365/29365 [==============================] - 1s 46us/sample - loss: 0.0566 - accuracy: 0.8198 - val_loss: 0.0481 - val_accuracy: 0.8481\n",
      "Epoch 3/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0455 - accuracy: 0.8590 - val_loss: 0.0423 - val_accuracy: 0.8673\n",
      "Epoch 4/3000\n",
      "29365/29365 [==============================] - 1s 47us/sample - loss: 0.0403 - accuracy: 0.8751 - val_loss: 0.0394 - val_accuracy: 0.8748\n",
      "Epoch 5/3000\n",
      "29365/29365 [==============================] - 1s 50us/sample - loss: 0.0362 - accuracy: 0.8879 - val_loss: 0.0368 - val_accuracy: 0.8885\n",
      "Epoch 6/3000\n",
      "29365/29365 [==============================] - 1s 47us/sample - loss: 0.0340 - accuracy: 0.8946 - val_loss: 0.0342 - val_accuracy: 0.8925\n",
      "Epoch 7/3000\n",
      "29365/29365 [==============================] - 1s 49us/sample - loss: 0.0322 - accuracy: 0.8997 - val_loss: 0.0339 - val_accuracy: 0.8908\n",
      "Epoch 8/3000\n",
      "29365/29365 [==============================] - 1s 46us/sample - loss: 0.0304 - accuracy: 0.9052 - val_loss: 0.0312 - val_accuracy: 0.8998\n",
      "Epoch 9/3000\n",
      "29365/29365 [==============================] - 1s 49us/sample - loss: 0.0298 - accuracy: 0.9067 - val_loss: 0.0313 - val_accuracy: 0.9014\n",
      "Epoch 10/3000\n",
      "29365/29365 [==============================] - 1s 49us/sample - loss: 0.0287 - accuracy: 0.9112 - val_loss: 0.0302 - val_accuracy: 0.9056\n",
      "Epoch 11/3000\n",
      "29365/29365 [==============================] - 1s 50us/sample - loss: 0.0274 - accuracy: 0.9150 - val_loss: 0.0297 - val_accuracy: 0.9060\n",
      "Epoch 12/3000\n",
      "29365/29365 [==============================] - 1s 47us/sample - loss: 0.0267 - accuracy: 0.9162 - val_loss: 0.0313 - val_accuracy: 0.8972\n",
      "Epoch 13/3000\n",
      "29365/29365 [==============================] - 1s 46us/sample - loss: 0.0257 - accuracy: 0.9205 - val_loss: 0.0292 - val_accuracy: 0.9057\n",
      "Epoch 14/3000\n",
      "29365/29365 [==============================] - 1s 50us/sample - loss: 0.0249 - accuracy: 0.9228 - val_loss: 0.0278 - val_accuracy: 0.9130\n",
      "Epoch 15/3000\n",
      "29365/29365 [==============================] - 1s 46us/sample - loss: 0.0246 - accuracy: 0.9239 - val_loss: 0.0264 - val_accuracy: 0.9166\n",
      "Epoch 16/3000\n",
      "29365/29365 [==============================] - 1s 49us/sample - loss: 0.0241 - accuracy: 0.9253 - val_loss: 0.0274 - val_accuracy: 0.9117\n",
      "Epoch 17/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0233 - accuracy: 0.9280 - val_loss: 0.0258 - val_accuracy: 0.9181\n",
      "Epoch 18/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0228 - accuracy: 0.9292 - val_loss: 0.0262 - val_accuracy: 0.9171\n",
      "Epoch 19/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0224 - accuracy: 0.9305 - val_loss: 0.0262 - val_accuracy: 0.9180\n",
      "Epoch 20/3000\n",
      "29365/29365 [==============================] - 1s 44us/sample - loss: 0.0220 - accuracy: 0.9322 - val_loss: 0.0245 - val_accuracy: 0.9230\n",
      "Epoch 21/3000\n",
      "29365/29365 [==============================] - 1s 45us/sample - loss: 0.0214 - accuracy: 0.9329 - val_loss: 0.0250 - val_accuracy: 0.9203\n",
      "Epoch 22/3000\n",
      "29365/29365 [==============================] - 1s 47us/sample - loss: 0.0210 - accuracy: 0.9351 - val_loss: 0.0248 - val_accuracy: 0.9198\n",
      "Epoch 23/3000\n",
      "29365/29365 [==============================] - 1s 46us/sample - loss: 0.0210 - accuracy: 0.9353 - val_loss: 0.0244 - val_accuracy: 0.9226\n",
      "Epoch 24/3000\n",
      "29365/29365 [==============================] - 1s 44us/sample - loss: 0.0211 - accuracy: 0.9340 - val_loss: 0.0243 - val_accuracy: 0.9239\n",
      "Epoch 25/3000\n",
      "29365/29365 [==============================] - 1s 50us/sample - loss: 0.0203 - accuracy: 0.9369 - val_loss: 0.0230 - val_accuracy: 0.9273\n",
      "Epoch 26/3000\n",
      "29365/29365 [==============================] - 2s 51us/sample - loss: 0.0198 - accuracy: 0.9395 - val_loss: 0.0225 - val_accuracy: 0.9282\n",
      "Epoch 27/3000\n",
      "29365/29365 [==============================] - 1s 49us/sample - loss: 0.0191 - accuracy: 0.9408 - val_loss: 0.0237 - val_accuracy: 0.9239\n",
      "Epoch 28/3000\n",
      "29365/29365 [==============================] - 1s 51us/sample - loss: 0.0192 - accuracy: 0.9419 - val_loss: 0.0234 - val_accuracy: 0.9260\n",
      "Epoch 29/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0198 - accuracy: 0.9392 - val_loss: 0.0230 - val_accuracy: 0.9274\n",
      "Epoch 30/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0187 - accuracy: 0.9429 - val_loss: 0.0219 - val_accuracy: 0.9312\n",
      "Epoch 31/3000\n",
      "29365/29365 [==============================] - 2s 59us/sample - loss: 0.0183 - accuracy: 0.9447 - val_loss: 0.0231 - val_accuracy: 0.9281\n",
      "Epoch 32/3000\n",
      "29365/29365 [==============================] - 2s 55us/sample - loss: 0.0182 - accuracy: 0.9447 - val_loss: 0.0224 - val_accuracy: 0.9286\n",
      "Epoch 33/3000\n",
      "29365/29365 [==============================] - 2s 55us/sample - loss: 0.0190 - accuracy: 0.9410 - val_loss: 0.0225 - val_accuracy: 0.9284\n",
      "Epoch 34/3000\n",
      "29365/29365 [==============================] - 2s 55us/sample - loss: 0.0179 - accuracy: 0.9457 - val_loss: 0.0233 - val_accuracy: 0.9252\n",
      "Epoch 35/3000\n",
      "29365/29365 [==============================] - 2s 54us/sample - loss: 0.0187 - accuracy: 0.9420 - val_loss: 0.0215 - val_accuracy: 0.9326\n",
      "Epoch 36/3000\n",
      "29365/29365 [==============================] - 1s 51us/sample - loss: 0.0178 - accuracy: 0.9454 - val_loss: 0.0219 - val_accuracy: 0.9289\n",
      "Epoch 37/3000\n",
      "29365/29365 [==============================] - 2s 56us/sample - loss: 0.0176 - accuracy: 0.9463 - val_loss: 0.0215 - val_accuracy: 0.9335\n",
      "Epoch 38/3000\n",
      "29365/29365 [==============================] - 2s 52us/sample - loss: 0.0174 - accuracy: 0.9467 - val_loss: 0.0207 - val_accuracy: 0.9350\n",
      "Epoch 39/3000\n",
      "29365/29365 [==============================] - 1s 49us/sample - loss: 0.0175 - accuracy: 0.9459 - val_loss: 0.0230 - val_accuracy: 0.9255\n",
      "Epoch 40/3000\n",
      "29365/29365 [==============================] - 2s 51us/sample - loss: 0.0172 - accuracy: 0.9475 - val_loss: 0.0221 - val_accuracy: 0.9304\n",
      "Epoch 41/3000\n",
      "29365/29365 [==============================] - 2s 53us/sample - loss: 0.0166 - accuracy: 0.9500 - val_loss: 0.0208 - val_accuracy: 0.9350\n",
      "Epoch 42/3000\n",
      "29365/29365 [==============================] - 2s 58us/sample - loss: 0.0177 - accuracy: 0.9456 - val_loss: 0.0213 - val_accuracy: 0.9337\n",
      "Epoch 43/3000\n",
      "29365/29365 [==============================] - 2s 52us/sample - loss: 0.0168 - accuracy: 0.9495 - val_loss: 0.0215 - val_accuracy: 0.9342\n",
      "Epoch 44/3000\n",
      "29365/29365 [==============================] - 2s 54us/sample - loss: 0.0164 - accuracy: 0.9495 - val_loss: 0.0197 - val_accuracy: 0.9395\n",
      "Epoch 45/3000\n",
      "29365/29365 [==============================] - 1s 49us/sample - loss: 0.0165 - accuracy: 0.9498 - val_loss: 0.0196 - val_accuracy: 0.9397\n",
      "Epoch 46/3000\n",
      "29365/29365 [==============================] - 2s 51us/sample - loss: 0.0161 - accuracy: 0.9508 - val_loss: 0.0205 - val_accuracy: 0.9364\n",
      "Epoch 47/3000\n",
      "29365/29365 [==============================] - 2s 75us/sample - loss: 0.0161 - accuracy: 0.9510 - val_loss: 0.0194 - val_accuracy: 0.9382\n",
      "Epoch 48/3000\n",
      "29365/29365 [==============================] - 4s 124us/sample - loss: 0.0155 - accuracy: 0.9526 - val_loss: 0.0201 - val_accuracy: 0.9354\n",
      "Epoch 49/3000\n",
      "29365/29365 [==============================] - 2s 65us/sample - loss: 0.0155 - accuracy: 0.9526 - val_loss: 0.0206 - val_accuracy: 0.9364\n",
      "Epoch 50/3000\n",
      "29365/29365 [==============================] - 2s 52us/sample - loss: 0.0153 - accuracy: 0.9537 - val_loss: 0.0199 - val_accuracy: 0.9365\n",
      "Epoch 51/3000\n",
      "29365/29365 [==============================] - 2s 59us/sample - loss: 0.0150 - accuracy: 0.9552 - val_loss: 0.0202 - val_accuracy: 0.9360\n",
      "Epoch 52/3000\n",
      "29365/29365 [==============================] - 1s 50us/sample - loss: 0.0148 - accuracy: 0.9553 - val_loss: 0.0204 - val_accuracy: 0.9367\n",
      "Epoch 53/3000\n",
      "29365/29365 [==============================] - 1s 47us/sample - loss: 0.0147 - accuracy: 0.9557 - val_loss: 0.0209 - val_accuracy: 0.9364\n",
      "Epoch 54/3000\n",
      "29365/29365 [==============================] - 2s 63us/sample - loss: 0.0150 - accuracy: 0.9549 - val_loss: 0.0204 - val_accuracy: 0.9371\n",
      "Epoch 55/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0149 - accuracy: 0.9541 - val_loss: 0.0198 - val_accuracy: 0.9388\n",
      "Epoch 56/3000\n",
      "29365/29365 [==============================] - 1s 47us/sample - loss: 0.0146 - accuracy: 0.9561 - val_loss: 0.0208 - val_accuracy: 0.9368\n",
      "Epoch 57/3000\n",
      "29365/29365 [==============================] - 2s 52us/sample - loss: 0.0148 - accuracy: 0.9558 - val_loss: 0.0185 - val_accuracy: 0.9408\n",
      "Epoch 58/3000\n",
      "29365/29365 [==============================] - 1s 51us/sample - loss: 0.0144 - accuracy: 0.9569 - val_loss: 0.0208 - val_accuracy: 0.9348\n",
      "Epoch 59/3000\n",
      "29365/29365 [==============================] - 2s 51us/sample - loss: 0.0146 - accuracy: 0.9565 - val_loss: 0.0205 - val_accuracy: 0.9354\n",
      "Epoch 60/3000\n",
      "29365/29365 [==============================] - 1s 50us/sample - loss: 0.0145 - accuracy: 0.9560 - val_loss: 0.0203 - val_accuracy: 0.9353\n",
      "Epoch 61/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0141 - accuracy: 0.9577 - val_loss: 0.0190 - val_accuracy: 0.9401\n",
      "Epoch 62/3000\n",
      "29365/29365 [==============================] - 1s 51us/sample - loss: 0.0143 - accuracy: 0.9564 - val_loss: 0.0195 - val_accuracy: 0.9383\n",
      "Epoch 63/3000\n",
      "29365/29365 [==============================] - 2s 52us/sample - loss: 0.0141 - accuracy: 0.9579 - val_loss: 0.0205 - val_accuracy: 0.9346\n",
      "Epoch 64/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0137 - accuracy: 0.9584 - val_loss: 0.0197 - val_accuracy: 0.9393\n",
      "Epoch 65/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0136 - accuracy: 0.9585 - val_loss: 0.0194 - val_accuracy: 0.9383\n",
      "Epoch 66/3000\n",
      "29365/29365 [==============================] - 1s 50us/sample - loss: 0.0141 - accuracy: 0.9584 - val_loss: 0.0198 - val_accuracy: 0.9350\n",
      "Epoch 67/3000\n",
      "29365/29365 [==============================] - 1s 47us/sample - loss: 0.0139 - accuracy: 0.9594 - val_loss: 0.0194 - val_accuracy: 0.9380\n",
      "Epoch 68/3000\n",
      "29365/29365 [==============================] - 1s 51us/sample - loss: 0.0133 - accuracy: 0.9616 - val_loss: 0.0187 - val_accuracy: 0.9398\n",
      "Epoch 69/3000\n",
      "29365/29365 [==============================] - 2s 55us/sample - loss: 0.0133 - accuracy: 0.9603 - val_loss: 0.0193 - val_accuracy: 0.9375\n",
      "Epoch 70/3000\n",
      "29365/29365 [==============================] - 1s 49us/sample - loss: 0.0133 - accuracy: 0.9608 - val_loss: 0.0210 - val_accuracy: 0.9350\n",
      "Epoch 71/3000\n",
      "29365/29365 [==============================] - 2s 54us/sample - loss: 0.0134 - accuracy: 0.9604 - val_loss: 0.0191 - val_accuracy: 0.9388\n",
      "Epoch 72/3000\n",
      "29365/29365 [==============================] - 1s 51us/sample - loss: 0.0133 - accuracy: 0.9604 - val_loss: 0.0187 - val_accuracy: 0.9394\n",
      "Epoch 73/3000\n",
      "29365/29365 [==============================] - 1s 51us/sample - loss: 0.0129 - accuracy: 0.9610 - val_loss: 0.0176 - val_accuracy: 0.9440\n",
      "Epoch 74/3000\n",
      "29365/29365 [==============================] - 2s 51us/sample - loss: 0.0127 - accuracy: 0.9617 - val_loss: 0.0180 - val_accuracy: 0.9418\n",
      "Epoch 75/3000\n",
      "29365/29365 [==============================] - 2s 55us/sample - loss: 0.0128 - accuracy: 0.9620 - val_loss: 0.0196 - val_accuracy: 0.9388\n",
      "Epoch 76/3000\n",
      "29365/29365 [==============================] - 1s 51us/sample - loss: 0.0130 - accuracy: 0.9610 - val_loss: 0.0184 - val_accuracy: 0.9431\n",
      "Epoch 77/3000\n",
      "29365/29365 [==============================] - 1s 46us/sample - loss: 0.0130 - accuracy: 0.9620 - val_loss: 0.0179 - val_accuracy: 0.9428\n",
      "Epoch 78/3000\n",
      "29365/29365 [==============================] - 1s 47us/sample - loss: 0.0126 - accuracy: 0.9621 - val_loss: 0.0178 - val_accuracy: 0.9451\n",
      "Epoch 79/3000\n",
      "29365/29365 [==============================] - 2s 54us/sample - loss: 0.0129 - accuracy: 0.9620 - val_loss: 0.0175 - val_accuracy: 0.9458\n",
      "Epoch 80/3000\n",
      "29365/29365 [==============================] - 1s 44us/sample - loss: 0.0128 - accuracy: 0.9613 - val_loss: 0.0177 - val_accuracy: 0.9447\n",
      "Epoch 81/3000\n",
      "29365/29365 [==============================] - 1s 45us/sample - loss: 0.0124 - accuracy: 0.9626 - val_loss: 0.0181 - val_accuracy: 0.9424\n",
      "Epoch 82/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0127 - accuracy: 0.9624 - val_loss: 0.0187 - val_accuracy: 0.9401\n",
      "Epoch 83/3000\n",
      "29365/29365 [==============================] - 1s 46us/sample - loss: 0.0126 - accuracy: 0.9630 - val_loss: 0.0192 - val_accuracy: 0.9403\n",
      "Epoch 84/3000\n",
      "29365/29365 [==============================] - 1s 50us/sample - loss: 0.0124 - accuracy: 0.9633 - val_loss: 0.0181 - val_accuracy: 0.9424\n",
      "Epoch 85/3000\n",
      "29365/29365 [==============================] - 1s 49us/sample - loss: 0.0127 - accuracy: 0.9622 - val_loss: 0.0196 - val_accuracy: 0.9387\n",
      "Epoch 86/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0120 - accuracy: 0.9649 - val_loss: 0.0179 - val_accuracy: 0.9440\n",
      "Epoch 87/3000\n",
      "29365/29365 [==============================] - 1s 50us/sample - loss: 0.0120 - accuracy: 0.9645 - val_loss: 0.0182 - val_accuracy: 0.9437\n",
      "Epoch 88/3000\n",
      "29365/29365 [==============================] - 1s 51us/sample - loss: 0.0116 - accuracy: 0.9651 - val_loss: 0.0173 - val_accuracy: 0.9448\n",
      "Epoch 89/3000\n",
      "29365/29365 [==============================] - 1s 47us/sample - loss: 0.0117 - accuracy: 0.9657 - val_loss: 0.0176 - val_accuracy: 0.9447\n",
      "Epoch 90/3000\n",
      "29365/29365 [==============================] - 2s 53us/sample - loss: 0.0116 - accuracy: 0.9656 - val_loss: 0.0175 - val_accuracy: 0.9459\n",
      "Epoch 91/3000\n",
      "29365/29365 [==============================] - 1s 50us/sample - loss: 0.0121 - accuracy: 0.9640 - val_loss: 0.0172 - val_accuracy: 0.9473\n",
      "Epoch 92/3000\n",
      "29365/29365 [==============================] - 2s 53us/sample - loss: 0.0121 - accuracy: 0.9643 - val_loss: 0.0207 - val_accuracy: 0.9354\n",
      "Epoch 93/3000\n",
      "29365/29365 [==============================] - 2s 55us/sample - loss: 0.0129 - accuracy: 0.9620 - val_loss: 0.0189 - val_accuracy: 0.9412\n",
      "Epoch 94/3000\n",
      "29365/29365 [==============================] - 2s 52us/sample - loss: 0.0116 - accuracy: 0.9655 - val_loss: 0.0179 - val_accuracy: 0.9436\n",
      "Epoch 95/3000\n",
      "29365/29365 [==============================] - 2s 55us/sample - loss: 0.0112 - accuracy: 0.9672 - val_loss: 0.0166 - val_accuracy: 0.9477\n",
      "Epoch 96/3000\n",
      "29365/29365 [==============================] - 1s 49us/sample - loss: 0.0116 - accuracy: 0.9660 - val_loss: 0.0185 - val_accuracy: 0.9429\n",
      "Epoch 97/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0117 - accuracy: 0.9653 - val_loss: 0.0180 - val_accuracy: 0.9435\n",
      "Epoch 98/3000\n",
      "29365/29365 [==============================] - 1s 45us/sample - loss: 0.0113 - accuracy: 0.9659 - val_loss: 0.0178 - val_accuracy: 0.9444\n",
      "Epoch 99/3000\n",
      "29365/29365 [==============================] - 1s 45us/sample - loss: 0.0117 - accuracy: 0.9653 - val_loss: 0.0181 - val_accuracy: 0.9448\n",
      "Epoch 100/3000\n",
      "29365/29365 [==============================] - 1s 45us/sample - loss: 0.0117 - accuracy: 0.9648 - val_loss: 0.0196 - val_accuracy: 0.9388\n",
      "Epoch 101/3000\n",
      "29365/29365 [==============================] - 1s 46us/sample - loss: 0.0115 - accuracy: 0.9657 - val_loss: 0.0186 - val_accuracy: 0.9413\n",
      "Epoch 102/3000\n",
      "29365/29365 [==============================] - 1s 47us/sample - loss: 0.0113 - accuracy: 0.9666 - val_loss: 0.0181 - val_accuracy: 0.9452\n",
      "Epoch 103/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0107 - accuracy: 0.9688 - val_loss: 0.0170 - val_accuracy: 0.9461\n",
      "Epoch 104/3000\n",
      "29365/29365 [==============================] - 1s 47us/sample - loss: 0.0111 - accuracy: 0.9672 - val_loss: 0.0174 - val_accuracy: 0.9457\n",
      "Epoch 105/3000\n",
      "29365/29365 [==============================] - 1s 46us/sample - loss: 0.0114 - accuracy: 0.9672 - val_loss: 0.0171 - val_accuracy: 0.9467\n",
      "Epoch 106/3000\n",
      "29365/29365 [==============================] - 1s 47us/sample - loss: 0.0109 - accuracy: 0.9675 - val_loss: 0.0181 - val_accuracy: 0.9440\n",
      "Epoch 107/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0113 - accuracy: 0.9667 - val_loss: 0.0188 - val_accuracy: 0.9416\n",
      "Epoch 108/3000\n",
      "29365/29365 [==============================] - 1s 45us/sample - loss: 0.0109 - accuracy: 0.9673 - val_loss: 0.0172 - val_accuracy: 0.9447\n",
      "Epoch 109/3000\n",
      "29365/29365 [==============================] - 1s 44us/sample - loss: 0.0107 - accuracy: 0.9685 - val_loss: 0.0174 - val_accuracy: 0.9465\n",
      "Epoch 110/3000\n",
      "29365/29365 [==============================] - 1s 46us/sample - loss: 0.0109 - accuracy: 0.9676 - val_loss: 0.0172 - val_accuracy: 0.9463\n",
      "Epoch 111/3000\n",
      "29365/29365 [==============================] - 1s 44us/sample - loss: 0.0103 - accuracy: 0.9697 - val_loss: 0.0164 - val_accuracy: 0.9480\n",
      "Epoch 112/3000\n",
      "29365/29365 [==============================] - 1s 46us/sample - loss: 0.0106 - accuracy: 0.9694 - val_loss: 0.0181 - val_accuracy: 0.9433\n",
      "Epoch 113/3000\n",
      "29365/29365 [==============================] - 1s 45us/sample - loss: 0.0110 - accuracy: 0.9676 - val_loss: 0.0175 - val_accuracy: 0.9461\n",
      "Epoch 114/3000\n",
      "29365/29365 [==============================] - 1s 45us/sample - loss: 0.0102 - accuracy: 0.9697 - val_loss: 0.0178 - val_accuracy: 0.9442\n",
      "Epoch 115/3000\n",
      "29365/29365 [==============================] - 1s 44us/sample - loss: 0.0107 - accuracy: 0.9683 - val_loss: 0.0197 - val_accuracy: 0.9409\n",
      "Epoch 116/3000\n",
      "29365/29365 [==============================] - 1s 44us/sample - loss: 0.0104 - accuracy: 0.9698 - val_loss: 0.0177 - val_accuracy: 0.9450\n",
      "Epoch 117/3000\n",
      "29365/29365 [==============================] - 1s 43us/sample - loss: 0.0105 - accuracy: 0.9697 - val_loss: 0.0168 - val_accuracy: 0.9462\n",
      "Epoch 118/3000\n",
      "29365/29365 [==============================] - 1s 45us/sample - loss: 0.0101 - accuracy: 0.9702 - val_loss: 0.0168 - val_accuracy: 0.9466\n",
      "Epoch 119/3000\n",
      "29365/29365 [==============================] - 1s 46us/sample - loss: 0.0104 - accuracy: 0.9695 - val_loss: 0.0174 - val_accuracy: 0.9469\n",
      "Epoch 120/3000\n",
      "29365/29365 [==============================] - 1s 47us/sample - loss: 0.0102 - accuracy: 0.9701 - val_loss: 0.0166 - val_accuracy: 0.9469\n",
      "Epoch 121/3000\n",
      "29365/29365 [==============================] - 1s 45us/sample - loss: 0.0104 - accuracy: 0.9692 - val_loss: 0.0165 - val_accuracy: 0.9480\n",
      "Epoch 122/3000\n",
      "29365/29365 [==============================] - 1s 46us/sample - loss: 0.0101 - accuracy: 0.9699 - val_loss: 0.0187 - val_accuracy: 0.9427\n",
      "Epoch 123/3000\n",
      "29365/29365 [==============================] - 1s 46us/sample - loss: 0.0102 - accuracy: 0.9698 - val_loss: 0.0180 - val_accuracy: 0.9455\n",
      "Epoch 124/3000\n",
      "29365/29365 [==============================] - 1s 49us/sample - loss: 0.0098 - accuracy: 0.9716 - val_loss: 0.0172 - val_accuracy: 0.9440\n",
      "Epoch 125/3000\n",
      "29365/29365 [==============================] - 1s 46us/sample - loss: 0.0097 - accuracy: 0.9715 - val_loss: 0.0170 - val_accuracy: 0.9476\n",
      "Epoch 126/3000\n",
      "29365/29365 [==============================] - 2s 59us/sample - loss: 0.0111 - accuracy: 0.9673 - val_loss: 0.0170 - val_accuracy: 0.9466\n",
      "Epoch 127/3000\n",
      "29365/29365 [==============================] - 2s 59us/sample - loss: 0.0101 - accuracy: 0.9700 - val_loss: 0.0169 - val_accuracy: 0.9462\n",
      "Epoch 128/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0106 - accuracy: 0.9687 - val_loss: 0.0167 - val_accuracy: 0.9473\n",
      "Epoch 129/3000\n",
      "29365/29365 [==============================] - 1s 50us/sample - loss: 0.0092 - accuracy: 0.9739 - val_loss: 0.0166 - val_accuracy: 0.9501\n",
      "Epoch 130/3000\n",
      "29365/29365 [==============================] - 1s 45us/sample - loss: 0.0101 - accuracy: 0.9710 - val_loss: 0.0174 - val_accuracy: 0.9477\n",
      "Epoch 131/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0095 - accuracy: 0.9723 - val_loss: 0.0153 - val_accuracy: 0.9525\n",
      "Epoch 132/3000\n",
      "29365/29365 [==============================] - 2s 52us/sample - loss: 0.0094 - accuracy: 0.9730 - val_loss: 0.0170 - val_accuracy: 0.9476\n",
      "Epoch 133/3000\n",
      "29365/29365 [==============================] - 1s 45us/sample - loss: 0.0103 - accuracy: 0.9701 - val_loss: 0.0172 - val_accuracy: 0.9454\n",
      "Epoch 134/3000\n",
      "29365/29365 [==============================] - 1s 51us/sample - loss: 0.0103 - accuracy: 0.9700 - val_loss: 0.0164 - val_accuracy: 0.9504\n",
      "Epoch 135/3000\n",
      "29365/29365 [==============================] - 2s 53us/sample - loss: 0.0099 - accuracy: 0.9713 - val_loss: 0.0189 - val_accuracy: 0.9436\n",
      "Epoch 136/3000\n",
      "29365/29365 [==============================] - 1s 51us/sample - loss: 0.0091 - accuracy: 0.9739 - val_loss: 0.0183 - val_accuracy: 0.9447\n",
      "Epoch 137/3000\n",
      "29365/29365 [==============================] - 1s 46us/sample - loss: 0.0096 - accuracy: 0.9724 - val_loss: 0.0164 - val_accuracy: 0.9499\n",
      "Epoch 138/3000\n",
      "29365/29365 [==============================] - 1s 48us/sample - loss: 0.0097 - accuracy: 0.9714 - val_loss: 0.0162 - val_accuracy: 0.9507\n",
      "Epoch 139/3000\n",
      "29365/29365 [==============================] - 1s 49us/sample - loss: 0.0112 - accuracy: 0.9689 - val_loss: 0.0202 - val_accuracy: 0.9394\n",
      "Epoch 140/3000\n",
      "29365/29365 [==============================] - 1s 44us/sample - loss: 0.0106 - accuracy: 0.9691 - val_loss: 0.0170 - val_accuracy: 0.9477\n",
      "Epoch 141/3000\n",
      "29365/29365 [==============================] - 1s 45us/sample - loss: 0.0095 - accuracy: 0.9718 - val_loss: 0.0175 - val_accuracy: 0.9452\n",
      "Epoch 142/3000\n",
      "29365/29365 [==============================] - 1s 47us/sample - loss: 0.0093 - accuracy: 0.9727 - val_loss: 0.0166 - val_accuracy: 0.9501\n",
      "Epoch 143/3000\n",
      "29365/29365 [==============================] - 1s 50us/sample - loss: 0.0093 - accuracy: 0.9730 - val_loss: 0.0157 - val_accuracy: 0.9511\n",
      "Epoch 144/3000\n",
      "29365/29365 [==============================] - 2s 62us/sample - loss: 0.0095 - accuracy: 0.9717 - val_loss: 0.0177 - val_accuracy: 0.9476\n",
      "Epoch 145/3000\n",
      "29365/29365 [==============================] - 2s 60us/sample - loss: 0.0090 - accuracy: 0.9739 - val_loss: 0.0160 - val_accuracy: 0.9508\n",
      "Epoch 146/3000\n",
      "29365/29365 [==============================] - 2s 52us/sample - loss: 0.0090 - accuracy: 0.9731 - val_loss: 0.0150 - val_accuracy: 0.9538\n",
      "Epoch 147/3000\n",
      "29365/29365 [==============================] - 1s 49us/sample - loss: 0.0091 - accuracy: 0.9736 - val_loss: 0.0156 - val_accuracy: 0.9516\n",
      "Epoch 148/3000\n",
      " 2600/29365 [=>............................] - ETA: 1s - loss: 0.0101 - accuracy: 0.9719"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1d1956df0fc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMeanSquaredError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Burak\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\Users\\Burak\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Burak\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    172\u001b[0m             batch_end=step * batch_size + current_batch_size)\n\u001b[0;32m    173\u001b[0m       \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m       \u001b[0mstep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Burak\\Anaconda3\\envs\\tf_gpu\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Burak\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_batch\u001b[1;34m(self, step, mode, size)\u001b[0m\n\u001b[0;32m    699\u001b[0m         self.callbacks._call_batch_hook(\n\u001b[0;32m    700\u001b[0m             mode, 'end', step, batch_logs)\n\u001b[1;32m--> 701\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Burak\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    758\u001b[0m     \u001b[1;31m# will be handled by on_epoch_end.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    759\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    762\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Burak\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values)\u001b[0m\n\u001b[0;32m    387\u001b[0m       \u001b[0mprev_total_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_total_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynamic_display\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\b'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mprev_total_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Burak\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    408\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_schedule_flush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwritelines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Burak\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36m_schedule_flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    332\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m_schedule_in_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_later\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_interval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_schedule_in_thread\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Burak\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Burak\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    398\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[0;32m    399\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Burak\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m=get_model(5)\n",
    "#X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],1)\n",
    "#X_test=X_test.reshape(X_test.shape[0],X_test.shape[1],1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "steps = int(X_train.shape[0] / 64)\n",
    "\n",
    "m.compile(optimizer=\"adam\", loss=tf.keras.losses.MeanSquaredError(), metrics=[\"accuracy\"])\n",
    "history=m.fit(X_train, y_train, batch_size=100,epochs=3000, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))  \n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions=NN.forward(X_test)\n",
    "print(accuracy_score(y_test, predictions, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.values,target_cate.values,test_size=0.2,random_state=4, shuffle=True)\n",
    "X_train=X_train.T\n",
    "X_test=X_test.T\n",
    "y_train=y_train.T\n",
    "y_test=y_test.T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.random.randn(76,76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v7\n",
    "from sklearn.metrics import accuracy_score\n",
    "class Neural_Network():   \n",
    "    def __init__(self,X_train,y_train,Number_Dense1,Number_Dense2,learning_rate,batch):\n",
    "        self.X_train=X_train\n",
    "        self.y_train=y_train\n",
    "        self.Number_Dense1=Number_Dense1 #76\n",
    "        self.Number_Dense2=Number_Dense2 #76\n",
    "        self.parameters={}\n",
    "        self.Adam_parameters={}\n",
    "        self.catch={}\n",
    "        self.grads={}\n",
    "        self.learning_rate=learning_rate\n",
    "        self.batch=batch        \n",
    "\n",
    "    \n",
    "    \n",
    " \n",
    "    def initialize_parameters_and_layer_sizes_NN(self):\n",
    "        parameters={\"weight1\":np.random.randn(self.Number_Dense1,self.X_train.shape[0])*0.01,\n",
    "                    \"bias1\":np.zeros((self.Number_Dense1,1)),\n",
    "                    \"weight2\":np.random.randn(self.Number_Dense2,self.Number_Dense1)*0.01,\n",
    "                    \"bias2\":np.zeros((self.Number_Dense2,1)),\n",
    "                    \"weight3\":np.random.randn(self.y_train.shape[0],self.Number_Dense2)*0.01,\n",
    "                    \"bias3\":np.zeros((self.y_train.shape[0],1))       \n",
    "        }\n",
    "        self.parameters=parameters\n",
    "        \n",
    "    def initialize_parameters_Adam_NN(self):        \n",
    "        parameters={\"weight1_vdw\":np.zeros((self.Number_Dense1,self.X_train.shape[0])),\n",
    "                    \"bias1_vdw\":np.zeros((self.Number_Dense1,1)),\n",
    "                    \"weight2_vdw\":np.zeros((self.Number_Dense2,self.Number_Dense1)),\n",
    "                    \"bias2_vdw\":np.zeros((self.Number_Dense2,1)),\n",
    "                    \"weight3_vdw\":np.zeros((self.y_train.shape[0],self.Number_Dense2)),\n",
    "                    \"bias3_vdw\":np.zeros((self.y_train.shape[0],1)),\n",
    "                    \"weight1_sdw\":np.zeros((self.Number_Dense1,self.X_train.shape[0])),\n",
    "                    \"bias1_sdw\":np.zeros((self.Number_Dense1,1)),\n",
    "                    \"weight2_sdw\":np.zeros((self.Number_Dense2,self.Number_Dense1)),\n",
    "                    \"bias2_sdw\":np.zeros((self.Number_Dense2,1)),\n",
    "                    \"weight3_sdw\":np.zeros((self.y_train.shape[0],self.Number_Dense2)),\n",
    "                    \"bias3_sdw\":np.zeros((self.y_train.shape[0],1))       \n",
    "        }\n",
    "        self.Adam_parameters=parameters      \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def Adam_optimizer(self,vdw,epoch,sdw,DW,w,learningRate,epsilon = np.array([pow(10, -8)])):                  \n",
    "        vdw = 0.9 * vdw + (0.1) * DW\n",
    "        sdw = 0.999 * sdw + (0.001) * pow(DW, 2)\n",
    "        vdw_corrected = vdw / (1-pow(0.9, epoch+1))\n",
    "        sdw_corrected = sdw / (1-pow(0.999,epoch+1))\n",
    "        w = w + learningRate * (vdw_corrected / (np.sqrt(sdw_corrected) + epsilon)) #- değiştir\n",
    "        return w,vdw,sdw\n",
    "\n",
    "        \n",
    "    def compute_cost(self,AL, Y): \n",
    "        m = Y.shape[1]\n",
    "        logprobs = np.multiply(np.log(AL),Y) +  np.multiply(np.log(1-AL), (1-Y))\n",
    "        cost = -1/m*np.sum(logprobs)\n",
    "        cost = np.squeeze(cost)\n",
    "        return cost\n",
    "\n",
    "        \n",
    "    def sigmoid(self,s):\n",
    "        return 1/(1+np.exp(-s))\n",
    "        \n",
    "    def sigmoidPrime(self,s):\n",
    "        return s*(1-s)\n",
    "    \n",
    "    def der_tanh(self,X):       \n",
    "        return 1-(np.tanh(X)**2)\n",
    "    \n",
    " \n",
    "\n",
    "    def forward_propagation_NN(self,X_train):\n",
    "        Z1=np.dot(self.parameters[\"weight1\"],X_train)+self.parameters[\"bias1\"]\n",
    "        A1=np.tanh(Z1)\n",
    "        Z2=np.dot(self.parameters[\"weight2\"],A1)+self.parameters[\"bias2\"]\n",
    "        A2=np.tanh(Z2)\n",
    "        Z3=np.dot(self.parameters[\"weight3\"],A2)+self.parameters[\"bias3\"]       \n",
    "        A3=self.sigmoid(Z3)\n",
    "    \n",
    "\n",
    "        self.cache={\n",
    "            \"A1\":A1,\n",
    "            \"A2\":A2,\n",
    "            \"A3\":A3,\n",
    "            \"Z1\":Z1,\n",
    "            \"Z2\":Z2,\n",
    "            \"Z3\":Z3}\n",
    "        return A3\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "\n",
    "        \n",
    "    def backward_propagation_NN(self,X,Y):\n",
    "        error=self.compute_cost(self.cache[\"A3\"],Y)\n",
    "        DW3_prime=(self.cache[\"A3\"]-Y)*self.sigmoidPrime(self.cache[\"Z3\"]) #DZ\n",
    "        DW3=np.dot(DW3_prime,self.cache[\"A2\"].T)/self.cache[\"A3\"].shape[1]\n",
    "        db3=np.sum(DW3_prime,axis=1,keepdims=True)/self.cache[\"A3\"].shape[1]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        DW2_prime=(np.dot(self.parameters[\"weight3\"].T,DW3_prime)*self.der_tanh(self.cache[\"Z2\"]))#76*1000 =\n",
    "        DW2=np.dot(DW2_prime,self.cache[\"A1\"].T)/self.cache[\"A2\"].shape[1] #DW2=76*76=    76*1000,1000*76\n",
    "        db2=np.sum(DW2_prime,axis=1,keepdims=True)/self.cache[\"A2\"].shape[1]\n",
    "\n",
    "        \n",
    "        \n",
    "        DW1_prime=np.dot(self.parameters[\"weight2\"].T,DW2_prime)*self.der_tanh(self.cache[\"Z1\"])\n",
    "        DW1=np.dot(DW1_prime,X.T)/self.cache[\"A1\"].shape[1]\n",
    "        db1=np.sum(DW1_prime,axis=1,keepdims=True)/self.cache[\"A1\"].shape[1]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        self.grads={ \"dweight1\":DW1,\n",
    "              \"dbias1\":db1,\n",
    "              \"dweight2\":DW2,\n",
    "              \"dbias2\":db2,\n",
    "              \"dweight3\":DW3,\n",
    "              \"dbias3\":db3}\n",
    "        return error\n",
    "        \n",
    "            \n",
    "    \n",
    " \n",
    "    def Adam_update_parameters_NN(self,epoch):                      \n",
    "        self.parameters[\"weight1\"],self.Adam_parameters[\"weight1_vdw\"],self.Adam_parameters[\"weight1_sdw\"]=self.Adam_optimizer(self.Adam_parameters[\"weight1_vdw\"],epoch,self.Adam_parameters[\"weight1_sdw\"],self.grads[\"dweight1\"],self.parameters[\"weight1\"],self.learning_rate,np.array([pow(10, -8)]))\n",
    "        self.parameters[\"bias1\"],self.Adam_parameters[\"bias1_vdw\"],self.Adam_parameters[\"bias1_sdw\"]=self.Adam_optimizer(self.Adam_parameters[\"bias1_vdw\"],epoch,self.Adam_parameters[\"bias1_sdw\"],self.grads[\"dbias1\"],self.parameters[\"bias1\"],self.learning_rate,np.array([pow(10, -8)]))\n",
    "        self.parameters[\"weight2\"],self.Adam_parameters[\"weight2_vdw\"],self.Adam_parameters[\"weight2_sdw\"]=self.Adam_optimizer(self.Adam_parameters[\"weight2_vdw\"],epoch,self.Adam_parameters[\"weight2_sdw\"],self.grads[\"dweight2\"],self.parameters[\"weight2\"],self.learning_rate,np.array([pow(10, -8)]))\n",
    "        self.parameters[\"bias2\"],self.Adam_parameters[\"bias2_vdw\"],self.Adam_parameters[\"bias2_sdw\"]=self.Adam_optimizer(self.Adam_parameters[\"bias2_vdw\"],epoch,self.Adam_parameters[\"bias2_sdw\"],self.grads[\"dbias2\"],self.parameters[\"bias2\"],self.learning_rate,np.array([pow(10, -8)]))\n",
    "        self.parameters[\"weight3\"],self.Adam_parameters[\"weight3_vdw\"],self.Adam_parameters[\"weight3_sdw\"]=self.Adam_optimizer(self.Adam_parameters[\"weight3_vdw\"],epoch,self.Adam_parameters[\"weight3_sdw\"],self.grads[\"dweight3\"],self.parameters[\"weight3\"],self.learning_rate,np.array([pow(10, -8)]))\n",
    "        self.parameters[\"bias3\"],self.Adam_parameters[\"bias3_vdw\"],self.Adam_parameters[\"bias3_sdw\"]=self.Adam_optimizer(self.Adam_parameters[\"bias3_vdw\"],epoch,self.Adam_parameters[\"bias3_sdw\"],self.grads[\"dbias3\"],self.parameters[\"bias3\"],self.learning_rate,np.array([pow(10, -8)]))\n",
    "                      \n",
    "        \n",
    "        \n",
    " \n",
    "    def train(self,X,y,epoch,X_test,y_test):\n",
    "        \n",
    "        self.initialize_parameters_and_layer_sizes_NN()\n",
    "        self.initialize_parameters_Adam_NN()\n",
    "        step_number=int(X.shape[1]/self.batch)\n",
    "        i1=0\n",
    "        for i1 in range(epoch):\n",
    "            i=0\n",
    "            if i1>0:\n",
    "                #print(\"Epoch number: \"+str(i1)+\"/\"+str(epoch)+ \"step_number: \"+str(i)+\"/\"+str(step_number),\"cost: \",error,\"accuracy: \",accuracy_score(self.forward_propagation_NN(X_test).argmax(axis=0), y_test.argmax(axis=0), normalize=True))\n",
    "                print(\"Epoch number: \"+str(i1)+\"/\"+str(epoch)+ \"step_number: \"+str(i)+\"/\"+str(step_number),\"Accuracy: \",accuracy_score(self.forward_propagation_NN(X).argmax(axis=0), y.argmax(axis=0), normalize=True),\"Loss: \",error,\"Val_accuracy: \",accuracy_score(self.forward_propagation_NN(X_test).argmax(axis=0), y_test.argmax(axis=0), normalize=True),\"Val_cost: \",error,\"Val_accuracy: \",accuracy_score(self.forward_propagation_NN(X_test).argmax(axis=0), y_test.argmax(axis=0), normalize=True),\"Val_Acc: \",self.compute_cost(self.forward_propagation_NN(X_test),y_test))\n",
    "\n",
    "            for i in range(step_number):\n",
    "                self.forward_propagation_NN((X[:,i*self.batch:(i+1)*self.batch]))\n",
    "                error=self.backward_propagation_NN(X[:,i*self.batch:(i+1)*self.batch],y[:,i*self.batch:(i+1)*self.batch])\n",
    "                self.Adam_update_parameters_NN(i1)\n",
    "        #return accuracy_score(self.forward_propagation_NN(X_test).argmax(axis=0), y_test.argmax(axis=0), normalize=True),error\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Epoch number: \"+str(i1)+\"/\"+str(epoch)+ \"step_number: \"+str(i)+\"/\"+str(step_number),\"Accuracy: \",accuracy_score(self.forward_propagation_NN(X).argmax(axis=0), y.argmax(axis=0), normalize=True),\"Loss: \",error,\"Val_accuracy: \",accuracy_score(self.forward_propagation_NN(X_test).argmax(axis=0), y_test.argmax(axis=0), normalize=True),\"Val_cost: \",error,\"Val_accuracy: \",accuracy_score(self.forward_propagation_NN(X_test).argmax(axis=0), y_test.argmax(axis=0), normalize=True),\"Val_Acc: \",self.compute_cost(self.forward_propagation_NN(X_test),y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1/10000step_number: 0/29 Accuracy:  0.181474544525796 Loss:  3.4143718042048024 Val_accuracy:  0.18836829201852356 Val_cost:  3.4143718042048024 Val_accuracy:  0.18836829201852356 Val_Acc:  3.4117906512814793\n",
      "Epoch number: 2/10000step_number: 0/29 Accuracy:  0.181474544525796 Loss:  3.544751461202138 Val_accuracy:  0.18836829201852356 Val_cost:  3.544751461202138 Val_accuracy:  0.18836829201852356 Val_Acc:  3.543410625771069\n",
      "Epoch number: 3/10000step_number: 0/29 Accuracy:  0.181474544525796 Loss:  3.7438728478783916 Val_accuracy:  0.18836829201852356 Val_cost:  3.7438728478783916 Val_accuracy:  0.18836829201852356 Val_Acc:  3.736350311776874\n",
      "Epoch number: 4/10000step_number: 0/29 Accuracy:  0.181474544525796 Loss:  3.8276962268322317 Val_accuracy:  0.18836829201852356 Val_cost:  3.8276962268322317 Val_accuracy:  0.18836829201852356 Val_Acc:  3.814135971297681\n",
      "Epoch number: 5/10000step_number: 0/29 Accuracy:  0.181474544525796 Loss:  3.8311268057618304 Val_accuracy:  0.18836829201852356 Val_cost:  3.8311268057618304 Val_accuracy:  0.18836829201852356 Val_Acc:  3.8159065032146122\n",
      "Epoch number: 6/10000step_number: 0/29 Accuracy:  0.18300698109994892 Loss:  3.8215869168324934 Val_accuracy:  0.18033233451375646 Val_cost:  3.8215869168324934 Val_accuracy:  0.18033233451375646 Val_Acc:  3.8061619982728963\n",
      "Epoch number: 7/10000step_number: 0/29 Accuracy:  0.18300698109994892 Loss:  3.8121521283394695 Val_accuracy:  0.18033233451375646 Val_cost:  3.8121521283394695 Val_accuracy:  0.18033233451375646 Val_Acc:  3.797123070184507\n",
      "Epoch number: 8/10000step_number: 0/29 Accuracy:  0.13638685509960838 Loss:  3.799520617451923 Val_accuracy:  0.14560065377281395 Val_cost:  3.799520617451923 Val_accuracy:  0.14560065377281395 Val_Acc:  3.7856537639063967\n",
      "Epoch number: 9/10000step_number: 0/29 Accuracy:  0.1530052783926443 Loss:  3.763479831686736 Val_accuracy:  0.16317079814764368 Val_cost:  3.763479831686736 Val_accuracy:  0.16317079814764368 Val_Acc:  3.7524903106064404\n",
      "Epoch number: 10/10000step_number: 0/29 Accuracy:  0.15082581304273796 Loss:  3.727853763544914 Val_accuracy:  0.16017433941705259 Val_cost:  3.727853763544914 Val_accuracy:  0.16017433941705259 Val_Acc:  3.7221643001812295\n",
      "Epoch number: 11/10000step_number: 0/29 Accuracy:  0.1481695896475396 Loss:  3.7119611835828463 Val_accuracy:  0.15404521928629802 Val_cost:  3.7119611835828463 Val_accuracy:  0.15404521928629802 Val_Acc:  3.707207644929008\n",
      "Epoch number: 12/10000step_number: 0/29 Accuracy:  0.18300698109994892 Loss:  3.6931888876416443 Val_accuracy:  0.18033233451375646 Val_cost:  3.6931888876416443 Val_accuracy:  0.18033233451375646 Val_Acc:  3.6883592208598963\n",
      "Epoch number: 13/10000step_number: 0/29 Accuracy:  0.18300698109994892 Loss:  3.6723012692838335 Val_accuracy:  0.18033233451375646 Val_cost:  3.6723012692838335 Val_accuracy:  0.18033233451375646 Val_Acc:  3.667596451613881\n",
      "Epoch number: 14/10000step_number: 0/29 Accuracy:  0.18300698109994892 Loss:  3.650181104456243 Val_accuracy:  0.18033233451375646 Val_cost:  3.650181104456243 Val_accuracy:  0.18033233451375646 Val_Acc:  3.6454855556799033\n",
      "Epoch number: 15/10000step_number: 0/29 Accuracy:  0.18300698109994892 Loss:  3.628249530885456 Val_accuracy:  0.18033233451375646 Val_cost:  3.628249530885456 Val_accuracy:  0.18033233451375646 Val_Acc:  3.6236086747267335\n",
      "Epoch number: 16/10000step_number: 0/29 Accuracy:  0.18300698109994892 Loss:  3.608622598184486 Val_accuracy:  0.18033233451375646 Val_cost:  3.608622598184486 Val_accuracy:  0.18033233451375646 Val_Acc:  3.603803790248139\n",
      "Epoch number: 17/10000step_number: 0/29 Accuracy:  0.18300698109994892 Loss:  3.5892979316535403 Val_accuracy:  0.18033233451375646 Val_cost:  3.5892979316535403 Val_accuracy:  0.18033233451375646 Val_Acc:  3.5840663047416066\n",
      "Epoch number: 18/10000step_number: 0/29 Accuracy:  0.18300698109994892 Loss:  3.57132162892228 Val_accuracy:  0.18033233451375646 Val_cost:  3.57132162892228 Val_accuracy:  0.18033233451375646 Val_Acc:  3.565805293679651\n",
      "Epoch number: 19/10000step_number: 0/29 Accuracy:  0.18300698109994892 Loss:  3.5552083946047204 Val_accuracy:  0.18033233451375646 Val_cost:  3.5552083946047204 Val_accuracy:  0.18033233451375646 Val_Acc:  3.5496283158753057\n",
      "Epoch number: 20/10000step_number: 0/29 Accuracy:  0.18300698109994892 Loss:  3.540995667148174 Val_accuracy:  0.18033233451375646 Val_cost:  3.540995667148174 Val_accuracy:  0.18033233451375646 Val_Acc:  3.5353173191341347\n",
      "Epoch number: 21/10000step_number: 0/29 Accuracy:  0.18300698109994892 Loss:  3.5287856712581087 Val_accuracy:  0.18046853718332878 Val_cost:  3.5287856712581087 Val_accuracy:  0.18046853718332878 Val_Acc:  3.522980881777422\n",
      "Epoch number: 22/10000step_number: 0/29 Accuracy:  0.1830410352460412 Loss:  3.5183395487439237 Val_accuracy:  0.18046853718332878 Val_cost:  3.5183395487439237 Val_accuracy:  0.18046853718332878 Val_Acc:  3.512450121557267\n",
      "Epoch number: 23/10000step_number: 0/29 Accuracy:  0.18310914353822577 Loss:  3.5102722335833514 Val_accuracy:  0.18046853718332878 Val_cost:  3.5102722335833514 Val_accuracy:  0.18046853718332878 Val_Acc:  3.5043301212609506\n",
      "Epoch number: 24/10000step_number: 0/29 Accuracy:  0.18324536012259493 Loss:  3.50376810202948 Val_accuracy:  0.18046853718332878 Val_cost:  3.50376810202948 Val_accuracy:  0.18046853718332878 Val_Acc:  3.497827059353702\n",
      "Epoch number: 25/10000step_number: 0/29 Accuracy:  0.1833134684147795 Loss:  3.4986992045050185 Val_accuracy:  0.18046853718332878 Val_cost:  3.4986992045050185 Val_accuracy:  0.18046853718332878 Val_Acc:  3.492876391602756\n",
      "Epoch number: 26/10000step_number: 0/29 Accuracy:  0.18338157670696406 Loss:  3.495756010277895 Val_accuracy:  0.18046853718332878 Val_cost:  3.495756010277895 Val_accuracy:  0.18046853718332878 Val_Acc:  3.4899336927987736\n",
      "Epoch number: 27/10000step_number: 0/29 Accuracy:  0.1840626596288098 Loss:  3.494574722060629 Val_accuracy:  0.1810133478616181 Val_cost:  3.494574722060629 Val_accuracy:  0.1810133478616181 Val_Acc:  3.488647843495121\n",
      "Epoch number: 28/10000step_number: 0/29 Accuracy:  0.18409671377490208 Loss:  3.4947962268884756 Val_accuracy:  0.1810133478616181 Val_cost:  3.4947962268884756 Val_accuracy:  0.1810133478616181 Val_Acc:  3.488767760859606\n",
      "Epoch number: 29/10000step_number: 0/29 Accuracy:  0.1841307679209944 Loss:  3.4964591344345437 Val_accuracy:  0.1810133478616181 Val_cost:  3.4964591344345437 Val_accuracy:  0.1810133478616181 Val_Acc:  3.4903159499951104\n",
      "Epoch number: 30/10000step_number: 0/29 Accuracy:  0.18416482206708668 Loss:  3.500001007031675 Val_accuracy:  0.1810133478616181 Val_cost:  3.500001007031675 Val_accuracy:  0.1810133478616181 Val_Acc:  3.493744928983157\n",
      "Epoch number: 31/10000step_number: 0/29 Accuracy:  0.1843350927975481 Loss:  3.5038741294166256 Val_accuracy:  0.1815581585399074 Val_cost:  3.5038741294166256 Val_accuracy:  0.1815581585399074 Val_Acc:  3.4972566185848173\n",
      "Epoch number: 32/10000step_number: 0/29 Accuracy:  0.1848799591350247 Loss:  3.5079844368958204 Val_accuracy:  0.18251157722691363 Val_cost:  3.5079844368958204 Val_accuracy:  0.18251157722691363 Val_Acc:  3.500920798048708\n",
      "Epoch number: 33/10000step_number: 0/29 Accuracy:  0.18566320449514728 Loss:  3.5123125461123474 Val_accuracy:  0.18319259057477527 Val_cost:  3.5123125461123474 Val_accuracy:  0.18319259057477527 Val_Acc:  3.50472626485911\n",
      "Epoch number: 34/10000step_number: 0/29 Accuracy:  0.18722969521539248 Loss:  3.51623819906603 Val_accuracy:  0.18387360392263688 Val_cost:  3.51623819906603 Val_accuracy:  0.18387360392263688 Val_Acc:  3.5080987987500767\n",
      "Epoch number: 35/10000step_number: 0/29 Accuracy:  0.18814915715988423 Loss:  3.5194760775817624 Val_accuracy:  0.18469081994007083 Val_cost:  3.5194760775817624 Val_accuracy:  0.18469081994007083 Val_Acc:  3.511057079116504\n",
      "Epoch number: 36/10000step_number: 0/29 Accuracy:  0.1907713264089903 Loss:  3.5236132966112974 Val_accuracy:  0.1874148733315173 Val_cost:  3.5236132966112974 Val_accuracy:  0.1874148733315173 Val_Acc:  3.5146797509857466\n",
      "Epoch number: 37/10000step_number: 0/29 Accuracy:  0.19499404052443384 Loss:  3.5267294855070075 Val_accuracy:  0.19190956142740398 Val_cost:  3.5267294855070075 Val_accuracy:  0.19190956142740398 Val_Acc:  3.5170579015914627\n",
      "Epoch number: 38/10000step_number: 0/29 Accuracy:  0.2056870423974119 Loss:  3.528669295569657 Val_accuracy:  0.200762734949605 Val_cost:  3.528669295569657 Val_accuracy:  0.200762734949605 Val_Acc:  3.518175890099035\n",
      "Epoch number: 39/10000step_number: 0/29 Accuracy:  0.22220330325217094 Loss:  3.529464542426695 Val_accuracy:  0.21656224461999454 Val_cost:  3.529464542426695 Val_accuracy:  0.21656224461999454 Val_Acc:  3.5181439535822627\n",
      "Epoch number: 40/10000step_number: 0/29 Accuracy:  0.2259492593223225 Loss:  3.529012113748047 Val_accuracy:  0.22037591936801962 Val_cost:  3.529012113748047 Val_accuracy:  0.22037591936801962 Val_Acc:  3.516859230453482\n",
      "Epoch number: 41/10000step_number: 0/29 Accuracy:  0.22908224076281286 Loss:  3.527266037939572 Val_accuracy:  0.22473440479433396 Val_cost:  3.527266037939572 Val_accuracy:  0.22473440479433396 Val_Acc:  3.514319107147313\n",
      "Epoch number: 42/10000step_number: 0/29 Accuracy:  0.23299846756342585 Loss:  3.524262235119324 Val_accuracy:  0.22786706619449743 Val_cost:  3.524262235119324 Val_accuracy:  0.22786706619449743 Val_Acc:  3.5105640641923035\n",
      "Epoch number: 43/10000step_number: 0/29 Accuracy:  0.23436063340711732 Loss:  3.520209114077352 Val_accuracy:  0.22868428221193135 Val_cost:  3.520209114077352 Val_accuracy:  0.22868428221193135 Val_Acc:  3.5058469301135387\n",
      "Epoch number: 44/10000step_number: 0/29 Accuracy:  0.23609739485782394 Loss:  3.515161309525461 Val_accuracy:  0.2301825115772269 Val_cost:  3.515161309525461 Val_accuracy:  0.2301825115772269 Val_Acc:  3.5001646489562455\n",
      "Epoch number: 45/10000step_number: 0/29 Accuracy:  0.23504171632896306 Loss:  3.5091581275868666 Val_accuracy:  0.22963770089893762 Val_cost:  3.5091581275868666 Val_accuracy:  0.22963770089893762 Val_Acc:  3.493559276572631\n",
      "Epoch number: 46/10000step_number: 0/29 Accuracy:  0.23524604120551676 Loss:  3.502394501928742 Val_accuracy:  0.22963770089893762 Val_cost:  3.502394501928742 Val_accuracy:  0.22963770089893762 Val_Acc:  3.4862708020121294\n",
      "Epoch number: 47/10000step_number: 0/29 Accuracy:  0.23558658266643964 Loss:  3.4950573663221816 Val_accuracy:  0.22977390356850994 Val_cost:  3.4950573663221816 Val_accuracy:  0.22977390356850994 Val_Acc:  3.478492618387411\n",
      "Epoch number: 48/10000step_number: 0/29 Accuracy:  0.23562063681253193 Loss:  3.4873056510695397 Val_accuracy:  0.22922909289022064 Val_cost:  3.4873056510695397 Val_accuracy:  0.22922909289022064 Val_Acc:  3.4703829877410524\n",
      "Epoch number: 49/10000step_number: 0/29 Accuracy:  0.23609739485782394 Loss:  3.4792838284117913 Val_accuracy:  0.22922909289022064 Val_cost:  3.4792838284117913 Val_accuracy:  0.22922909289022064 Val_Acc:  3.462082409335933\n",
      "Epoch number: 50/10000step_number: 0/29 Accuracy:  0.2367103694874851 Loss:  3.4710421784626107 Val_accuracy:  0.228956687551076 Val_cost:  3.4710421784626107 Val_accuracy:  0.228956687551076 Val_Acc:  3.4536458432577493\n",
      "Epoch number: 51/10000step_number: 0/29 Accuracy:  0.23711901924059253 Loss:  3.4625826548259786 Val_accuracy:  0.22854807954235903 Val_cost:  3.4625826548259786 Val_accuracy:  0.22854807954235903 Val_Acc:  3.4449880487992917\n",
      "Epoch number: 52/10000step_number: 0/29 Accuracy:  0.23807253533117656 Loss:  3.4539741362884344 Val_accuracy:  0.22909289022064833 Val_cost:  3.4539741362884344 Val_accuracy:  0.22909289022064833 Val_Acc:  3.43624151418561\n",
      "Epoch number: 53/10000step_number: 0/29 Accuracy:  0.23885578069129917 Loss:  3.445409935552332 Val_accuracy:  0.22991010623808228 Val_cost:  3.445409935552332 Val_accuracy:  0.22991010623808228 Val_Acc:  3.4275727611250124\n",
      "Epoch number: 54/10000step_number: 0/29 Accuracy:  0.2395368636131449 Loss:  3.4369650382575685 Val_accuracy:  0.2305911195859439 Val_cost:  3.4369650382575685 Val_accuracy:  0.2305911195859439 Val_Acc:  3.4190433356119847\n",
      "Epoch number: 55/10000step_number: 0/29 Accuracy:  0.23994551336625233 Loss:  3.428580544418825 Val_accuracy:  0.2312721329338055 Val_cost:  3.428580544418825 Val_accuracy:  0.2312721329338055 Val_Acc:  3.4105963835587394\n",
      "Epoch number: 56/10000step_number: 0/29 Accuracy:  0.24052443384982122 Loss:  3.4202884122485395 Val_accuracy:  0.23195314628166713 Val_cost:  3.4202884122485395 Val_accuracy:  0.23195314628166713 Val_Acc:  3.402268654085965\n",
      "Epoch number: 57/10000step_number: 0/29 Accuracy:  0.2407968670185595 Loss:  3.412076630860388 Val_accuracy:  0.23277036229910106 Val_cost:  3.412076630860388 Val_accuracy:  0.23277036229910106 Val_Acc:  3.3940402316599165\n",
      "Epoch number: 58/10000step_number: 0/29 Accuracy:  0.2410693001872978 Loss:  3.4038299746045917 Val_accuracy:  0.23290656496867337 Val_cost:  3.4038299746045917 Val_accuracy:  0.23290656496867337 Val_Acc:  3.3858797656652393\n",
      "Epoch number: 59/10000step_number: 0/29 Accuracy:  0.24052443384982122 Loss:  3.395769135326493 Val_accuracy:  0.23317897030781803 Val_cost:  3.395769135326493 Val_accuracy:  0.23317897030781803 Val_Acc:  3.377845967384111\n",
      "Epoch number: 60/10000step_number: 0/29 Accuracy:  0.23837902264600716 Loss:  3.3880542338510113 Val_accuracy:  0.23099972759466086 Val_cost:  3.3880542338510113 Val_accuracy:  0.23099972759466086 Val_Acc:  3.370191599401843\n",
      "Epoch number: 61/10000step_number: 0/29 Accuracy:  0.2335773880469947 Loss:  3.3804394093315775 Val_accuracy:  0.2254154181421956 Val_cost:  3.3804394093315775 Val_accuracy:  0.2254154181421956 Val_Acc:  3.362669471705139\n",
      "Epoch number: 62/10000step_number: 0/29 Accuracy:  0.22697088370509108 Loss:  3.3728752219913605 Val_accuracy:  0.22037591936801962 Val_cost:  3.3728752219913605 Val_accuracy:  0.22037591936801962 Val_Acc:  3.3551865661244684\n",
      "Epoch number: 63/10000step_number: 0/29 Accuracy:  0.22244168227481695 Loss:  3.3653823711206443 Val_accuracy:  0.2161536366112776 Val_cost:  3.3653823711206443 Val_accuracy:  0.2161536366112776 Val_Acc:  3.347810310902213\n",
      "Epoch number: 64/10000step_number: 0/29 Accuracy:  0.2212497871615869 Loss:  3.3581231202468533 Val_accuracy:  0.21506401525469898 Val_cost:  3.3581231202468533 Val_accuracy:  0.21506401525469898 Val_Acc:  3.3406090083085482\n",
      "Epoch number: 65/10000step_number: 0/29 Accuracy:  0.21675463987740506 Loss:  3.3511323900455636 Val_accuracy:  0.21070552982838464 Val_cost:  3.3511323900455636 Val_accuracy:  0.21070552982838464 Val_Acc:  3.333701026179488\n",
      "Epoch number: 66/10000step_number: 0/29 Accuracy:  0.2133492252681764 Loss:  3.3442870133936102 Val_accuracy:  0.20798147643693815 Val_cost:  3.3442870133936102 Val_accuracy:  0.20798147643693815 Val_Acc:  3.3269531442223736\n",
      "Epoch number: 67/10000step_number: 0/29 Accuracy:  0.21253192576196153 Loss:  3.3371429547546634 Val_accuracy:  0.20743666575864886 Val_cost:  3.3371429547546634 Val_accuracy:  0.20743666575864886 Val_Acc:  3.3199010353377068\n",
      "Epoch number: 68/10000step_number: 0/29 Accuracy:  0.21365571258300697 Loss:  3.330182045006077 Val_accuracy:  0.20798147643693815 Val_cost:  3.330182045006077 Val_accuracy:  0.20798147643693815 Val_Acc:  3.3130615000940806\n",
      "Epoch number: 69/10000step_number: 0/29 Accuracy:  0.21372382087519157 Loss:  3.323435410338695 Val_accuracy:  0.20730046308907654 Val_cost:  3.323435410338695 Val_accuracy:  0.20730046308907654 Val_Acc:  3.3064545996392787\n",
      "Epoch number: 70/10000step_number: 0/29 Accuracy:  0.2136216584369147 Loss:  3.3168079864361846 Val_accuracy:  0.20675565241078725 Val_cost:  3.3168079864361846 Val_accuracy:  0.20675565241078725 Val_Acc:  3.2999940846495663\n",
      "Epoch number: 71/10000step_number: 0/29 Accuracy:  0.21368976672909926 Loss:  3.310222760489484 Val_accuracy:  0.20675565241078725 Val_cost:  3.310222760489484 Val_accuracy:  0.20675565241078725 Val_Acc:  3.293615458121208\n",
      "Epoch number: 72/10000step_number: 0/29 Accuracy:  0.21314490039162268 Loss:  3.303481949930392 Val_accuracy:  0.20634704440207027 Val_cost:  3.303481949930392 Val_accuracy:  0.20634704440207027 Val_Acc:  3.2872031464523452\n",
      "Epoch number: 73/10000step_number: 0/29 Accuracy:  0.21328111697599184 Loss:  3.296598183716949 Val_accuracy:  0.20648324707164262 Val_cost:  3.296598183716949 Val_accuracy:  0.20648324707164262 Val_Acc:  3.2807112364045534\n",
      "Epoch number: 74/10000step_number: 0/29 Accuracy:  0.21379192916737613 Loss:  3.2891266791898266 Val_accuracy:  0.20689185508035957 Val_cost:  3.2891266791898266 Val_accuracy:  0.20689185508035957 Val_Acc:  3.2740454807770707\n",
      "Epoch number: 75/10000step_number: 0/29 Accuracy:  0.21450706623531415 Loss:  3.2813178110232633 Val_accuracy:  0.2070280577499319 Val_cost:  3.2813178110232633 Val_accuracy:  0.2070280577499319 Val_Acc:  3.266891596679288\n",
      "Epoch number: 76/10000step_number: 0/29 Accuracy:  0.21522220330325217 Loss:  3.2755874259839404 Val_accuracy:  0.20716426041950423 Val_cost:  3.2755874259839404 Val_accuracy:  0.20716426041950423 Val_Acc:  3.261832786500677\n",
      "Epoch number: 77/10000step_number: 0/29 Accuracy:  0.21546058232589818 Loss:  3.268546340341656 Val_accuracy:  0.20675565241078725 Val_cost:  3.268546340341656 Val_accuracy:  0.20675565241078725 Val_Acc:  3.255307845456284\n",
      "Epoch number: 78/10000step_number: 0/29 Accuracy:  0.21539247403371362 Loss:  3.262482094388479 Val_accuracy:  0.20730046308907654 Val_cost:  3.262482094388479 Val_accuracy:  0.20730046308907654 Val_Acc:  3.2497267236288407\n",
      "Epoch number: 79/10000step_number: 0/29 Accuracy:  0.21603950280946704 Loss:  3.2564111400155564 Val_accuracy:  0.20784527376736583 Val_cost:  3.2564111400155564 Val_accuracy:  0.20784527376736583 Val_Acc:  3.2440776870960724\n",
      "Epoch number: 80/10000step_number: 0/29 Accuracy:  0.21607355695555933 Loss:  3.2501760685324177 Val_accuracy:  0.2087986924543721 Val_cost:  3.2501760685324177 Val_accuracy:  0.2087986924543721 Val_Acc:  3.238172001647402\n",
      "Epoch number: 81/10000step_number: 0/29 Accuracy:  0.21675463987740506 Loss:  3.244121457308825 Val_accuracy:  0.21016071915009535 Val_cost:  3.244121457308825 Val_accuracy:  0.21016071915009535 Val_Acc:  3.2325166925327884\n",
      "Epoch number: 82/10000step_number: 0/29 Accuracy:  0.21682274816958966 Loss:  3.238243824909956 Val_accuracy:  0.21016071915009535 Val_cost:  3.238243824909956 Val_accuracy:  0.21016071915009535 Val_Acc:  3.227030878836171\n",
      "Epoch number: 83/10000step_number: 0/29 Accuracy:  0.21648220670866677 Loss:  3.232411820309338 Val_accuracy:  0.20961590847180606 Val_cost:  3.232411820309338 Val_accuracy:  0.20961590847180606 Val_Acc:  3.221589793833038\n",
      "Epoch number: 84/10000step_number: 0/29 Accuracy:  0.21603950280946704 Loss:  3.2268163229475775 Val_accuracy:  0.2087986924543721 Val_cost:  3.2268163229475775 Val_accuracy:  0.2087986924543721 Val_Acc:  3.216369199566949\n",
      "Epoch number: 85/10000step_number: 0/29 Accuracy:  0.2156649072024519 Loss:  3.2217329631005933 Val_accuracy:  0.20920730046308908 Val_cost:  3.2217329631005933 Val_accuracy:  0.20920730046308908 Val_Acc:  3.2116203286670455\n",
      "Epoch number: 86/10000step_number: 0/29 Accuracy:  0.21529031159543674 Loss:  3.216515427354946 Val_accuracy:  0.20893489512394442 Val_cost:  3.216515427354946 Val_accuracy:  0.20893489512394442 Val_Acc:  3.2066096726415143\n",
      "Epoch number: 87/10000step_number: 0/29 Accuracy:  0.21501787842669845 Loss:  3.21134568253199 Val_accuracy:  0.2087986924543721 Val_cost:  3.21134568253199 Val_accuracy:  0.2087986924543721 Val_Acc:  3.2017163532166575\n",
      "Epoch number: 88/10000step_number: 0/29 Accuracy:  0.21477949940405244 Loss:  3.2065005509410645 Val_accuracy:  0.2087986924543721 Val_cost:  3.2065005509410645 Val_accuracy:  0.2087986924543721 Val_Acc:  3.1971335036585167\n",
      "Epoch number: 89/10000step_number: 0/29 Accuracy:  0.2151200408649753 Loss:  3.201435036674059 Val_accuracy:  0.2093435031326614 Val_cost:  3.201435036674059 Val_accuracy:  0.2093435031326614 Val_Acc:  3.1923471968662454\n",
      "Epoch number: 90/10000step_number: 0/29 Accuracy:  0.21508598671888302 Loss:  3.1965194235778136 Val_accuracy:  0.20920730046308908 Val_cost:  3.1965194235778136 Val_accuracy:  0.20920730046308908 Val_Acc:  3.187716007261743\n",
      "Epoch number: 91/10000step_number: 0/29 Accuracy:  0.21447301208922187 Loss:  3.1916038630448336 Val_accuracy:  0.20784527376736583 Val_cost:  3.1916038630448336 Val_accuracy:  0.20784527376736583 Val_Acc:  3.1831269917426273\n",
      "Epoch number: 92/10000step_number: 0/29 Accuracy:  0.21423463306657586 Loss:  3.1871773390068108 Val_accuracy:  0.20784527376736583 Val_cost:  3.1871773390068108 Val_accuracy:  0.20784527376736583 Val_Acc:  3.1789139742051664\n",
      "Epoch number: 93/10000step_number: 0/29 Accuracy:  0.2135876042908224 Loss:  3.1826274480140997 Val_accuracy:  0.2075728684282212 Val_cost:  3.1826274480140997 Val_accuracy:  0.2075728684282212 Val_Acc:  3.1744363132360247\n",
      "Epoch number: 94/10000step_number: 0/29 Accuracy:  0.21396219989783757 Loss:  3.178084856293887 Val_accuracy:  0.2082538817760828 Val_cost:  3.178084856293887 Val_accuracy:  0.2082538817760828 Val_Acc:  3.1700096528277637\n",
      "Epoch number: 95/10000step_number: 0/29 Accuracy:  0.21253192576196153 Loss:  3.1737647594945226 Val_accuracy:  0.20648324707164262 Val_cost:  3.1737647594945226 Val_accuracy:  0.20648324707164262 Val_Acc:  3.1657864070545987\n",
      "Epoch number: 96/10000step_number: 0/29 Accuracy:  0.21242976332368466 Loss:  3.1695898567054432 Val_accuracy:  0.20661944974121493 Val_cost:  3.1695898567054432 Val_accuracy:  0.20661944974121493 Val_Acc:  3.1617022120318827\n",
      "Epoch number: 97/10000step_number: 0/29 Accuracy:  0.21246381746977694 Loss:  3.165562284967682 Val_accuracy:  0.20661944974121493 Val_cost:  3.165562284967682 Val_accuracy:  0.20661944974121493 Val_Acc:  3.1577786735913365\n",
      "Epoch number: 98/10000step_number: 0/29 Accuracy:  0.21239570917759237 Loss:  3.161677399872918 Val_accuracy:  0.20716426041950423 Val_cost:  3.161677399872918 Val_accuracy:  0.20716426041950423 Val_Acc:  3.1539933191475438\n",
      "Epoch number: 99/10000step_number: 0/29 Accuracy:  0.21273625063851523 Loss:  3.1578431075882043 Val_accuracy:  0.20675565241078725 Val_cost:  3.1578431075882043 Val_accuracy:  0.20675565241078725 Val_Acc:  3.150243601221711\n",
      "Epoch number: 100/10000step_number: 0/29 Accuracy:  0.21222543844713093 Loss:  3.1540202027770086 Val_accuracy:  0.20634704440207027 Val_cost:  3.1540202027770086 Val_accuracy:  0.20634704440207027 Val_Acc:  3.146498328251044\n",
      "Epoch number: 101/10000step_number: 0/29 Accuracy:  0.21229354673931553 Loss:  3.1503175842467037 Val_accuracy:  0.20634704440207027 Val_cost:  3.1503175842467037 Val_accuracy:  0.20634704440207027 Val_Acc:  3.1428652923704057\n",
      "Epoch number: 102/10000step_number: 0/29 Accuracy:  0.2123276008854078 Loss:  3.146738264529349 Val_accuracy:  0.20730046308907654 Val_cost:  3.146738264529349 Val_accuracy:  0.20730046308907654 Val_Acc:  3.139352370010593\n",
      "Epoch number: 103/10000step_number: 0/29 Accuracy:  0.2123276008854078 Loss:  3.1432993739708603 Val_accuracy:  0.20716426041950423 Val_cost:  3.1432993739708603 Val_accuracy:  0.20716426041950423 Val_Acc:  3.135975632569312\n",
      "Epoch number: 104/10000step_number: 0/29 Accuracy:  0.2123276008854078 Loss:  3.1400234211771916 Val_accuracy:  0.20675565241078725 Val_cost:  3.1400234211771916 Val_accuracy:  0.20675565241078725 Val_Acc:  3.132755078253099\n",
      "Epoch number: 105/10000step_number: 0/29 Accuracy:  0.21212327600885408 Loss:  3.1369282682712636 Val_accuracy:  0.20675565241078725 Val_cost:  3.1369282682712636 Val_accuracy:  0.20675565241078725 Val_Acc:  3.1296946961441052\n",
      "Epoch number: 106/10000step_number: 0/29 Accuracy:  0.2120211135705772 Loss:  3.133976637151046 Val_accuracy:  0.20770907109779352 Val_cost:  3.133976637151046 Val_accuracy:  0.20770907109779352 Val_Acc:  3.1267459576960843\n",
      "Epoch number: 107/10000step_number: 0/29 Accuracy:  0.2126000340541461 Loss:  3.1311423798936255 Val_accuracy:  0.2081176791065105 Val_cost:  3.1311423798936255 Val_accuracy:  0.2081176791065105 Val_Acc:  3.1238789146845516\n",
      "Epoch number: 108/10000step_number: 0/29 Accuracy:  0.2131108462455304 Loss:  3.1284788952383042 Val_accuracy:  0.2093435031326614 Val_cost:  3.1284788952383042 Val_accuracy:  0.2093435031326614 Val_Acc:  3.12115516227754\n",
      "Epoch number: 109/10000step_number: 0/29 Accuracy:  0.2136216584369147 Loss:  3.1260548197109856 Val_accuracy:  0.21029692181966766 Val_cost:  3.1260548197109856 Val_accuracy:  0.21029692181966766 Val_Acc:  3.1186299478179236\n",
      "Epoch number: 110/10000step_number: 0/29 Accuracy:  0.21430274135876043 Loss:  3.1237891997785456 Val_accuracy:  0.20961590847180606 Val_cost:  3.1237891997785456 Val_accuracy:  0.20961590847180606 Val_Acc:  3.1162453652411966\n",
      "Epoch number: 111/10000step_number: 0/29 Accuracy:  0.21699301890005107 Loss:  3.121504843420372 Val_accuracy:  0.2122037591936802 Val_cost:  3.121504843420372 Val_accuracy:  0.2122037591936802 Val_Acc:  3.1138449456498725\n",
      "Epoch number: 112/10000step_number: 0/29 Accuracy:  0.21879788864294228 Loss:  3.1191328244609577 Val_accuracy:  0.21411059656769274 Val_cost:  3.1191328244609577 Val_accuracy:  0.21411059656769274 Val_Acc:  3.111359745460859\n",
      "Epoch number: 113/10000step_number: 0/29 Accuracy:  0.2200238379022646 Loss:  3.11675510520611 Val_accuracy:  0.21560882593298827 Val_cost:  3.11675510520611 Val_accuracy:  0.21560882593298827 Val_Acc:  3.1088559371948965\n",
      "Epoch number: 114/10000step_number: 0/29 Accuracy:  0.22097735399284862 Loss:  3.114436796991291 Val_accuracy:  0.2166984472895669 Val_cost:  3.114436796991291 Val_accuracy:  0.2166984472895669 Val_Acc:  3.1063906177801996\n",
      "Epoch number: 115/10000step_number: 0/29 Accuracy:  0.2231227651966627 Loss:  3.1121872364385945 Val_accuracy:  0.21969490602015798 Val_cost:  3.1121872364385945 Val_accuracy:  0.21969490602015798 Val_Acc:  3.1039749933151772\n",
      "Epoch number: 116/10000step_number: 0/29 Accuracy:  0.22431466030989272 Loss:  3.109989548233715 Val_accuracy:  0.2214655407245982 Val_cost:  3.109989548233715 Val_accuracy:  0.2214655407245982 Val_Acc:  3.101598165195931\n",
      "Epoch number: 117/10000step_number: 0/29 Accuracy:  0.22574493444576876 Loss:  3.1078496485391405 Val_accuracy:  0.22337237809861074 Val_cost:  3.1078496485391405 Val_accuracy:  0.22337237809861074 Val_Acc:  3.0992720461028602\n",
      "Epoch number: 118/10000step_number: 0/29 Accuracy:  0.2275157500425677 Loss:  3.1057439272925262 Val_accuracy:  0.22527921547262325 Val_cost:  3.1057439272925262 Val_accuracy:  0.22527921547262325 Val_Acc:  3.096974895449841\n",
      "Epoch number: 119/10000step_number: 0/29 Accuracy:  0.22846926613315172 Loss:  3.1036653293968928 Val_accuracy:  0.22623263415962952 Val_cost:  3.1036653293968928 Val_accuracy:  0.22623263415962952 Val_Acc:  3.094701046479014\n",
      "Epoch number: 120/10000step_number: 0/29 Accuracy:  0.23136386855099608 Loss:  3.101630147888391 Val_accuracy:  0.2295014982293653 Val_cost:  3.101630147888391 Val_accuracy:  0.2295014982293653 Val_Acc:  3.0924764391125983\n",
      "Epoch number: 121/10000step_number: 0/29 Accuracy:  0.23299846756342585 Loss:  3.099638199683056 Val_accuracy:  0.23099972759466086 Val_cost:  3.099638199683056 Val_accuracy:  0.23099972759466086 Val_Acc:  3.0903059865814053\n",
      "Epoch number: 122/10000step_number: 0/29 Accuracy:  0.23381576706964072 Loss:  3.097665468681539 Val_accuracy:  0.2318169436120948 Val_cost:  3.097665468681539 Val_accuracy:  0.2318169436120948 Val_Acc:  3.088173141681042\n",
      "Epoch number: 123/10000step_number: 0/29 Accuracy:  0.23654009875702367 Loss:  3.095696356241979 Val_accuracy:  0.23426859166439662 Val_cost:  3.095696356241979 Val_accuracy:  0.23426859166439662 Val_Acc:  3.0860678002880646\n",
      "Epoch number: 124/10000step_number: 0/29 Accuracy:  0.23814064362336115 Loss:  3.0937592447741418 Val_accuracy:  0.23617542903840916 Val_cost:  3.0937592447741418 Val_accuracy:  0.23617542903840916 Val_Acc:  3.084015438434066\n",
      "Epoch number: 125/10000step_number: 0/29 Accuracy:  0.24049037970372894 Loss:  3.0918534025010254 Val_accuracy:  0.23889948242985562 Val_cost:  3.0918534025010254 Val_accuracy:  0.23889948242985562 Val_Acc:  3.082012606220377\n",
      "Epoch number: 126/10000step_number: 0/29 Accuracy:  0.2408309211646518 Loss:  3.089918220428941 Val_accuracy:  0.23971669844728957 Val_cost:  3.089918220428941 Val_accuracy:  0.23971669844728957 Val_Acc:  3.0799967528075847\n",
      "Epoch number: 127/10000step_number: 0/29 Accuracy:  0.24202281627788183 Loss:  3.0879392740114273 Val_accuracy:  0.23971669844728957 Val_cost:  3.0879392740114273 Val_accuracy:  0.23971669844728957 Val_Acc:  3.0779475104471157\n",
      "Epoch number: 128/10000step_number: 0/29 Accuracy:  0.24096713774902095 Loss:  3.085930959267158 Val_accuracy:  0.23917188776900028 Val_cost:  3.085930959267158 Val_accuracy:  0.23917188776900028 Val_Acc:  3.075876637588246\n",
      "Epoch number: 129/10000step_number: 0/29 Accuracy:  0.2433849821215733 Loss:  3.083905747289372 Val_accuracy:  0.24094252247344047 Val_cost:  3.083905747289372 Val_accuracy:  0.24094252247344047 Val_Acc:  3.073794971799215\n",
      "Epoch number: 130/10000step_number: 0/29 Accuracy:  0.24410011918951133 Loss:  3.081869204696105 Val_accuracy:  0.24175973849087443 Val_cost:  3.081869204696105 Val_accuracy:  0.24175973849087443 Val_Acc:  3.0717072343457605\n",
      "Epoch number: 131/10000step_number: 0/29 Accuracy:  0.2441682274816959 Loss:  3.079823423360528 Val_accuracy:  0.24189594116044674 Val_cost:  3.079823423360528 Val_accuracy:  0.24189594116044674 Val_Acc:  3.0696155356813697\n",
      "Epoch number: 132/10000step_number: 0/29 Accuracy:  0.24651796356206368 Loss:  3.0777691867445673 Val_accuracy:  0.242849359847453 Val_cost:  3.0777691867445673 Val_accuracy:  0.242849359847453 Val_Acc:  3.067520989260604\n",
      "Epoch number: 133/10000step_number: 0/29 Accuracy:  0.24808445428230888 Loss:  3.075706996946864 Val_accuracy:  0.24380277853445928 Val_cost:  3.075706996946864 Val_accuracy:  0.24380277853445928 Val_Acc:  3.0654242726048744\n",
      "Epoch number: 134/10000step_number: 0/29 Accuracy:  0.24815256257449345 Loss:  3.0736374983187233 Val_accuracy:  0.24353037319531462 Val_cost:  3.0736374983187233 Val_accuracy:  0.24353037319531462 Val_Acc:  3.06332587107163\n",
      "Epoch number: 135/10000step_number: 0/29 Accuracy:  0.24665418014643284 Loss:  3.071562098981869 Val_accuracy:  0.24012530645600655 Val_cost:  3.071562098981869 Val_accuracy:  0.24012530645600655 Val_Acc:  3.061226901782237\n",
      "Epoch number: 136/10000step_number: 0/29 Accuracy:  0.24862932061978546 Loss:  3.0694865575949595 Val_accuracy:  0.2416235358213021 Val_cost:  3.0694865575949595 Val_accuracy:  0.2416235358213021 Val_Acc:  3.0591342518222215\n",
      "Epoch number: 137/10000step_number: 0/29 Accuracy:  0.24893580793461603 Loss:  3.067442892204149 Val_accuracy:  0.24230454916916372 Val_cost:  3.067442892204149 Val_accuracy:  0.24230454916916372 Val_Acc:  3.0570881574949347\n",
      "Epoch number: 138/10000step_number: 0/29 Accuracy:  0.24988932402520006 Loss:  3.0654686697654747 Val_accuracy:  0.242849359847453 Val_cost:  3.0654686697654747 Val_accuracy:  0.242849359847453 Val_Acc:  3.0551221233281747\n",
      "Epoch number: 139/10000step_number: 0/29 Accuracy:  0.2505704069470458 Loss:  3.063517101618737 Val_accuracy:  0.24257695450830835 Val_cost:  3.063517101618737 Val_accuracy:  0.24257695450830835 Val_Acc:  3.0531688765630087\n",
      "Epoch number: 140/10000step_number: 0/29 Accuracy:  0.24988932402520006 Loss:  3.061560547293503 Val_accuracy:  0.24244075183873603 Val_cost:  3.061560547293503 Val_accuracy:  0.24244075183873603 Val_Acc:  3.0512113119618416\n",
      "Epoch number: 141/10000step_number: 0/29 Accuracy:  0.2502298654861229 Loss:  3.059615898756655 Val_accuracy:  0.2440751838736039 Val_cost:  3.059615898756655 Val_accuracy:  0.2440751838736039 Val_Acc:  3.0492706786147727\n",
      "Epoch number: 142/10000step_number: 0/29 Accuracy:  0.24883364549633918 Loss:  3.0576936519754634 Val_accuracy:  0.2427131571778807 Val_cost:  3.0576936519754634 Val_accuracy:  0.2427131571778807 Val_Acc:  3.047357096231761\n",
      "Epoch number: 143/10000step_number: 0/29 Accuracy:  0.24610931380895623 Loss:  3.055798781773867 Val_accuracy:  0.23849087442113864 Val_cost:  3.055798781773867 Val_accuracy:  0.23849087442113864 Val_Acc:  3.045475918304726\n",
      "Epoch number: 144/10000step_number: 0/29 Accuracy:  0.24679039673080197 Loss:  3.0539338931295332 Val_accuracy:  0.2393080904385726 Val_cost:  3.0539338931295332 Val_accuracy:  0.2393080904385726 Val_Acc:  3.0436304049429315\n",
      "Epoch number: 145/10000step_number: 0/29 Accuracy:  0.24018389238889834 Loss:  3.0520960131547774 Val_accuracy:  0.23331517297739035 Val_cost:  3.0520960131547774 Val_accuracy:  0.23331517297739035 Val_Acc:  3.0418203242016237\n",
      "Epoch number: 146/10000step_number: 0/29 Accuracy:  0.23538225778988592 Loss:  3.0502841891041537 Val_accuracy:  0.22977390356850994 Val_cost:  3.0502841891041537 Val_accuracy:  0.22977390356850994 Val_Acc:  3.0400568863441118\n",
      "Epoch number: 147/10000step_number: 0/29 Accuracy:  0.22969521539247403 Loss:  3.0484843263212325 Val_accuracy:  0.22459820212476164 Val_cost:  3.0484843263212325 Val_accuracy:  0.22459820212476164 Val_Acc:  3.0383268292400167\n",
      "Epoch number: 148/10000step_number: 0/29 Accuracy:  0.22836710369487484 Loss:  3.0467311430036745 Val_accuracy:  0.22418959411604467 Val_cost:  3.0467311430036745 Val_accuracy:  0.22418959411604467 Val_Acc:  3.0366314196288036\n",
      "Epoch number: 149/10000step_number: 0/29 Accuracy:  0.23064873148305806 Loss:  3.0449447430881142 Val_accuracy:  0.2267774448379188 Val_cost:  3.0449447430881142 Val_accuracy:  0.2267774448379188 Val_Acc:  3.0348888556888727\n",
      "Epoch number: 150/10000step_number: 0/29 Accuracy:  0.23446279584539417 Loss:  3.043228352997641 Val_accuracy:  0.233996186325252 Val_cost:  3.043228352997641 Val_accuracy:  0.233996186325252 Val_Acc:  3.0332122160206607\n",
      "Epoch number: 151/10000step_number: 0/29 Accuracy:  0.2343946875532096 Loss:  3.041566329244339 Val_accuracy:  0.23385998365567964 Val_cost:  3.041566329244339 Val_accuracy:  0.23385998365567964 Val_Acc:  3.031576036537323\n",
      "Epoch number: 152/10000step_number: 0/29 Accuracy:  0.23841307679209944 Loss:  3.0399410823404347 Val_accuracy:  0.238627077090711 Val_cost:  3.0399410823404347 Val_accuracy:  0.238627077090711 Val_Acc:  3.029965416820365\n",
      "Epoch number: 153/10000step_number: 0/29 Accuracy:  0.23694874851013112 Loss:  3.038346202130484 Val_accuracy:  0.2353582130209752 Val_cost:  3.038346202130484 Val_accuracy:  0.2353582130209752 Val_Acc:  3.0283822198727783\n",
      "Epoch number: 154/10000step_number: 0/29 Accuracy:  0.23446279584539417 Loss:  3.0367727011538546 Val_accuracy:  0.23426859166439662 Val_cost:  3.0367727011538546 Val_accuracy:  0.23426859166439662 Val_Acc:  3.026821033542171\n",
      "Epoch number: 155/10000step_number: 0/29 Accuracy:  0.23218116805721098 Loss:  3.0352113165811097 Val_accuracy:  0.23277036229910106 Val_cost:  3.0352113165811097 Val_accuracy:  0.23277036229910106 Val_Acc:  3.025274076170996\n",
      "Epoch number: 156/10000step_number: 0/29 Accuracy:  0.23061467733696578 Loss:  3.03365466483816 Val_accuracy:  0.23154453827295016 Val_cost:  3.03365466483816 Val_accuracy:  0.23154453827295016 Val_Acc:  3.0237339888143877\n",
      "Epoch number: 157/10000step_number: 0/29 Accuracy:  0.2313298144049038 Loss:  3.0321000771838547 Val_accuracy:  0.23331517297739035 Val_cost:  3.0321000771838547 Val_accuracy:  0.23331517297739035 Val_Acc:  3.0221973479884516\n",
      "Epoch number: 158/10000step_number: 0/29 Accuracy:  0.22537033883875363 Loss:  3.030547423791123 Val_accuracy:  0.22704985017706347 Val_cost:  3.030547423791123 Val_accuracy:  0.22704985017706347 Val_Acc:  3.02066319897416\n",
      "Epoch number: 159/10000step_number: 0/29 Accuracy:  0.2251660139621999 Loss:  3.0289953739174034 Val_accuracy:  0.2259602288204849 Val_cost:  3.0289953739174034 Val_accuracy:  0.2259602288204849 Val_Acc:  3.019129807603454\n",
      "Epoch number: 160/10000step_number: 0/29 Accuracy:  0.22502979737783074 Loss:  3.027443210989718 Val_accuracy:  0.2266412421683465 Val_cost:  3.027443210989718 Val_accuracy:  0.2266412421683465 Val_Acc:  3.017596610609536\n",
      "Epoch number: 161/10000step_number: 0/29 Accuracy:  0.22537033883875363 Loss:  3.025896025271534 Val_accuracy:  0.2267774448379188 Val_cost:  3.025896025271534 Val_accuracy:  0.2267774448379188 Val_Acc:  3.016069122969658\n",
      "Epoch number: 162/10000step_number: 0/29 Accuracy:  0.2256768261535842 Loss:  3.024366334279155 Val_accuracy:  0.22786706619449743 Val_cost:  3.024366334279155 Val_accuracy:  0.22786706619449743 Val_Acc:  3.0145602447492776\n",
      "Epoch number: 163/10000step_number: 0/29 Accuracy:  0.22761791248084454 Loss:  3.0228671762142594 Val_accuracy:  0.2307273222555162 Val_cost:  3.0228671762142594 Val_accuracy:  0.2307273222555162 Val_Acc:  3.013084700702012\n",
      "Epoch number: 164/10000step_number: 0/29 Accuracy:  0.22809467052613655 Loss:  3.0214025672268026 Val_accuracy:  0.23249795695995643 Val_cost:  3.0214025672268026 Val_accuracy:  0.23249795695995643 Val_Acc:  3.011648650808777\n",
      "Epoch number: 165/10000step_number: 0/29 Accuracy:  0.22959305295419719 Loss:  3.0199690370859607 Val_accuracy:  0.2353582130209752 Val_cost:  3.0199690370859607 Val_accuracy:  0.2353582130209752 Val_Acc:  3.010249022655366\n",
      "Epoch number: 166/10000step_number: 0/29 Accuracy:  0.2307508939213349 Loss:  3.0185604992014907 Val_accuracy:  0.23631163170798147 Val_cost:  3.0185604992014907 Val_accuracy:  0.23631163170798147 Val_Acc:  3.0088729390139184\n",
      "Epoch number: 167/10000step_number: 0/29 Accuracy:  0.23115954367444236 Loss:  3.0171169057679625 Val_accuracy:  0.23617542903840916 Val_cost:  3.0171169057679625 Val_accuracy:  0.23617542903840916 Val_Acc:  3.00747504844149\n",
      "Epoch number: 168/10000step_number: 0/29 Accuracy:  0.23255576366422612 Loss:  3.0157427353846105 Val_accuracy:  0.23672023971669845 Val_cost:  3.0157427353846105 Val_accuracy:  0.23672023971669845 Val_Acc:  3.0061957963420287\n",
      "Epoch number: 169/10000step_number: 0/29 Accuracy:  0.23218116805721098 Loss:  3.0142295727021233 Val_accuracy:  0.2359030236992645 Val_cost:  3.0142295727021233 Val_accuracy:  0.2359030236992645 Val_Acc:  3.00476788147062\n",
      "Epoch number: 170/10000step_number: 0/29 Accuracy:  0.23245360122594927 Loss:  3.0128247308792866 Val_accuracy:  0.23603922636883684 Val_cost:  3.0128247308792866 Val_accuracy:  0.23603922636883684 Val_Acc:  3.003384195684107\n",
      "Epoch number: 171/10000step_number: 0/29 Accuracy:  0.23463306657585561 Loss:  3.011373999304746 Val_accuracy:  0.2387632797602833 Val_cost:  3.011373999304746 Val_accuracy:  0.2387632797602833 Val_Acc:  3.001936723849098\n",
      "Epoch number: 172/10000step_number: 0/29 Accuracy:  0.2372552358249617 Loss:  3.0099115781453296 Val_accuracy:  0.24244075183873603 Val_cost:  3.0099115781453296 Val_accuracy:  0.24244075183873603 Val_Acc:  3.0004739505596447\n",
      "Epoch number: 173/10000step_number: 0/29 Accuracy:  0.23715307338668482 Loss:  3.0086108516625885 Val_accuracy:  0.24325796785617 Val_cost:  3.0086108516625885 Val_accuracy:  0.24325796785617 Val_Acc:  2.999126438606961\n",
      "Epoch number: 174/10000step_number: 0/29 Accuracy:  0.23453090413757874 Loss:  3.0073838585783133 Val_accuracy:  0.2399891037864342 Val_cost:  3.0073838585783133 Val_accuracy:  0.2399891037864342 Val_Acc:  2.997829584231272\n",
      "Epoch number: 175/10000step_number: 0/29 Accuracy:  0.23463306657585561 Loss:  3.0061386627470648 Val_accuracy:  0.2387632797602833 Val_cost:  3.0061386627470648 Val_accuracy:  0.2387632797602833 Val_Acc:  2.9965126523003445\n",
      "Epoch number: 176/10000step_number: 0/29 Accuracy:  0.23558658266643964 Loss:  3.0048641952835977 Val_accuracy:  0.2393080904385726 Val_cost:  3.0048641952835977 Val_accuracy:  0.2393080904385726 Val_Acc:  2.9951711819404925\n",
      "Epoch number: 177/10000step_number: 0/29 Accuracy:  0.23272603439468756 Loss:  3.00357461951546 Val_accuracy:  0.2341323889948243 Val_cost:  3.00357461951546 Val_accuracy:  0.2341323889948243 Val_Acc:  2.99381761104661\n",
      "Epoch number: 178/10000step_number: 0/29 Accuracy:  0.23337306317044101 Loss:  3.0022724184841714 Val_accuracy:  0.23508580768183057 Val_cost:  3.0022724184841714 Val_accuracy:  0.23508580768183057 Val_Acc:  2.992452863329774\n",
      "Epoch number: 179/10000step_number: 0/29 Accuracy:  0.23068278562915034 Loss:  3.0009621617588493 Val_accuracy:  0.22963770089893762 Val_cost:  3.0009621617588493 Val_accuracy:  0.22963770089893762 Val_Acc:  2.991080295072436\n",
      "Epoch number: 180/10000step_number: 0/29 Accuracy:  0.2338838753618253 Loss:  2.999647799234274 Val_accuracy:  0.23154453827295016 Val_cost:  2.999647799234274 Val_accuracy:  0.23154453827295016 Val_Acc:  2.9897027720063702\n",
      "Epoch number: 181/10000step_number: 0/29 Accuracy:  0.23398603780010216 Loss:  2.9983335412236367 Val_accuracy:  0.23263415962952874 Val_cost:  2.9983335412236367 Val_accuracy:  0.23263415962952874 Val_Acc:  2.988324068983849\n",
      "Epoch number: 182/10000step_number: 0/29 Accuracy:  0.23510982462114763 Loss:  2.9970215244118537 Val_accuracy:  0.23317897030781803 Val_cost:  2.9970215244118537 Val_accuracy:  0.23317897030781803 Val_Acc:  2.9869466083069187\n",
      "Epoch number: 183/10000step_number: 0/29 Accuracy:  0.23572279925080877 Loss:  2.9957130470636866 Val_accuracy:  0.23304276763824572 Val_cost:  2.9957130470636866 Val_accuracy:  0.23304276763824572 Val_Acc:  2.985572448802938\n",
      "Epoch number: 184/10000step_number: 0/29 Accuracy:  0.24188659969351267 Loss:  2.994409291884796 Val_accuracy:  0.24012530645600655 Val_cost:  2.994409291884796 Val_accuracy:  0.24012530645600655 Val_Acc:  2.9842038086740534\n",
      "Epoch number: 185/10000step_number: 0/29 Accuracy:  0.24127362506385153 Loss:  2.993111904644711 Val_accuracy:  0.23740125306456006 Val_cost:  2.993111904644711 Val_accuracy:  0.23740125306456006 Val_Acc:  2.982843517084754\n",
      "Epoch number: 186/10000step_number: 0/29 Accuracy:  0.24321471139111187 Loss:  2.991822608812188 Val_accuracy:  0.23917188776900028 Val_cost:  2.991822608812188 Val_accuracy:  0.23917188776900028 Val_Acc:  2.9814944477039735\n",
      "Epoch number: 187/10000step_number: 0/29 Accuracy:  0.2446449855269879 Loss:  2.9905423023086826 Val_accuracy:  0.24094252247344047 Val_cost:  2.9905423023086826 Val_accuracy:  0.24094252247344047 Val_Acc:  2.9801584707480786\n",
      "Epoch number: 188/10000step_number: 0/29 Accuracy:  0.24655201770815596 Loss:  2.989270408662502 Val_accuracy:  0.24353037319531462 Val_cost:  2.989270408662502 Val_accuracy:  0.24353037319531462 Val_Acc:  2.978835718485998\n",
      "Epoch number: 189/10000step_number: 0/29 Accuracy:  0.24750553379874 Loss:  2.9880056033519207 Val_accuracy:  0.24421138654317626 Val_cost:  2.9880056033519207 Val_accuracy:  0.24421138654317626 Val_Acc:  2.977525075943488\n",
      "Epoch number: 190/10000step_number: 0/29 Accuracy:  0.24845904988932402 Loss:  2.9867475138752035 Val_accuracy:  0.24598202124761645 Val_cost:  2.9867475138752035 Val_accuracy:  0.24598202124761645 Val_Acc:  2.9762257266343037\n",
      "Epoch number: 191/10000step_number: 0/29 Accuracy:  0.2490720245189852 Loss:  2.9854976220442557 Val_accuracy:  0.24639062925633343 Val_cost:  2.9854976220442557 Val_accuracy:  0.24639062925633343 Val_Acc:  2.9749390065318533\n",
      "Epoch number: 192/10000step_number: 0/29 Accuracy:  0.2500936489017538 Loss:  2.9842579220891703 Val_accuracy:  0.247480250612912 Val_cost:  2.9842579220891703 Val_accuracy:  0.247480250612912 Val_Acc:  2.9736673217464755\n",
      "Epoch number: 193/10000step_number: 0/29 Accuracy:  0.2503320279243998 Loss:  2.9830285649381696 Val_accuracy:  0.24829746663034596 Val_cost:  2.9830285649381696 Val_accuracy:  0.24829746663034596 Val_Acc:  2.972411188047276\n",
      "Epoch number: 194/10000step_number: 0/29 Accuracy:  0.2508428401157841 Loss:  2.9818046248831225 Val_accuracy:  0.24829746663034596 Val_cost:  2.9818046248831225 Val_accuracy:  0.24829746663034596 Val_Acc:  2.9711671272184756\n",
      "Epoch number: 195/10000step_number: 0/29 Accuracy:  0.25203473522901415 Loss:  2.980574353519686 Val_accuracy:  0.24965949332606918 Val_cost:  2.980574353519686 Val_accuracy:  0.24965949332606918 Val_Acc:  2.969926898581517\n",
      "Epoch number: 196/10000step_number: 0/29 Accuracy:  0.2523071683977524 Loss:  2.9793332126407672 Val_accuracy:  0.25061291201307545 Val_cost:  2.9793332126407672 Val_accuracy:  0.25061291201307545 Val_Acc:  2.968685587781178\n",
      "Epoch number: 197/10000step_number: 0/29 Accuracy:  0.2526817640047676 Loss:  2.978093723582546 Val_accuracy:  0.2515663307000817 Val_cost:  2.978093723582546 Val_accuracy:  0.2515663307000817 Val_Acc:  2.9674481054143635\n",
      "Epoch number: 198/10000step_number: 0/29 Accuracy:  0.2529201430274136 Loss:  2.976873806001596 Val_accuracy:  0.25211114137837104 Val_cost:  2.976873806001596 Val_accuracy:  0.25211114137837104 Val_Acc:  2.966238549604473\n",
      "Epoch number: 199/10000step_number: 0/29 Accuracy:  0.2531244679039673 Loss:  2.9757054358771207 Val_accuracy:  0.2515663307000817 Val_cost:  2.9757054358771207 Val_accuracy:  0.2515663307000817 Val_Acc:  2.965072805870007\n",
      "Epoch number: 200/10000step_number: 0/29 Accuracy:  0.2533628469266133 Loss:  2.9745789182560274 Val_accuracy:  0.25238354671751567 Val_cost:  2.9745789182560274 Val_accuracy:  0.25238354671751567 Val_Acc:  2.9639339773484643\n",
      "Epoch number: 201/10000step_number: 0/29 Accuracy:  0.2528860888813213 Loss:  2.97347855015433 Val_accuracy:  0.2526559520566603 Val_cost:  2.97347855015433 Val_accuracy:  0.2526559520566603 Val_Acc:  2.9628101992290237\n",
      "Epoch number: 202/10000step_number: 0/29 Accuracy:  0.2534650093648902 Loss:  2.972391554265257 Val_accuracy:  0.25238354671751567 Val_cost:  2.972391554265257 Val_accuracy:  0.25238354671751567 Val_Acc:  2.9616947450978097\n",
      "Epoch number: 203/10000step_number: 0/29 Accuracy:  0.25373744253362845 Loss:  2.9713141388657816 Val_accuracy:  0.25224734404794336 Val_cost:  2.9713141388657816 Val_accuracy:  0.25224734404794336 Val_Acc:  2.960588395268238\n",
      "Epoch number: 204/10000step_number: 0/29 Accuracy:  0.25397582155627446 Loss:  2.970245510746488 Val_accuracy:  0.25170253336965404 Val_cost:  2.970245510746488 Val_accuracy:  0.25170253336965404 Val_Acc:  2.9594907098157854\n",
      "Epoch number: 205/10000step_number: 0/29 Accuracy:  0.253328792780521 Loss:  2.9691842458371323 Val_accuracy:  0.25074911468264777 Val_cost:  2.9691842458371323 Val_accuracy:  0.25074911468264777 Val_Acc:  2.9584003576126365\n",
      "Epoch number: 206/10000step_number: 0/29 Accuracy:  0.25295419717350587 Loss:  2.968131645051783 Val_accuracy:  0.2514301280305094 Val_cost:  2.968131645051783 Val_accuracy:  0.2514301280305094 Val_Acc:  2.957318954077304\n",
      "Epoch number: 207/10000step_number: 0/29 Accuracy:  0.25200068108292184 Loss:  2.967087637095716 Val_accuracy:  0.24993189866521384 Val_cost:  2.967087637095716 Val_accuracy:  0.24993189866521384 Val_Acc:  2.956246889185609\n",
      "Epoch number: 208/10000step_number: 0/29 Accuracy:  0.25131959816107613 Loss:  2.9660478244379136 Val_accuracy:  0.24938708798692455 Val_cost:  2.9660478244379136 Val_accuracy:  0.24938708798692455 Val_Acc:  2.9551793452968154\n",
      "Epoch number: 209/10000step_number: 0/29 Accuracy:  0.25087689426187637 Loss:  2.965013010747263 Val_accuracy:  0.24938708798692455 Val_cost:  2.965013010747263 Val_accuracy:  0.24938708798692455 Val_Acc:  2.954118091968826\n",
      "Epoch number: 210/10000step_number: 0/29 Accuracy:  0.24924229524944663 Loss:  2.963970386377452 Val_accuracy:  0.24816126396077362 Val_cost:  2.963970386377452 Val_accuracy:  0.24816126396077362 Val_Acc:  2.9530499874795004\n",
      "Epoch number: 211/10000step_number: 0/29 Accuracy:  0.24760769623701687 Loss:  2.9629116917305383 Val_accuracy:  0.24598202124761645 Val_cost:  2.9629116917305383 Val_accuracy:  0.24598202124761645 Val_Acc:  2.9519669042272194\n",
      "Epoch number: 212/10000step_number: 0/29 Accuracy:  0.24719904648390942 Loss:  2.961836938483037 Val_accuracy:  0.24434758921274857 Val_cost:  2.961836938483037 Val_accuracy:  0.24434758921274857 Val_Acc:  2.9508712600084133\n",
      "Epoch number: 213/10000step_number: 0/29 Accuracy:  0.24706282989954026 Loss:  2.96075763336043 Val_accuracy:  0.24434758921274857 Val_cost:  2.96075763336043 Val_accuracy:  0.24434758921274857 Val_Acc:  2.9497753717309254\n",
      "Epoch number: 214/10000step_number: 0/29 Accuracy:  0.24716499233781714 Loss:  2.9596801613054393 Val_accuracy:  0.2446199945518932 Val_cost:  2.9596801613054393 Val_accuracy:  0.2446199945518932 Val_Acc:  2.948683565396539\n",
      "Epoch number: 215/10000step_number: 0/29 Accuracy:  0.24784607525966287 Loss:  2.9586068977285525 Val_accuracy:  0.24543721056932716 Val_cost:  2.9586068977285525 Val_accuracy:  0.24543721056932716 Val_Acc:  2.947595969242882\n",
      "Epoch number: 216/10000step_number: 0/29 Accuracy:  0.24999148646347694 Loss:  2.957540152570915 Val_accuracy:  0.24693543993462272 Val_cost:  2.957540152570915 Val_accuracy:  0.24693543993462272 Val_Acc:  2.94651439002399\n",
      "Epoch number: 217/10000step_number: 0/29 Accuracy:  0.24968499914864634 Loss:  2.956481636874291 Val_accuracy:  0.24611822391718877 Val_cost:  2.956481636874291 Val_accuracy:  0.24611822391718877 Val_Acc:  2.945440264398451\n",
      "Epoch number: 218/10000step_number: 0/29 Accuracy:  0.25121743572279925 Loss:  2.9554319914583185 Val_accuracy:  0.24720784527376738 Val_cost:  2.9554319914583185 Val_accuracy:  0.24720784527376738 Val_Acc:  2.9443738920128397\n",
      "Epoch number: 219/10000step_number: 0/29 Accuracy:  0.2512855440149838 Loss:  2.9543913217074107 Val_accuracy:  0.24761645328248433 Val_cost:  2.9543913217074107 Val_accuracy:  0.24761645328248433 Val_Acc:  2.943315304050037\n",
      "Epoch number: 220/10000step_number: 0/29 Accuracy:  0.25203473522901415 Loss:  2.9533595225076374 Val_accuracy:  0.24816126396077362 Val_cost:  2.9533595225076374 Val_accuracy:  0.24816126396077362 Val_Acc:  2.9422645926044284\n",
      "Epoch number: 221/10000step_number: 0/29 Accuracy:  0.25302230546569043 Loss:  2.9523364352475023 Val_accuracy:  0.2491146826477799 Val_cost:  2.9523364352475023 Val_accuracy:  0.2491146826477799 Val_Acc:  2.9412218807819177\n",
      "Epoch number: 222/10000step_number: 0/29 Accuracy:  0.25274987229695217 Loss:  2.9513219294716464 Val_accuracy:  0.24897847997820757 Val_cost:  2.9513219294716464 Val_accuracy:  0.24897847997820757 Val_Acc:  2.940187263006344\n",
      "Epoch number: 223/10000step_number: 0/29 Accuracy:  0.2533628469266133 Loss:  2.9503159013997236 Val_accuracy:  0.24979569599564153 Val_cost:  2.9503159013997236 Val_accuracy:  0.24979569599564153 Val_Acc:  2.9391607596135407\n",
      "Epoch number: 224/10000step_number: 0/29 Accuracy:  0.254043929848459 Loss:  2.949318217524476 Val_accuracy:  0.25102152002179245 Val_cost:  2.949318217524476 Val_accuracy:  0.25102152002179245 Val_Acc:  2.938142291656886\n",
      "Epoch number: 225/10000step_number: 0/29 Accuracy:  0.25455474203984335 Loss:  2.948328659634912 Val_accuracy:  0.25183873603922635 Val_cost:  2.948328659634912 Val_accuracy:  0.25183873603922635 Val_Acc:  2.937131684744543\n",
      "Epoch number: 226/10000step_number: 0/29 Accuracy:  0.25489528350076623 Loss:  2.9473469026077583 Val_accuracy:  0.252519749387088 Val_cost:  2.9473469026077583 Val_accuracy:  0.252519749387088 Val_Acc:  2.9361286969249165\n",
      "Epoch number: 227/10000step_number: 0/29 Accuracy:  0.25537204154605825 Loss:  2.946372519412367 Val_accuracy:  0.25333696540452194 Val_cost:  2.946372519412367 Val_accuracy:  0.25333696540452194 Val_Acc:  2.935133053669914\n",
      "Epoch number: 228/10000step_number: 0/29 Accuracy:  0.2556444747147965 Loss:  2.945404999847074 Val_accuracy:  0.2532007627349496 Val_cost:  2.945404999847074 Val_accuracy:  0.2532007627349496 Val_Acc:  2.9341444773862535\n",
      "Epoch number: 229/10000step_number: 0/29 Accuracy:  0.2542482547250128 Loss:  2.944443792276559 Val_accuracy:  0.2515663307000817 Val_cost:  2.944443792276559 Val_accuracy:  0.2515663307000817 Val_Acc:  2.9331627075364755\n",
      "Epoch number: 230/10000step_number: 0/29 Accuracy:  0.2541801464328282 Loss:  2.9434884115981403 Val_accuracy:  0.2508853173522201 Val_cost:  2.9434884115981403 Val_accuracy:  0.2508853173522201 Val_Acc:  2.932187518316602\n",
      "Epoch number: 231/10000step_number: 0/29 Accuracy:  0.25407798399455134 Loss:  2.9425386670040203 Val_accuracy:  0.25102152002179245 Val_cost:  2.9425386670040203 Val_accuracy:  0.25102152002179245 Val_Acc:  2.931218769407047\n",
      "Epoch number: 232/10000step_number: 0/29 Accuracy:  0.25411203814064365 Loss:  2.9415950052513797 Val_accuracy:  0.25102152002179245 Val_cost:  2.9415950052513797 Val_accuracy:  0.25102152002179245 Val_Acc:  2.930256538949314\n",
      "Epoch number: 233/10000step_number: 0/29 Accuracy:  0.2547250127703048 Loss:  2.9406587430310682 Val_accuracy:  0.25183873603922635 Val_cost:  2.9406587430310682 Val_accuracy:  0.25183873603922635 Val_Acc:  2.9293012373841347\n",
      "Epoch number: 234/10000step_number: 0/29 Accuracy:  0.25503150008513537 Loss:  2.93973138708876 Val_accuracy:  0.25170253336965404 Val_cost:  2.93973138708876 Val_accuracy:  0.25170253336965404 Val_Acc:  2.928353068572544\n",
      "Epoch number: 235/10000step_number: 0/29 Accuracy:  0.2549633917929508 Loss:  2.9388117271706022 Val_accuracy:  0.2515663307000817 Val_cost:  2.9388117271706022 Val_accuracy:  0.2515663307000817 Val_Acc:  2.927409897673322\n",
      "Epoch number: 236/10000step_number: 0/29 Accuracy:  0.2552017708155968 Loss:  2.9378922408353847 Val_accuracy:  0.25211114137837104 Val_cost:  2.9378922408353847 Val_accuracy:  0.25211114137837104 Val_Acc:  2.926465305999823\n",
      "Epoch number: 237/10000step_number: 0/29 Accuracy:  0.25547420398433507 Loss:  2.9369574213762784 Val_accuracy:  0.2530645600653773 Val_cost:  2.9369574213762784 Val_accuracy:  0.2530645600653773 Val_Acc:  2.9255059078753485\n",
      "Epoch number: 238/10000step_number: 0/29 Accuracy:  0.2557806912991657 Loss:  2.936029420586203 Val_accuracy:  0.2530645600653773 Val_cost:  2.936029420586203 Val_accuracy:  0.2530645600653773 Val_Acc:  2.924545127262502\n",
      "Epoch number: 239/10000step_number: 0/29 Accuracy:  0.25744934445768775 Loss:  2.9352252074208813 Val_accuracy:  0.25456278943067284 Val_cost:  2.9352252074208813 Val_accuracy:  0.25456278943067284 Val_Acc:  2.9237352336920477\n",
      "Epoch number: 240/10000step_number: 0/29 Accuracy:  0.2578239400647029 Loss:  2.9344573035290527 Val_accuracy:  0.2549713974393898 Val_cost:  2.9344573035290527 Val_accuracy:  0.2549713974393898 Val_Acc:  2.922963692986741\n",
      "Epoch number: 241/10000step_number: 0/29 Accuracy:  0.257960156649072 Loss:  2.9336655851537823 Val_accuracy:  0.2553800054481068 Val_cost:  2.9336655851537823 Val_accuracy:  0.2553800054481068 Val_Acc:  2.9221406406332107\n",
      "Epoch number: 242/10000step_number: 0/29 Accuracy:  0.25969691809977863 Loss:  2.9328366546123394 Val_accuracy:  0.2576954508308363 Val_cost:  2.9328366546123394 Val_accuracy:  0.2576954508308363 Val_Acc:  2.921281350395373\n",
      "Epoch number: 243/10000step_number: 0/29 Accuracy:  0.2600374595607015 Loss:  2.9320014167874566 Val_accuracy:  0.2579678561699809 Val_cost:  2.9320014167874566 Val_accuracy:  0.2579678561699809 Val_Acc:  2.9204116518039416\n",
      "Epoch number: 244/10000step_number: 0/29 Accuracy:  0.25949259322322493 Loss:  2.93116395678959 Val_accuracy:  0.25619722146554075 Val_cost:  2.93116395678959 Val_accuracy:  0.25619722146554075 Val_Acc:  2.919537412758663\n",
      "Epoch number: 245/10000step_number: 0/29 Accuracy:  0.26024178443725526 Loss:  2.930328647698162 Val_accuracy:  0.257150640152547 Val_cost:  2.930328647698162 Val_accuracy:  0.257150640152547 Val_Acc:  2.9186625112083773\n",
      "Epoch number: 246/10000step_number: 0/29 Accuracy:  0.2610590839434701 Loss:  2.929496839073559 Val_accuracy:  0.25755924816126397 Val_cost:  2.929496839073559 Val_accuracy:  0.25755924816126397 Val_Acc:  2.9177888093231092\n",
      "Epoch number: 247/10000step_number: 0/29 Accuracy:  0.26194449174186957 Loss:  2.9286691897104813 Val_accuracy:  0.2583764641786979 Val_cost:  2.9286691897104813 Val_accuracy:  0.2583764641786979 Val_Acc:  2.916916646260239\n",
      "Epoch number: 248/10000step_number: 0/29 Accuracy:  0.2623190873488847 Loss:  2.927846455258684 Val_accuracy:  0.2590574775265595 Val_cost:  2.927846455258684 Val_accuracy:  0.2590574775265595 Val_Acc:  2.916046345734973\n",
      "Epoch number: 249/10000step_number: 0/29 Accuracy:  0.2626936829558999 Loss:  2.927029304370383 Val_accuracy:  0.2593298828657042 Val_cost:  2.927029304370383 Val_accuracy:  0.2593298828657042 Val_Acc:  2.915178355740329\n",
      "Epoch number: 250/10000step_number: 0/29 Accuracy:  0.26334071173165335 Loss:  2.9262178028847385 Val_accuracy:  0.26001089621356577 Val_cost:  2.9262178028847385 Val_accuracy:  0.26001089621356577 Val_Acc:  2.9143129493654327\n",
      "Epoch number: 251/10000step_number: 0/29 Accuracy:  0.26412395709177594 Loss:  2.925411749538168 Val_accuracy:  0.26041950422228277 Val_cost:  2.925411749538168 Val_accuracy:  0.26041950422228277 Val_Acc:  2.9134503721904292\n",
      "Epoch number: 252/10000step_number: 0/29 Accuracy:  0.2649753107440831 Loss:  2.9246109405123306 Val_accuracy:  0.26150912557886136 Val_cost:  2.9246109405123306 Val_accuracy:  0.26150912557886136 Val_Acc:  2.9125909437015296\n",
      "Epoch number: 253/10000step_number: 0/29 Accuracy:  0.26528179805891366 Loss:  2.9238152528914507 Val_accuracy:  0.2616453282484337 Val_cost:  2.9238152528914507 Val_accuracy:  0.2616453282484337 Val_Acc:  2.911735047011504\n",
      "Epoch number: 254/10000step_number: 0/29 Accuracy:  0.26534990635109823 Loss:  2.9230246144199747 Val_accuracy:  0.2619177335875783 Val_cost:  2.9230246144199747 Val_accuracy:  0.2619177335875783 Val_Acc:  2.910883073277775\n",
      "Epoch number: 255/10000step_number: 0/29 Accuracy:  0.2651796356206368 Loss:  2.9222389722240916 Val_accuracy:  0.2623263415962953 Val_cost:  2.9222389722240916 Val_accuracy:  0.2623263415962953 Val_Acc:  2.910035381311556\n",
      "Epoch number: 256/10000step_number: 0/29 Accuracy:  0.2654520687893751 Loss:  2.921458273407166 Val_accuracy:  0.2631435576137292 Val_cost:  2.921458273407166 Val_accuracy:  0.2631435576137292 Val_Acc:  2.9091922826644936\n",
      "Epoch number: 257/10000step_number: 0/29 Accuracy:  0.2661672058573131 Loss:  2.920682459244734 Val_accuracy:  0.2630073549441569 Val_cost:  2.920682459244734 Val_accuracy:  0.2630073549441569 Val_Acc:  2.908354046942394\n",
      "Epoch number: 258/10000step_number: 0/29 Accuracy:  0.26640558487995913 Loss:  2.919911470029273 Val_accuracy:  0.2634159629528739 Val_cost:  2.919911470029273 Val_accuracy:  0.2634159629528739 Val_Acc:  2.9075209207799526\n",
      "Epoch number: 259/10000step_number: 0/29 Accuracy:  0.26977694534309554 Loss:  2.9191452629791246 Val_accuracy:  0.2675020430400436 Val_cost:  2.9191452629791246 Val_accuracy:  0.2675020430400436 Val_Acc:  2.906693149207833\n",
      "Epoch number: 260/10000step_number: 0/29 Accuracy:  0.27073046143367957 Loss:  2.9183838333643517 Val_accuracy:  0.26900027240533914 Val_cost:  2.9183838333643517 Val_accuracy:  0.26900027240533914 Val_Acc:  2.905870972001931\n",
      "Epoch number: 261/10000step_number: 0/29 Accuracy:  0.2715477609398944 Loss:  2.917627206586791 Val_accuracy:  0.27063470444020704 Val_cost:  2.917627206586791 Val_accuracy:  0.27063470444020704 Val_Acc:  2.9050545689608294\n",
      "Epoch number: 262/10000step_number: 0/29 Accuracy:  0.2720245189851864 Loss:  2.9168753902814757 Val_accuracy:  0.271043312448924 Val_cost:  2.9168753902814757 Val_accuracy:  0.271043312448924 Val_Acc:  2.904243985467705\n",
      "Epoch number: 263/10000step_number: 0/29 Accuracy:  0.27233100630001705 Loss:  2.9161283267278915 Val_accuracy:  0.2715881231272133 Val_cost:  2.9161283267278915 Val_accuracy:  0.2715881231272133 Val_Acc:  2.903439103826436\n",
      "Epoch number: 264/10000step_number: 0/29 Accuracy:  0.2731483058062319 Loss:  2.915385877443542 Val_accuracy:  0.2725415418142196 Val_cost:  2.915385877443542 Val_accuracy:  0.2725415418142196 Val_Acc:  2.9026396696106995\n",
      "Epoch number: 265/10000step_number: 0/29 Accuracy:  0.2750212838413077 Loss:  2.914647831507129 Val_accuracy:  0.27417597384908743 Val_cost:  2.914647831507129 Val_accuracy:  0.27417597384908743 Val_Acc:  2.9018453369441866\n",
      "Epoch number: 266/10000step_number: 0/29 Accuracy:  0.27611101651626085 Loss:  2.913913921449307 Val_accuracy:  0.2749931898665214 Val_cost:  2.913913921449307 Val_accuracy:  0.2749931898665214 Val_Acc:  2.901055710540821\n",
      "Epoch number: 267/10000step_number: 0/29 Accuracy:  0.27668993699982974 Loss:  2.9131838426283427 Val_accuracy:  0.275674203214383 Val_cost:  2.9131838426283427 Val_accuracy:  0.275674203214383 Val_Acc:  2.9002703829409766\n",
      "Epoch number: 268/10000step_number: 0/29 Accuracy:  0.27791588625915203 Loss:  2.9124572771682504 Val_accuracy:  0.2769000272405339 Val_cost:  2.9124572771682504 Val_accuracy:  0.2769000272405339 Val_Acc:  2.8994889699221997\n",
      "Epoch number: 269/10000step_number: 0/29 Accuracy:  0.2795164311254895 Loss:  2.911733921716674 Val_accuracy:  0.2793516752928357 Val_cost:  2.911733921716674 Val_accuracy:  0.2793516752928357 Val_Acc:  2.898711145757016\n",
      "Epoch number: 270/10000step_number: 0/29 Accuracy:  0.28128724672228844 Loss:  2.9110135198644302 Val_accuracy:  0.2809861073277036 Val_cost:  2.9110135198644302 Val_accuracy:  0.2809861073277036 Val_Acc:  2.8979366791770005\n",
      "Epoch number: 271/10000step_number: 0/29 Accuracy:  0.2826834667120722 Loss:  2.9102959041734975 Val_accuracy:  0.28221193135385453 Val_cost:  2.9102959041734975 Val_accuracy:  0.28221193135385453 Val_Acc:  2.8971654659764887\n",
      "Epoch number: 272/10000step_number: 0/29 Accuracy:  0.2831942789034565 Loss:  2.909581042416974 Val_accuracy:  0.2831653500408608 Val_cost:  2.909581042416974 Val_accuracy:  0.2831653500408608 Val_Acc:  2.896397541515463\n",
      "Epoch number: 273/10000step_number: 0/29 Accuracy:  0.2849650945002554 Loss:  2.9088690572512896 Val_accuracy:  0.28411876872786707 Val_cost:  2.9088690572512896 Val_accuracy:  0.28411876872786707 Val_Acc:  2.8956330513008175\n",
      "Epoch number: 274/10000step_number: 0/29 Accuracy:  0.2864975310744083 Loss:  2.9081601909458166 Val_accuracy:  0.2856169980931626 Val_cost:  2.9081601909458166 Val_accuracy:  0.2856169980931626 Val_Acc:  2.894872183708357\n",
      "Epoch number: 275/10000step_number: 0/29 Accuracy:  0.28717861399625405 Loss:  2.907454733495862 Val_accuracy:  0.28657041678016887 Val_cost:  2.907454733495862 Val_accuracy:  0.28657041678016887 Val_Acc:  2.8941151046665796\n",
      "Epoch number: 276/10000step_number: 0/29 Accuracy:  0.2893240252000681 Loss:  2.906752960977961 Val_accuracy:  0.2883410514846091 Val_cost:  2.906752960977961 Val_accuracy:  0.2883410514846091 Val_Acc:  2.8933619284478866\n",
      "Epoch number: 277/10000step_number: 0/29 Accuracy:  0.29075429933594416 Loss:  2.906055106190277 Val_accuracy:  0.2884772541541814 Val_cost:  2.906055106190277 Val_accuracy:  0.2884772541541814 Val_Acc:  2.8926127207046544\n",
      "Epoch number: 278/10000step_number: 0/29 Accuracy:  0.29330836029286567 Loss:  2.905361349800508 Val_accuracy:  0.2910651048760556 Val_cost:  2.905361349800508 Val_accuracy:  0.2910651048760556 Val_Acc:  2.8918675101513234\n",
      "Epoch number: 279/10000step_number: 0/29 Accuracy:  0.29487485101311084 Loss:  2.904671813770473 Val_accuracy:  0.29201852356306185 Val_cost:  2.904671813770473 Val_accuracy:  0.29201852356306185 Val_Acc:  2.891126294208537\n",
      "Epoch number: 280/10000step_number: 0/29 Accuracy:  0.2956580963732334 Loss:  2.903986550924852 Val_accuracy:  0.2922909289022065 Val_cost:  2.903986550924852 Val_accuracy:  0.2922909289022065 Val_Acc:  2.8903890392272134\n",
      "Epoch number: 281/10000step_number: 0/29 Accuracy:  0.29640728758726376 Loss:  2.9033055356708184 Val_accuracy:  0.29310814491964043 Val_cost:  2.9033055356708184 Val_accuracy:  0.29310814491964043 Val_Acc:  2.889655683120805\n",
      "Epoch number: 282/10000step_number: 0/29 Accuracy:  0.2980418865996935 Loss:  2.9026286657562848 Val_accuracy:  0.29378915826750207 Val_cost:  2.9026286657562848 Val_accuracy:  0.29378915826750207 Val_Acc:  2.888926148902499\n",
      "Epoch number: 283/10000step_number: 0/29 Accuracy:  0.2991316192746467 Loss:  2.9019557905854407 Val_accuracy:  0.29433396894579134 Val_cost:  2.9019557905854407 Val_accuracy:  0.29433396894579134 Val_Acc:  2.8882003790702626\n",
      "Epoch number: 284/10000step_number: 0/29 Accuracy:  0.2998127021964924 Loss:  2.9012867977287096 Val_accuracy:  0.2958321983110869 Val_cost:  2.9012867977287096 Val_accuracy:  0.2958321983110869 Val_Acc:  2.887478407220807\n",
      "Epoch number: 285/10000step_number: 0/29 Accuracy:  0.30056189341052275 Loss:  2.9006218190674837 Val_accuracy:  0.2966494143285208 Val_cost:  2.9006218190674837 Val_accuracy:  0.2966494143285208 Val_Acc:  2.8867604898093973\n",
      "Epoch number: 286/10000step_number: 0/29 Accuracy:  0.301072705601907 Loss:  2.899961573937526 Val_accuracy:  0.2966494143285208 Val_cost:  2.899961573937526 Val_accuracy:  0.2966494143285208 Val_Acc:  2.8860472779500115\n",
      "Epoch number: 287/10000step_number: 0/29 Accuracy:  0.3016516260854759 Loss:  2.899307370658941 Val_accuracy:  0.2974666303459548 Val_cost:  2.899307370658941 Val_accuracy:  0.2974666303459548 Val_Acc:  2.885339748236376\n",
      "Epoch number: 288/10000step_number: 0/29 Accuracy:  0.30280946705261363 Loss:  2.898659959553956 Val_accuracy:  0.29842004903296104 Val_cost:  2.898659959553956 Val_accuracy:  0.29842004903296104 Val_Acc:  2.884638460944424\n",
      "Epoch number: 289/10000step_number: 0/29 Accuracy:  0.30512514898688914 Loss:  2.898018855805809 Val_accuracy:  0.3003268864069736 Val_cost:  2.898018855805809 Val_accuracy:  0.3003268864069736 Val_Acc:  2.883943122647964\n",
      "Epoch number: 290/10000step_number: 0/29 Accuracy:  0.30733866848288777 Loss:  2.89738310550679 Val_accuracy:  0.3031871424679924 Val_cost:  2.89738310550679 Val_accuracy:  0.3031871424679924 Val_Acc:  2.8832531284503835\n",
      "Epoch number: 291/10000step_number: 0/29 Accuracy:  0.308666780180487 Loss:  2.8967516466279672 Val_accuracy:  0.30414056115499866 Val_cost:  2.8967516466279672 Val_accuracy:  0.30414056115499866 Val_Acc:  2.882567911129427\n",
      "Epoch number: 292/10000step_number: 0/29 Accuracy:  0.3092457006640558 Loss:  2.8961240625590663 Val_accuracy:  0.3045491691637156 Val_cost:  2.8961240625590663 Val_accuracy:  0.3045491691637156 Val_Acc:  2.8818874232337675\n",
      "Epoch number: 293/10000step_number: 0/29 Accuracy:  0.31026732504682447 Loss:  2.89550060943635 Val_accuracy:  0.3055025878507219 Val_cost:  2.89550060943635 Val_accuracy:  0.3055025878507219 Val_Acc:  2.8812119901699393\n",
      "Epoch number: 294/10000step_number: 0/29 Accuracy:  0.31101651626085475 Loss:  2.8948816035383613 Val_accuracy:  0.3070008172160174 Val_cost:  2.8948816035383613 Val_accuracy:  0.3070008172160174 Val_Acc:  2.8805418295109786\n",
      "Epoch number: 295/10000step_number: 0/29 Accuracy:  0.31179976162097733 Loss:  2.8942672171807455 Val_accuracy:  0.3079542359030237 Val_cost:  2.8942672171807455 Val_accuracy:  0.3079542359030237 Val_Acc:  2.8798769160578312\n",
      "Epoch number: 296/10000step_number: 0/29 Accuracy:  0.3124467903967308 Loss:  2.893657417233171 Val_accuracy:  0.308499046581313 Val_cost:  2.893657417233171 Val_accuracy:  0.308499046581313 Val_Acc:  2.879216975834021\n",
      "Epoch number: 297/10000step_number: 0/29 Accuracy:  0.3185765366933424 Loss:  2.893051986474243 Val_accuracy:  0.31312993734677197 Val_cost:  2.893051986474243 Val_accuracy:  0.31312993734677197 Val_Acc:  2.8785615864053575\n",
      "Epoch number: 298/10000step_number: 0/29 Accuracy:  0.3201430274135876 Loss:  2.892450564463995 Val_accuracy:  0.3149005720512122 Val_cost:  2.892450564463995 Val_accuracy:  0.3149005720512122 Val_Acc:  2.8779103496282796\n",
      "Epoch number: 299/10000step_number: 0/29 Accuracy:  0.3204154605823259 Loss:  2.8918526660009958 Val_accuracy:  0.3151729773903568 Val_cost:  2.8918526660009958 Val_accuracy:  0.3151729773903568 Val_Acc:  2.877263030210894\n",
      "Epoch number: 300/10000step_number: 0/29 Accuracy:  0.3211305976502639 Loss:  2.89125768181997 Val_accuracy:  0.3161263960773631 Val_cost:  2.89125768181997 Val_accuracy:  0.3161263960773631 Val_Acc:  2.876619511210172\n",
      "Epoch number: 301/10000step_number: 0/29 Accuracy:  0.32130086838072536 Loss:  2.8906648860195756 Val_accuracy:  0.3166712067556524 Val_cost:  2.8906648860195756 Val_accuracy:  0.3166712067556524 Val_Acc:  2.875979617692439\n",
      "Epoch number: 302/10000step_number: 0/29 Accuracy:  0.32375276689937 Loss:  2.8900734673462893 Val_accuracy:  0.3189866521383819 Val_cost:  2.8900734673462893 Val_accuracy:  0.3189866521383819 Val_Acc:  2.875343029863172\n",
      "Epoch number: 303/10000step_number: 0/29 Accuracy:  0.32416141665247744 Loss:  2.8894825737419323 Val_accuracy:  0.3200762734949605 Val_cost:  2.8894825737419323 Val_accuracy:  0.3200762734949605 Val_Acc:  2.8747093201245697\n",
      "Epoch number: 304/10000step_number: 0/29 Accuracy:  0.3252852034735229 Loss:  2.888891347567543 Val_accuracy:  0.3207572868428221 Val_cost:  2.888891347567543 Val_accuracy:  0.3207572868428221 Val_Acc:  2.8740780074104397\n",
      "Epoch number: 305/10000step_number: 0/29 Accuracy:  0.3262727737101992 Loss:  2.8882989551105505 Val_accuracy:  0.3218469081994007 Val_cost:  2.8882989551105505 Val_accuracy:  0.3218469081994007 Val_Acc:  2.873448589078249\n",
      "Epoch number: 306/10000step_number: 0/29 Accuracy:  0.3273625063851524 Loss:  2.8877046303822964 Val_accuracy:  0.3234813402342686 Val_cost:  2.8877046303822964 Val_accuracy:  0.3234813402342686 Val_Acc:  2.8728205709973236\n",
      "Epoch number: 307/10000step_number: 0/29 Accuracy:  0.32841818491401326 Loss:  2.887107733949158 Val_accuracy:  0.3252519749387088 Val_cost:  2.887107733949158 Val_accuracy:  0.3252519749387088 Val_Acc:  2.872193509208524\n",
      "Epoch number: 308/10000step_number: 0/29 Accuracy:  0.3297462966116125 Loss:  2.8865078075940493 Val_accuracy:  0.32606919095614273 Val_cost:  2.8865078075940493 Val_accuracy:  0.32606919095614273 Val_Acc:  2.8715670546538865\n",
      "Epoch number: 309/10000step_number: 0/29 Accuracy:  0.32600034054146093 Loss:  2.885904606064292 Val_accuracy:  0.3232089348951239 Val_cost:  2.885904606064292 Val_accuracy:  0.3232089348951239 Val_Acc:  2.8709409856397006\n",
      "Epoch number: 310/10000step_number: 0/29 Accuracy:  0.3257619615188149 Loss:  2.8852980983845393 Val_accuracy:  0.32375374557341324 Val_cost:  2.8852980983845393 Val_accuracy:  0.32375374557341324 Val_Acc:  2.870315218011413\n",
      "Epoch number: 311/10000step_number: 0/29 Accuracy:  0.3257279073727226 Loss:  2.8846884412585605 Val_accuracy:  0.3230727322255516 Val_cost:  2.8846884412585605 Val_accuracy:  0.3230727322255516 Val_Acc:  2.8696897912512296\n",
      "Epoch number: 312/10000step_number: 0/29 Accuracy:  0.32671547760939895 Loss:  2.8840759329672134 Val_accuracy:  0.3245709615908472 Val_cost:  2.8840759329672134 Val_accuracy:  0.3245709615908472 Val_Acc:  2.8690648357482287\n",
      "Epoch number: 313/10000step_number: 0/29 Accuracy:  0.327907372722629 Loss:  2.8834609588321487 Val_accuracy:  0.32511577226913646 Val_cost:  2.8834609588321487 Val_accuracy:  0.32511577226913646 Val_Acc:  2.8684405310633827\n",
      "Epoch number: 314/10000step_number: 0/29 Accuracy:  0.3291333219819513 Loss:  2.8828439390800877 Val_accuracy:  0.3257967856169981 Val_cost:  2.8828439390800877 Val_accuracy:  0.3257967856169981 Val_Acc:  2.867817065945712\n",
      "Epoch number: 315/10000step_number: 0/29 Accuracy:  0.3308019751404733 Loss:  2.8822252868564076 Val_accuracy:  0.3271588123127213 Val_cost:  2.8822252868564076 Val_accuracy:  0.3271588123127213 Val_Acc:  2.867194607918481\n",
      "Epoch number: 316/10000step_number: 0/29 Accuracy:  0.3314490039162268 Loss:  2.8816053794716847 Val_accuracy:  0.32783982566058295 Val_cost:  2.8816053794716847 Val_accuracy:  0.32783982566058295 Val_Acc:  2.866573285248647\n",
      "Epoch number: 317/10000step_number: 0/29 Accuracy:  0.333253873659118 Loss:  2.880984541876781 Val_accuracy:  0.3298828657041678 Val_cost:  2.880984541876781 Val_accuracy:  0.3298828657041678 Val_Acc:  2.86595317979441\n",
      "Epoch number: 318/10000step_number: 0/29 Accuracy:  0.3337987399965946 Loss:  2.8803630392996986 Val_accuracy:  0.3308362843911741 Val_cost:  2.8803630392996986 Val_accuracy:  0.3308362843911741 Val_Acc:  2.86533432726443\n",
      "Epoch number: 319/10000step_number: 0/29 Accuracy:  0.3345138770645326 Loss:  2.8797410759618156 Val_accuracy:  0.3326069190956143 Val_cost:  2.8797410759618156 Val_accuracy:  0.3326069190956143 Val_Acc:  2.8647167217095366\n",
      "Epoch number: 320/10000step_number: 0/29 Accuracy:  0.3352971224246552 Loss:  2.8791187980979975 Val_accuracy:  0.3327431217651866 Val_cost:  2.8791187980979975 Val_accuracy:  0.3327431217651866 Val_Acc:  2.864100322614244\n",
      "Epoch number: 321/10000step_number: 0/29 Accuracy:  0.33652307168397755 Loss:  2.8784963016465963 Val_accuracy:  0.33410514846090983 Val_cost:  2.8784963016465963 Val_accuracy:  0.33410514846090983 Val_Acc:  2.863485064932303\n",
      "Epoch number: 322/10000step_number: 0/29 Accuracy:  0.3391111867869913 Loss:  2.87787364769672 Val_accuracy:  0.33832743121765185 Val_cost:  2.87787364769672 Val_accuracy:  0.33832743121765185 Val_Acc:  2.862870874052245\n",
      "Epoch number: 323/10000step_number: 0/29 Accuracy:  0.34003064873148303 Loss:  2.8772508889184247 Val_accuracy:  0.33982566058294744 Val_cost:  2.8772508889184247 Val_accuracy:  0.33982566058294744 Val_Acc:  2.8622576858793534\n",
      "Epoch number: 324/10000step_number: 0/29 Accuracy:  0.34074578579942105 Loss:  2.8766280926453907 Val_accuracy:  0.3402342685916644 Val_cost:  2.8766280926453907 Val_accuracy:  0.3402342685916644 Val_Acc:  2.8616454567732577\n",
      "Epoch number: 325/10000step_number: 0/29 Accuracy:  0.3411544355525285 Loss:  2.8760052981403508 Val_accuracy:  0.340506673930809 Val_cost:  2.8760052981403508 Val_accuracy:  0.340506673930809 Val_Acc:  2.8610341172722276\n",
      "Epoch number: 326/10000step_number: 0/29 Accuracy:  0.3416652477439128 Loss:  2.875382381721629 Val_accuracy:  0.3414600926178153 Val_cost:  2.875382381721629 Val_accuracy:  0.3414600926178153 Val_Acc:  2.8604234671040736\n",
      "Epoch number: 327/10000step_number: 0/29 Accuracy:  0.3420057892048357 Loss:  2.8747590390048763 Val_accuracy:  0.34173249795696 Val_cost:  2.8747590390048763 Val_accuracy:  0.34173249795696 Val_Acc:  2.8598131772166235\n",
      "Epoch number: 328/10000step_number: 0/29 Accuracy:  0.3426868721266814 Loss:  2.8741349779479597 Val_accuracy:  0.34282211931353856 Val_cost:  2.8741349779479597 Val_accuracy:  0.34282211931353856 Val_Acc:  2.859202942139449\n",
      "Epoch number: 329/10000step_number: 0/29 Accuracy:  0.3444917418695726 Loss:  2.8735100291484708 Val_accuracy:  0.3447289566875511 Val_cost:  2.8735100291484708 Val_accuracy:  0.3447289566875511 Val_Acc:  2.858592554193746\n",
      "Epoch number: 330/10000step_number: 0/29 Accuracy:  0.3451047164992338 Loss:  2.87288411229224 Val_accuracy:  0.3448651593571234 Val_cost:  2.87288411229224 Val_accuracy:  0.3448651593571234 Val_Acc:  2.857981872438922\n",
      "Epoch number: 331/10000step_number: 0/29 Accuracy:  0.3461263408820024 Loss:  2.8722571953372484 Val_accuracy:  0.34636338872241895 Val_cost:  2.8722571953372484 Val_accuracy:  0.34636338872241895 Val_Acc:  2.8573707920880214\n",
      "Epoch number: 332/10000step_number: 0/29 Accuracy:  0.34650093648901753 Loss:  2.871629284238957 Val_accuracy:  0.34636338872241895 Val_cost:  2.871629284238957 Val_accuracy:  0.34636338872241895 Val_Acc:  2.856759238053628\n",
      "Epoch number: 333/10000step_number: 0/29 Accuracy:  0.3468074238038481 Loss:  2.8710004257981616 Val_accuracy:  0.3456823753745573 Val_cost:  2.8710004257981616 Val_accuracy:  0.3456823753745573 Val_Acc:  2.856147168561259\n",
      "Epoch number: 334/10000step_number: 0/29 Accuracy:  0.34725012770304786 Loss:  2.8703707098011697 Val_accuracy:  0.3454099700354127 Val_cost:  2.8703707098011697 Val_accuracy:  0.3454099700354127 Val_Acc:  2.8555345792303433\n",
      "Epoch number: 335/10000step_number: 0/29 Accuracy:  0.34793121062489357 Loss:  2.869740265091634 Val_accuracy:  0.34622718605284664 Val_cost:  2.869740265091634 Val_accuracy:  0.34622718605284664 Val_Acc:  2.854921503626664\n",
      "Epoch number: 336/10000step_number: 0/29 Accuracy:  0.3487825642772007 Loss:  2.8691092489512413 Val_accuracy:  0.3466357940615636 Val_cost:  2.8691092489512413 Val_accuracy:  0.3466357940615636 Val_Acc:  2.854308009171753\n",
      "Epoch number: 337/10000step_number: 0/29 Accuracy:  0.34925932232249274 Loss:  2.868477832427367 Val_accuracy:  0.3481340234268592 Val_cost:  2.868477832427367 Val_accuracy:  0.3481340234268592 Val_Acc:  2.8536941896897536\n",
      "Epoch number: 338/10000step_number: 0/29 Accuracy:  0.34973608036778475 Loss:  2.8678461863985185 Val_accuracy:  0.3481340234268592 Val_cost:  2.8678461863985185 Val_accuracy:  0.3481340234268592 Val_Acc:  2.8530801577772213\n",
      "Epoch number: 339/10000step_number: 0/29 Accuracy:  0.3509620296271071 Loss:  2.8672144737821608 Val_accuracy:  0.3489512394442931 Val_cost:  2.8672144737821608 Val_accuracy:  0.3489512394442931 Val_Acc:  2.852466041025871\n",
      "Epoch number: 340/10000step_number: 0/29 Accuracy:  0.35218797888642944 Loss:  2.8665828519222774 Val_accuracy:  0.3493598474530101 Val_cost:  2.8665828519222774 Val_accuracy:  0.3493598474530101 Val_Acc:  2.851851985243873\n",
      "Epoch number: 341/10000step_number: 0/29 Accuracy:  0.35297122424655203 Loss:  2.8659514853529875 Val_accuracy:  0.349768455461727 Val_cost:  2.8659514853529875 Val_accuracy:  0.349768455461727 Val_Acc:  2.8512381643892453\n",
      "Epoch number: 342/10000step_number: 0/29 Accuracy:  0.35446960667461264 Loss:  2.865320562605118 Val_accuracy:  0.3511304821574503 Val_cost:  2.865320562605118 Val_accuracy:  0.3511304821574503 Val_Acc:  2.8506247906564885\n",
      "Epoch number: 343/10000step_number: 0/29 Accuracy:  0.356649072024519 Loss:  2.864690303744721 Val_accuracy:  0.35303731953146283 Val_cost:  2.864690303744721 Val_accuracy:  0.35303731953146283 Val_Acc:  2.8500121117919552\n",
      "Epoch number: 344/10000step_number: 0/29 Accuracy:  0.3571598842159033 Loss:  2.8640609449185095 Val_accuracy:  0.35330972487060747 Val_cost:  2.8640609449185095 Val_accuracy:  0.35330972487060747 Val_Acc:  2.8494003838339865\n",
      "Epoch number: 345/10000step_number: 0/29 Accuracy:  0.3575685339690107 Loss:  2.8634326990957324 Val_accuracy:  0.35385453554889673 Val_cost:  2.8634326990957324 Val_accuracy:  0.35385453554889673 Val_Acc:  2.8487898219889307\n",
      "Epoch number: 346/10000step_number: 0/29 Accuracy:  0.35828367103694875 Loss:  2.8628057121185777 Val_accuracy:  0.35453554889675837 Val_cost:  2.8628057121185777 Val_accuracy:  0.35453554889675837 Val_Acc:  2.8481805517513417\n",
      "Epoch number: 347/10000step_number: 0/29 Accuracy:  0.3592371871275328 Loss:  2.862180040797092 Val_accuracy:  0.35562517025333695 Val_cost:  2.862180040797092 Val_accuracy:  0.35562517025333695 Val_Acc:  2.847572587197968\n",
      "Epoch number: 348/10000step_number: 0/29 Accuracy:  0.3596798910267325 Loss:  2.861555665478468 Val_accuracy:  0.35603377826205396 Val_cost:  2.861555665478468 Val_accuracy:  0.35603377826205396 Val_Acc:  2.846965847516877\n",
      "Epoch number: 349/10000step_number: 0/29 Accuracy:  0.3606334071173165 Loss:  2.860932524882398 Val_accuracy:  0.3564423862707709 Val_cost:  2.860932524882398 Val_accuracy:  0.3564423862707709 Val_Acc:  2.8463602002644\n",
      "Epoch number: 350/10000step_number: 0/29 Accuracy:  0.3610080027243317 Loss:  2.860310543559083 Val_accuracy:  0.35685099427948785 Val_cost:  2.860310543559083 Val_accuracy:  0.35685099427948785 Val_Acc:  2.845755504110245\n",
      "Epoch number: 351/10000step_number: 0/29 Accuracy:  0.36206368125319255 Loss:  2.8596896277838275 Val_accuracy:  0.3580768183056388 Val_cost:  2.8596896277838275 Val_accuracy:  0.3580768183056388 Val_Acc:  2.845151623176788\n",
      "Epoch number: 352/10000step_number: 0/29 Accuracy:  0.3625063851523923 Loss:  2.8590696418398083 Val_accuracy:  0.3587578316535004 Val_cost:  2.8590696418398083 Val_accuracy:  0.3587578316535004 Val_Acc:  2.8445484103719862\n",
      "Epoch number: 353/10000step_number: 0/29 Accuracy:  0.3629831431976843 Loss:  2.8584504072733523 Val_accuracy:  0.3593026423317897 Val_cost:  2.8584504072733523 Val_accuracy:  0.3593026423317897 Val_Acc:  2.8439456919531363\n",
      "Epoch number: 354/10000step_number: 0/29 Accuracy:  0.3635280095351609 Loss:  2.8578317379045948 Val_accuracy:  0.359847453010079 Val_cost:  2.8578317379045948 Val_accuracy:  0.359847453010079 Val_Acc:  2.8433432768860567\n",
      "Epoch number: 355/10000step_number: 0/29 Accuracy:  0.3640728758726375 Loss:  2.8572134708335297 Val_accuracy:  0.3614818850449469 Val_cost:  2.8572134708335297 Val_accuracy:  0.3614818850449469 Val_Acc:  2.8427409671908044\n",
      "Epoch number: 356/10000step_number: 0/29 Accuracy:  0.36461774221011406 Loss:  2.8565954575273143 Val_accuracy:  0.36229910106238084 Val_cost:  2.8565954575273143 Val_accuracy:  0.36229910106238084 Val_Acc:  2.8421385282639813\n",
      "Epoch number: 357/10000step_number: 0/29 Accuracy:  0.36543504171632896 Loss:  2.8559775121237925 Val_accuracy:  0.3629801144102424 Val_cost:  2.8559775121237925 Val_accuracy:  0.3629801144102424 Val_Acc:  2.8415355853138213\n",
      "Epoch number: 358/10000step_number: 0/29 Accuracy:  0.36591179976162097 Loss:  2.855359318299218 Val_accuracy:  0.36379733042767637 Val_cost:  2.855359318299218 Val_accuracy:  0.36379733042767637 Val_Acc:  2.8409313784817476\n",
      "Epoch number: 359/10000step_number: 0/29 Accuracy:  0.3669674782904819 Loss:  2.854740331088067 Val_accuracy:  0.364478343775538 Val_cost:  2.854740331088067 Val_accuracy:  0.364478343775538 Val_Acc:  2.840324222264973\n",
      "Epoch number: 360/10000step_number: 0/29 Accuracy:  0.367580452920143 Loss:  2.8541200705523133 Val_accuracy:  0.3657041678016889 Val_cost:  2.8541200705523133 Val_accuracy:  0.3657041678016889 Val_Acc:  2.839710399119546\n",
      "Epoch number: 361/10000step_number: 0/29 Accuracy:  0.3689085646177422 Loss:  2.853500172285203 Val_accuracy:  0.36638518114955054 Val_cost:  2.853500172285203 Val_accuracy:  0.36638518114955054 Val_Acc:  2.8390819128406015\n",
      "Epoch number: 362/10000step_number: 0/29 Accuracy:  0.36958964753958795 Loss:  2.852888102208812 Val_accuracy:  0.3672023971669845 Val_cost:  2.852888102208812 Val_accuracy:  0.3672023971669845 Val_Acc:  2.838437246365432\n",
      "Epoch number: 363/10000step_number: 0/29 Accuracy:  0.3707134343606334 Loss:  2.852290930394477 Val_accuracy:  0.36761100517570144 Val_cost:  2.852290930394477 Val_accuracy:  0.36761100517570144 Val_Acc:  2.83781035619111\n",
      "Epoch number: 364/10000step_number: 0/29 Accuracy:  0.371973437766048 Loss:  2.851702567026503 Val_accuracy:  0.3680196131844184 Val_cost:  2.851702567026503 Val_accuracy:  0.3680196131844184 Val_Acc:  2.837200406779267\n",
      "Epoch number: 365/10000step_number: 0/29 Accuracy:  0.37268857483398604 Loss:  2.8511174109631474 Val_accuracy:  0.3678834105148461 Val_cost:  2.8511174109631474 Val_accuracy:  0.3678834105148461 Val_Acc:  2.8365902208193745\n",
      "Epoch number: 366/10000step_number: 0/29 Accuracy:  0.37452749872296953 Loss:  2.850513916849011 Val_accuracy:  0.3707436665758649 Val_cost:  2.850513916849011 Val_accuracy:  0.3707436665758649 Val_Acc:  2.835964936840294\n",
      "Epoch number: 367/10000step_number: 0/29 Accuracy:  0.376128043589307 Loss:  2.849885573645572 Val_accuracy:  0.37292290928902205 Val_cost:  2.849885573645572 Val_accuracy:  0.37292290928902205 Val_Acc:  2.8353318082833123\n",
      "Epoch number: 368/10000step_number: 0/29 Accuracy:  0.3766388557806913 Loss:  2.849209395517135 Val_accuracy:  0.3736039226368837 Val_cost:  2.849209395517135 Val_accuracy:  0.3736039226368837 Val_Acc:  2.8347004608570048\n",
      "Epoch number: 369/10000step_number: 0/29 Accuracy:  0.37718372211816786 Loss:  2.848551500086886 Val_accuracy:  0.3742849359847453 Val_cost:  2.848551500086886 Val_accuracy:  0.3742849359847453 Val_Acc:  2.834089289883864\n",
      "Epoch number: 370/10000step_number: 0/29 Accuracy:  0.3779669674782905 Loss:  2.8479201519790154 Val_accuracy:  0.37455734132388996 Val_cost:  2.8479201519790154 Val_accuracy:  0.37455734132388996 Val_Acc:  2.833469414365524\n",
      "Epoch number: 371/10000step_number: 0/29 Accuracy:  0.37881832113059766 Loss:  2.8472850365109057 Val_accuracy:  0.37564696268046854 Val_cost:  2.8472850365109057 Val_accuracy:  0.37564696268046854 Val_Acc:  2.8328367665828558\n",
      "Epoch number: 372/10000step_number: 0/29 Accuracy:  0.37963562063681255 Loss:  2.8466460631268036 Val_accuracy:  0.3760555706891855 Val_cost:  2.8466460631268036 Val_accuracy:  0.3760555706891855 Val_Acc:  2.8321984245742438\n",
      "Epoch number: 373/10000step_number: 0/29 Accuracy:  0.38041886599693514 Loss:  2.8460059700391658 Val_accuracy:  0.3772813947153364 Val_cost:  2.8460059700391658 Val_accuracy:  0.3772813947153364 Val_Acc:  2.8315569685289828\n",
      "Epoch number: 374/10000step_number: 0/29 Accuracy:  0.3819853567171803 Loss:  2.8453666953201173 Val_accuracy:  0.3789158267502043 Val_cost:  2.8453666953201173 Val_accuracy:  0.3789158267502043 Val_Acc:  2.8309136895092295\n",
      "Epoch number: 375/10000step_number: 0/29 Accuracy:  0.38242806061638 Loss:  2.844729291756598 Val_accuracy:  0.37973304276763825 Val_cost:  2.844729291756598 Val_accuracy:  0.37973304276763825 Val_Acc:  2.8302692790738675\n",
      "Epoch number: 376/10000step_number: 0/29 Accuracy:  0.3820194108632726 Loss:  2.8440941327753646 Val_accuracy:  0.3800054481067829 Val_cost:  2.8440941327753646 Val_accuracy:  0.3800054481067829 Val_Acc:  2.829623886673542\n",
      "Epoch number: 377/10000step_number: 0/29 Accuracy:  0.3835859015835178 Loss:  2.843461330080428 Val_accuracy:  0.38245709615908474 Val_cost:  2.843461330080428 Val_accuracy:  0.38245709615908474 Val_Acc:  2.8289774149898506\n",
      "Epoch number: 378/10000step_number: 0/29 Accuracy:  0.3840967137749021 Loss:  2.8428309390273405 Val_accuracy:  0.3828657041678017 Val_cost:  2.8428309390273405 Val_accuracy:  0.3828657041678017 Val_Acc:  2.828329685942633\n",
      "Epoch number: 379/10000step_number: 0/29 Accuracy:  0.3848799591350247 Loss:  2.8422030509449048 Val_accuracy:  0.3835467175156633 Val_cost:  2.8422030509449048 Val_accuracy:  0.3835467175156633 Val_Acc:  2.8276805272273853\n",
      "Epoch number: 380/10000step_number: 0/29 Accuracy:  0.38399455133662524 Loss:  2.8415778369994653 Val_accuracy:  0.3828657041678017 Val_cost:  2.8415778369994653 Val_accuracy:  0.3828657041678017 Val_Acc:  2.8270298150056434\n",
      "Epoch number: 381/10000step_number: 0/29 Accuracy:  0.3844032010897327 Loss:  2.840955580377433 Val_accuracy:  0.383410514846091 Val_cost:  2.840955580377433 Val_accuracy:  0.383410514846091 Val_Acc:  2.826377502571254\n",
      "Epoch number: 382/10000step_number: 0/29 Accuracy:  0.3830410352460412 Loss:  2.8403367188026194 Val_accuracy:  0.3827295014982294 Val_cost:  2.8403367188026194 Val_accuracy:  0.3827295014982294 Val_Acc:  2.8257236523642617\n",
      "Epoch number: 383/10000step_number: 0/29 Accuracy:  0.38375617231397924 Loss:  2.839721910848411 Val_accuracy:  0.3835467175156633 Val_cost:  2.839721910848411 Val_accuracy:  0.3835467175156633 Val_Acc:  2.8250684807111046\n",
      "Epoch number: 384/10000step_number: 0/29 Accuracy:  0.3837902264600715 Loss:  2.8391121211236086 Val_accuracy:  0.3835467175156633 Val_cost:  2.8391121211236086 Val_accuracy:  0.3835467175156633 Val_Acc:  2.8244124093413845\n",
      "Epoch number: 385/10000step_number: 0/29 Accuracy:  0.38443725523582495 Loss:  2.838508663853512 Val_accuracy:  0.3839553255243803 Val_cost:  2.838508663853512 Val_accuracy:  0.3839553255243803 Val_Acc:  2.8237560740575853\n",
      "Epoch number: 386/10000step_number: 0/29 Accuracy:  0.38559509620296273 Loss:  2.8379130210394417 Val_accuracy:  0.3845001362026696 Val_cost:  2.8379130210394417 Val_accuracy:  0.3845001362026696 Val_Acc:  2.8231001388600703\n",
      "Epoch number: 387/10000step_number: 0/29 Accuracy:  0.38678699131619276 Loss:  2.837326152830895 Val_accuracy:  0.3851811495505312 Val_cost:  2.837326152830895 Val_accuracy:  0.3851811495505312 Val_Acc:  2.8224446898830187\n",
      "Epoch number: 388/10000step_number: 0/29 Accuracy:  0.3877405074067768 Loss:  2.8367474618983026 Val_accuracy:  0.38613456823753745 Val_cost:  2.8367474618983026 Val_accuracy:  0.38613456823753745 Val_Acc:  2.821788508312928\n",
      "Epoch number: 389/10000step_number: 0/29 Accuracy:  0.38801294057551505 Loss:  2.8361750760000612 Val_accuracy:  0.38613456823753745 Val_cost:  2.8361750760000612 Val_accuracy:  0.38613456823753745 Val_Acc:  2.821129967952465\n",
      "Epoch number: 390/10000step_number: 0/29 Accuracy:  0.3875021283841308 Loss:  2.8356085420883654 Val_accuracy:  0.3853173522201035 Val_cost:  2.8356085420883654 Val_accuracy:  0.3853173522201035 Val_Acc:  2.8204696475534416\n",
      "Epoch number: 391/10000step_number: 0/29 Accuracy:  0.38709347863102334 Loss:  2.8350491265454956 Val_accuracy:  0.3853173522201035 Val_cost:  2.8350491265454956 Val_accuracy:  0.3853173522201035 Val_Acc:  2.8198097464762046\n",
      "Epoch number: 392/10000step_number: 0/29 Accuracy:  0.3884556444747148 Loss:  2.834495654793338 Val_accuracy:  0.38667937891582677 Val_cost:  2.834495654793338 Val_accuracy:  0.38667937891582677 Val_Acc:  2.8191505027198582\n",
      "Epoch number: 393/10000step_number: 0/29 Accuracy:  0.38903456495828365 Loss:  2.833944337790448 Val_accuracy:  0.38776900027240535 Val_cost:  2.833944337790448 Val_accuracy:  0.38776900027240535 Val_Acc:  2.818490182601302\n",
      "Epoch number: 394/10000step_number: 0/29 Accuracy:  0.3893410522731143 Loss:  2.8333922515023318 Val_accuracy:  0.3883138109506946 Val_cost:  2.8333922515023318 Val_accuracy:  0.3883138109506946 Val_Acc:  2.817827632601054\n",
      "Epoch number: 395/10000step_number: 0/29 Accuracy:  0.390737272262898 Loss:  2.832838270483408 Val_accuracy:  0.3898120403159902 Val_cost:  2.832838270483408 Val_accuracy:  0.3898120403159902 Val_Acc:  2.817163083566018\n",
      "Epoch number: 396/10000step_number: 0/29 Accuracy:  0.39284862932061976 Loss:  2.832282122152017 Val_accuracy:  0.39131026968128574 Val_cost:  2.832282122152017 Val_accuracy:  0.39131026968128574 Val_Acc:  2.816497512398985\n",
      "Epoch number: 397/10000step_number: 0/29 Accuracy:  0.3940745785799421 Loss:  2.831723822114799 Val_accuracy:  0.39171887769000274 Val_cost:  2.831723822114799 Val_accuracy:  0.39171887769000274 Val_Acc:  2.8158320758158863\n",
      "Epoch number: 398/10000step_number: 0/29 Accuracy:  0.3952324195470799 Loss:  2.831163597533054 Val_accuracy:  0.3923998910378643 Val_cost:  2.831163597533054 Val_accuracy:  0.3923998910378643 Val_Acc:  2.8151678543334078\n",
      "Epoch number: 399/10000step_number: 0/29 Accuracy:  0.39632215222203304 Loss:  2.830601858732737 Val_accuracy:  0.3932171070552983 Val_cost:  2.830601858732737 Val_accuracy:  0.3932171070552983 Val_Acc:  2.8145057210729876\n",
      "Epoch number: 400/10000step_number: 0/29 Accuracy:  0.39710539758215563 Loss:  2.8300391125908835 Val_accuracy:  0.3933533097248706 Val_cost:  2.8300391125908835 Val_accuracy:  0.3933533097248706 Val_Acc:  2.813846282390847\n",
      "Epoch number: 401/10000step_number: 0/29 Accuracy:  0.39829729269538566 Loss:  2.8294758689162607 Val_accuracy:  0.3938981204031599 Val_cost:  2.8294758689162607 Val_accuracy:  0.3938981204031599 Val_Acc:  2.8131898844535117\n",
      "Epoch number: 402/10000step_number: 0/29 Accuracy:  0.3990124297633237 Loss:  2.82891256977238 Val_accuracy:  0.3944429310814492 Val_cost:  2.82891256977238 Val_accuracy:  0.3944429310814492 Val_Acc:  2.8125366494550983\n",
      "Epoch number: 403/10000step_number: 0/29 Accuracy:  0.40034054146092285 Loss:  2.828349542048072 Val_accuracy:  0.39553255243802776 Val_cost:  2.828349542048072 Val_accuracy:  0.39553255243802776 Val_Acc:  2.811886508269337\n",
      "Epoch number: 404/10000step_number: 0/29 Accuracy:  0.4017708155967989 Loss:  2.8277869708794743 Val_accuracy:  0.39689457913375104 Val_cost:  2.8277869708794743 Val_accuracy:  0.39689457913375104 Val_Acc:  2.8112392237706447\n",
      "Epoch number: 405/10000step_number: 0/29 Accuracy:  0.40350757704750556 Loss:  2.827224894190533 Val_accuracy:  0.3978479978207573 Val_cost:  2.827224894190533 Val_accuracy:  0.3978479978207573 Val_Acc:  2.810594414349518\n",
      "Epoch number: 406/10000step_number: 0/29 Accuracy:  0.4046994721607356 Loss:  2.826663216402346 Val_accuracy:  0.3989376191773359 Val_cost:  2.826663216402346 Val_accuracy:  0.3989376191773359 Val_Acc:  2.8099515850190118\n",
      "Epoch number: 407/10000step_number: 0/29 Accuracy:  0.4065043419036268 Loss:  2.8261017352270557 Val_accuracy:  0.4001634432034868 Val_cost:  2.8261017352270557 Val_accuracy:  0.4001634432034868 Val_Acc:  2.8093101654578962\n",
      "Epoch number: 408/10000step_number: 0/29 Accuracy:  0.4074238038481185 Loss:  2.82554017340093 Val_accuracy:  0.4017978752383547 Val_cost:  2.82554017340093 Val_accuracy:  0.4017978752383547 Val_Acc:  2.808669549055362\n",
      "Epoch number: 409/10000step_number: 0/29 Accuracy:  0.40909245700664054 Loss:  2.824978207993303 Val_accuracy:  0.40343230727322255 Val_cost:  2.824978207993303 Val_accuracy:  0.40343230727322255 Val_Acc:  2.8080291262936696\n",
      "Epoch number: 410/10000step_number: 0/29 Accuracy:  0.40936489017537886 Loss:  2.824415492319891 Val_accuracy:  0.4053391446472351 Val_cost:  2.824415492319891 Val_accuracy:  0.4053391446472351 Val_Acc:  2.8073883078331123\n",
      "Epoch number: 411/10000step_number: 0/29 Accuracy:  0.4113740847948238 Loss:  2.8238516680352213 Val_accuracy:  0.40765459002996457 Val_cost:  2.8238516680352213 Val_accuracy:  0.40765459002996457 Val_Acc:  2.8067465352718117\n",
      "Epoch number: 412/10000step_number: 0/29 Accuracy:  0.4132130086838072 Loss:  2.8232863667732584 Val_accuracy:  0.41024244075183874 Val_cost:  2.8232863667732584 Val_accuracy:  0.41024244075183874 Val_Acc:  2.806103279427968\n",
      "Epoch number: 413/10000step_number: 0/29 Accuracy:  0.4146773369657756 Loss:  2.8227192014057993 Val_accuracy:  0.41160446744756196 Val_cost:  2.8227192014057993 Val_accuracy:  0.41160446744756196 Val_Acc:  2.8054580266625826\n",
      "Epoch number: 414/10000step_number: 0/29 Accuracy:  0.41576706964072874 Loss:  2.8221497465381717 Val_accuracy:  0.4136475074911468 Val_cost:  2.8221497465381717 Val_accuracy:  0.4136475074911468 Val_Acc:  2.804810253151256\n",
      "Epoch number: 415/10000step_number: 0/29 Accuracy:  0.4173676145070662 Loss:  2.8215775061742963 Val_accuracy:  0.41432852083900845 Val_cost:  2.8215775061742963 Val_accuracy:  0.41432852083900845 Val_Acc:  2.804159385010772\n",
      "Epoch number: 416/10000step_number: 0/29 Accuracy:  0.41971735058743403 Loss:  2.821001863106113 Val_accuracy:  0.416235358213021 Val_cost:  2.821001863106113 Val_accuracy:  0.416235358213021 Val_Acc:  2.803504738253532\n",
      "Epoch number: 417/10000step_number: 0/29 Accuracy:  0.4212497871615869 Loss:  2.8204219981919474 Val_accuracy:  0.4173249795695996 Val_cost:  2.8204219981919474 Val_accuracy:  0.4173249795695996 Val_Acc:  2.802845425162335\n",
      "Epoch number: 418/10000step_number: 0/29 Accuracy:  0.42213519495998636 Loss:  2.8198367549964285 Val_accuracy:  0.4181421955870335 Val_cost:  2.8198367549964285 Val_accuracy:  0.4181421955870335 Val_Acc:  2.802180199083626\n",
      "Epoch number: 419/10000step_number: 0/29 Accuracy:  0.4235654690958624 Loss:  2.8192443982539226 Val_accuracy:  0.4189594116044674 Val_cost:  2.8192443982539226 Val_accuracy:  0.4189594116044674 Val_Acc:  2.8015071785282246\n",
      "Epoch number: 420/10000step_number: 0/29 Accuracy:  0.4247233100630002 Loss:  2.8186421529375316 Val_accuracy:  0.42059384363933533 Val_cost:  2.8186421529375316 Val_accuracy:  0.42059384363933533 Val_Acc:  2.8008233199147616\n",
      "Epoch number: 421/10000step_number: 0/29 Accuracy:  0.42707304614336794 Loss:  2.818025259689978 Val_accuracy:  0.42345409970035414 Val_cost:  2.818025259689978 Val_accuracy:  0.42345409970035414 Val_Acc:  2.8001233312602825\n",
      "Epoch number: 422/10000step_number: 0/29 Accuracy:  0.42894602417844374 Loss:  2.8173848883814223 Val_accuracy:  0.4245437210569327 Val_cost:  2.8173848883814223 Val_accuracy:  0.4245437210569327 Val_Acc:  2.7993972518863655\n",
      "Epoch number: 423/10000step_number: 0/29 Accuracy:  0.43143197684318063 Loss:  2.816703192496392 Val_accuracy:  0.425497139743939 Val_cost:  2.816703192496392 Val_accuracy:  0.425497139743939 Val_Acc:  2.7986246536325834\n",
      "Epoch number: 424/10000step_number: 0/29 Accuracy:  0.4326919802485953 Loss:  2.815941291446826 Val_accuracy:  0.42767638245709616 Val_cost:  2.815941291446826 Val_accuracy:  0.42767638245709616 Val_Acc:  2.79776043942311\n",
      "Epoch number: 425/10000step_number: 0/29 Accuracy:  0.4361655031500085 Loss:  2.8150163613464336 Val_accuracy:  0.43121765186597655 Val_cost:  2.8150163613464336 Val_accuracy:  0.43121765186597655 Val_Acc:  2.7967087487646887\n",
      "Epoch number: 426/10000step_number: 0/29 Accuracy:  0.43919632215222204 Loss:  2.813832520275007 Val_accuracy:  0.43407790792699535 Val_cost:  2.813832520275007 Val_accuracy:  0.43407790792699535 Val_Acc:  2.795377790795593\n",
      "Epoch number: 427/10000step_number: 0/29 Accuracy:  0.4432828196832964 Loss:  2.8125827573877213 Val_accuracy:  0.43789158267502043 Val_cost:  2.8125827573877213 Val_accuracy:  0.43789158267502043 Val_Acc:  2.794066226194328\n",
      "Epoch number: 428/10000step_number: 0/29 Accuracy:  0.4438617401668653 Loss:  2.8116086429445604 Val_accuracy:  0.43816398801416506 Val_cost:  2.8116086429445604 Val_accuracy:  0.43816398801416506 Val_Acc:  2.793051656644256\n",
      "Epoch number: 429/10000step_number: 0/29 Accuracy:  0.4449514728418185 Loss:  2.8108070103003704 Val_accuracy:  0.4399346227186053 Val_cost:  2.8108070103003704 Val_accuracy:  0.4399346227186053 Val_Acc:  2.7921505659430745\n",
      "Epoch number: 430/10000step_number: 0/29 Accuracy:  0.447982291844032 Loss:  2.8100271338947294 Val_accuracy:  0.4427948787796241 Val_cost:  2.8100271338947294 Val_accuracy:  0.4427948787796241 Val_Acc:  2.79126229335256\n",
      "Epoch number: 431/10000step_number: 0/29 Accuracy:  0.44995743231738466 Loss:  2.8092610558495736 Val_accuracy:  0.44483791882320894 Val_cost:  2.8092610558495736 Val_accuracy:  0.44483791882320894 Val_Acc:  2.790383814201307\n",
      "Epoch number: 432/10000step_number: 0/29 Accuracy:  0.45118338157670695 Loss:  2.8085055873029576 Val_accuracy:  0.44606374284935985 Val_cost:  2.8085055873029576 Val_accuracy:  0.44606374284935985 Val_Acc:  2.7895118989650736\n",
      "Epoch number: 433/10000step_number: 0/29 Accuracy:  0.45349906351098246 Loss:  2.8077479407042176 Val_accuracy:  0.4494688095886679 Val_cost:  2.8077479407042176 Val_accuracy:  0.4494688095886679 Val_Acc:  2.788635220060391\n",
      "Epoch number: 434/10000step_number: 0/29 Accuracy:  0.4550315000851354 Loss:  2.806976696529162 Val_accuracy:  0.45014982293652955 Val_cost:  2.806976696529162 Val_accuracy:  0.45014982293652955 Val_Acc:  2.7877428255963994\n",
      "Epoch number: 435/10000step_number: 0/29 Accuracy:  0.45629150349055 Loss:  2.806182463611386 Val_accuracy:  0.45164805230182514 Val_cost:  2.806182463611386 Val_accuracy:  0.45164805230182514 Val_Acc:  2.7868248967565106\n",
      "Epoch number: 436/10000step_number: 0/29 Accuracy:  0.4577898859186106 Loss:  2.805355807126816 Val_accuracy:  0.4545083083628439 Val_cost:  2.805355807126816 Val_accuracy:  0.4545083083628439 Val_Acc:  2.7858708979802675\n",
      "Epoch number: 437/10000step_number: 0/29 Accuracy:  0.4600034054146092 Loss:  2.80448522600873 Val_accuracy:  0.4562789430672841 Val_cost:  2.80448522600873 Val_accuracy:  0.4562789430672841 Val_Acc:  2.784867488906087\n",
      "Epoch number: 438/10000step_number: 0/29 Accuracy:  0.4628639536863613 Loss:  2.803554725492425 Val_accuracy:  0.45982021247616456 Val_cost:  2.803554725492425 Val_accuracy:  0.45982021247616456 Val_Acc:  2.7837958109254717\n",
      "Epoch number: 439/10000step_number: 0/29 Accuracy:  0.4636812531925762 Loss:  2.8025400783633985 Val_accuracy:  0.4603650231544538 Val_cost:  2.8025400783633985 Val_accuracy:  0.4603650231544538 Val_Acc:  2.7826270828664126\n",
      "Epoch number: 440/10000step_number: 0/29 Accuracy:  0.4656904478120211 Loss:  2.8014018713778133 Val_accuracy:  0.4626804685371833 Val_cost:  2.8014018713778133 Val_accuracy:  0.4626804685371833 Val_Acc:  2.7813142582826185\n",
      "Epoch number: 441/10000step_number: 0/29 Accuracy:  0.46940234973608036 Loss:  2.800071212986626 Val_accuracy:  0.4664941432852084 Val_cost:  2.800071212986626 Val_accuracy:  0.4664941432852084 Val_Acc:  2.7797746619298014\n",
      "Epoch number: 442/10000step_number: 0/29 Accuracy:  0.47423803848118506 Loss:  2.798417910270424 Val_accuracy:  0.47126123672023973 Val_cost:  2.798417910270424 Val_accuracy:  0.47126123672023973 Val_Acc:  2.7778506755430814\n",
      "Epoch number: 443/10000step_number: 0/29 Accuracy:  0.4860207730291163 Loss:  2.7961739592175934 Val_accuracy:  0.485698719694906 Val_cost:  2.7961739592175934 Val_accuracy:  0.485698719694906 Val_Acc:  2.775213716308423\n",
      "Epoch number: 444/10000step_number: 0/29 Accuracy:  0.4963391792950792 Loss:  2.792748661862668 Val_accuracy:  0.49441569054753476 Val_cost:  2.792748661862668 Val_accuracy:  0.49441569054753476 Val_Acc:  2.7711301034011067\n",
      "Epoch number: 445/10000step_number: 0/29 Accuracy:  0.49865486122935465 Loss:  2.786802831042526 Val_accuracy:  0.4960501225824026 Val_cost:  2.786802831042526 Val_accuracy:  0.4960501225824026 Val_Acc:  2.763938927572555\n",
      "Epoch number: 446/10000step_number: 0/29 Accuracy:  0.5337646858505023 Loss:  2.775164963339546 Val_accuracy:  0.5301007899754835 Val_cost:  2.775164963339546 Val_accuracy:  0.5301007899754835 Val_Acc:  2.749989761979084\n",
      "Epoch number: 447/10000step_number: 0/29 Accuracy:  0.5540950110675975 Loss:  2.765722343877638 Val_accuracy:  0.5491691637156089 Val_cost:  2.765722343877638 Val_accuracy:  0.5491691637156089 Val_Acc:  2.7393838715757997\n",
      "Epoch number: 448/10000step_number: 0/29 Accuracy:  0.5649242295249447 Loss:  2.763698098555803 Val_accuracy:  0.5593843639335331 Val_cost:  2.763698098555803 Val_accuracy:  0.5593843639335331 Val_Acc:  2.7389658412725795\n",
      "Epoch number: 449/10000step_number: 0/29 Accuracy:  0.5583517793291333 Loss:  2.7627375068568707 Val_accuracy:  0.5478071370198856 Val_cost:  2.7627375068568707 Val_accuracy:  0.5478071370198856 Val_Acc:  2.738843226284598\n",
      "Epoch number: 450/10000step_number: 0/29 Accuracy:  0.5594415120040865 Loss:  2.7615777305515024 Val_accuracy:  0.5487605557068919 Val_cost:  2.7615777305515024 Val_accuracy:  0.5487605557068919 Val_Acc:  2.7379540446628616\n",
      "Epoch number: 451/10000step_number: 0/29 Accuracy:  0.5602928656563937 Loss:  2.760733338992085 Val_accuracy:  0.5501225824026151 Val_cost:  2.760733338992085 Val_accuracy:  0.5501225824026151 Val_Acc:  2.737320397693439\n",
      "Epoch number: 452/10000step_number: 0/29 Accuracy:  0.5596117827345479 Loss:  2.759948007213167 Val_accuracy:  0.5503949877417598 Val_cost:  2.759948007213167 Val_accuracy:  0.5503949877417598 Val_Acc:  2.736742755716226\n",
      "Epoch number: 453/10000step_number: 0/29 Accuracy:  0.5598501617571939 Loss:  2.759185366301 Val_accuracy:  0.5510760010896214 Val_cost:  2.759185366301 Val_accuracy:  0.5510760010896214 Val_Acc:  2.736098444975892\n",
      "Epoch number: 454/10000step_number: 0/29 Accuracy:  0.561995572961008 Loss:  2.7584815392391 Val_accuracy:  0.5523018251157723 Val_cost:  2.7584815392391 Val_accuracy:  0.5523018251157723 Val_Acc:  2.7354718353401544\n",
      "Epoch number: 455/10000step_number: 0/29 Accuracy:  0.5557296100800272 Loss:  2.7577920839002963 Val_accuracy:  0.5456278943067284 Val_cost:  2.7577920839002963 Val_accuracy:  0.5456278943067284 Val_Acc:  2.7348321069005057\n",
      "Epoch number: 456/10000step_number: 0/29 Accuracy:  0.5557296100800272 Loss:  2.757130718420309 Val_accuracy:  0.5463089076545901 Val_cost:  2.757130718420309 Val_accuracy:  0.5463089076545901 Val_Acc:  2.7341884787226562\n",
      "Epoch number: 457/10000step_number: 0/29 Accuracy:  0.5549123105738124 Loss:  2.7565000036004186 Val_accuracy:  0.5453554889675838 Val_cost:  2.7565000036004186 Val_accuracy:  0.5453554889675838 Val_Acc:  2.733551689607148\n",
      "Epoch number: 458/10000step_number: 0/29 Accuracy:  0.5523923037629831 Loss:  2.7558997530857345 Val_accuracy:  0.542903840915282 Val_cost:  2.7558997530857345 Val_accuracy:  0.542903840915282 Val_Acc:  2.732926414291014\n",
      "Epoch number: 459/10000step_number: 0/29 Accuracy:  0.5551506895964584 Loss:  2.755328715120834 Val_accuracy:  0.5461727049850177 Val_cost:  2.755328715120834 Val_accuracy:  0.5461727049850177 Val_Acc:  2.7323167510907513\n",
      "Epoch number: 460/10000step_number: 0/29 Accuracy:  0.5586923207900562 Loss:  2.7547834649461644 Val_accuracy:  0.5506673930809044 Val_cost:  2.7547834649461644 Val_accuracy:  0.5506673930809044 Val_Acc:  2.7317241541129484\n",
      "Epoch number: 461/10000step_number: 0/29 Accuracy:  0.5544355525285204 Loss:  2.7542595685571416 Val_accuracy:  0.5465813129937347 Val_cost:  2.7542595685571416 Val_accuracy:  0.5465813129937347 Val_Acc:  2.7311481268419606\n",
      "Epoch number: 462/10000step_number: 0/29 Accuracy:  0.5546739315511664 Loss:  2.7537524178678514 Val_accuracy:  0.5469899210024517 Val_cost:  2.7537524178678514 Val_accuracy:  0.5469899210024517 Val_Acc:  2.730587018369575\n",
      "Epoch number: 463/10000step_number: 0/29 Accuracy:  0.5546058232589818 Loss:  2.7532578301489212 Val_accuracy:  0.5465813129937347 Val_cost:  2.7532578301489212 Val_accuracy:  0.5465813129937347 Val_Acc:  2.730038724339535\n",
      "Epoch number: 464/10000step_number: 0/29 Accuracy:  0.5544696066746126 Loss:  2.7527723703393137 Val_accuracy:  0.546717515663307 Val_cost:  2.7527723703393137 Val_accuracy:  0.546717515663307 Val_Acc:  2.7295012474133578\n",
      "Epoch number: 465/10000step_number: 0/29 Accuracy:  0.5531755491231057 Loss:  2.752293393947912 Val_accuracy:  0.5456278943067284 Val_cost:  2.752293393947912 Val_accuracy:  0.5456278943067284 Val_Acc:  2.7289729872652373\n",
      "Epoch number: 466/10000step_number: 0/29 Accuracy:  0.5539928486293206 Loss:  2.7518189380260045 Val_accuracy:  0.5463089076545901 Val_cost:  2.7518189380260045 Val_accuracy:  0.5463089076545901 Val_Acc:  2.7284528233152217\n",
      "Epoch number: 467/10000step_number: 0/29 Accuracy:  0.5543333900902435 Loss:  2.7513475643663976 Val_accuracy:  0.5469899210024517 Val_cost:  2.7513475643663976 Val_accuracy:  0.5469899210024517 Val_Acc:  2.7279400742324214\n",
      "Epoch number: 468/10000step_number: 0/29 Accuracy:  0.5548442022816278 Loss:  2.750878237405687 Val_accuracy:  0.5476709343503132 Val_cost:  2.750878237405687 Val_accuracy:  0.5476709343503132 Val_Acc:  2.7274343920124595\n",
      "Epoch number: 469/10000step_number: 0/29 Accuracy:  0.5542993359441512 Loss:  2.7504102671145536 Val_accuracy:  0.5480795423590302 Val_cost:  2.7504102671145536 Val_accuracy:  0.5480795423590302 Val_Acc:  2.72693562546008\n",
      "Epoch number: 470/10000step_number: 0/29 Accuracy:  0.5552869061808275 Loss:  2.7499432871831853 Val_accuracy:  0.5478071370198856 Val_cost:  2.7499432871831853 Val_accuracy:  0.5478071370198856 Val_Acc:  2.7264436861630506\n",
      "Epoch number: 471/10000step_number: 0/29 Accuracy:  0.55368636131449 Loss:  2.7494772160938212 Val_accuracy:  0.545491691637156 Val_cost:  2.7494772160938212 Val_accuracy:  0.545491691637156 Val_Acc:  2.725958455574142\n",
      "Epoch number: 472/10000step_number: 0/29 Accuracy:  0.55368636131449 Loss:  2.7490121751586383 Val_accuracy:  0.5457640969763007 Val_cost:  2.7490121751586383 Val_accuracy:  0.5457640969763007 Val_Acc:  2.7254797521379044\n",
      "Epoch number: 473/10000step_number: 0/29 Accuracy:  0.5538225778988591 Loss:  2.748548376101531 Val_accuracy:  0.5453554889675838 Val_cost:  2.748548376101531 Val_accuracy:  0.5453554889675838 Val_Acc:  2.725007342788116\n",
      "Epoch number: 474/10000step_number: 0/29 Accuracy:  0.5544696066746126 Loss:  2.748086009406532 Val_accuracy:  0.5453554889675838 Val_cost:  2.748086009406532 Val_accuracy:  0.5453554889675838 Val_Acc:  2.724540966275402\n",
      "Epoch number: 475/10000step_number: 0/29 Accuracy:  0.5550144730120892 Loss:  2.747625163806523 Val_accuracy:  0.5463089076545901 Val_cost:  2.747625163806523 Val_accuracy:  0.5463089076545901 Val_Acc:  2.7240803453279603\n",
      "Epoch number: 476/10000step_number: 0/29 Accuracy:  0.556649072024519 Loss:  2.747165795098341 Val_accuracy:  0.5478071370198856 Val_cost:  2.747165795098341 Val_accuracy:  0.5478071370198856 Val_Acc:  2.723625187442689\n",
      "Epoch number: 477/10000step_number: 0/29 Accuracy:  0.5569215051932572 Loss:  2.746707741599692 Val_accuracy:  0.5482157450286026 Val_cost:  2.746707741599692 Val_accuracy:  0.5482157450286026 Val_Acc:  2.7231751863022846\n",
      "Epoch number: 478/10000step_number: 0/29 Accuracy:  0.557364209092457 Loss:  2.7462507654823494 Val_accuracy:  0.5487605557068919 Val_cost:  2.7462507654823494 Val_accuracy:  0.5487605557068919 Val_Acc:  2.7227300295524475\n",
      "Epoch number: 479/10000step_number: 0/29 Accuracy:  0.5577388046994721 Loss:  2.7457945964100925 Val_accuracy:  0.5490329610460365 Val_cost:  2.7457945964100925 Val_accuracy:  0.5490329610460365 Val_Acc:  2.722289409201344\n",
      "Epoch number: 480/10000step_number: 0/29 Accuracy:  0.5583858334752256 Loss:  2.745338963855365 Val_accuracy:  0.5493053663851811 Val_cost:  2.745338963855365 Val_accuracy:  0.5493053663851811 Val_Acc:  2.721853029652458\n",
      "Epoch number: 481/10000step_number: 0/29 Accuracy:  0.5590669163970713 Loss:  2.744883615856149 Val_accuracy:  0.5502587850721874 Val_cost:  2.744883615856149 Val_accuracy:  0.5502587850721874 Val_Acc:  2.7214206120394677\n",
      "Epoch number: 482/10000step_number: 0/29 Accuracy:  0.559271241273625 Loss:  2.7444283278077415 Val_accuracy:  0.550939798420049 Val_cost:  2.7444283278077415 Val_accuracy:  0.550939798420049 Val_Acc:  2.720991896049917\n",
      "Epoch number: 483/10000step_number: 0/29 Accuracy:  0.5598501617571939 Loss:  2.743972905591323 Val_accuracy:  0.5516208117679107 Val_cost:  2.743972905591323 Val_accuracy:  0.5516208117679107 Val_Acc:  2.7205666406799542\n",
      "Epoch number: 484/10000step_number: 0/29 Accuracy:  0.5597479993189171 Loss:  2.7435171859955756 Val_accuracy:  0.5518932171070553 Val_cost:  2.7435171859955756 Val_accuracy:  0.5518932171070553 Val_Acc:  2.720144624708644\n",
      "Epoch number: 485/10000step_number: 0/29 Accuracy:  0.5604631363868551 Loss:  2.743061035991098 Val_accuracy:  0.5523018251157723 Val_cost:  2.743061035991098 Val_accuracy:  0.5523018251157723 Val_Acc:  2.7197256471050912\n",
      "Epoch number: 486/10000step_number: 0/29 Accuracy:  0.5605993529712242 Loss:  2.742604351538448 Val_accuracy:  0.5532552438027786 Val_cost:  2.742604351538448 Val_accuracy:  0.5532552438027786 Val_Acc:  2.719309527323809\n",
      "Epoch number: 487/10000step_number: 0/29 Accuracy:  0.5612123276008854 Loss:  2.7421470561699035 Val_accuracy:  0.5538000544810678 Val_cost:  2.7421470561699035 Val_accuracy:  0.5538000544810678 Val_Acc:  2.718896105398758\n",
      "Epoch number: 488/10000step_number: 0/29 Accuracy:  0.5618593563766389 Loss:  2.741689099390724 Val_accuracy:  0.5540724598202125 Val_cost:  2.741689099390724 Val_accuracy:  0.5540724598202125 Val_Acc:  2.718485241774051\n",
      "Epoch number: 489/10000step_number: 0/29 Accuracy:  0.5600544866337477 Loss:  2.7412304548648954 Val_accuracy:  0.5535276491419232 Val_cost:  2.7412304548648954 Val_accuracy:  0.5535276491419232 Val_Acc:  2.718076816834774\n",
      "Epoch number: 490/10000step_number: 0/29 Accuracy:  0.5602247573642091 Loss:  2.7407711183176535 Val_accuracy:  0.5542086624897848 Val_cost:  2.7407711183176535 Val_accuracy:  0.5542086624897848 Val_Acc:  2.717670730106954\n",
      "Epoch number: 491/10000step_number: 0/29 Accuracy:  0.5604971905329473 Loss:  2.74031110507723 Val_accuracy:  0.5551620811767911 Val_cost:  2.74031110507723 Val_accuracy:  0.5551620811767911 Val_Acc:  2.7172668990888487\n",
      "Epoch number: 492/10000step_number: 0/29 Accuracy:  0.5609398944321471 Loss:  2.7398504471847027 Val_accuracy:  0.555570689185508 Val_cost:  2.7398504471847027 Val_accuracy:  0.555570689185508 Val_Acc:  2.7168652576698435\n",
      "Epoch number: 493/10000step_number: 0/29 Accuracy:  0.5612463817469777 Loss:  2.7393891900245206 Val_accuracy:  0.5554344865159357 Val_cost:  2.7393891900245206 Val_accuracy:  0.5554344865159357 Val_Acc:  2.716465754098989\n",
      "Epoch number: 494/10000step_number: 0/29 Accuracy:  0.5612123276008854 Loss:  2.7389273884720313 Val_accuracy:  0.5561154998637974 Val_cost:  2.7389273884720313 Val_accuracy:  0.5561154998637974 Val_Acc:  2.716068348489623\n",
      "Epoch number: 495/10000step_number: 0/29 Accuracy:  0.5604290822407628 Loss:  2.738465102618993 Val_accuracy:  0.5557068918550804 Val_cost:  2.738465102618993 Val_accuracy:  0.5557068918550804 Val_Acc:  2.7156730098924964\n",
      "Epoch number: 496/10000step_number: 0/29 Accuracy:  0.5605312446790397 Loss:  2.738002393217325 Val_accuracy:  0.556387905202942 Val_cost:  2.738002393217325 Val_accuracy:  0.556387905202942 Val_Acc:  2.7152797130339934\n",
      "Epoch number: 497/10000step_number: 0/29 Accuracy:  0.561042056870424 Loss:  2.73753931705863 Val_accuracy:  0.5566603105420866 Val_cost:  2.73753931705863 Val_accuracy:  0.5566603105420866 Val_Acc:  2.7148884348867206\n",
      "Epoch number: 498/10000step_number: 0/29 Accuracy:  0.5615869232079006 Loss:  2.7370759225560013 Val_accuracy:  0.5570689185508036 Val_cost:  2.7370759225560013 Val_accuracy:  0.5570689185508036 Val_Acc:  2.7144991512958114\n",
      "Epoch number: 499/10000step_number: 0/29 Accuracy:  0.5628809807594075 Loss:  2.7366122457893622 Val_accuracy:  0.5584309452465268 Val_cost:  2.7366122457893622 Val_accuracy:  0.5584309452465268 Val_Acc:  2.7141118339018715\n",
      "Epoch number: 500/10000step_number: 0/29 Accuracy:  0.5635620636812532 Loss:  2.7361483072066193 Val_accuracy:  0.5584309452465268 Val_cost:  2.7361483072066193 Val_accuracy:  0.5584309452465268 Val_Acc:  2.7137264475660086\n",
      "Epoch number: 501/10000step_number: 0/29 Accuracy:  0.5644815256257449 Loss:  2.7356841090597412 Val_accuracy:  0.5592481612639608 Val_cost:  2.7356841090597412 Val_accuracy:  0.5592481612639608 Val_Acc:  2.713342948420201\n",
      "Epoch number: 502/10000step_number: 0/29 Accuracy:  0.564958283671037 Loss:  2.7352196335391477 Val_accuracy:  0.5599291746118223 Val_cost:  2.7352196335391477 Val_accuracy:  0.5599291746118223 Val_Acc:  2.712961282563375\n",
      "Epoch number: 503/10000step_number: 0/29 Accuracy:  0.5656053124467904 Loss:  2.7347548414906404 Val_accuracy:  0.5604739852901117 Val_cost:  2.7347548414906404 Val_accuracy:  0.5604739852901117 Val_Acc:  2.7125813853282876\n",
      "Epoch number: 504/10000step_number: 0/29 Accuracy:  0.5651626085475907 Loss:  2.7342896715696154 Val_accuracy:  0.5603377826205393 Val_cost:  2.7342896715696154 Val_accuracy:  0.5603377826205393 Val_Acc:  2.7122031809702336\n",
      "Epoch number: 505/10000step_number: 0/29 Accuracy:  0.5657415290311596 Loss:  2.7338240396968185 Val_accuracy:  0.5607463906292564 Val_cost:  2.7338240396968185 Val_accuracy:  0.5607463906292564 Val_Acc:  2.7118265825757883\n",
      "Epoch number: 506/10000step_number: 0/29 Accuracy:  0.5665928826834667 Loss:  2.733357838715818 Val_accuracy:  0.5615636066466902 Val_cost:  2.733357838715818 Val_accuracy:  0.5615636066466902 Val_Acc:  2.7114514919625523\n",
      "Epoch number: 507/10000step_number: 0/29 Accuracy:  0.5672739656053124 Loss:  2.7328909382106015 Val_accuracy:  0.5618360119858349 Val_cost:  2.7328909382106015 Val_accuracy:  0.5618360119858349 Val_Acc:  2.7110777993543205\n",
      "Epoch number: 508/10000step_number: 0/29 Accuracy:  0.5676485612123277 Loss:  2.7324231845172653 Val_accuracy:  0.5627894306728412 Val_cost:  2.7324231845172653 Val_accuracy:  0.5627894306728412 Val_Acc:  2.710705382682582\n",
      "Epoch number: 509/10000step_number: 0/29 Accuracy:  0.5677166695045122 Loss:  2.731954401044786 Val_accuracy:  0.5630618360119858 Val_cost:  2.731954401044786 Val_accuracy:  0.5630618360119858 Val_Acc:  2.7103341064799364\n",
      "Epoch number: 510/10000step_number: 0/29 Accuracy:  0.5682615358419888 Loss:  2.731484389107745 Val_accuracy:  0.5637428493598474 Val_cost:  2.731484389107745 Val_accuracy:  0.5637428493598474 Val_Acc:  2.7099638204827783\n",
      "Epoch number: 511/10000step_number: 0/29 Accuracy:  0.5688404563255577 Loss:  2.7310129296101793 Val_accuracy:  0.5645600653772814 Val_cost:  2.7310129296101793 Val_accuracy:  0.5645600653772814 Val_Acc:  2.709594358256787\n",
      "Epoch number: 512/10000step_number: 0/29 Accuracy:  0.5691469436403882 Loss:  2.730539786190344 Val_accuracy:  0.5649686733859983 Val_cost:  2.730539786190344 Val_accuracy:  0.5649686733859983 Val_Acc:  2.7092255364381157\n",
      "Epoch number: 513/10000step_number: 0/29 Accuracy:  0.5694193768091265 Loss:  2.7300647109231098 Val_accuracy:  0.5646962680468537 Val_cost:  2.7300647109231098 Val_accuracy:  0.5646962680468537 Val_Acc:  2.7088571555877303\n",
      "Epoch number: 514/10000step_number: 0/29 Accuracy:  0.5700323514387877 Loss:  2.7295874543292875 Val_accuracy:  0.5653772813947153 Val_cost:  2.7295874543292875 Val_accuracy:  0.5653772813947153 Val_Acc:  2.7084890041412497\n",
      "Epoch number: 515/10000step_number: 0/29 Accuracy:  0.5693172143708497 Loss:  2.729107781845779 Val_accuracy:  0.5645600653772814 Val_cost:  2.729107781845779 Val_accuracy:  0.5645600653772814 Val_Acc:  2.708120867205726\n",
      "Epoch number: 516/10000step_number: 0/29 Accuracy:  0.5695215392474033 Loss:  2.728625498072608 Val_accuracy:  0.5652410787251431 Val_cost:  2.728625498072608 Val_accuracy:  0.5652410787251431 Val_Acc:  2.707752541315224\n",
      "Epoch number: 517/10000step_number: 0/29 Accuracy:  0.5698961348544185 Loss:  2.7281404767507635 Val_accuracy:  0.5648324707164261 Val_cost:  2.7281404767507635 Val_accuracy:  0.5648324707164261 Val_Acc:  2.707383853843638\n",
      "Epoch number: 518/10000step_number: 0/29 Accuracy:  0.5703388387536182 Loss:  2.727652688497268 Val_accuracy:  0.5651048760555707 Val_cost:  2.727652688497268 Val_accuracy:  0.5651048760555707 Val_Acc:  2.707014681624933\n",
      "Epoch number: 519/10000step_number: 0/29 Accuracy:  0.5708155967989103 Loss:  2.7271622132769755 Val_accuracy:  0.5657858894034323 Val_cost:  2.7271622132769755 Val_accuracy:  0.5657858894034323 Val_Acc:  2.7066449598946436\n",
      "Epoch number: 520/10000step_number: 0/29 Accuracy:  0.5714285714285714 Loss:  2.726669226723219 Val_accuracy:  0.566466902751294 Val_cost:  2.726669226723219 Val_accuracy:  0.566466902751294 Val_Acc:  2.706274674245295\n",
      "Epoch number: 521/10000step_number: 0/29 Accuracy:  0.5719393836199558 Loss:  2.726173961217375 Val_accuracy:  0.5667393080904386 Val_cost:  2.726173961217375 Val_accuracy:  0.5667393080904386 Val_Acc:  2.7059038364258923\n",
      "Epoch number: 522/10000step_number: 0/29 Accuracy:  0.5724842499574323 Loss:  2.7256766565010357 Val_accuracy:  0.5674203214383002 Val_cost:  2.7256766565010357 Val_accuracy:  0.5674203214383002 Val_Acc:  2.705532454146607\n",
      "Epoch number: 523/10000step_number: 0/29 Accuracy:  0.572688574833986 Loss:  2.7251775187827105 Val_accuracy:  0.5679651321165895 Val_cost:  2.7251775187827105 Val_accuracy:  0.5679651321165895 Val_Acc:  2.705160507565477\n",
      "Epoch number: 524/10000step_number: 0/29 Accuracy:  0.5733356036097395 Loss:  2.7246766993308182 Val_accuracy:  0.5686461454644511 Val_cost:  2.7246766993308182 Val_accuracy:  0.5686461454644511 Val_Acc:  2.7047879393868866\n",
      "Epoch number: 525/10000step_number: 0/29 Accuracy:  0.5705091094840797 Loss:  2.7241742920223126 Val_accuracy:  0.5646962680468537 Val_cost:  2.7241742920223126 Val_accuracy:  0.5646962680468537 Val_Acc:  2.7044146576443286\n",
      "Epoch number: 526/10000step_number: 0/29 Accuracy:  0.5691469436403882 Loss:  2.7236703427888433 Val_accuracy:  0.5627894306728412 Val_cost:  2.7236703427888433 Val_accuracy:  0.5627894306728412 Val_Acc:  2.7040405460755257\n",
      "Epoch number: 527/10000step_number: 0/29 Accuracy:  0.5694534309552188 Loss:  2.723164863567815 Val_accuracy:  0.5636066466902752 Val_cost:  2.723164863567815 Val_accuracy:  0.5636066466902752 Val_Acc:  2.703665477024439\n",
      "Epoch number: 528/10000step_number: 0/29 Accuracy:  0.5697939724161417 Loss:  2.7226578458794455 Val_accuracy:  0.5641514573685644 Val_cost:  2.7226578458794455 Val_accuracy:  0.5641514573685644 Val_Acc:  2.703289323529604\n",
      "Epoch number: 529/10000step_number: 0/29 Accuracy:  0.569112889494296 Loss:  2.7221492716494935 Val_accuracy:  0.5637428493598474 Val_cost:  2.7221492716494935 Val_accuracy:  0.5637428493598474 Val_Acc:  2.7029119688118977\n",
      "Epoch number: 530/10000step_number: 0/29 Accuracy:  0.5694193768091265 Loss:  2.7216391205274695 Val_accuracy:  0.5638790520294198 Val_cost:  2.7216391205274695 Val_accuracy:  0.5638790520294198 Val_Acc:  2.7025333123740016\n",
      "Epoch number: 531/10000step_number: 0/29 Accuracy:  0.5702026221692491 Loss:  2.721127373921123 Val_accuracy:  0.5638790520294198 Val_cost:  2.721127373921123 Val_accuracy:  0.5638790520294198 Val_Acc:  2.7021532726275206\n",
      "Epoch number: 532/10000step_number: 0/29 Accuracy:  0.570781542652818 Loss:  2.7206140165475428 Val_accuracy:  0.5641514573685644 Val_cost:  2.7206140165475428 Val_accuracy:  0.5641514573685644 Val_Acc:  2.701771786545642\n",
      "Epoch number: 533/10000step_number: 0/29 Accuracy:  0.5701685680231569 Loss:  2.7200990365429125 Val_accuracy:  0.5638790520294198 Val_cost:  2.7200990365429125 Val_accuracy:  0.5638790520294198 Val_Acc:  2.7013888072483008\n",
      "Epoch number: 534/10000step_number: 0/29 Accuracy:  0.5721437084965094 Loss:  2.7195824250653855 Val_accuracy:  0.5649686733859983 Val_cost:  2.7195824250653855 Val_accuracy:  0.5649686733859983 Val_Acc:  2.701004300549666\n",
      "Epoch number: 535/10000step_number: 0/29 Accuracy:  0.5726204665418014 Loss:  2.719064175955503 Val_accuracy:  0.5661944974121493 Val_cost:  2.719064175955503 Val_accuracy:  0.5661944974121493 Val_Acc:  2.7006182413225286\n",
      "Epoch number: 536/10000step_number: 0/29 Accuracy:  0.5731312787331858 Loss:  2.7185442855851476 Val_accuracy:  0.566466902751294 Val_cost:  2.7185442855851476 Val_accuracy:  0.566466902751294 Val_Acc:  2.700230610189538\n",
      "Epoch number: 537/10000step_number: 0/29 Accuracy:  0.5743572279925081 Loss:  2.71802275273552 Val_accuracy:  0.5674203214383002 Val_cost:  2.71802275273552 Val_accuracy:  0.5674203214383002 Val_Acc:  2.6998413907279253\n",
      "Epoch number: 538/10000step_number: 0/29 Accuracy:  0.5749020943299846 Loss:  2.717499578292556 Val_accuracy:  0.5679651321165895 Val_cost:  2.717499578292556 Val_accuracy:  0.5679651321165895 Val_Acc:  2.6994505672062483\n",
      "Epoch number: 539/10000step_number: 0/29 Accuracy:  0.5759577728588455 Loss:  2.716974764682859 Val_accuracy:  0.5686461454644511 Val_cost:  2.716974764682859 Val_accuracy:  0.5686461454644511 Val_Acc:  2.6990581228684394\n",
      "Epoch number: 540/10000step_number: 0/29 Accuracy:  0.575412906521369 Loss:  2.7164483151556684 Val_accuracy:  0.5681013347861618 Val_cost:  2.7164483151556684 Val_accuracy:  0.5681013347861618 Val_Acc:  2.698664038854077\n",
      "Epoch number: 541/10000step_number: 0/29 Accuracy:  0.576128043589307 Loss:  2.715920233118991 Val_accuracy:  0.5685099427948788 Val_cost:  2.715920233118991 Val_accuracy:  0.5685099427948788 Val_Acc:  2.6982682938888014\n",
      "Epoch number: 542/10000step_number: 0/29 Accuracy:  0.5770475055337987 Loss:  2.715390521707265 Val_accuracy:  0.569463361481885 Val_cost:  2.715390521707265 Val_accuracy:  0.569463361481885 Val_Acc:  2.697870864836687\n",
      "Epoch number: 543/10000step_number: 0/29 Accuracy:  0.5769793972416142 Loss:  2.714859183619391 Val_accuracy:  0.569054753473168 Val_cost:  2.714859183619391 Val_accuracy:  0.569054753473168 Val_Acc:  2.697471728080408\n",
      "Epoch number: 544/10000step_number: 0/29 Accuracy:  0.5780691299165673 Loss:  2.714326221091199 Val_accuracy:  0.5705529828384637 Val_cost:  2.714326221091199 Val_accuracy:  0.5705529828384637 Val_Acc:  2.69707086152987\n",
      "Epoch number: 545/10000step_number: 0/29 Accuracy:  0.5794653499063511 Loss:  2.7137916357333536 Val_accuracy:  0.5721874148733315 Val_cost:  2.7137916357333536 Val_accuracy:  0.5721874148733315 Val_Acc:  2.696668246906971\n",
      "Epoch number: 546/10000step_number: 0/29 Accuracy:  0.5801804869742891 Loss:  2.7132554279266388 Val_accuracy:  0.5727322255516208 Val_cost:  2.7132554279266388 Val_accuracy:  0.5727322255516208 Val_Acc:  2.69626387183538\n",
      "Epoch number: 547/10000step_number: 0/29 Accuracy:  0.5812702196492423 Loss:  2.712717595539176 Val_accuracy:  0.5739580495777717 Val_cost:  2.712717595539176 Val_accuracy:  0.5739580495777717 Val_Acc:  2.6958577311449767\n",
      "Epoch number: 548/10000step_number: 0/29 Accuracy:  0.5820194108632726 Loss:  2.7121781319242464 Val_accuracy:  0.5736856442386271 Val_cost:  2.7121781319242464 Val_accuracy:  0.5736856442386271 Val_Acc:  2.6954498265939137\n",
      "Epoch number: 549/10000step_number: 0/29 Accuracy:  0.5828707645155797 Loss:  2.7116370235565825 Val_accuracy:  0.574502860256061 Val_cost:  2.7116370235565825 Val_accuracy:  0.574502860256061 Val_Acc:  2.69504016386452\n",
      "Epoch number: 550/10000step_number: 0/29 Accuracy:  0.584198876213179 Loss:  2.7110942485937275 Val_accuracy:  0.5758648869517843 Val_cost:  2.7110942485937275 Val_accuracy:  0.5758648869517843 Val_Acc:  2.694628745484473\n",
      "Epoch number: 551/10000step_number: 0/29 Accuracy:  0.5846415801123787 Loss:  2.7105497799370544 Val_accuracy:  0.5769545083083628 Val_cost:  2.7105497799370544 Val_accuracy:  0.5769545083083628 Val_Acc:  2.694215559662279\n",
      "Epoch number: 552/10000step_number: 0/29 Accuracy:  0.5859015835177933 Loss:  2.7100036013152424 Val_accuracy:  0.5781803323345137 Val_cost:  2.7100036013152424 Val_accuracy:  0.5781803323345137 Val_Acc:  2.6938005715910447\n",
      "Epoch number: 553/10000step_number: 0/29 Accuracy:  0.5878086156989614 Loss:  2.709455751911722 Val_accuracy:  0.579950967038954 Val_cost:  2.709455751911722 Val_accuracy:  0.579950967038954 Val_Acc:  2.69338373992865\n",
      "Epoch number: 554/10000step_number: 0/29 Accuracy:  0.5884896986208071 Loss:  2.7089064130458054 Val_accuracy:  0.5806319803868156 Val_cost:  2.7089064130458054 Val_accuracy:  0.5806319803868156 Val_Acc:  2.6929650974868555\n",
      "Epoch number: 555/10000step_number: 0/29 Accuracy:  0.5894091605652988 Loss:  2.7083560119203076 Val_accuracy:  0.5809043857259603 Val_cost:  2.7083560119203076 Val_accuracy:  0.5809043857259603 Val_Acc:  2.6925449036141575\n",
      "Epoch number: 556/10000step_number: 0/29 Accuracy:  0.5898518644644986 Loss:  2.707805243865877 Val_accuracy:  0.5811767910651049 Val_cost:  2.707805243865877 Val_accuracy:  0.5811767910651049 Val_Acc:  2.692123757872718\n",
      "Epoch number: 557/10000step_number: 0/29 Accuracy:  0.590260514217606 Loss:  2.707254921211814 Val_accuracy:  0.5821302097521112 Val_cost:  2.707254921211814 Val_accuracy:  0.5821302097521112 Val_Acc:  2.6917025042737763\n",
      "Epoch number: 558/10000step_number: 0/29 Accuracy:  0.5903967308019752 Loss:  2.706705731362919 Val_accuracy:  0.5824026150912558 Val_cost:  2.706705731362919 Val_accuracy:  0.5824026150912558 Val_Acc:  2.6912819593545994\n",
      "Epoch number: 559/10000step_number: 0/29 Accuracy:  0.5908734888472672 Loss:  2.706158107688346 Val_accuracy:  0.5821302097521112 Val_cost:  2.706158107688346 Val_accuracy:  0.5821302097521112 Val_Acc:  2.690862724404513\n",
      "Epoch number: 560/10000step_number: 0/29 Accuracy:  0.6022475736420909 Loss:  2.705612303020533 Val_accuracy:  0.5931626259874694 Val_cost:  2.705612303020533 Val_accuracy:  0.5931626259874694 Val_Acc:  2.690445238342747\n",
      "Epoch number: 561/10000step_number: 0/29 Accuracy:  0.6067086667801805 Loss:  2.7050686327675093 Val_accuracy:  0.5982021247616454 Val_cost:  2.7050686327675093 Val_accuracy:  0.5982021247616454 Val_Acc:  2.6900300220191227\n",
      "Epoch number: 562/10000step_number: 0/29 Accuracy:  0.6071854248254726 Loss:  2.7045278448957077 Val_accuracy:  0.59847453010079 Val_cost:  2.7045278448957077 Val_accuracy:  0.59847453010079 Val_Acc:  2.6896180093118334\n",
      "Epoch number: 563/10000step_number: 0/29 Accuracy:  0.6076962370168568 Loss:  2.703991425309088 Val_accuracy:  0.5987469354399346 Val_cost:  2.703991425309088 Val_accuracy:  0.5987469354399346 Val_Acc:  2.6892107692649647\n",
      "Epoch number: 564/10000step_number: 0/29 Accuracy:  0.6083432657926102 Loss:  2.7034611895905174 Val_accuracy:  0.5983383274312176 Val_cost:  2.7034611895905174 Val_accuracy:  0.5983383274312176 Val_Acc:  2.6888102203711437\n",
      "Epoch number: 565/10000step_number: 0/29 Accuracy:  0.6089221862761791 Loss:  2.7029377967833916 Val_accuracy:  0.5987469354399346 Val_cost:  2.7029377967833916 Val_accuracy:  0.5987469354399346 Val_Acc:  2.688417779805737\n",
      "Epoch number: 566/10000step_number: 0/29 Accuracy:  0.6096713774902094 Loss:  2.702419902396675 Val_accuracy:  0.5998365567965133 Val_cost:  2.702419902396675 Val_accuracy:  0.5998365567965133 Val_Acc:  2.6880338273310116\n",
      "Epoch number: 567/10000step_number: 0/29 Accuracy:  0.6100119189511323 Loss:  2.7019053406616083 Val_accuracy:  0.6007899754835194 Val_cost:  2.7019053406616083 Val_accuracy:  0.6007899754835194 Val_Acc:  2.68765791448801\n",
      "Epoch number: 568/10000step_number: 0/29 Accuracy:  0.6103865145581474 Loss:  2.7013925592554253 Val_accuracy:  0.6010623808226642 Val_cost:  2.7013925592554253 Val_accuracy:  0.6010623808226642 Val_Acc:  2.6872892453746173\n",
      "Epoch number: 569/10000step_number: 0/29 Accuracy:  0.6107611101651627 Loss:  2.7008810595146384 Val_accuracy:  0.6011985834922364 Val_cost:  2.7008810595146384 Val_accuracy:  0.6011985834922364 Val_Acc:  2.6869271109674147\n",
      "Epoch number: 570/10000step_number: 0/29 Accuracy:  0.6112378682104547 Loss:  2.700371278521185 Val_accuracy:  0.6014709888313811 Val_cost:  2.700371278521185 Val_accuracy:  0.6014709888313811 Val_Acc:  2.686570979980984\n",
      "Epoch number: 571/10000step_number: 0/29 Accuracy:  0.6116805721096543 Loss:  2.6998642173722 Val_accuracy:  0.6021520021792427 Val_cost:  2.6998642173722 Val_accuracy:  0.6021520021792427 Val_Acc:  2.6862202993264543\n",
      "Epoch number: 572/10000step_number: 0/29 Accuracy:  0.6122594925932232 Loss:  2.6993606414071256 Val_accuracy:  0.6020157995096704 Val_cost:  2.6993606414071256 Val_accuracy:  0.6020157995096704 Val_Acc:  2.6858742380786866\n",
      "Epoch number: 573/10000step_number: 0/29 Accuracy:  0.6128043589306998 Loss:  2.6988601213829266 Val_accuracy:  0.6022882048488151 Val_cost:  2.6988601213829266 Val_accuracy:  0.6022882048488151 Val_Acc:  2.685531499736883\n",
      "Epoch number: 574/10000step_number: 0/29 Accuracy:  0.6130767920994381 Loss:  2.6983609169917946 Val_accuracy:  0.602696812857532 Val_cost:  2.6983609169917946 Val_accuracy:  0.602696812857532 Val_Acc:  2.6851903186225483\n",
      "Epoch number: 575/10000step_number: 0/29 Accuracy:  0.6138259833134684 Loss:  2.6978608095100975 Val_accuracy:  0.6036502315445382 Val_cost:  2.6978608095100975 Val_accuracy:  0.6036502315445382 Val_Acc:  2.6848486915699903\n",
      "Epoch number: 576/10000step_number: 0/29 Accuracy:  0.6144049037970373 Loss:  2.6973578557508353 Val_accuracy:  0.6044674475619722 Val_cost:  2.6973578557508353 Val_accuracy:  0.6044674475619722 Val_Acc:  2.684504735349627\n",
      "Epoch number: 577/10000step_number: 0/29 Accuracy:  0.6144730120892219 Loss:  2.696850540786266 Val_accuracy:  0.6043312448923999 Val_cost:  2.696850540786266 Val_accuracy:  0.6043312448923999 Val_Acc:  2.6841569119068533\n",
      "Epoch number: 578/10000step_number: 0/29 Accuracy:  0.6149157159884215 Loss:  2.6963375858248875 Val_accuracy:  0.6051484609098339 Val_cost:  2.6963375858248875 Val_accuracy:  0.6051484609098339 Val_Acc:  2.6838039822689925\n",
      "Epoch number: 579/10000step_number: 0/29 Accuracy:  0.6151540950110675 Loss:  2.6958177751712493 Val_accuracy:  0.6058294742576954 Val_cost:  2.6958177751712493 Val_accuracy:  0.6058294742576954 Val_Acc:  2.6834448377049247\n",
      "Epoch number: 580/10000step_number: 0/29 Accuracy:  0.6154946364719904 Loss:  2.695289948749582 Val_accuracy:  0.6062380822664124 Val_cost:  2.695289948749582 Val_accuracy:  0.6062380822664124 Val_Acc:  2.683078412277937\n",
      "Epoch number: 581/10000step_number: 0/29 Accuracy:  0.6158692320790056 Loss:  2.694753151741208 Val_accuracy:  0.606510487605557 Val_cost:  2.694753151741208 Val_accuracy:  0.606510487605557 Val_Acc:  2.6827037607084927\n",
      "Epoch number: 582/10000step_number: 0/29 Accuracy:  0.6162778818321131 Loss:  2.6942069222628198 Val_accuracy:  0.6074639062925633 Val_cost:  2.6942069222628198 Val_accuracy:  0.6074639062925633 Val_Acc:  2.682320318200339\n",
      "Epoch number: 583/10000step_number: 0/29 Accuracy:  0.6165162608547591 Loss:  2.693651712328169 Val_accuracy:  0.6086897303187142 Val_cost:  2.693651712328169 Val_accuracy:  0.6086897303187142 Val_Acc:  2.681928339752776\n",
      "Epoch number: 584/10000step_number: 0/29 Accuracy:  0.6170270730461433 Loss:  2.6930893584624576 Val_accuracy:  0.6095069463361482 Val_cost:  2.6930893584624576 Val_accuracy:  0.6095069463361482 Val_Acc:  2.6815294362722404\n",
      "Epoch number: 585/10000step_number: 0/29 Accuracy:  0.6176400476758045 Loss:  2.6925233276403087 Val_accuracy:  0.6097793516752928 Val_cost:  2.6925233276403087 Val_accuracy:  0.6097793516752928 Val_Acc:  2.681126938447564\n",
      "Epoch number: 586/10000step_number: 0/29 Accuracy:  0.6179465349906351 Loss:  2.691958339328719 Val_accuracy:  0.6100517570144375 Val_cost:  2.691958339328719 Val_accuracy:  0.6100517570144375 Val_Acc:  2.6807256659222958\n",
      "Epoch number: 587/10000step_number: 0/29 Accuracy:  0.6183211305976503 Loss:  2.6913992716565125 Val_accuracy:  0.6103241623535821 Val_cost:  2.6913992716565125 Val_accuracy:  0.6103241623535821 Val_Acc:  2.6803309025512685\n",
      "Epoch number: 588/10000step_number: 0/29 Accuracy:  0.6192065383960497 Loss:  2.6908499734362867 Val_accuracy:  0.6114137837101608 Val_cost:  2.6908499734362867 Val_accuracy:  0.6114137837101608 Val_Acc:  2.6799470487522856\n",
      "Epoch number: 589/10000step_number: 0/29 Accuracy:  0.6195130257108803 Loss:  2.6903128091913855 Val_accuracy:  0.6114137837101608 Val_cost:  2.6903128091913855 Val_accuracy:  0.6114137837101608 Val_Acc:  2.679576799590217\n",
      "Epoch number: 590/10000step_number: 0/29 Accuracy:  0.6195811340030649 Loss:  2.6897889688514667 Val_accuracy:  0.6116861890493054 Val_cost:  2.6897889688514667 Val_accuracy:  0.6116861890493054 Val_Acc:  2.6792211617004273\n",
      "Epoch number: 591/10000step_number: 0/29 Accuracy:  0.619478971564788 Loss:  2.6892788929593556 Val_accuracy:  0.6116861890493054 Val_cost:  2.6892788929593556 Val_accuracy:  0.6116861890493054 Val_Acc:  2.6788798967232204\n",
      "Epoch number: 592/10000step_number: 0/29 Accuracy:  0.6196492422952494 Loss:  2.688782438257722 Val_accuracy:  0.6116861890493054 Val_cost:  2.688782438257722 Val_accuracy:  0.6116861890493054 Val_Acc:  2.678551952104534\n",
      "Epoch number: 593/10000step_number: 0/29 Accuracy:  0.6199897837561723 Loss:  2.688298917898805 Val_accuracy:  0.61195859438845 Val_cost:  2.688298917898805 Val_accuracy:  0.61195859438845 Val_Acc:  2.678235785100665\n",
      "Epoch number: 594/10000step_number: 0/29 Accuracy:  0.6198876213178954 Loss:  2.6878272126766007 Val_accuracy:  0.6116861890493054 Val_cost:  2.6878272126766007 Val_accuracy:  0.6116861890493054 Val_Acc:  2.67792962362506\n",
      "Epoch number: 595/10000step_number: 0/29 Accuracy:  0.6202962710710029 Loss:  2.687365967816491 Val_accuracy:  0.6118223917188776 Val_cost:  2.687365967816491 Val_accuracy:  0.6118223917188776 Val_Acc:  2.6776316780101084\n",
      "Epoch number: 596/10000step_number: 0/29 Accuracy:  0.6205346500936489 Loss:  2.686913798340068 Val_accuracy:  0.6120947970580224 Val_cost:  2.686913798340068 Val_accuracy:  0.6120947970580224 Val_Acc:  2.6773403066783765\n",
      "Epoch number: 597/10000step_number: 0/29 Accuracy:  0.6205005959475566 Loss:  2.6864694602902737 Val_accuracy:  0.6126396077363117 Val_cost:  2.6864694602902737 Val_accuracy:  0.6126396077363117 Val_Acc:  2.6770541640757997\n",
      "Epoch number: 598/10000step_number: 0/29 Accuracy:  0.6208070832623872 Loss:  2.6860319958128787 Val_accuracy:  0.6127758104058839 Val_cost:  2.6860319958128787 Val_accuracy:  0.6127758104058839 Val_Acc:  2.6767723717590575\n",
      "Epoch number: 599/10000step_number: 0/29 Accuracy:  0.6210454622850332 Loss:  2.6856008450275834 Val_accuracy:  0.6127758104058839 Val_cost:  2.6856008450275834 Val_accuracy:  0.6127758104058839 Val_Acc:  2.676494696318976\n",
      "Epoch number: 600/10000step_number: 0/29 Accuracy:  0.6202622169249106 Loss:  2.685175842598018 Val_accuracy:  0.6125034050667393 Val_cost:  2.685175842598018 Val_accuracy:  0.6125034050667393 Val_Acc:  2.676221576033498\n",
      "Epoch number: 601/10000step_number: 0/29 Accuracy:  0.620773029116295 Loss:  2.684757000998768 Val_accuracy:  0.6129120130754563 Val_cost:  2.684757000998768 Val_accuracy:  0.6129120130754563 Val_Acc:  2.6759537915753793\n",
      "Epoch number: 602/10000step_number: 0/29 Accuracy:  0.6207389749702026 Loss:  2.6843441490734303 Val_accuracy:  0.6131844184146009 Val_cost:  2.6843441490734303 Val_accuracy:  0.6131844184146009 Val_Acc:  2.675691876121504\n",
      "Epoch number: 603/10000step_number: 0/29 Accuracy:  0.6206708666780181 Loss:  2.6839366009123427 Val_accuracy:  0.6131844184146009 Val_cost:  2.6839366009123427 Val_accuracy:  0.6131844184146009 Val_Acc:  2.67543561148815\n",
      "Epoch number: 604/10000step_number: 0/29 Accuracy:  0.6207389749702026 Loss:  2.6835328962262333 Val_accuracy:  0.6129120130754563 Val_cost:  2.6835328962262333 Val_accuracy:  0.6129120130754563 Val_Acc:  2.675183699031052\n",
      "Epoch number: 605/10000step_number: 0/29 Accuracy:  0.6210454622850332 Loss:  2.683131071909224 Val_accuracy:  0.6131844184146009 Val_cost:  2.683131071909224 Val_accuracy:  0.6131844184146009 Val_Acc:  2.6749340129966783\n",
      "Epoch number: 606/10000step_number: 0/29 Accuracy:  0.6210795164311255 Loss:  2.6827289044677007 Val_accuracy:  0.6135930264233179 Val_cost:  2.6827289044677007 Val_accuracy:  0.6135930264233179 Val_Acc:  2.6746840889233456\n",
      "Epoch number: 607/10000step_number: 0/29 Accuracy:  0.6211135705772177 Loss:  2.68232189590036 Val_accuracy:  0.6137292290928902 Val_cost:  2.68232189590036 Val_accuracy:  0.6137292290928902 Val_Acc:  2.674429750820144\n",
      "Epoch number: 608/10000step_number: 0/29 Accuracy:  0.6210454622850332 Loss:  2.6819056172618265 Val_accuracy:  0.6140016344320348 Val_cost:  2.6819056172618265 Val_accuracy:  0.6140016344320348 Val_Acc:  2.674167981296381\n",
      "Epoch number: 609/10000step_number: 0/29 Accuracy:  0.6213860037459561 Loss:  2.6814829962844926 Val_accuracy:  0.6138654317624626 Val_cost:  2.6814829962844926 Val_accuracy:  0.6138654317624626 Val_Acc:  2.673901910750411\n",
      "Epoch number: 610/10000step_number: 0/29 Accuracy:  0.6215562744764175 Loss:  2.6810619851404183 Val_accuracy:  0.6142740397711796 Val_cost:  2.6810619851404183 Val_accuracy:  0.6142740397711796 Val_Acc:  2.673637818745599\n",
      "Epoch number: 611/10000step_number: 0/29 Accuracy:  0.621964924229525 Loss:  2.6806461365158265 Val_accuracy:  0.6148188504494688 Val_cost:  2.6806461365158265 Val_accuracy:  0.6148188504494688 Val_Acc:  2.6733787226001753\n",
      "Epoch number: 612/10000step_number: 0/29 Accuracy:  0.6220330325217095 Loss:  2.6802349011813713 Val_accuracy:  0.6149550531190411 Val_cost:  2.6802349011813713 Val_accuracy:  0.6149550531190411 Val_Acc:  2.673124738218162\n",
      "Epoch number: 613/10000step_number: 0/29 Accuracy:  0.6222714115443555 Loss:  2.679827117372117 Val_accuracy:  0.6152274584581858 Val_cost:  2.679827117372117 Val_accuracy:  0.6152274584581858 Val_Acc:  2.6728753072549045\n",
      "Epoch number: 614/10000step_number: 0/29 Accuracy:  0.6225438447130939 Loss:  2.6794219708618807 Val_accuracy:  0.6156360664669027 Val_cost:  2.6794219708618807 Val_accuracy:  0.6156360664669027 Val_Acc:  2.6726298756475226\n",
      "Epoch number: 615/10000step_number: 0/29 Accuracy:  0.6231227651966627 Loss:  2.679018953318342 Val_accuracy:  0.6157722691364751 Val_cost:  2.679018953318342 Val_accuracy:  0.6157722691364751 Val_Acc:  2.6723879929260916\n",
      "Epoch number: 616/10000step_number: 0/29 Accuracy:  0.6234973608036779 Loss:  2.678617748324652 Val_accuracy:  0.6160446744756197 Val_cost:  2.678617748324652 Val_accuracy:  0.6160446744756197 Val_Acc:  2.672149294476355\n",
      "Epoch number: 617/10000step_number: 0/29 Accuracy:  0.6238038481185084 Loss:  2.678218141611963 Val_accuracy:  0.6164532824843367 Val_cost:  2.678218141611963 Val_accuracy:  0.6164532824843367 Val_Acc:  2.6719134695982962\n",
      "Epoch number: 618/10000step_number: 0/29 Accuracy:  0.6239400647028776 Loss:  2.6778199634602213 Val_accuracy:  0.616589485153909 Val_cost:  2.6778199634602213 Val_accuracy:  0.616589485153909 Val_Acc:  2.671680228917953\n",
      "Epoch number: 619/10000step_number: 0/29 Accuracy:  0.6240422271411544 Loss:  2.6774230588733934 Val_accuracy:  0.6167256878234814 Val_cost:  2.6774230588733934 Val_accuracy:  0.6167256878234814 Val_Acc:  2.6714492769115625\n",
      "Epoch number: 620/10000step_number: 0/29 Accuracy:  0.6245189851864464 Loss:  2.6770272672791395 Val_accuracy:  0.6172704985017706 Val_cost:  2.6770272672791395 Val_accuracy:  0.6172704985017706 Val_Acc:  2.671220292190016\n",
      "Epoch number: 621/10000step_number: 0/29 Accuracy:  0.6252681764004767 Loss:  2.676632385139617 Val_accuracy:  0.6175429038409153 Val_cost:  2.676632385139617 Val_accuracy:  0.6175429038409153 Val_Acc:  2.6709929208409933\n",
      "Epoch number: 622/10000step_number: 0/29 Accuracy:  0.6256087178613996 Loss:  2.6762380898598184 Val_accuracy:  0.6176791065104876 Val_cost:  2.6762380898598184 Val_accuracy:  0.6176791065104876 Val_Acc:  2.6707667800851285\n",
      "Epoch number: 623/10000step_number: 0/29 Accuracy:  0.6259492593223225 Loss:  2.6758438673165292 Val_accuracy:  0.6179515118496323 Val_cost:  2.6758438673165292 Val_accuracy:  0.6179515118496323 Val_Acc:  2.670541452915521\n",
      "Epoch number: 624/10000step_number: 0/29 Accuracy:  0.6262898007832454 Loss:  2.6754490983596844 Val_accuracy:  0.6176791065104876 Val_cost:  2.6754490983596844 Val_accuracy:  0.6176791065104876 Val_Acc:  2.670316489684788\n",
      "Epoch number: 625/10000step_number: 0/29 Accuracy:  0.6263919632215222 Loss:  2.6750533573560653 Val_accuracy:  0.6178153091800599 Val_cost:  2.6750533573560653 Val_accuracy:  0.6178153091800599 Val_Acc:  2.67009151586816\n",
      "Epoch number: 626/10000step_number: 0/29 Accuracy:  0.6269027754129065 Loss:  2.674656655363464 Val_accuracy:  0.6176791065104876 Val_cost:  2.674656655363464 Val_accuracy:  0.6176791065104876 Val_Acc:  2.669866515461246\n",
      "Epoch number: 627/10000step_number: 0/29 Accuracy:  0.6269027754129065 Loss:  2.67425944813635 Val_accuracy:  0.6175429038409153 Val_cost:  2.67425944813635 Val_accuracy:  0.6175429038409153 Val_Acc:  2.6696420227791346\n",
      "Epoch number: 628/10000step_number: 0/29 Accuracy:  0.6270049378511834 Loss:  2.6738625227304054 Val_accuracy:  0.6175429038409153 Val_cost:  2.6738625227304054 Val_accuracy:  0.6175429038409153 Val_Acc:  2.6694186621181393\n",
      "Epoch number: 629/10000step_number: 0/29 Accuracy:  0.6271411544355525 Loss:  2.673466821326525 Val_accuracy:  0.6182239171887769 Val_cost:  2.673466821326525 Val_accuracy:  0.6182239171887769 Val_Acc:  2.6691966751959337\n",
      "Epoch number: 630/10000step_number: 0/29 Accuracy:  0.627311425166014 Loss:  2.6730732739797256 Val_accuracy:  0.6186325251974939 Val_cost:  2.6730732739797256 Val_accuracy:  0.6186325251974939 Val_Acc:  2.6689766048286883\n",
      "Epoch number: 631/10000step_number: 0/29 Accuracy:  0.6274476417503831 Loss:  2.6726825435211494 Val_accuracy:  0.6187687278670662 Val_cost:  2.6726825435211494 Val_accuracy:  0.6187687278670662 Val_Acc:  2.6687596224701013\n",
      "Epoch number: 632/10000step_number: 0/29 Accuracy:  0.6275838583347523 Loss:  2.6722947261896794 Val_accuracy:  0.6190411332062108 Val_cost:  2.6722947261896794 Val_accuracy:  0.6190411332062108 Val_Acc:  2.6685466891978784\n",
      "Epoch number: 633/10000step_number: 0/29 Accuracy:  0.6276179124808445 Loss:  2.6719093906948084 Val_accuracy:  0.6190411332062108 Val_cost:  2.6719093906948084 Val_accuracy:  0.6190411332062108 Val_Acc:  2.66833802428685\n",
      "Epoch number: 634/10000step_number: 0/29 Accuracy:  0.6286735910097054 Loss:  2.67152591898488 Val_accuracy:  0.6197221465540724 Val_cost:  2.67152591898488 Val_accuracy:  0.6197221465540724 Val_Acc:  2.6681332387691\n",
      "Epoch number: 635/10000step_number: 0/29 Accuracy:  0.6287757534479823 Loss:  2.671143820408231 Val_accuracy:  0.6194497412149278 Val_cost:  2.671143820408231 Val_accuracy:  0.6194497412149278 Val_Acc:  2.6679316270431324\n",
      "Epoch number: 636/10000step_number: 0/29 Accuracy:  0.6289460241784437 Loss:  2.670762857269052 Val_accuracy:  0.6194497412149278 Val_cost:  2.670762857269052 Val_accuracy:  0.6194497412149278 Val_Acc:  2.6677324064179055\n",
      "Epoch number: 637/10000step_number: 0/29 Accuracy:  0.6290822407628128 Loss:  2.6703830322784525 Val_accuracy:  0.6202669572323618 Val_cost:  2.6703830322784525 Val_accuracy:  0.6202669572323618 Val_Acc:  2.667534893071247\n",
      "Epoch number: 638/10000step_number: 0/29 Accuracy:  0.6292184573471821 Loss:  2.6700045179242053 Val_accuracy:  0.6205393625715064 Val_cost:  2.6700045179242053 Val_accuracy:  0.6205393625715064 Val_Acc:  2.6673386038607916\n",
      "Epoch number: 639/10000step_number: 0/29 Accuracy:  0.6295589988081048 Loss:  2.6696275732548367 Val_accuracy:  0.6208117679106511 Val_cost:  2.6696275732548367 Val_accuracy:  0.6208117679106511 Val_Acc:  2.667143278314745\n",
      "Epoch number: 640/10000step_number: 0/29 Accuracy:  0.6298314319768432 Loss:  2.6692524750671622 Val_accuracy:  0.6208117679106511 Val_cost:  2.6692524750671622 Val_accuracy:  0.6208117679106511 Val_Acc:  2.6669488442278353\n",
      "Epoch number: 641/10000step_number: 0/29 Accuracy:  0.6302741358760429 Loss:  2.6688794751480374 Val_accuracy:  0.6214927812585127 Val_cost:  2.6688794751480374 Val_accuracy:  0.6214927812585127 Val_Acc:  2.666755362602975\n",
      "Epoch number: 642/10000step_number: 0/29 Accuracy:  0.6308871105057041 Loss:  2.668508781364276 Val_accuracy:  0.6228548079542359 Val_cost:  2.668508781364276 Val_accuracy:  0.6228548079542359 Val_Acc:  2.6665629773606594\n",
      "Epoch number: 643/10000step_number: 0/29 Accuracy:  0.6309552187978886 Loss:  2.668140553780425 Val_accuracy:  0.6229910106238082 Val_cost:  2.668140553780425 Val_accuracy:  0.6229910106238082 Val_Acc:  2.6663718788995183\n",
      "Epoch number: 644/10000step_number: 0/29 Accuracy:  0.6310233270900732 Loss:  2.667774907348585 Val_accuracy:  0.6236720239716699 Val_cost:  2.667774907348585 Val_accuracy:  0.6236720239716699 Val_Acc:  2.66618228043807\n",
      "Epoch number: 645/10000step_number: 0/29 Accuracy:  0.6308530563596118 Loss:  2.667411915933143 Val_accuracy:  0.6235358213020975 Val_cost:  2.667411915933143 Val_accuracy:  0.6235358213020975 Val_Acc:  2.6659944026102904\n",
      "Epoch number: 646/10000step_number: 0/29 Accuracy:  0.6309552187978886 Loss:  2.6670516153117294 Val_accuracy:  0.6242168346499591 Val_cost:  2.6670516153117294 Val_accuracy:  0.6242168346499591 Val_Acc:  2.665808461660468\n",
      "Epoch number: 647/10000step_number: 0/29 Accuracy:  0.6309892729439809 Loss:  2.6666940047647687 Val_accuracy:  0.6246254426586761 Val_cost:  2.6666940047647687 Val_accuracy:  0.6246254426586761 Val_Acc:  2.665624658266171\n",
      "Epoch number: 648/10000step_number: 0/29 Accuracy:  0.6312617061127193 Loss:  2.666339047970225 Val_accuracy:  0.6247616453282484 Val_cost:  2.666339047970225 Val_accuracy:  0.6247616453282484 Val_Acc:  2.6654431665746086\n",
      "Epoch number: 649/10000step_number: 0/29 Accuracy:  0.6312617061127193 Loss:  2.6659866738848703 Val_accuracy:  0.6246254426586761 Val_cost:  2.6659866738848703 Val_accuracy:  0.6246254426586761 Val_Acc:  2.665264124781752\n",
      "Epoch number: 650/10000step_number: 0/29 Accuracy:  0.6312617061127193 Loss:  2.665636777613724 Val_accuracy:  0.6246254426586761 Val_cost:  2.665636777613724 Val_accuracy:  0.6246254426586761 Val_Acc:  2.6650876286311584\n",
      "Epoch number: 651/10000step_number: 0/29 Accuracy:  0.6315341392814575 Loss:  2.6652892207960415 Val_accuracy:  0.62544265867611 Val_cost:  2.6652892207960415 Val_accuracy:  0.62544265867611 Val_Acc:  2.6649137281610638\n",
      "Epoch number: 652/10000step_number: 0/29 Accuracy:  0.6317044100119189 Loss:  2.6649438310157088 Val_accuracy:  0.62544265867611 Val_cost:  2.6649438310157088 Val_accuracy:  0.62544265867611 Val_Acc:  2.664742426948198\n",
      "Epoch number: 653/10000step_number: 0/29 Accuracy:  0.6318746807423804 Loss:  2.6646004000062833 Val_accuracy:  0.6257150640152547 Val_cost:  2.6646004000062833 Val_accuracy:  0.6257150640152547 Val_Acc:  2.664573682638341\n",
      "Epoch number: 654/10000step_number: 0/29 Accuracy:  0.6319427890345649 Loss:  2.6642586807715163 Val_accuracy:  0.625851266684827 Val_cost:  2.6642586807715163 Val_accuracy:  0.625851266684827 Val_Acc:  2.6644074077548416\n",
      "Epoch number: 655/10000step_number: 0/29 Accuracy:  0.6321130597650264 Loss:  2.663918384033982 Val_accuracy:  0.6257150640152547 Val_cost:  2.663918384033982 Val_accuracy:  0.6257150640152547 Val_Acc:  2.6642434702947\n",
      "Epoch number: 656/10000step_number: 0/29 Accuracy:  0.6322833304954878 Loss:  2.663579174576091 Val_accuracy:  0.625851266684827 Val_cost:  2.663579174576091 Val_accuracy:  0.625851266684827 Val_Acc:  2.6640816941111245\n",
      "Epoch number: 657/10000step_number: 0/29 Accuracy:  0.6325217095181338 Loss:  2.6632406680601717 Val_accuracy:  0.6261236720239717 Val_cost:  2.6632406680601717 Val_accuracy:  0.6261236720239717 Val_Acc:  2.6639218593895406\n",
      "Epoch number: 658/10000step_number: 0/29 Accuracy:  0.6326238719564107 Loss:  2.6629024288850625 Val_accuracy:  0.6262598746935439 Val_cost:  2.6629024288850625 Val_accuracy:  0.6262598746935439 Val_Acc:  2.663763703651047\n",
      "Epoch number: 659/10000step_number: 0/29 Accuracy:  0.6325217095181338 Loss:  2.662563969637965 Val_accuracy:  0.6262598746935439 Val_cost:  2.662563969637965 Val_accuracy:  0.6262598746935439 Val_Acc:  2.6636069236926447\n",
      "Epoch number: 660/10000step_number: 0/29 Accuracy:  0.6324536012259493 Loss:  2.662224752773477 Val_accuracy:  0.6262598746935439 Val_cost:  2.662224752773477 Val_accuracy:  0.6262598746935439 Val_Acc:  2.663451178692642\n",
      "Epoch number: 661/10000step_number: 0/29 Accuracy:  0.6326579261025029 Loss:  2.6618841952845624 Val_accuracy:  0.627077090710978 Val_cost:  2.6618841952845624 Val_accuracy:  0.627077090710978 Val_Acc:  2.6632960943572015\n",
      "Epoch number: 662/10000step_number: 0/29 Accuracy:  0.633134684147795 Loss:  2.6615416772530653 Val_accuracy:  0.6272132933805502 Val_cost:  2.6615416772530653 Val_accuracy:  0.6272132933805502 Val_Acc:  2.6631412675095247\n",
      "Epoch number: 663/10000step_number: 0/29 Accuracy:  0.6331687382938873 Loss:  2.6611965551302736 Val_accuracy:  0.6273494960501226 Val_cost:  2.6611965551302736 Val_accuracy:  0.6273494960501226 Val_Acc:  2.6629862701098683\n",
      "Epoch number: 664/10000step_number: 0/29 Accuracy:  0.6334411714626256 Loss:  2.6608481801444346 Val_accuracy:  0.6273494960501226 Val_cost:  2.6608481801444346 Val_accuracy:  0.6273494960501226 Val_Acc:  2.6628306516385396\n",
      "Epoch number: 665/10000step_number: 0/29 Accuracy:  0.6334752256087178 Loss:  2.6604959210533696 Val_accuracy:  0.6273494960501226 Val_cost:  2.6604959210533696 Val_accuracy:  0.6273494960501226 Val_Acc:  2.6626739392994083\n",
      "Epoch number: 666/10000step_number: 0/29 Accuracy:  0.6334411714626256 Loss:  2.6601391884660663 Val_accuracy:  0.6273494960501226 Val_cost:  2.6601391884660663 Val_accuracy:  0.6273494960501226 Val_Acc:  2.662515636493483\n",
      "Epoch number: 667/10000step_number: 0/29 Accuracy:  0.6337136046313638 Loss:  2.6597774557537552 Val_accuracy:  0.627485698719695 Val_cost:  2.6597774557537552 Val_accuracy:  0.627485698719695 Val_Acc:  2.662355220965148\n",
      "Epoch number: 668/10000step_number: 0/29 Accuracy:  0.633849821215733 Loss:  2.659410270712702 Val_accuracy:  0.6276219013892672 Val_cost:  2.659410270712702 Val_accuracy:  0.6276219013892672 Val_Acc:  2.662192144429492\n",
      "Epoch number: 669/10000step_number: 0/29 Accuracy:  0.633849821215733 Loss:  2.659037254421546 Val_accuracy:  0.627485698719695 Val_cost:  2.659037254421546 Val_accuracy:  0.627485698719695 Val_Acc:  2.6620258353680915\n",
      "Epoch number: 670/10000step_number: 0/29 Accuracy:  0.633849821215733 Loss:  2.6586580894567953 Val_accuracy:  0.627077090710978 Val_cost:  2.6586580894567953 Val_accuracy:  0.627077090710978 Val_Acc:  2.6618557065983968\n",
      "Epoch number: 671/10000step_number: 0/29 Accuracy:  0.6339519836540098 Loss:  2.6582725062730925 Val_accuracy:  0.627077090710978 Val_cost:  2.6582725062730925 Val_accuracy:  0.627077090710978 Val_Acc:  2.661681169597216\n",
      "Epoch number: 672/10000step_number: 0/29 Accuracy:  0.6340541460922867 Loss:  2.657880279754742 Val_accuracy:  0.6272132933805502 Val_cost:  2.657880279754742 Val_accuracy:  0.6272132933805502 Val_Acc:  2.6615016579415283\n",
      "Epoch number: 673/10000step_number: 0/29 Accuracy:  0.6341563085305636 Loss:  2.657481244660111 Val_accuracy:  0.6272132933805502 Val_cost:  2.657481244660111 Val_accuracy:  0.6272132933805502 Val_Acc:  2.6613166614284802\n",
      "Epoch number: 674/10000step_number: 0/29 Accuracy:  0.634326579261025 Loss:  2.6570753298586105 Val_accuracy:  0.6276219013892672 Val_cost:  2.6570753298586105 Val_accuracy:  0.6276219013892672 Val_Acc:  2.661125769576243\n",
      "Epoch number: 675/10000step_number: 0/29 Accuracy:  0.6343946875532096 Loss:  2.656662601423937 Val_accuracy:  0.6277581040588396 Val_cost:  2.656662601423937 Val_accuracy:  0.6277581040588396 Val_Acc:  2.660928718802513\n",
      "Epoch number: 676/10000step_number: 0/29 Accuracy:  0.6344968499914865 Loss:  2.656243298837005 Val_accuracy:  0.6278943067284118 Val_cost:  2.656243298837005 Val_accuracy:  0.6278943067284118 Val_Acc:  2.660725433574068\n",
      "Epoch number: 677/10000step_number: 0/29 Accuracy:  0.6347011748680402 Loss:  2.6558178493609748 Val_accuracy:  0.6284391174067012 Val_cost:  2.6558178493609748 Val_accuracy:  0.6284391174067012 Val_Acc:  2.660516050510705\n",
      "Epoch number: 678/10000step_number: 0/29 Accuracy:  0.6347692831602247 Loss:  2.6553868523355124 Val_accuracy:  0.6285753200762735 Val_cost:  2.6553868523355124 Val_accuracy:  0.6285753200762735 Val_Acc:  2.6603009170638905\n",
      "Epoch number: 679/10000step_number: 0/29 Accuracy:  0.6349054997445939 Loss:  2.654951034602981 Val_accuracy:  0.6288477254154181 Val_cost:  2.654951034602981 Val_accuracy:  0.6288477254154181 Val_Acc:  2.660080562412527\n",
      "Epoch number: 680/10000step_number: 0/29 Accuracy:  0.6349736080367785 Loss:  2.6545111867490307 Val_accuracy:  0.6292563334241351 Val_cost:  2.6545111867490307 Val_accuracy:  0.6292563334241351 Val_Acc:  2.659855645445819\n",
      "Epoch number: 681/10000step_number: 0/29 Accuracy:  0.6351098246211476 Loss:  2.6540680943794563 Val_accuracy:  0.6292563334241351 Val_cost:  2.6540680943794563 Val_accuracy:  0.6292563334241351 Val_Acc:  2.659626890362902\n",
      "Epoch number: 682/10000step_number: 0/29 Accuracy:  0.6351438787672399 Loss:  2.6536224781817963 Val_accuracy:  0.6292563334241351 Val_cost:  2.6536224781817963 Val_accuracy:  0.6292563334241351 Val_Acc:  2.65939502247697\n",
      "Epoch number: 683/10000step_number: 0/29 Accuracy:  0.6353822577898859 Loss:  2.653174952008298 Val_accuracy:  0.6293925360937075 Val_cost:  2.653174952008298 Val_accuracy:  0.6293925360937075 Val_Acc:  2.659160714900713\n",
      "Epoch number: 684/10000step_number: 0/29 Accuracy:  0.635756853396901 Loss:  2.65272600199351 Val_accuracy:  0.6296649414328521 Val_cost:  2.65272600199351 Val_accuracy:  0.6296649414328521 Val_Acc:  2.6589245522045104\n",
      "Epoch number: 685/10000step_number: 0/29 Accuracy:  0.6360292865656394 Loss:  2.6522759842244734 Val_accuracy:  0.6296649414328521 Val_cost:  2.6522759842244734 Val_accuracy:  0.6296649414328521 Val_Acc:  2.6586870119660233\n",
      "Epoch number: 686/10000step_number: 0/29 Accuracy:  0.6356546909586243 Loss:  2.6518251352062046 Val_accuracy:  0.6298011441024244 Val_cost:  2.6518251352062046 Val_accuracy:  0.6298011441024244 Val_Acc:  2.6584484611377093\n",
      "Epoch number: 687/10000step_number: 0/29 Accuracy:  0.6358249616890856 Loss:  2.651373588511435 Val_accuracy:  0.6302097521111414 Val_cost:  2.651373588511435 Val_accuracy:  0.6302097521111414 Val_Acc:  2.658209162121693\n",
      "Epoch number: 688/10000step_number: 0/29 Accuracy:  0.636471990464839 Loss:  2.650921391860057 Val_accuracy:  0.630482157450286 Val_cost:  2.650921391860057 Val_accuracy:  0.630482157450286 Val_Acc:  2.6579692831608557\n",
      "Epoch number: 689/10000step_number: 0/29 Accuracy:  0.6365060446109314 Loss:  2.6504685205139853 Val_accuracy:  0.6302097521111414 Val_cost:  2.6504685205139853 Val_accuracy:  0.6302097521111414 Val_Acc:  2.657728908458559\n",
      "Epoch number: 690/10000step_number: 0/29 Accuracy:  0.6366763153413928 Loss:  2.650014884747942 Val_accuracy:  0.630482157450286 Val_cost:  2.650014884747942 Val_accuracy:  0.630482157450286 Val_Acc:  2.6574880447667337\n",
      "Epoch number: 691/10000step_number: 0/29 Accuracy:  0.6367784777796697 Loss:  2.649560331363905 Val_accuracy:  0.630482157450286 Val_cost:  2.649560331363905 Val_accuracy:  0.630482157450286 Val_Acc:  2.657246622983513\n",
      "Epoch number: 692/10000step_number: 0/29 Accuracy:  0.6368806402179465 Loss:  2.6491046423183024 Val_accuracy:  0.6303459547807136 Val_cost:  2.6491046423183024 Val_accuracy:  0.6303459547807136 Val_Acc:  2.657004496096642\n",
      "Epoch number: 693/10000step_number: 0/29 Accuracy:  0.6369487485101311 Loss:  2.648647537588971 Val_accuracy:  0.630482157450286 Val_cost:  2.648647537588971 Val_accuracy:  0.630482157450286 Val_Acc:  2.656761439068667\n",
      "Epoch number: 694/10000step_number: 0/29 Accuracy:  0.6369828026562234 Loss:  2.6481886920527686 Val_accuracy:  0.630482157450286 Val_cost:  2.6481886920527686 Val_accuracy:  0.630482157450286 Val_Acc:  2.6565171605031463\n",
      "Epoch number: 695/10000step_number: 0/29 Accuracy:  0.6370849650945003 Loss:  2.6477277717360987 Val_accuracy:  0.6303459547807136 Val_cost:  2.6477277717360987 Val_accuracy:  0.6303459547807136 Val_Acc:  2.6562713345616875\n",
      "Epoch number: 696/10000step_number: 0/29 Accuracy:  0.6372552358249617 Loss:  2.6472644802447345 Val_accuracy:  0.6303459547807136 Val_cost:  2.6472644802447345 Val_accuracy:  0.6303459547807136 Val_Acc:  2.65602364867351\n",
      "Epoch number: 697/10000step_number: 0/29 Accuracy:  0.6374255065554231 Loss:  2.646798591954011 Val_accuracy:  0.630890765459003 Val_cost:  2.646798591954011 Val_accuracy:  0.630890765459003 Val_Acc:  2.6557738450114434\n",
      "Epoch number: 698/10000step_number: 0/29 Accuracy:  0.6376298314319768 Loss:  2.646329953562429 Val_accuracy:  0.6310269681285753 Val_cost:  2.646329953562429 Val_accuracy:  0.6310269681285753 Val_Acc:  2.65552173295524\n",
      "Epoch number: 699/10000step_number: 0/29 Accuracy:  0.6375617231397923 Loss:  2.645858458948339 Val_accuracy:  0.6303459547807136 Val_cost:  2.645858458948339 Val_accuracy:  0.6303459547807136 Val_Acc:  2.655267172043544\n",
      "Epoch number: 700/10000step_number: 0/29 Accuracy:  0.6376638855780691 Loss:  2.64538401828264 Val_accuracy:  0.630482157450286 Val_cost:  2.64538401828264 Val_accuracy:  0.630482157450286 Val_Acc:  2.655010045170203\n",
      "Epoch number: 701/10000step_number: 0/29 Accuracy:  0.6379703728928997 Loss:  2.6449065372035894 Val_accuracy:  0.6303459547807136 Val_cost:  2.6449065372035894 Val_accuracy:  0.6303459547807136 Val_Acc:  2.654750239842031\n",
      "Epoch number: 702/10000step_number: 0/29 Accuracy:  0.6381406436233611 Loss:  2.644425908537514 Val_accuracy:  0.6303459547807136 Val_cost:  2.644425908537514 Val_accuracy:  0.6303459547807136 Val_Acc:  2.654487641516054\n",
      "Epoch number: 703/10000step_number: 0/29 Accuracy:  0.6385492933764686 Loss:  2.643942011930113 Val_accuracy:  0.630890765459003 Val_cost:  2.643942011930113 Val_accuracy:  0.630890765459003 Val_Acc:  2.654222134487108\n",
      "Epoch number: 704/10000step_number: 0/29 Accuracy:  0.6385492933764686 Loss:  2.643454716674363 Val_accuracy:  0.6311631707981477 Val_cost:  2.643454716674363 Val_accuracy:  0.6311631707981477 Val_Acc:  2.653953605336275\n",
      "Epoch number: 705/10000step_number: 0/29 Accuracy:  0.6383790226460071 Loss:  2.642963885281609 Val_accuracy:  0.6306183601198584 Val_cost:  2.642963885281609 Val_accuracy:  0.6306183601198584 Val_Acc:  2.6536819464212478\n",
      "Epoch number: 706/10000step_number: 0/29 Accuracy:  0.6383790226460071 Loss:  2.6424693771349896 Val_accuracy:  0.6307545627894307 Val_cost:  2.6424693771349896 Val_accuracy:  0.6307545627894307 Val_Acc:  2.653407058777233\n",
      "Epoch number: 707/10000step_number: 0/29 Accuracy:  0.6386855099608377 Loss:  2.6419710523930924 Val_accuracy:  0.630482157450286 Val_cost:  2.6419710523930924 Val_accuracy:  0.630482157450286 Val_Acc:  2.6531288545402334\n",
      "Epoch number: 708/10000step_number: 0/29 Accuracy:  0.6389238889834837 Loss:  2.641468776561642 Val_accuracy:  0.6303459547807136 Val_cost:  2.641468776561642 Val_accuracy:  0.6303459547807136 Val_Acc:  2.652847259128996\n",
      "Epoch number: 709/10000step_number: 0/29 Accuracy:  0.6390601055678529 Loss:  2.6409624261917224 Val_accuracy:  0.6307545627894307 Val_cost:  2.6409624261917224 Val_accuracy:  0.6307545627894307 Val_Acc:  2.652562213378406\n",
      "Epoch number: 710/10000step_number: 0/29 Accuracy:  0.6394687553209604 Loss:  2.6404518961190293 Val_accuracy:  0.6307545627894307 Val_cost:  2.6404518961190293 Val_accuracy:  0.6307545627894307 Val_Acc:  2.6522736757573537\n",
      "Epoch number: 711/10000step_number: 0/29 Accuracy:  0.6396049719053295 Loss:  2.639937108507616 Val_accuracy:  0.6307545627894307 Val_cost:  2.639937108507616 Val_accuracy:  0.6307545627894307 Val_Acc:  2.6519816247052743\n",
      "Epoch number: 712/10000step_number: 0/29 Accuracy:  0.6396390260514218 Loss:  2.639418023660379 Val_accuracy:  0.630890765459003 Val_cost:  2.639418023660379 Val_accuracy:  0.630890765459003 Val_Acc:  2.6516860609352837\n",
      "Epoch number: 713/10000step_number: 0/29 Accuracy:  0.6397071343436064 Loss:  2.638894652123238 Val_accuracy:  0.6314355761372923 Val_cost:  2.638894652123238 Val_accuracy:  0.6314355761372923 Val_Acc:  2.6513870093065184\n",
      "Epoch number: 714/10000step_number: 0/29 Accuracy:  0.63991145922016 Loss:  2.6383670671476676 Val_accuracy:  0.6315717788068647 Val_cost:  2.6383670671476676 Val_accuracy:  0.6315717788068647 Val_Acc:  2.6510845196919233\n",
      "Epoch number: 715/10000step_number: 0/29 Accuracy:  0.6401838923888984 Loss:  2.6378354162316295 Val_accuracy:  0.6317079814764369 Val_cost:  2.6378354162316295 Val_accuracy:  0.6317079814764369 Val_Acc:  2.650778666294916\n",
      "Epoch number: 716/10000step_number: 0/29 Accuracy:  0.6403541631193598 Loss:  2.6372999302946307 Val_accuracy:  0.6314355761372923 Val_cost:  2.6372999302946307 Val_accuracy:  0.6314355761372923 Val_Acc:  2.6504695450909495\n",
      "Epoch number: 717/10000step_number: 0/29 Accuracy:  0.6406947045802827 Loss:  2.636760928970752 Val_accuracy:  0.6314355761372923 Val_cost:  2.636760928970752 Val_accuracy:  0.6314355761372923 Val_Acc:  2.65015726930042\n",
      "Epoch number: 718/10000step_number: 0/29 Accuracy:  0.6408990294568364 Loss:  2.636218820377529 Val_accuracy:  0.6315717788068647 Val_cost:  2.636218820377529 Val_accuracy:  0.6315717788068647 Val_Acc:  2.649841962830634\n",
      "Epoch number: 719/10000step_number: 0/29 Accuracy:  0.6413417333560361 Loss:  2.6356740935204708 Val_accuracy:  0.6321165894851539 Val_cost:  2.6356740935204708 Val_accuracy:  0.6321165894851539 Val_Acc:  2.6495237514383194\n",
      "Epoch number: 720/10000step_number: 0/29 Accuracy:  0.6414438957943129 Loss:  2.635127301436287 Val_accuracy:  0.6323889948242986 Val_cost:  2.635127301436287 Val_accuracy:  0.6323889948242986 Val_Acc:  2.649202751170601\n",
      "Epoch number: 721/10000step_number: 0/29 Accuracy:  0.6418865996935127 Loss:  2.6345790336353696 Val_accuracy:  0.6326614001634432 Val_cost:  2.6345790336353696 Val_accuracy:  0.6326614001634432 Val_Acc:  2.6488790537397557\n",
      "Epoch number: 722/10000step_number: 0/29 Accuracy:  0.6420909245700664 Loss:  2.6340298777229694 Val_accuracy:  0.6327976028330156 Val_cost:  2.6340298777229694 Val_accuracy:  0.6327976028330156 Val_Acc:  2.6485527090910606\n",
      "Epoch number: 723/10000step_number: 0/29 Accuracy:  0.642874169930189 Loss:  2.6334803723648106 Val_accuracy:  0.6333424135113048 Val_cost:  2.6334803723648106 Val_accuracy:  0.6333424135113048 Val_Acc:  2.648223706557749\n",
      "Epoch number: 724/10000step_number: 0/29 Accuracy:  0.6429422782223736 Loss:  2.632930956681925 Val_accuracy:  0.6334786161808772 Val_cost:  2.632930956681925 Val_accuracy:  0.6334786161808772 Val_Acc:  2.647891957426611\n",
      "Epoch number: 725/10000step_number: 0/29 Accuracy:  0.6429422782223736 Loss:  2.6323819238457644 Val_accuracy:  0.6336148188504495 Val_cost:  2.6323819238457644 Val_accuracy:  0.6336148188504495 Val_Acc:  2.6475572829478113\n",
      "Epoch number: 726/10000step_number: 0/29 Accuracy:  0.6430444406606505 Loss:  2.631833387887246 Val_accuracy:  0.6334786161808772 Val_cost:  2.631833387887246 Val_accuracy:  0.6334786161808772 Val_Acc:  2.6472194121414963\n",
      "Epoch number: 727/10000step_number: 0/29 Accuracy:  0.643112548952835 Loss:  2.631285271514832 Val_accuracy:  0.6336148188504495 Val_cost:  2.631285271514832 Val_accuracy:  0.6336148188504495 Val_Acc:  2.6468779926688204\n",
      "Epoch number: 728/10000step_number: 0/29 Accuracy:  0.6430444406606505 Loss:  2.6307373189107595 Val_accuracy:  0.6344320348678835 Val_cost:  2.6307373189107595 Val_accuracy:  0.6344320348678835 Val_Acc:  2.6465326155681446\n",
      "Epoch number: 729/10000step_number: 0/29 Accuracy:  0.6435552528520347 Loss:  2.6301891320930686 Val_accuracy:  0.6345682375374557 Val_cost:  2.6301891320930686 Val_accuracy:  0.6345682375374557 Val_Acc:  2.6461828514952046\n",
      "Epoch number: 730/10000step_number: 0/29 Accuracy:  0.6436233611442194 Loss:  2.6296402243346724 Val_accuracy:  0.6345682375374557 Val_cost:  2.6296402243346724 Val_accuracy:  0.6345682375374557 Val_Acc:  2.6458282932849655\n",
      "Epoch number: 731/10000step_number: 0/29 Accuracy:  0.643589306998127 Loss:  2.6290900809786164 Val_accuracy:  0.635113048215745 Val_cost:  2.6290900809786164 Val_accuracy:  0.635113048215745 Val_Acc:  2.6454685980111456\n",
      "Epoch number: 732/10000step_number: 0/29 Accuracy:  0.6437595777285885 Loss:  2.628538217466173 Val_accuracy:  0.6352492508853174 Val_cost:  2.628538217466173 Val_accuracy:  0.6352492508853174 Val_Acc:  2.6451035216371053\n",
      "Epoch number: 733/10000step_number: 0/29 Accuracy:  0.6443384982121574 Loss:  2.6279842262129054 Val_accuracy:  0.6357940615636066 Val_cost:  2.6279842262129054 Val_accuracy:  0.6357940615636066 Val_Acc:  2.6447329409273586\n",
      "Epoch number: 734/10000step_number: 0/29 Accuracy:  0.6445087689426188 Loss:  2.6274278073954584 Val_accuracy:  0.6360664669027513 Val_cost:  2.6274278073954584 Val_accuracy:  0.6360664669027513 Val_Acc:  2.6443568603846717\n",
      "Epoch number: 735/10000step_number: 0/29 Accuracy:  0.6448152562574494 Loss:  2.6268687828219837 Val_accuracy:  0.6364750749114683 Val_cost:  2.6268687828219837 Val_accuracy:  0.6364750749114683 Val_Acc:  2.643975405778816\n",
      "Epoch number: 736/10000step_number: 0/29 Accuracy:  0.6448493104035417 Loss:  2.626307095633102 Val_accuracy:  0.6371560882593299 Val_cost:  2.626307095633102 Val_accuracy:  0.6371560882593299 Val_Acc:  2.643588808776145\n",
      "Epoch number: 737/10000step_number: 0/29 Accuracy:  0.6460412055167717 Loss:  2.625742800463367 Val_accuracy:  0.6379733042767638 Val_cost:  2.625742800463367 Val_accuracy:  0.6379733042767638 Val_Acc:  2.6431973880138346\n",
      "Epoch number: 738/10000step_number: 0/29 Accuracy:  0.6464158011237868 Loss:  2.625176048577351 Val_accuracy:  0.6381095069463362 Val_cost:  2.625176048577351 Val_accuracy:  0.6381095069463362 Val_Acc:  2.642801530825017\n",
      "Epoch number: 739/10000step_number: 0/29 Accuracy:  0.6467222884386175 Loss:  2.624607071038437 Val_accuracy:  0.6387905202941978 Val_cost:  2.624607071038437 Val_accuracy:  0.6387905202941978 Val_Acc:  2.642401677863574\n",
      "Epoch number: 740/10000step_number: 0/29 Accuracy:  0.6468925591690788 Loss:  2.6240361610792133 Val_accuracy:  0.6393353309724871 Val_cost:  2.6240361610792133 Val_accuracy:  0.6393353309724871 Val_Acc:  2.6419983110798144\n",
      "Epoch number: 741/10000step_number: 0/29 Accuracy:  0.647267154776094 Loss:  2.623463655130551 Val_accuracy:  0.6391991283029147 Val_cost:  2.623463655130551 Val_accuracy:  0.6391991283029147 Val_Acc:  2.6415919441807256\n",
      "Epoch number: 742/10000step_number: 0/29 Accuracy:  0.6473352630682786 Loss:  2.6228899108637704 Val_accuracy:  0.6394715336420593 Val_cost:  2.6228899108637704 Val_accuracy:  0.6394715336420593 Val_Acc:  2.64118311386726\n",
      "Epoch number: 743/10000step_number: 0/29 Accuracy:  0.6474714796526477 Loss:  2.6223152807224084 Val_accuracy:  0.6393353309724871 Val_cost:  2.6223152807224084 Val_accuracy:  0.6393353309724871 Val_Acc:  2.6407723696942624\n",
      "Epoch number: 744/10000step_number: 0/29 Accuracy:  0.6474374255065555 Loss:  2.621740081804169 Val_accuracy:  0.6391991283029147 Val_cost:  2.621740081804169 Val_accuracy:  0.6391991283029147 Val_Acc:  2.6403602597023212\n",
      "Epoch number: 745/10000step_number: 0/29 Accuracy:  0.647743912821386 Loss:  2.6211645689780725 Val_accuracy:  0.6391991283029147 Val_cost:  2.6211645689780725 Val_accuracy:  0.6391991283029147 Val_Acc:  2.639947305193217\n",
      "Epoch number: 746/10000step_number: 0/29 Accuracy:  0.647743912821386 Loss:  2.6205889288190596 Val_accuracy:  0.6394715336420593 Val_cost:  2.6205889288190596 Val_accuracy:  0.6394715336420593 Val_Acc:  2.639533945706946\n",
      "Epoch number: 747/10000step_number: 0/29 Accuracy:  0.6475736420909246 Loss:  2.6200133357838813 Val_accuracy:  0.6390629256333424 Val_cost:  2.6200133357838813 Val_accuracy:  0.6390629256333424 Val_Acc:  2.639120443487886\n",
      "Epoch number: 748/10000step_number: 0/29 Accuracy:  0.6476076962370169 Loss:  2.619438216801147 Val_accuracy:  0.6390629256333424 Val_cost:  2.619438216801147 Val_accuracy:  0.6390629256333424 Val_Acc:  2.638707000970937\n",
      "Epoch number: 749/10000step_number: 0/29 Accuracy:  0.6478801294057551 Loss:  2.6188649107146595 Val_accuracy:  0.6391991283029147 Val_cost:  2.6188649107146595 Val_accuracy:  0.6391991283029147 Val_Acc:  2.6382947210675507\n",
      "Epoch number: 750/10000step_number: 0/29 Accuracy:  0.6480504001362166 Loss:  2.6182960496334418 Val_accuracy:  0.6396077363116317 Val_cost:  2.6182960496334418 Val_accuracy:  0.6396077363116317 Val_Acc:  2.6378862542589143\n",
      "Epoch number: 751/10000step_number: 0/29 Accuracy:  0.6480163459901243 Loss:  2.61773580973057 Val_accuracy:  0.6397439389812041 Val_cost:  2.61773580973057 Val_accuracy:  0.6397439389812041 Val_Acc:  2.6374843629423657\n",
      "Epoch number: 752/10000step_number: 0/29 Accuracy:  0.6481185084284011 Loss:  2.6171884920183976 Val_accuracy:  0.6400163443203487 Val_cost:  2.6171884920183976 Val_accuracy:  0.6400163443203487 Val_Acc:  2.6370882127185533\n",
      "Epoch number: 753/10000step_number: 0/29 Accuracy:  0.6487995913502469 Loss:  2.6166463307367094 Val_accuracy:  0.640561154998638 Val_cost:  2.6166463307367094 Val_accuracy:  0.640561154998638 Val_Acc:  2.636689177694908\n",
      "Epoch number: 754/10000step_number: 0/29 Accuracy:  0.64869742891197 Loss:  2.6161001508654005 Val_accuracy:  0.6406973576682103 Val_cost:  2.6161001508654005 Val_accuracy:  0.6406973576682103 Val_Acc:  2.636283711718139\n",
      "Epoch number: 755/10000step_number: 0/29 Accuracy:  0.6487314830580623 Loss:  2.6155522407335265 Val_accuracy:  0.6416507763552166 Val_cost:  2.6155522407335265 Val_accuracy:  0.6416507763552166 Val_Acc:  2.635877771782494\n",
      "Epoch number: 756/10000step_number: 0/29 Accuracy:  0.6487655372041546 Loss:  2.614998584174203 Val_accuracy:  0.6415145736856442 Val_cost:  2.614998584174203 Val_accuracy:  0.6415145736856442 Val_Acc:  2.6354688440071237\n",
      "Epoch number: 757/10000step_number: 0/29 Accuracy:  0.6491060786650775 Loss:  2.6144329670765982 Val_accuracy:  0.6415145736856442 Val_cost:  2.6144329670765982 Val_accuracy:  0.6415145736856442 Val_Acc:  2.635052093822013\n",
      "Epoch number: 758/10000step_number: 0/29 Accuracy:  0.6498893240252 Loss:  2.6138566839090935 Val_accuracy:  0.6423317897030781 Val_cost:  2.6138566839090935 Val_accuracy:  0.6423317897030781 Val_Acc:  2.6346309936937846\n",
      "Epoch number: 759/10000step_number: 0/29 Accuracy:  0.6504001362165843 Loss:  2.6132738725075844 Val_accuracy:  0.6428766003813675 Val_cost:  2.6132738725075844 Val_accuracy:  0.6428766003813675 Val_Acc:  2.6342149725814337\n",
      "Epoch number: 760/10000step_number: 0/29 Accuracy:  0.6507747318235996 Loss:  2.6127103294557936 Val_accuracy:  0.6428766003813675 Val_cost:  2.6127103294557936 Val_accuracy:  0.6428766003813675 Val_Acc:  2.633829613251924\n",
      "Epoch number: 761/10000step_number: 0/29 Accuracy:  0.6508087859696918 Loss:  2.6121441142780206 Val_accuracy:  0.6432852083900844 Val_cost:  2.6121441142780206 Val_accuracy:  0.6432852083900844 Val_Acc:  2.6334656011142683\n",
      "Epoch number: 762/10000step_number: 0/29 Accuracy:  0.650945002554061 Loss:  2.6116031417930445 Val_accuracy:  0.643966221737946 Val_cost:  2.6116031417930445 Val_accuracy:  0.643966221737946 Val_Acc:  2.633129473374139\n",
      "Epoch number: 763/10000step_number: 0/29 Accuracy:  0.6508087859696918 Loss:  2.6110844762014414 Val_accuracy:  0.643966221737946 Val_cost:  2.6110844762014414 Val_accuracy:  0.643966221737946 Val_Acc:  2.6327830206018104\n",
      "Epoch number: 764/10000step_number: 0/29 Accuracy:  0.6511493274306147 Loss:  2.6105564863618307 Val_accuracy:  0.6441024244075184 Val_cost:  2.6105564863618307 Val_accuracy:  0.6441024244075184 Val_Acc:  2.632411779970187\n",
      "Epoch number: 765/10000step_number: 0/29 Accuracy:  0.6525796015664908 Loss:  2.610039611486017 Val_accuracy:  0.6466902751293926 Val_cost:  2.610039611486017 Val_accuracy:  0.6466902751293926 Val_Acc:  2.6320478732579367\n",
      "Epoch number: 766/10000step_number: 0/29 Accuracy:  0.6524433849821216 Loss:  2.6095099754624433 Val_accuracy:  0.6466902751293926 Val_cost:  2.6095099754624433 Val_accuracy:  0.6466902751293926 Val_Acc:  2.631671831624269\n",
      "Epoch number: 767/10000step_number: 0/29 Accuracy:  0.6526477098586753 Loss:  2.60897886925473 Val_accuracy:  0.6465540724598202 Val_cost:  2.60897886925473 Val_accuracy:  0.6465540724598202 Val_Acc:  2.631294060102817\n",
      "Epoch number: 768/10000step_number: 0/29 Accuracy:  0.6534650093648902 Loss:  2.6084394196695158 Val_accuracy:  0.6465540724598202 Val_cost:  2.6084394196695158 Val_accuracy:  0.6465540724598202 Val_Acc:  2.6309087220064713\n",
      "Epoch number: 769/10000step_number: 0/29 Accuracy:  0.6537714966797208 Loss:  2.6078972785863943 Val_accuracy:  0.6470988831381095 Val_cost:  2.6078972785863943 Val_accuracy:  0.6470988831381095 Val_Acc:  2.6305203537143367\n",
      "Epoch number: 770/10000step_number: 0/29 Accuracy:  0.653805550825813 Loss:  2.6073509820093603 Val_accuracy:  0.6469626804685372 Val_cost:  2.6073509820093603 Val_accuracy:  0.6469626804685372 Val_Acc:  2.6301275278062954\n",
      "Epoch number: 771/10000step_number: 0/29 Accuracy:  0.6541460922867359 Loss:  2.60680233631143 Val_accuracy:  0.6469626804685372 Val_cost:  2.60680233631143 Val_accuracy:  0.6469626804685372 Val_Acc:  2.6297315685260942\n",
      "Epoch number: 772/10000step_number: 0/29 Accuracy:  0.6543844713093819 Loss:  2.606251113117619 Val_accuracy:  0.6469626804685372 Val_cost:  2.606251113117619 Val_accuracy:  0.6469626804685372 Val_Acc:  2.6293320630365873\n",
      "Epoch number: 773/10000step_number: 0/29 Accuracy:  0.6546228503320279 Loss:  2.6056981406587956 Val_accuracy:  0.6470988831381095 Val_cost:  2.6056981406587956 Val_accuracy:  0.6470988831381095 Val_Acc:  2.6289295501771734\n",
      "Epoch number: 774/10000step_number: 0/29 Accuracy:  0.6549633917929508 Loss:  2.6051434378692155 Val_accuracy:  0.6476436938163987 Val_cost:  2.6051434378692155 Val_accuracy:  0.6476436938163987 Val_Acc:  2.6285238637643786\n",
      "Epoch number: 775/10000step_number: 0/29 Accuracy:  0.6542823088711051 Loss:  2.6045873744765307 Val_accuracy:  0.6473712884772541 Val_cost:  2.6045873744765307 Val_accuracy:  0.6473712884772541 Val_Acc:  2.6281151683840513\n",
      "Epoch number: 776/10000step_number: 0/29 Accuracy:  0.6543504171632897 Loss:  2.604029910983548 Val_accuracy:  0.6473712884772541 Val_cost:  2.604029910983548 Val_accuracy:  0.6473712884772541 Val_Acc:  2.6277033039436226\n",
      "Epoch number: 777/10000step_number: 0/29 Accuracy:  0.6546228503320279 Loss:  2.603471050221264 Val_accuracy:  0.6473712884772541 Val_cost:  2.603471050221264 Val_accuracy:  0.6473712884772541 Val_Acc:  2.6272882061013814\n",
      "Epoch number: 778/10000step_number: 0/29 Accuracy:  0.6548271752085817 Loss:  2.602910555246516 Val_accuracy:  0.6477798964859711 Val_cost:  2.602910555246516 Val_accuracy:  0.6477798964859711 Val_Acc:  2.6268697163986596\n",
      "Epoch number: 779/10000step_number: 0/29 Accuracy:  0.6550655542312277 Loss:  2.602348169135318 Val_accuracy:  0.6477798964859711 Val_cost:  2.602348169135318 Val_accuracy:  0.6477798964859711 Val_Acc:  2.626447850076223\n",
      "Epoch number: 780/10000step_number: 0/29 Accuracy:  0.6554401498382428 Loss:  2.6017836559734677 Val_accuracy:  0.6477798964859711 Val_cost:  2.6017836559734677 Val_accuracy:  0.6477798964859711 Val_Acc:  2.6260229232299794\n",
      "Epoch number: 781/10000step_number: 0/29 Accuracy:  0.6555082581304273 Loss:  2.601217063061493 Val_accuracy:  0.6480523018251158 Val_cost:  2.601217063061493 Val_accuracy:  0.6480523018251158 Val_Acc:  2.625595803495114\n",
      "Epoch number: 782/10000step_number: 0/29 Accuracy:  0.6557466371530734 Loss:  2.6006488207431158 Val_accuracy:  0.6484609098338328 Val_cost:  2.6006488207431158 Val_accuracy:  0.6484609098338328 Val_Acc:  2.6251678142804717\n",
      "Epoch number: 783/10000step_number: 0/29 Accuracy:  0.6557806912991657 Loss:  2.6000797016360315 Val_accuracy:  0.648597112503405 Val_cost:  2.6000797016360315 Val_accuracy:  0.648597112503405 Val_Acc:  2.624740296928862\n",
      "Epoch number: 784/10000step_number: 0/29 Accuracy:  0.6559169078835348 Loss:  2.5995107499167993 Val_accuracy:  0.6487333151729774 Val_cost:  2.5995107499167993 Val_accuracy:  0.6487333151729774 Val_Acc:  2.6243142421667027\n",
      "Epoch number: 785/10000step_number: 0/29 Accuracy:  0.6562233951983654 Loss:  2.598943201144848 Val_accuracy:  0.648597112503405 Val_cost:  2.598943201144848 Val_accuracy:  0.648597112503405 Val_Acc:  2.6238902354024822\n",
      "Epoch number: 786/10000step_number: 0/29 Accuracy:  0.6564958283671037 Loss:  2.598378011496342 Val_accuracy:  0.648597112503405 Val_cost:  2.598378011496342 Val_accuracy:  0.648597112503405 Val_Acc:  2.6234682360519868\n",
      "Epoch number: 787/10000step_number: 0/29 Accuracy:  0.6568704239741189 Loss:  2.5978156168117175 Val_accuracy:  0.648597112503405 Val_cost:  2.5978156168117175 Val_accuracy:  0.648597112503405 Val_Acc:  2.623047659880446\n",
      "Epoch number: 788/10000step_number: 0/29 Accuracy:  0.6559850161757194 Loss:  2.5972562776870483 Val_accuracy:  0.6464178697902478 Val_cost:  2.5972562776870483 Val_accuracy:  0.6464178697902478 Val_Acc:  2.622627988999902\n",
      "Epoch number: 789/10000step_number: 0/29 Accuracy:  0.6561552869061809 Loss:  2.5967002850979206 Val_accuracy:  0.6464178697902478 Val_cost:  2.5967002850979206 Val_accuracy:  0.6464178697902478 Val_Acc:  2.622209077979597\n",
      "Epoch number: 790/10000step_number: 0/29 Accuracy:  0.6564958283671037 Loss:  2.596147918691343 Val_accuracy:  0.6464178697902478 Val_cost:  2.596147918691343 Val_accuracy:  0.6464178697902478 Val_Acc:  2.621791059054556\n",
      "Epoch number: 791/10000step_number: 0/29 Accuracy:  0.6568363698280265 Loss:  2.5955994020216897 Val_accuracy:  0.6465540724598202 Val_cost:  2.5955994020216897 Val_accuracy:  0.6465540724598202 Val_Acc:  2.621374193250762\n",
      "Epoch number: 792/10000step_number: 0/29 Accuracy:  0.6570747488506725 Loss:  2.595054904735657 Val_accuracy:  0.6469626804685372 Val_cost:  2.595054904735657 Val_accuracy:  0.6469626804685372 Val_Acc:  2.620958785470435\n",
      "Epoch number: 793/10000step_number: 0/29 Accuracy:  0.6574152903115954 Loss:  2.594514565873781 Val_accuracy:  0.6473712884772541 Val_cost:  2.594514565873781 Val_accuracy:  0.6473712884772541 Val_Acc:  2.620545153549524\n",
      "Epoch number: 794/10000step_number: 0/29 Accuracy:  0.6587774561552869 Loss:  2.593978504578384 Val_accuracy:  0.6487333151729774 Val_cost:  2.593978504578384 Val_accuracy:  0.6487333151729774 Val_Acc:  2.620133612790206\n",
      "Epoch number: 795/10000step_number: 0/29 Accuracy:  0.6593223224927635 Loss:  2.593446820424758 Val_accuracy:  0.6492781258512667 Val_cost:  2.593446820424758 Val_accuracy:  0.6492781258512667 Val_Acc:  2.6197244661579893\n",
      "Epoch number: 796/10000step_number: 0/29 Accuracy:  0.6596288098075941 Loss:  2.5929195895404273 Val_accuracy:  0.649414328520839 Val_cost:  2.5929195895404273 Val_accuracy:  0.649414328520839 Val_Acc:  2.619317997749407\n",
      "Epoch number: 797/10000step_number: 0/29 Accuracy:  0.659492593223225 Loss:  2.5923968609515686 Val_accuracy:  0.649414328520839 Val_cost:  2.5923968609515686 Val_accuracy:  0.649414328520839 Val_Acc:  2.618914469095616\n",
      "Epoch number: 798/10000step_number: 0/29 Accuracy:  0.6597990805380555 Loss:  2.5918786548548978 Val_accuracy:  0.6499591391991283 Val_cost:  2.5918786548548978 Val_accuracy:  0.6499591391991283 Val_Acc:  2.618514117791821\n",
      "Epoch number: 799/10000step_number: 0/29 Accuracy:  0.6601396219989784 Loss:  2.5913649625563306 Val_accuracy:  0.6502315445382729 Val_cost:  2.5913649625563306 Val_accuracy:  0.6502315445382729 Val_Acc:  2.6181171573729203\n",
      "Epoch number: 800/10000step_number: 0/29 Accuracy:  0.6615017878426699 Loss:  2.5908557475227805 Val_accuracy:  0.6520021792427132 Val_cost:  2.5908557475227805 Val_accuracy:  0.6520021792427132 Val_Acc:  2.6177237776744446\n",
      "Epoch number: 801/10000step_number: 0/29 Accuracy:  0.6626596288098076 Loss:  2.590350946664749 Val_accuracy:  0.6530918005992917 Val_cost:  2.590350946664749 Val_accuracy:  0.6530918005992917 Val_Acc:  2.617334144972413\n",
      "Epoch number: 802/10000step_number: 0/29 Accuracy:  0.6628639536863613 Loss:  2.5898504712373582 Val_accuracy:  0.6530918005992917 Val_cost:  2.5898504712373582 Val_accuracy:  0.6530918005992917 Val_Acc:  2.6169484016564466\n",
      "Epoch number: 803/10000step_number: 0/29 Accuracy:  0.664123957091776 Loss:  2.589354206956553 Val_accuracy:  0.654045219286298 Val_cost:  2.589354206956553 Val_accuracy:  0.654045219286298 Val_Acc:  2.6165666655307156\n",
      "Epoch number: 804/10000step_number: 0/29 Accuracy:  0.6642261195300528 Loss:  2.5888620133364983 Val_accuracy:  0.654453827295015 Val_cost:  2.5888620133364983 Val_accuracy:  0.654453827295015 Val_Acc:  2.6161890292650707\n",
      "Epoch number: 805/10000step_number: 0/29 Accuracy:  0.6644985526987911 Loss:  2.5883737227452555 Val_accuracy:  0.6545900299645873 Val_cost:  2.5883737227452555 Val_accuracy:  0.6545900299645873 Val_Acc:  2.6158155609093114\n",
      "Epoch number: 806/10000step_number: 0/29 Accuracy:  0.6647709858675294 Loss:  2.5878891403741604 Val_accuracy:  0.6547262326341596 Val_cost:  2.5878891403741604 Val_accuracy:  0.6547262326341596 Val_Acc:  2.615446306801951\n",
      "Epoch number: 807/10000step_number: 0/29 Accuracy:  0.6651115273284522 Loss:  2.5874080473163827 Val_accuracy:  0.6549986379733043 Val_cost:  2.5874080473163827 Val_accuracy:  0.6549986379733043 Val_Acc:  2.615081298672486\n",
      "Epoch number: 808/10000step_number: 0/29 Accuracy:  0.6656223395198365 Loss:  2.5869302103435317 Val_accuracy:  0.6551348406428766 Val_cost:  2.5869302103435317 Val_accuracy:  0.6551348406428766 Val_Acc:  2.6147205672313873\n",
      "Epoch number: 809/10000step_number: 0/29 Accuracy:  0.66626936829559 Loss:  2.586455403719059 Val_accuracy:  0.6556796513211659 Val_cost:  2.586455403719059 Val_accuracy:  0.6556796513211659 Val_Acc:  2.61436416488617\n",
      "Epoch number: 810/10000step_number: 0/29 Accuracy:  0.6662353141494977 Loss:  2.5859834500254992 Val_accuracy:  0.6559520566603105 Val_cost:  2.5859834500254992 Val_accuracy:  0.6559520566603105 Val_Acc:  2.614012199867103\n",
      "Epoch number: 811/10000step_number: 0/29 Accuracy:  0.6664055848799592 Loss:  2.5855142871497763 Val_accuracy:  0.6560882593298829 Val_cost:  2.5855142871497763 Val_accuracy:  0.6560882593298829 Val_Acc:  2.613664881907469\n",
      "Epoch number: 812/10000step_number: 0/29 Accuracy:  0.6668482887791589 Loss:  2.585048064312011 Val_accuracy:  0.6564968673385998 Val_cost:  2.585048064312011 Val_accuracy:  0.6564968673385998 Val_Acc:  2.6133225740808337\n",
      "Epoch number: 813/10000step_number: 0/29 Accuracy:  0.6668823429252512 Loss:  2.584585256657879 Val_accuracy:  0.6567692726777444 Val_cost:  2.584585256657879 Val_accuracy:  0.6567692726777444 Val_Acc:  2.6129858352468225\n",
      "Epoch number: 814/10000step_number: 0/29 Accuracy:  0.6669163970713434 Loss:  2.5841267617543946 Val_accuracy:  0.6567692726777444 Val_cost:  2.5841267617543946 Val_accuracy:  0.6567692726777444 Val_Acc:  2.612655424959389\n",
      "Epoch number: 815/10000step_number: 0/29 Accuracy:  0.6670185595096203 Loss:  2.5836739085797684 Val_accuracy:  0.6570416780168892 Val_cost:  2.5836739085797684 Val_accuracy:  0.6570416780168892 Val_Acc:  2.6123322378201603\n",
      "Epoch number: 816/10000step_number: 0/29 Accuracy:  0.6659969351268517 Loss:  2.5832282980921932 Val_accuracy:  0.6573140833560338 Val_cost:  2.5832282980921932 Val_accuracy:  0.6573140833560338 Val_Acc:  2.612017153896726\n",
      "Epoch number: 817/10000step_number: 0/29 Accuracy:  0.6663715307338669 Loss:  2.582791442001404 Val_accuracy:  0.6574502860256061 Val_cost:  2.582791442001404 Val_accuracy:  0.6574502860256061 Val_Acc:  2.6117108349622224\n",
      "Epoch number: 818/10000step_number: 0/29 Accuracy:  0.6666099097565129 Loss:  2.582364258797046 Val_accuracy:  0.6575864886951784 Val_cost:  2.582364258797046 Val_accuracy:  0.6575864886951784 Val_Acc:  2.611413504871904\n",
      "Epoch number: 819/10000step_number: 0/29 Accuracy:  0.6666780180486974 Loss:  2.5819465373819233 Val_accuracy:  0.6579950967038954 Val_cost:  2.5819465373819233 Val_accuracy:  0.6579950967038954 Val_Acc:  2.6111246719287546\n",
      "Epoch number: 820/10000step_number: 0/29 Accuracy:  0.6667120721947897 Loss:  2.581536570374093 Val_accuracy:  0.6579950967038954 Val_cost:  2.581536570374093 Val_accuracy:  0.6579950967038954 Val_Acc:  2.6108428216247415\n",
      "Epoch number: 821/10000step_number: 0/29 Accuracy:  0.6668823429252512 Loss:  2.5811315421647207 Val_accuracy:  0.6581312993734677 Val_cost:  2.5811315421647207 Val_accuracy:  0.6581312993734677 Val_Acc:  2.610565682856064\n",
      "Epoch number: 822/10000step_number: 0/29 Accuracy:  0.6668482887791589 Loss:  2.580728951285425 Val_accuracy:  0.6581312993734677 Val_cost:  2.580728951285425 Val_accuracy:  0.6581312993734677 Val_Acc:  2.6102914767050756\n",
      "Epoch number: 823/10000step_number: 0/29 Accuracy:  0.6672569385322663 Loss:  2.5803275908472982 Val_accuracy:  0.6582675020430401 Val_cost:  2.5803275908472982 Val_accuracy:  0.6582675020430401 Val_Acc:  2.610019642176987\n",
      "Epoch number: 824/10000step_number: 0/29 Accuracy:  0.6673931551166354 Loss:  2.579927112161593 Val_accuracy:  0.6582675020430401 Val_cost:  2.579927112161593 Val_accuracy:  0.6582675020430401 Val_Acc:  2.6097501484222816\n",
      "Epoch number: 825/10000step_number: 0/29 Accuracy:  0.6672569385322663 Loss:  2.579527424825909 Val_accuracy:  0.6581312993734677 Val_cost:  2.579527424825909 Val_accuracy:  0.6581312993734677 Val_Acc:  2.6094828854695127\n",
      "Epoch number: 826/10000step_number: 0/29 Accuracy:  0.6671547760939894 Loss:  2.579128551701518 Val_accuracy:  0.6581312993734677 Val_cost:  2.579128551701518 Val_accuracy:  0.6581312993734677 Val_Acc:  2.6092176954599595\n",
      "Epoch number: 827/10000step_number: 0/29 Accuracy:  0.6672569385322663 Loss:  2.57873058617226 Val_accuracy:  0.6581312993734677 Val_cost:  2.57873058617226 Val_accuracy:  0.6581312993734677 Val_Acc:  2.608954486566632\n",
      "Epoch number: 828/10000step_number: 0/29 Accuracy:  0.6686531585220501 Loss:  2.5783336469433444 Val_accuracy:  0.6597657314083356 Val_cost:  2.5783336469433444 Val_accuracy:  0.6597657314083356 Val_Acc:  2.6086932483852934\n",
      "Epoch number: 829/10000step_number: 0/29 Accuracy:  0.6686531585220501 Loss:  2.5779378366607886 Val_accuracy:  0.659901934077908 Val_cost:  2.5779378366607886 Val_accuracy:  0.659901934077908 Val_Acc:  2.6084340135870727\n",
      "Epoch number: 830/10000step_number: 0/29 Accuracy:  0.6686531585220501 Loss:  2.5775432190978016 Val_accuracy:  0.6597657314083356 Val_cost:  2.5775432190978016 Val_accuracy:  0.6597657314083356 Val_Acc:  2.6081768215240757\n",
      "Epoch number: 831/10000step_number: 0/29 Accuracy:  0.6688234292525115 Loss:  2.5771498120990666 Val_accuracy:  0.6603105420866249 Val_cost:  2.5771498120990666 Val_accuracy:  0.6603105420866249 Val_Acc:  2.6079216978580972\n",
      "Epoch number: 832/10000step_number: 0/29 Accuracy:  0.6688915375446961 Loss:  2.576757591028253 Val_accuracy:  0.6603105420866249 Val_cost:  2.576757591028253 Val_accuracy:  0.6603105420866249 Val_Acc:  2.607668647651406\n",
      "Epoch number: 833/10000step_number: 0/29 Accuracy:  0.6683126170611272 Loss:  2.5763664974289195 Val_accuracy:  0.659901934077908 Val_cost:  2.5763664974289195 Val_accuracy:  0.659901934077908 Val_Acc:  2.6074176558920272\n",
      "Epoch number: 834/10000step_number: 0/29 Accuracy:  0.668278562915035 Loss:  2.575976448603784 Val_accuracy:  0.6597657314083356 Val_cost:  2.575976448603784 Val_accuracy:  0.6597657314083356 Val_Acc:  2.6071686906464278\n",
      "Epoch number: 835/10000step_number: 0/29 Accuracy:  0.6684828877915886 Loss:  2.575587346305607 Val_accuracy:  0.659901934077908 Val_cost:  2.575587346305607 Val_accuracy:  0.659901934077908 Val_Acc:  2.606921706734729\n",
      "Epoch number: 836/10000step_number: 0/29 Accuracy:  0.6687893751064192 Loss:  2.5751990836619103 Val_accuracy:  0.6597657314083356 Val_cost:  2.5751990836619103 Val_accuracy:  0.6597657314083356 Val_Acc:  2.6066766488504727\n",
      "Epoch number: 837/10000step_number: 0/29 Accuracy:  0.6689596458368806 Loss:  2.574811550399514 Val_accuracy:  0.659901934077908 Val_cost:  2.574811550399514 Val_accuracy:  0.659901934077908 Val_Acc:  2.606433453954165\n",
      "Epoch number: 838/10000step_number: 0/29 Accuracy:  0.6678358590158352 Loss:  2.5744246365778642 Val_accuracy:  0.6593571233996186 Val_cost:  2.5744246365778642 Val_accuracy:  0.6593571233996186 Val_Acc:  2.6061920529578604\n",
      "Epoch number: 839/10000step_number: 0/29 Accuracy:  0.6679720756002043 Loss:  2.574038235219208 Val_accuracy:  0.6597657314083356 Val_cost:  2.574038235219208 Val_accuracy:  0.6597657314083356 Val_Acc:  2.6059523719141113\n",
      "Epoch number: 840/10000step_number: 0/29 Accuracy:  0.668040183892389 Loss:  2.5736522441519907 Val_accuracy:  0.6596295287387632 Val_cost:  2.5736522441519907 Val_accuracy:  0.6596295287387632 Val_Acc:  2.6057143328931276\n",
      "Epoch number: 841/10000step_number: 0/29 Accuracy:  0.6684147794994041 Loss:  2.5732665673534085 Val_accuracy:  0.6603105420866249 Val_cost:  2.5732665673534085 Val_accuracy:  0.6603105420866249 Val_Acc:  2.6054778547323556\n",
      "Epoch number: 842/10000step_number: 0/29 Accuracy:  0.6685509960837732 Loss:  2.5728811159832103 Val_accuracy:  0.6605829474257695 Val_cost:  2.5728811159832103 Val_accuracy:  0.6605829474257695 Val_Acc:  2.6052428537848287\n",
      "Epoch number: 843/10000step_number: 0/29 Accuracy:  0.668755320960327 Loss:  2.572495809241896 Val_accuracy:  0.6605829474257695 Val_cost:  2.572495809241896 Val_accuracy:  0.6605829474257695 Val_Acc:  2.6050092447596422\n",
      "Epoch number: 844/10000step_number: 0/29 Accuracy:  0.6687893751064192 Loss:  2.5721105751262785 Val_accuracy:  0.6604467447561972 Val_cost:  2.5721105751262785 Val_accuracy:  0.6604467447561972 Val_Acc:  2.6047769417064703\n",
      "Epoch number: 845/10000step_number: 0/29 Accuracy:  0.6688574833986037 Loss:  2.571725351123608 Val_accuracy:  0.6604467447561972 Val_cost:  2.571725351123608 Val_accuracy:  0.6604467447561972 Val_Acc:  2.604545859169931\n",
      "Epoch number: 846/10000step_number: 0/29 Accuracy:  0.6688574833986037 Loss:  2.5713400848646506 Val_accuracy:  0.6601743394170526 Val_cost:  2.5713400848646506 Val_accuracy:  0.6601743394170526 Val_Acc:  2.6043159135128082\n",
      "Epoch number: 847/10000step_number: 0/29 Accuracy:  0.6690618082751575 Loss:  2.5709547347503614 Val_accuracy:  0.6601743394170526 Val_cost:  2.5709547347503614 Val_accuracy:  0.6601743394170526 Val_Acc:  2.604087024385187\n",
      "Epoch number: 848/10000step_number: 0/29 Accuracy:  0.6690958624212497 Loss:  2.5705692705645604 Val_accuracy:  0.6601743394170526 Val_cost:  2.5705692705645604 Val_accuracy:  0.6601743394170526 Val_Acc:  2.603859116293065\n",
      "Epoch number: 849/10000step_number: 0/29 Accuracy:  0.6691639707134344 Loss:  2.570183674083648 Val_accuracy:  0.6601743394170526 Val_cost:  2.570183674083648 Val_accuracy:  0.6601743394170526 Val_Acc:  2.6036321201990646\n",
      "Epoch number: 850/10000step_number: 0/29 Accuracy:  0.6690277541290652 Loss:  2.569797939688306 Val_accuracy:  0.6601743394170526 Val_cost:  2.569797939688306 Val_accuracy:  0.6601743394170526 Val_Acc:  2.6034059750704666\n",
      "Epoch number: 851/10000step_number: 0/29 Accuracy:  0.6686531585220501 Loss:  2.569412074971451 Val_accuracy:  0.659901934077908 Val_cost:  2.569412074971451 Val_accuracy:  0.659901934077908 Val_Acc:  2.60318062928052\n",
      "Epoch number: 852/10000step_number: 0/29 Accuracy:  0.6688234292525115 Loss:  2.5690261013230367 Val_accuracy:  0.659901934077908 Val_cost:  2.5690261013230367 Val_accuracy:  0.659901934077908 Val_Acc:  2.602956041770373\n",
      "Epoch number: 853/10000step_number: 0/29 Accuracy:  0.6688915375446961 Loss:  2.5686400544597228 Val_accuracy:  0.6603105420866249 Val_cost:  2.5686400544597228 Val_accuracy:  0.6603105420866249 Val_Acc:  2.6027321828917156\n",
      "Epoch number: 854/10000step_number: 0/29 Accuracy:  0.668993699982973 Loss:  2.5682539848596253 Val_accuracy:  0.6604467447561972 Val_cost:  2.5682539848596253 Val_accuracy:  0.6604467447561972 Val_Acc:  2.602509034872809\n",
      "Epoch number: 855/10000step_number: 0/29 Accuracy:  0.6691299165673421 Loss:  2.567867958061445 Val_accuracy:  0.6612639607736311 Val_cost:  2.567867958061445 Val_accuracy:  0.6612639607736311 Val_Acc:  2.6022865918788063\n",
      "Epoch number: 856/10000step_number: 0/29 Accuracy:  0.6691639707134344 Loss:  2.5674820547927686 Val_accuracy:  0.6614001634432035 Val_cost:  2.5674820547927686 Val_accuracy:  0.6614001634432035 Val_Acc:  2.602064859666357\n",
      "Epoch number: 857/10000step_number: 0/29 Accuracy:  0.6692661331517112 Loss:  2.5670963709019907 Val_accuracy:  0.6616725687823481 Val_cost:  2.5670963709019907 Val_accuracy:  0.6616725687823481 Val_Acc:  2.601843854858654\n",
      "Epoch number: 858/10000step_number: 0/29 Accuracy:  0.6693682955899881 Loss:  2.566711017078774 Val_accuracy:  0.6618087714519204 Val_cost:  2.566711017078774 Val_accuracy:  0.6618087714519204 Val_Acc:  2.601623603887171\n",
      "Epoch number: 859/10000step_number: 0/29 Accuracy:  0.6694364038821726 Loss:  2.5663261183564536 Val_accuracy:  0.6616725687823481 Val_cost:  2.5663261183564536 Val_accuracy:  0.6616725687823481 Val_Acc:  2.6014041416602454\n",
      "Epoch number: 860/10000step_number: 0/29 Accuracy:  0.6695385663204495 Loss:  2.565941813394567 Val_accuracy:  0.6615363661127758 Val_cost:  2.565941813394567 Val_accuracy:  0.6615363661127758 Val_Acc:  2.6011855100270314\n",
      "Epoch number: 861/10000step_number: 0/29 Accuracy:  0.6698450536352801 Loss:  2.565558253540232 Val_accuracy:  0.6620811767910652 Val_cost:  2.565558253540232 Val_accuracy:  0.6620811767910652 Val_Acc:  2.600967756109644\n",
      "Epoch number: 862/10000step_number: 0/29 Accuracy:  0.6698109994891878 Loss:  2.565175601663981 Val_accuracy:  0.6622173794606374 Val_cost:  2.565175601663981 Val_accuracy:  0.6622173794606374 Val_Acc:  2.6007509305779695\n",
      "Epoch number: 863/10000step_number: 0/29 Accuracy:  0.6699812702196493 Loss:  2.5647940307597348 Val_accuracy:  0.6622173794606374 Val_cost:  2.5647940307597348 Val_accuracy:  0.6622173794606374 Val_Acc:  2.6005350859411034\n",
      "Epoch number: 864/10000step_number: 0/29 Accuracy:  0.6702196492422953 Loss:  2.5644137222905137 Val_accuracy:  0.6623535821302098 Val_cost:  2.5644137222905137 Val_accuracy:  0.6623535821302098 Val_Acc:  2.600320274925476\n",
      "Epoch number: 865/10000step_number: 0/29 Accuracy:  0.6701515409501106 Loss:  2.564034864251352 Val_accuracy:  0.6622173794606374 Val_cost:  2.564034864251352 Val_accuracy:  0.6622173794606374 Val_Acc:  2.6001065490010147\n",
      "Epoch number: 866/10000step_number: 0/29 Accuracy:  0.6700834326579261 Loss:  2.5636576489087273 Val_accuracy:  0.6626259874693544 Val_cost:  2.5636576489087273 Val_accuracy:  0.6626259874693544 Val_Acc:  2.5998939571010067\n",
      "Epoch number: 867/10000step_number: 0/29 Accuracy:  0.6701515409501106 Loss:  2.5632822701622 Val_accuracy:  0.6626259874693544 Val_cost:  2.5632822701622 Val_accuracy:  0.6626259874693544 Val_Acc:  2.5996825445581746\n",
      "Epoch number: 868/10000step_number: 0/29 Accuracy:  0.6702196492422953 Loss:  2.562908920461681 Val_accuracy:  0.662898392808499 Val_cost:  2.562908920461681 Val_accuracy:  0.662898392808499 Val_Acc:  2.599472352250891\n",
      "Epoch number: 869/10000step_number: 0/29 Accuracy:  0.6698109994891878 Loss:  2.5625377872082864 Val_accuracy:  0.6626259874693544 Val_cost:  2.5625377872082864 Val_accuracy:  0.6626259874693544 Val_Acc:  2.5992634159241543\n",
      "Epoch number: 870/10000step_number: 0/29 Accuracy:  0.6698109994891878 Loss:  2.5621690485765805 Val_accuracy:  0.6626259874693544 Val_cost:  2.5621690485765805 Val_accuracy:  0.6626259874693544 Val_Acc:  2.599055765626743\n",
      "Epoch number: 871/10000step_number: 0/29 Accuracy:  0.6699812702196493 Loss:  2.561802868730128 Val_accuracy:  0.6627621901389267 Val_cost:  2.561802868730128 Val_accuracy:  0.6627621901389267 Val_Acc:  2.5988494251939582\n",
      "Epoch number: 872/10000step_number: 0/29 Accuracy:  0.6699131619274646 Loss:  2.5614393924670065 Val_accuracy:  0.6630345954780714 Val_cost:  2.5614393924670065 Val_accuracy:  0.6630345954780714 Val_Acc:  2.598644411706313\n",
      "Epoch number: 873/10000step_number: 0/29 Accuracy:  0.6702537033883875 Loss:  2.561078739426818 Val_accuracy:  0.6635794061563607 Val_cost:  2.561078739426818 Val_accuracy:  0.6635794061563607 Val_Acc:  2.598440734864781\n",
      "Epoch number: 874/10000step_number: 0/29 Accuracy:  0.670185595096203 Loss:  2.5607209981058703 Val_accuracy:  0.6638518114955053 Val_cost:  2.5607209981058703 Val_accuracy:  0.6638518114955053 Val_Acc:  2.5982383962361255\n",
      "Epoch number: 875/10000step_number: 0/29 Accuracy:  0.6703899199727567 Loss:  2.560366220042368 Val_accuracy:  0.6643966221737946 Val_cost:  2.560366220042368 Val_accuracy:  0.6643966221737946 Val_Acc:  2.598037388331235\n",
      "Epoch number: 876/10000step_number: 0/29 Accuracy:  0.6704580282649413 Loss:  2.560014414621309 Val_accuracy:  0.6643966221737946 Val_cost:  2.560014414621309 Val_accuracy:  0.6643966221737946 Val_Acc:  2.597837693484341\n",
      "Epoch number: 877/10000step_number: 0/29 Accuracy:  0.6706282989954027 Loss:  2.5596655449801533 Val_accuracy:  0.6646690275129392 Val_cost:  2.5596655449801533 Val_accuracy:  0.6646690275129392 Val_Acc:  2.5976392825047476\n",
      "Epoch number: 878/10000step_number: 0/29 Accuracy:  0.670662353141495 Loss:  2.5593195254495202 Val_accuracy:  0.6648052301825116 Val_cost:  2.5593195254495202 Val_accuracy:  0.6648052301825116 Val_Acc:  2.5974421130828658\n",
      "Epoch number: 879/10000step_number: 0/29 Accuracy:  0.6707985697258642 Loss:  2.5589762208327778 Val_accuracy:  0.6646690275129392 Val_cost:  2.5589762208327778 Val_accuracy:  0.6646690275129392 Val_Acc:  2.5972461279543713\n",
      "Epoch number: 880/10000step_number: 0/29 Accuracy:  0.6710369487485102 Loss:  2.5586354476309934 Val_accuracy:  0.6649414328520838 Val_cost:  2.5586354476309934 Val_accuracy:  0.6649414328520838 Val_Acc:  2.597051252861116\n",
      "Epoch number: 881/10000step_number: 0/29 Accuracy:  0.6711050570406947 Loss:  2.558296977092703 Val_accuracy:  0.6652138381912286 Val_cost:  2.558296977092703 Val_accuracy:  0.6652138381912286 Val_Acc:  2.596857394389561\n",
      "Epoch number: 882/10000step_number: 0/29 Accuracy:  0.671139111186787 Loss:  2.557960539758976 Val_accuracy:  0.6650776355216562 Val_cost:  2.557960539758976 Val_accuracy:  0.6650776355216562 Val_Acc:  2.5966644378060906\n",
      "Epoch number: 883/10000step_number: 0/29 Accuracy:  0.6713434360633407 Loss:  2.557625831026116 Val_accuracy:  0.6653500408608009 Val_cost:  2.557625831026116 Val_accuracy:  0.6653500408608009 Val_Acc:  2.5964722450313875\n",
      "Epoch number: 884/10000step_number: 0/29 Accuracy:  0.6718201941086327 Loss:  2.5572925171851613 Val_accuracy:  0.6654862435303732 Val_cost:  2.5572925171851613 Val_accuracy:  0.6654862435303732 Val_Acc:  2.5962806528933835\n",
      "Epoch number: 885/10000step_number: 0/29 Accuracy:  0.6720245189851864 Loss:  2.5569602414183166 Val_accuracy:  0.6657586488695179 Val_cost:  2.5569602414183166 Val_accuracy:  0.6657586488695179 Val_Acc:  2.5960894717666774\n",
      "Epoch number: 886/10000step_number: 0/29 Accuracy:  0.6729439809296782 Loss:  2.556628629315968 Val_accuracy:  0.6663034595478071 Val_cost:  2.556628629315968 Val_accuracy:  0.6663034595478071 Val_Acc:  2.5958984846500743\n",
      "Epoch number: 887/10000step_number: 0/29 Accuracy:  0.6737953345819854 Loss:  2.5562972935920643 Val_accuracy:  0.6672568782348134 Val_cost:  2.5562972935920643 Val_accuracy:  0.6672568782348134 Val_Acc:  2.5957074466640138\n",
      "Epoch number: 888/10000step_number: 0/29 Accuracy:  0.6738293887280776 Loss:  2.555965837790044 Val_accuracy:  0.6671206755652411 Val_cost:  2.555965837790044 Val_accuracy:  0.6671206755652411 Val_Acc:  2.5955160848786822\n",
      "Epoch number: 889/10000step_number: 0/29 Accuracy:  0.6740677677507236 Loss:  2.5556338588651912 Val_accuracy:  0.6672568782348134 Val_cost:  2.5556338588651912 Val_accuracy:  0.6672568782348134 Val_Acc:  2.595324098323847\n",
      "Epoch number: 890/10000step_number: 0/29 Accuracy:  0.6749531755491232 Loss:  2.5553009485931844 Val_accuracy:  0.6680740942522474 Val_cost:  2.5553009485931844 Val_accuracy:  0.6680740942522474 Val_Acc:  2.5951311579890124\n",
      "Epoch number: 891/10000step_number: 0/29 Accuracy:  0.6752937170100459 Loss:  2.5549666937900093 Val_accuracy:  0.668346499591392 Val_cost:  2.5549666937900093 Val_accuracy:  0.668346499591392 Val_Acc:  2.594936906599414\n",
      "Epoch number: 892/10000step_number: 0/29 Accuracy:  0.6754639877405074 Loss:  2.5546306753431405 Val_accuracy:  0.6684827022609643 Val_cost:  2.5546306753431405 Val_accuracy:  0.6684827022609643 Val_Acc:  2.594740957947604\n",
      "Epoch number: 893/10000step_number: 0/29 Accuracy:  0.6757023667631534 Loss:  2.554292466058106 Val_accuracy:  0.6686189049305367 Val_cost:  2.554292466058106 Val_accuracy:  0.6686189049305367 Val_Acc:  2.5945428955681007\n",
      "Epoch number: 894/10000step_number: 0/29 Accuracy:  0.6757704750553379 Loss:  2.553951627327002 Val_accuracy:  0.6690275129392536 Val_cost:  2.553951627327002 Val_accuracy:  0.6690275129392536 Val_Acc:  2.594342270558852\n",
      "Epoch number: 895/10000step_number: 0/29 Accuracy:  0.6758385833475226 Loss:  2.553607704629969 Val_accuracy:  0.6691637156088259 Val_cost:  2.553607704629969 Val_accuracy:  0.6691637156088259 Val_Acc:  2.5941385983723926\n",
      "Epoch number: 896/10000step_number: 0/29 Accuracy:  0.6763834496849992 Loss:  2.55326022188535 Val_accuracy:  0.6692999182783983 Val_cost:  2.55326022188535 Val_accuracy:  0.6692999182783983 Val_Acc:  2.593931354412309\n",
      "Epoch number: 897/10000step_number: 0/29 Accuracy:  0.6763153413928146 Loss:  2.552908674663195 Val_accuracy:  0.6691637156088259 Val_cost:  2.552908674663195 Val_accuracy:  0.6691637156088259 Val_Acc:  2.593719968267479\n",
      "Epoch number: 898/10000step_number: 0/29 Accuracy:  0.6766558828537375 Loss:  2.5525525222644836 Val_accuracy:  0.6698447289566876 Val_cost:  2.5525525222644836 Val_accuracy:  0.6698447289566876 Val_Acc:  2.59350381638867\n",
      "Epoch number: 899/10000step_number: 0/29 Accuracy:  0.6769283160224757 Loss:  2.552191178644902 Val_accuracy:  0.6701171342958322 Val_cost:  2.552191178644902 Val_accuracy:  0.6701171342958322 Val_Acc:  2.593282212955559\n",
      "Epoch number: 900/10000step_number: 0/29 Accuracy:  0.6769283160224757 Loss:  2.551824002136335 Val_accuracy:  0.6703895396349768 Val_cost:  2.551824002136335 Val_accuracy:  0.6703895396349768 Val_Acc:  2.593054398600655\n",
      "Epoch number: 901/10000step_number: 0/29 Accuracy:  0.6771666950451217 Loss:  2.551450283910556 Val_accuracy:  0.6703895396349768 Val_cost:  2.551450283910556 Val_accuracy:  0.6703895396349768 Val_Acc:  2.5928195265600995\n",
      "Epoch number: 902/10000step_number: 0/29 Accuracy:  0.6772348033373063 Loss:  2.551069235166548 Val_accuracy:  0.6702533369654046 Val_cost:  2.551069235166548 Val_accuracy:  0.6702533369654046 Val_Acc:  2.5925766457250883\n",
      "Epoch number: 903/10000step_number: 0/29 Accuracy:  0.6780861569896135 Loss:  2.5506799731450993 Val_accuracy:  0.6709343503132661 Val_cost:  2.5506799731450993 Val_accuracy:  0.6709343503132661 Val_Acc:  2.592324679992368\n",
      "Epoch number: 904/10000step_number: 0/29 Accuracy:  0.6785629150349055 Loss:  2.5502815063381274 Val_accuracy:  0.6721601743394171 Val_cost:  2.5502815063381274 Val_accuracy:  0.6721601743394171 Val_Acc:  2.5920624032870956\n",
      "Epoch number: 905/10000step_number: 0/29 Accuracy:  0.6792439979567513 Loss:  2.549872719754937 Val_accuracy:  0.6731135930264233 Val_cost:  2.549872719754937 Val_accuracy:  0.6731135930264233 Val_Acc:  2.5917884097075112\n",
      "Epoch number: 906/10000step_number: 0/29 Accuracy:  0.6807764345309041 Loss:  2.54945236198967 Val_accuracy:  0.6743394170525743 Val_cost:  2.54945236198967 Val_accuracy:  0.6743394170525743 Val_Acc:  2.5915010785234895\n",
      "Epoch number: 907/10000step_number: 0/29 Accuracy:  0.6807764345309041 Loss:  2.549019037401527 Val_accuracy:  0.6740670117134295 Val_cost:  2.549019037401527 Val_accuracy:  0.6740670117134295 Val_Acc:  2.591198534483669\n",
      "Epoch number: 908/10000step_number: 0/29 Accuracy:  0.681116975991827 Loss:  2.5485712095541206 Val_accuracy:  0.6740670117134295 Val_cost:  2.5485712095541206 Val_accuracy:  0.6740670117134295 Val_Acc:  2.5908786055698054\n",
      "Epoch number: 909/10000step_number: 0/29 Accuracy:  0.6815596798910267 Loss:  2.5481072272599348 Val_accuracy:  0.6744756197221465 Val_cost:  2.5481072272599348 Val_accuracy:  0.6744756197221465 Val_Acc:  2.590538784097797\n",
      "Epoch number: 910/10000step_number: 0/29 Accuracy:  0.6826834667120721 Loss:  2.5476253940172366 Val_accuracy:  0.6754290384091528 Val_cost:  2.5476253940172366 Val_accuracy:  0.6754290384091528 Val_Acc:  2.5901762050972095\n",
      "Epoch number: 911/10000step_number: 0/29 Accuracy:  0.6848969862080708 Loss:  2.547124117986834 Val_accuracy:  0.6773358757831653 Val_cost:  2.547124117986834 Val_accuracy:  0.6773358757831653 Val_Acc:  2.5897876720983857\n",
      "Epoch number: 912/10000step_number: 0/29 Accuracy:  0.6852034735229015 Loss:  2.546602205302662 Val_accuracy:  0.6777444837918823 Val_cost:  2.546602205302662 Val_accuracy:  0.6777444837918823 Val_Acc:  2.5893697906917135\n",
      "Epoch number: 913/10000step_number: 0/29 Accuracy:  0.6862591520517624 Loss:  2.5460593917763705 Val_accuracy:  0.6777444837918823 Val_cost:  2.5460593917763705 Val_accuracy:  0.6777444837918823 Val_Acc:  2.5889193204305134\n",
      "Epoch number: 914/10000step_number: 0/29 Accuracy:  0.6877575344798229 Loss:  2.545497225182259 Val_accuracy:  0.6792427131571779 Val_cost:  2.545497225182259 Val_accuracy:  0.6792427131571779 Val_Acc:  2.5884339217360988\n",
      "Epoch number: 915/10000step_number: 0/29 Accuracy:  0.6891197003235144 Loss:  2.544920341173599 Val_accuracy:  0.6803323345137565 Val_cost:  2.544920341173599 Val_accuracy:  0.6803323345137565 Val_Acc:  2.5879135111477263\n",
      "Epoch number: 916/10000step_number: 0/29 Accuracy:  0.6908224076281287 Loss:  2.544337872037921 Val_accuracy:  0.6823753745573413 Val_cost:  2.544337872037921 Val_accuracy:  0.6823753745573413 Val_Acc:  2.5873622996345205\n",
      "Epoch number: 917/10000step_number: 0/29 Accuracy:  0.6917759237187128 Loss:  2.5437640684192293 Val_accuracy:  0.6840098065922092 Val_cost:  2.5437640684192293 Val_accuracy:  0.6840098065922092 Val_Acc:  2.5867910181935785\n",
      "Epoch number: 918/10000step_number: 0/29 Accuracy:  0.6930359271241273 Loss:  2.5432166024683767 Val_accuracy:  0.6849632252792155 Val_cost:  2.5432166024683767 Val_accuracy:  0.6849632252792155 Val_Acc:  2.5862177989246473\n",
      "Epoch number: 919/10000step_number: 0/29 Accuracy:  0.6942278222373574 Loss:  2.5427118553261945 Val_accuracy:  0.6870062653228003 Val_cost:  2.5427118553261945 Val_accuracy:  0.6870062653228003 Val_Acc:  2.585665670265756\n",
      "Epoch number: 920/10000step_number: 0/29 Accuracy:  0.6948407968670186 Loss:  2.5422593963811853 Val_accuracy:  0.6876872786706619 Val_cost:  2.5422593963811853 Val_accuracy:  0.6876872786706619 Val_Acc:  2.585156399258357\n",
      "Epoch number: 921/10000step_number: 0/29 Accuracy:  0.6954537714966798 Loss:  2.541859509123016 Val_accuracy:  0.6879596840098066 Val_cost:  2.541859509123016 Val_accuracy:  0.6879596840098066 Val_Acc:  2.5847039005500005\n",
      "Epoch number: 922/10000step_number: 0/29 Accuracy:  0.6960667461263409 Loss:  2.541504969341742 Val_accuracy:  0.6882320893489512 Val_cost:  2.541504969341742 Val_accuracy:  0.6882320893489512 Val_Acc:  2.584311563314319\n",
      "Epoch number: 923/10000step_number: 0/29 Accuracy:  0.6965435041716329 Loss:  2.541185004950302 Val_accuracy:  0.6886406973576682 Val_cost:  2.541185004950302 Val_accuracy:  0.6886406973576682 Val_Acc:  2.583974574819792\n",
      "Epoch number: 924/10000step_number: 0/29 Accuracy:  0.6971905329473863 Loss:  2.540888873319774 Val_accuracy:  0.6887769000272406 Val_cost:  2.540888873319774 Val_accuracy:  0.6887769000272406 Val_Acc:  2.5836842889161398\n",
      "Epoch number: 925/10000step_number: 0/29 Accuracy:  0.6975991827004938 Loss:  2.5406076743365 Val_accuracy:  0.6891855080359575 Val_cost:  2.5406076743365 Val_accuracy:  0.6891855080359575 Val_Acc:  2.5834313999924747\n",
      "Epoch number: 926/10000step_number: 0/29 Accuracy:  0.697735399284863 Loss:  2.540334584067977 Val_accuracy:  0.6891855080359575 Val_cost:  2.540334584067977 Val_accuracy:  0.6891855080359575 Val_Acc:  2.583207263435608\n",
      "Epoch number: 927/10000step_number: 0/29 Accuracy:  0.697973778307509 Loss:  2.540064467625542 Val_accuracy:  0.6893217107055298 Val_cost:  2.540064467625542 Val_accuracy:  0.6893217107055298 Val_Acc:  2.5830042610670056\n",
      "Epoch number: 928/10000step_number: 0/29 Accuracy:  0.6984845904988932 Loss:  2.5397934977469276 Val_accuracy:  0.6894579133751022 Val_cost:  2.5397934977469276 Val_accuracy:  0.6894579133751022 Val_Acc:  2.5828159085808298\n",
      "Epoch number: 929/10000step_number: 0/29 Accuracy:  0.6986548612293547 Loss:  2.5395189145426453 Val_accuracy:  0.6895941160446745 Val_cost:  2.5395189145426453 Val_accuracy:  0.6895941160446745 Val_Acc:  2.5826369556524975\n",
      "Epoch number: 930/10000step_number: 0/29 Accuracy:  0.6988251319598161 Loss:  2.5392388831256456 Val_accuracy:  0.6897303187142468 Val_cost:  2.5392388831256456 Val_accuracy:  0.6897303187142468 Val_Acc:  2.5824635664200346\n",
      "Epoch number: 931/10000step_number: 0/29 Accuracy:  0.6988591861059084 Loss:  2.5389523491310557 Val_accuracy:  0.6897303187142468 Val_cost:  2.5389523491310557 Val_accuracy:  0.6897303187142468 Val_Acc:  2.5822935312442574\n",
      "Epoch number: 932/10000step_number: 0/29 Accuracy:  0.6989613485441852 Loss:  2.538658754414152 Val_accuracy:  0.6897303187142468 Val_cost:  2.538658754414152 Val_accuracy:  0.6897303187142468 Val_Acc:  2.582126189053902\n",
      "Epoch number: 933/10000step_number: 0/29 Accuracy:  0.6988251319598161 Loss:  2.5383575486565944 Val_accuracy:  0.6898665213838191 Val_cost:  2.5383575486565944 Val_accuracy:  0.6898665213838191 Val_Acc:  2.581961582146657\n",
      "Epoch number: 934/10000step_number: 0/29 Accuracy:  0.6987910778137238 Loss:  2.538047727105962 Val_accuracy:  0.6898665213838191 Val_cost:  2.538047727105962 Val_accuracy:  0.6898665213838191 Val_Acc:  2.581798991897828\n",
      "Epoch number: 935/10000step_number: 0/29 Accuracy:  0.6987910778137238 Loss:  2.5377278176791447 Val_accuracy:  0.6898665213838191 Val_cost:  2.5377278176791447 Val_accuracy:  0.6898665213838191 Val_Acc:  2.581636121386818\n",
      "Epoch number: 936/10000step_number: 0/29 Accuracy:  0.6984164822067087 Loss:  2.53739630016686 Val_accuracy:  0.6898665213838191 Val_cost:  2.53739630016686 Val_accuracy:  0.6898665213838191 Val_Acc:  2.5814698507162928\n",
      "Epoch number: 937/10000step_number: 0/29 Accuracy:  0.6984164822067087 Loss:  2.5370522107899234 Val_accuracy:  0.6897303187142468 Val_cost:  2.5370522107899234 Val_accuracy:  0.6897303187142468 Val_Acc:  2.581297819145418\n",
      "Epoch number: 938/10000step_number: 0/29 Accuracy:  0.698450536352801 Loss:  2.5366960033177235 Val_accuracy:  0.6897303187142468 Val_cost:  2.5366960033177235 Val_accuracy:  0.6897303187142468 Val_Acc:  2.5811194472222367\n",
      "Epoch number: 939/10000step_number: 0/29 Accuracy:  0.6981781031840627 Loss:  2.536329440119599 Val_accuracy:  0.6894579133751022 Val_cost:  2.536329440119599 Val_accuracy:  0.6894579133751022 Val_Acc:  2.580935405945404\n",
      "Epoch number: 940/10000step_number: 0/29 Accuracy:  0.6982462114762472 Loss:  2.5359539523171 Val_accuracy:  0.6890493053663852 Val_cost:  2.5359539523171 Val_accuracy:  0.6890493053663852 Val_Acc:  2.5807461221923558\n",
      "Epoch number: 941/10000step_number: 0/29 Accuracy:  0.6981781031840627 Loss:  2.53556996417434 Val_accuracy:  0.6887769000272406 Val_cost:  2.53556996417434 Val_accuracy:  0.6887769000272406 Val_Acc:  2.580551220543126\n",
      "Epoch number: 942/10000step_number: 0/29 Accuracy:  0.6981440490379703 Loss:  2.5351776408963986 Val_accuracy:  0.6886406973576682 Val_cost:  2.5351776408963986 Val_accuracy:  0.6886406973576682 Val_Acc:  2.580350066709841\n",
      "Epoch number: 943/10000step_number: 0/29 Accuracy:  0.6982802656223395 Loss:  2.5347773415478634 Val_accuracy:  0.6887769000272406 Val_cost:  2.5347773415478634 Val_accuracy:  0.6887769000272406 Val_Acc:  2.580142130605273\n",
      "Epoch number: 944/10000step_number: 0/29 Accuracy:  0.6981781031840627 Loss:  2.5343695355276665 Val_accuracy:  0.6887769000272406 Val_cost:  2.5343695355276665 Val_accuracy:  0.6887769000272406 Val_Acc:  2.5799269694916447\n",
      "Epoch number: 945/10000step_number: 0/29 Accuracy:  0.698212157330155 Loss:  2.5339547733316397 Val_accuracy:  0.6887769000272406 Val_cost:  2.5339547733316397 Val_accuracy:  0.6887769000272406 Val_Acc:  2.5797042626327893\n",
      "Epoch number: 946/10000step_number: 0/29 Accuracy:  0.6982462114762472 Loss:  2.5335337166646004 Val_accuracy:  0.6890493053663852 Val_cost:  2.5335337166646004 Val_accuracy:  0.6890493053663852 Val_Acc:  2.5794738466693037\n",
      "Epoch number: 947/10000step_number: 0/29 Accuracy:  0.6983824280606163 Loss:  2.533107151218053 Val_accuracy:  0.6891855080359575 Val_cost:  2.533107151218053 Val_accuracy:  0.6891855080359575 Val_Acc:  2.5792357253796254\n",
      "Epoch number: 948/10000step_number: 0/29 Accuracy:  0.6982802656223395 Loss:  2.5326759727831716 Val_accuracy:  0.6893217107055298 Val_cost:  2.5326759727831716 Val_accuracy:  0.6893217107055298 Val_Acc:  2.5789900517846394\n",
      "Epoch number: 949/10000step_number: 0/29 Accuracy:  0.6983824280606163 Loss:  2.532241159686379 Val_accuracy:  0.6890493053663852 Val_cost:  2.532241159686379 Val_accuracy:  0.6890493053663852 Val_Acc:  2.5787371036996976\n",
      "Epoch number: 950/10000step_number: 0/29 Accuracy:  0.6984164822067087 Loss:  2.531803753259342 Val_accuracy:  0.6890493053663852 Val_cost:  2.531803753259342 Val_accuracy:  0.6890493053663852 Val_Acc:  2.578477267891879\n",
      "Epoch number: 951/10000step_number: 0/29 Accuracy:  0.6985867529371701 Loss:  2.531364839792682 Val_accuracy:  0.6889131026968128 Val_cost:  2.531364839792682 Val_accuracy:  0.6889131026968128 Val_Acc:  2.578211028073315\n",
      "Epoch number: 952/10000step_number: 0/29 Accuracy:  0.6987229695215392 Loss:  2.530925540644708 Val_accuracy:  0.6890493053663852 Val_cost:  2.530925540644708 Val_accuracy:  0.6890493053663852 Val_Acc:  2.5779389627340237\n",
      "Epoch number: 953/10000step_number: 0/29 Accuracy:  0.6988591861059084 Loss:  2.5304870005550577 Val_accuracy:  0.6891855080359575 Val_cost:  2.5304870005550577 Val_accuracy:  0.6891855080359575 Val_Acc:  2.5776617404175632\n",
      "Epoch number: 954/10000step_number: 0/29 Accuracy:  0.6989954026902775 Loss:  2.530050374489114 Val_accuracy:  0.6891855080359575 Val_cost:  2.530050374489114 Val_accuracy:  0.6891855080359575 Val_Acc:  2.5773801136899146\n",
      "Epoch number: 955/10000step_number: 0/29 Accuracy:  0.6992678358590159 Loss:  2.5296168078199885 Val_accuracy:  0.6894579133751022 Val_cost:  2.5296168078199885 Val_accuracy:  0.6894579133751022 Val_Acc:  2.5770949053770327\n",
      "Epoch number: 956/10000step_number: 0/29 Accuracy:  0.6998467563425848 Loss:  2.5291874102426783 Val_accuracy:  0.6898665213838191 Val_cost:  2.5291874102426783 Val_accuracy:  0.6898665213838191 Val_Acc:  2.576806989082719\n",
      "Epoch number: 957/10000step_number: 0/29 Accuracy:  0.7001872978035075 Loss:  2.5287632259550366 Val_accuracy:  0.6904113320621084 Val_cost:  2.5287632259550366 Val_accuracy:  0.6904113320621084 Val_Acc:  2.576517264873724\n",
      "Epoch number: 958/10000step_number: 0/29 Accuracy:  0.700357568533969 Loss:  2.5283452042596273 Val_accuracy:  0.6904113320621084 Val_cost:  2.5283452042596273 Val_accuracy:  0.6904113320621084 Val_Acc:  2.5762266329552244\n",
      "Epoch number: 959/10000step_number: 0/29 Accuracy:  0.7005618934105228 Loss:  2.5279341763103997 Val_accuracy:  0.6908199400708254 Val_cost:  2.5279341763103997 Val_accuracy:  0.6908199400708254 Val_Acc:  2.5759359687731584\n",
      "Epoch number: 960/10000step_number: 0/29 Accuracy:  0.7009705431636302 Loss:  2.527530840308231 Val_accuracy:  0.69109234540997 Val_cost:  2.527530840308231 Val_accuracy:  0.69109234540997 Val_Acc:  2.575646101029552\n",
      "Epoch number: 961/10000step_number: 0/29 Accuracy:  0.7009364890175379 Loss:  2.5271357560098044 Val_accuracy:  0.69109234540997 Val_cost:  2.5271357560098044 Val_accuracy:  0.69109234540997 Val_Acc:  2.575357794437035\n",
      "Epoch number: 962/10000step_number: 0/29 Accuracy:  0.701311084624553 Loss:  2.526749346267506 Val_accuracy:  0.6912285480795424 Val_cost:  2.526749346267506 Val_accuracy:  0.6912285480795424 Val_Acc:  2.5750717368348974\n",
      "Epoch number: 963/10000step_number: 0/29 Accuracy:  0.7017197343776604 Loss:  2.5263719032791276 Val_accuracy:  0.6912285480795424 Val_cost:  2.5263719032791276 Val_accuracy:  0.6912285480795424 Val_Acc:  2.574788530711837\n",
      "Epoch number: 964/10000step_number: 0/29 Accuracy:  0.7019581134003064 Loss:  2.526003597285627 Val_accuracy:  0.6916371560882594 Val_cost:  2.526003597285627 Val_accuracy:  0.6916371560882594 Val_Acc:  2.5745086883483084\n",
      "Epoch number: 965/10000step_number: 0/29 Accuracy:  0.702128384130768 Loss:  2.5256444863993956 Val_accuracy:  0.691909561427404 Val_cost:  2.5256444863993956 Val_accuracy:  0.691909561427404 Val_Acc:  2.574232630135841\n",
      "Epoch number: 966/10000step_number: 0/29 Accuracy:  0.702366763153414 Loss:  2.5252945269682323 Val_accuracy:  0.6920457640969763 Val_cost:  2.5252945269682323 Val_accuracy:  0.6920457640969763 Val_Acc:  2.57396068554896\n",
      "Epoch number: 967/10000step_number: 0/29 Accuracy:  0.7025370338838753 Loss:  2.5249535841950275 Val_accuracy:  0.6921819667665486 Val_cost:  2.5249535841950275 Val_accuracy:  0.6921819667665486 Val_Acc:  2.5736930962694387\n",
      "Epoch number: 968/10000step_number: 0/29 Accuracy:  0.7026391963221522 Loss:  2.524621442976281 Val_accuracy:  0.6921819667665486 Val_cost:  2.524621442976281 Val_accuracy:  0.6921819667665486 Val_Acc:  2.573430021049872\n",
      "Epoch number: 969/10000step_number: 0/29 Accuracy:  0.7014813553550144 Loss:  2.5242978188120553 Val_accuracy:  0.6912285480795424 Val_cost:  2.5242978188120553 Val_accuracy:  0.6912285480795424 Val_Acc:  2.5731715418144714\n",
      "Epoch number: 970/10000step_number: 0/29 Accuracy:  0.7016856802315682 Loss:  2.5239823686435603 Val_accuracy:  0.6913647507491146 Val_cost:  2.5239823686435603 Val_accuracy:  0.6913647507491146 Val_Acc:  2.5729176706140224\n",
      "Epoch number: 971/10000step_number: 0/29 Accuracy:  0.7017537885237528 Loss:  2.523674701387179 Val_accuracy:  0.6913647507491146 Val_cost:  2.523674701387179 Val_accuracy:  0.6913647507491146 Val_Acc:  2.572668357041694\n",
      "Epoch number: 972/10000step_number: 0/29 Accuracy:  0.7018900051081219 Loss:  2.5233743879533583 Val_accuracy:  0.6912285480795424 Val_cost:  2.5233743879533583 Val_accuracy:  0.6912285480795424 Val_Acc:  2.5724234958323606\n",
      "Epoch number: 973/10000step_number: 0/29 Accuracy:  0.7020602758385833 Loss:  2.523080970566449 Val_accuracy:  0.6912285480795424 Val_cost:  2.523080970566449 Val_accuracy:  0.6912285480795424 Val_Acc:  2.572182934413619\n",
      "Epoch number: 974/10000step_number: 0/29 Accuracy:  0.7021624382768602 Loss:  2.5227939712527707 Val_accuracy:  0.6912285480795424 Val_cost:  2.5227939712527707 Val_accuracy:  0.6912285480795424 Val_Acc:  2.5719464802407375\n",
      "Epoch number: 975/10000step_number: 0/29 Accuracy:  0.7023327090073216 Loss:  2.522512899422095 Val_accuracy:  0.6912285480795424 Val_cost:  2.522512899422095 Val_accuracy:  0.6912285480795424 Val_Acc:  2.5717139077848525\n",
      "Epoch number: 976/10000step_number: 0/29 Accuracy:  0.7022986548612293 Loss:  2.5222372585101653 Val_accuracy:  0.6913647507491146 Val_cost:  2.5222372585101653 Val_accuracy:  0.6913647507491146 Val_Acc:  2.5714849650690574\n",
      "Epoch number: 977/10000step_number: 0/29 Accuracy:  0.702366763153414 Loss:  2.5219665516911394 Val_accuracy:  0.691500953418687 Val_cost:  2.5219665516911394 Val_accuracy:  0.691500953418687 Val_Acc:  2.57125937967523\n",
      "Epoch number: 978/10000step_number: 0/29 Accuracy:  0.7025029797377831 Loss:  2.5217002866953133 Val_accuracy:  0.691500953418687 Val_cost:  2.5217002866953133 Val_accuracy:  0.691500953418687 Val_Acc:  2.5710368641650114\n",
      "Epoch number: 979/10000step_number: 0/29 Accuracy:  0.7026732504682445 Loss:  2.521437979790037 Val_accuracy:  0.6916371560882594 Val_cost:  2.521437979790037 Val_accuracy:  0.6916371560882594 Val_Acc:  2.5708171208862556\n",
      "Epoch number: 980/10000step_number: 0/29 Accuracy:  0.7026732504682445 Loss:  2.52117915899612 Val_accuracy:  0.6917733587578316 Val_cost:  2.52117915899612 Val_accuracy:  0.6917733587578316 Val_Acc:  2.5705998461595394\n",
      "Epoch number: 981/10000step_number: 0/29 Accuracy:  0.7027413587604291 Loss:  2.52092336662182 Val_accuracy:  0.6917733587578316 Val_cost:  2.52092336662182 Val_accuracy:  0.6917733587578316 Val_Acc:  2.57038473386355\n",
      "Epoch number: 982/10000step_number: 0/29 Accuracy:  0.702843521198706 Loss:  2.520670161201461 Val_accuracy:  0.6920457640969763 Val_cost:  2.520670161201461 Val_accuracy:  0.6920457640969763 Val_Acc:  2.570171478457577\n",
      "Epoch number: 983/10000step_number: 0/29 Accuracy:  0.7029116294908905 Loss:  2.5204191189260636 Val_accuracy:  0.6920457640969763 Val_cost:  2.5204191189260636 Val_accuracy:  0.6920457640969763 Val_Acc:  2.569959777494603\n",
      "Epoch number: 984/10000step_number: 0/29 Accuracy:  0.7029797377830751 Loss:  2.520169834649286 Val_accuracy:  0.6920457640969763 Val_cost:  2.520169834649286 Val_accuracy:  0.6920457640969763 Val_Acc:  2.569749333686858\n",
      "Epoch number: 985/10000step_number: 0/29 Accuracy:  0.7029797377830751 Loss:  2.519921922542512 Val_accuracy:  0.6920457640969763 Val_cost:  2.519921922542512 Val_accuracy:  0.6920457640969763 Val_Acc:  2.569539856586401\n",
      "Epoch number: 986/10000step_number: 0/29 Accuracy:  0.7029456836369828 Loss:  2.5196750164579025 Val_accuracy:  0.6920457640969763 Val_cost:  2.5196750164579025 Val_accuracy:  0.6920457640969763 Val_Acc:  2.569331063933466\n",
      "Epoch number: 987/10000step_number: 0/29 Accuracy:  0.7030478460752596 Loss:  2.519428770036564 Val_accuracy:  0.6920457640969763 Val_cost:  2.519428770036564 Val_accuracy:  0.6920457640969763 Val_Acc:  2.56912268270409\n",
      "Epoch number: 988/10000step_number: 0/29 Accuracy:  0.7031840626596289 Loss:  2.5191828565701107 Val_accuracy:  0.6921819667665486 Val_cost:  2.5191828565701107 Val_accuracy:  0.6921819667665486 Val_Acc:  2.5689144498530636\n",
      "Epoch number: 989/10000step_number: 0/29 Accuracy:  0.7032862250979056 Loss:  2.518936968585514 Val_accuracy:  0.6921819667665486 Val_cost:  2.518936968585514 Val_accuracy:  0.6921819667665486 Val_Acc:  2.568706112696535\n",
      "Epoch number: 990/10000step_number: 0/29 Accuracy:  0.7039673080197514 Loss:  2.518690817070557 Val_accuracy:  0.6925905747752656 Val_cost:  2.518690817070557 Val_accuracy:  0.6925905747752656 Val_Acc:  2.568497428805207\n",
      "Epoch number: 991/10000step_number: 0/29 Accuracy:  0.704273795334582 Loss:  2.51844413018097 Val_accuracy:  0.6927267774448379 Val_cost:  2.51844413018097 Val_accuracy:  0.6927267774448379 Val_Acc:  2.568288165175311\n",
      "Epoch number: 992/10000step_number: 0/29 Accuracy:  0.7043759577728589 Loss:  2.51819665115604 Val_accuracy:  0.6929991827839825 Val_cost:  2.51819665115604 Val_accuracy:  0.6929991827839825 Val_Acc:  2.568078096294498\n",
      "Epoch number: 993/10000step_number: 0/29 Accuracy:  0.7045462285033203 Loss:  2.5179481350034583 Val_accuracy:  0.6925905747752656 Val_cost:  2.5179481350034583 Val_accuracy:  0.6925905747752656 Val_Acc:  2.5678670005085302\n",
      "Epoch number: 994/10000step_number: 0/29 Accuracy:  0.7048527158181509 Loss:  2.5176983433018454 Val_accuracy:  0.6923181694361209 Val_cost:  2.5176983433018454 Val_accuracy:  0.6923181694361209 Val_Acc:  2.567654653821802\n",
      "Epoch number: 995/10000step_number: 0/29 Accuracy:  0.7048867699642432 Loss:  2.5174470362788814 Val_accuracy:  0.6923181694361209 Val_cost:  2.5174470362788814 Val_accuracy:  0.6923181694361209 Val_Acc:  2.567440819996664\n",
      "Epoch number: 996/10000step_number: 0/29 Accuracy:  0.70498893240252 Loss:  2.517193961362311 Val_accuracy:  0.6923181694361209 Val_cost:  2.517193961362311 Val_accuracy:  0.6923181694361209 Val_Acc:  2.567225235776306\n",
      "Epoch number: 997/10000step_number: 0/29 Accuracy:  0.7050570406947045 Loss:  2.516938838108849 Val_accuracy:  0.6924543721056933 Val_cost:  2.516938838108849 Val_accuracy:  0.6924543721056933 Val_Acc:  2.5670075907585694\n",
      "Epoch number: 998/10000step_number: 0/29 Accuracy:  0.7056700153243658 Loss:  2.516681341443471 Val_accuracy:  0.6927267774448379 Val_cost:  2.516681341443471 Val_accuracy:  0.6927267774448379 Val_Acc:  2.566787503762055\n",
      "Epoch number: 999/10000step_number: 0/29 Accuracy:  0.7045802826494125 Loss:  2.516421088945904 Val_accuracy:  0.6913647507491146 Val_cost:  2.516421088945904 Val_accuracy:  0.6913647507491146 Val_Acc:  2.566564502355481\n",
      "Epoch number: 1000/10000step_number: 0/29 Accuracy:  0.7043759577728589 Loss:  2.5161576427736665 Val_accuracy:  0.6902751293925361 Val_cost:  2.5161576427736665 Val_accuracy:  0.6902751293925361 Val_Acc:  2.566338019414842\n",
      "Epoch number: 1001/10000step_number: 0/29 Accuracy:  0.7047846075259663 Loss:  2.515890539933406 Val_accuracy:  0.6901389267229637 Val_cost:  2.515890539933406 Val_accuracy:  0.6901389267229637 Val_Acc:  2.5661074272928976\n",
      "Epoch number: 1002/10000step_number: 0/29 Accuracy:  0.7051251489868892 Loss:  2.5156193621708707 Val_accuracy:  0.6909561427403977 Val_cost:  2.5156193621708707 Val_accuracy:  0.6909561427403977 Val_Acc:  2.5658721301480543\n",
      "Epoch number: 1003/10000step_number: 0/29 Accuracy:  0.7051592031329814 Loss:  2.515343845917777 Val_accuracy:  0.69109234540997 Val_cost:  2.515343845917777 Val_accuracy:  0.69109234540997 Val_Acc:  2.565631719569839\n",
      "Epoch number: 1004/10000step_number: 0/29 Accuracy:  0.7053975821556274 Loss:  2.515064010362583 Val_accuracy:  0.6913647507491146 Val_cost:  2.515064010362583 Val_accuracy:  0.6913647507491146 Val_Acc:  2.5653861607158492\n",
      "Epoch number: 1005/10000step_number: 0/29 Accuracy:  0.705465690447812 Loss:  2.5147802465147167 Val_accuracy:  0.6913647507491146 Val_cost:  2.5147802465147167 Val_accuracy:  0.6913647507491146 Val_Acc:  2.565135923687344\n",
      "Epoch number: 1006/10000step_number: 0/29 Accuracy:  0.7055678528860889 Loss:  2.5144932855434328 Val_accuracy:  0.6913647507491146 Val_cost:  2.5144932855434328 Val_accuracy:  0.6913647507491146 Val_Acc:  2.5648819522139825\n",
      "Epoch number: 1007/10000step_number: 0/29 Accuracy:  0.7056700153243658 Loss:  2.5142040060312 Val_accuracy:  0.691500953418687 Val_cost:  2.5142040060312 Val_accuracy:  0.691500953418687 Val_Acc:  2.564625428948293\n",
      "Epoch number: 1008/10000step_number: 0/29 Accuracy:  0.7059424484931041 Loss:  2.513913154679461 Val_accuracy:  0.691500953418687 Val_cost:  2.513913154679461 Val_accuracy:  0.691500953418687 Val_Acc:  2.56436743572954\n",
      "Epoch number: 1009/10000step_number: 0/29 Accuracy:  0.7060446109313809 Loss:  2.513621135297878 Val_accuracy:  0.691500953418687 Val_cost:  2.513621135297878 Val_accuracy:  0.691500953418687 Val_Acc:  2.5641086876826\n",
      "Epoch number: 1010/10000step_number: 0/29 Accuracy:  0.7061808275157501 Loss:  2.5133279674394258 Val_accuracy:  0.6916371560882594 Val_cost:  2.5133279674394258 Val_accuracy:  0.6916371560882594 Val_Acc:  2.563849452074767\n",
      "Epoch number: 1011/10000step_number: 0/29 Accuracy:  0.7064192065383961 Loss:  2.51303338923212 Val_accuracy:  0.6916371560882594 Val_cost:  2.51303338923212 Val_accuracy:  0.6916371560882594 Val_Acc:  2.5635896267858573\n",
      "Epoch number: 1012/10000step_number: 0/29 Accuracy:  0.7064532606844883 Loss:  2.5127370079877767 Val_accuracy:  0.691909561427404 Val_cost:  2.5127370079877767 Val_accuracy:  0.691909561427404 Val_Acc:  2.5633288819577738\n",
      "Epoch number: 1013/10000step_number: 0/29 Accuracy:  0.7066575855610421 Loss:  2.5124384207307604 Val_accuracy:  0.691909561427404 Val_cost:  2.5124384207307604 Val_accuracy:  0.691909561427404 Val_Acc:  2.5630667872640918\n",
      "Epoch number: 1014/10000step_number: 0/29 Accuracy:  0.7068619104375958 Loss:  2.5121372792172996 Val_accuracy:  0.6921819667665486 Val_cost:  2.5121372792172996 Val_accuracy:  0.6921819667665486 Val_Acc:  2.5628028963586007\n",
      "Epoch number: 1015/10000step_number: 0/29 Accuracy:  0.7069300187297803 Loss:  2.5118333096546044 Val_accuracy:  0.6921819667665486 Val_cost:  2.5118333096546044 Val_accuracy:  0.6921819667665486 Val_Acc:  2.5625367920799595\n",
      "Epoch number: 1016/10000step_number: 0/29 Accuracy:  0.7069640728758726 Loss:  2.511526306897732 Val_accuracy:  0.6924543721056933 Val_cost:  2.511526306897732 Val_accuracy:  0.6924543721056933 Val_Acc:  2.5622681052916945\n",
      "Epoch number: 1017/10000step_number: 0/29 Accuracy:  0.7072024518985186 Loss:  2.511216118505586 Val_accuracy:  0.6925905747752656 Val_cost:  2.511216118505586 Val_accuracy:  0.6925905747752656 Val_Acc:  2.5619965184640843\n",
      "Epoch number: 1018/10000step_number: 0/29 Accuracy:  0.7083943470117486 Loss:  2.510902627037132 Val_accuracy:  0.6939526014709888 Val_cost:  2.510902627037132 Val_accuracy:  0.6939526014709888 Val_Acc:  2.5617217611598972\n",
      "Epoch number: 1019/10000step_number: 0/29 Accuracy:  0.7083262387195641 Loss:  2.5105857340174587 Val_accuracy:  0.6939526014709888 Val_cost:  2.5105857340174587 Val_accuracy:  0.6939526014709888 Val_Acc:  2.561443601598399\n",
      "Epoch number: 1020/10000step_number: 0/29 Accuracy:  0.7084624553039333 Loss:  2.510265346472699 Val_accuracy:  0.6940888041405612 Val_cost:  2.510265346472699 Val_accuracy:  0.6940888041405612 Val_Acc:  2.561161836666246\n",
      "Epoch number: 1021/10000step_number: 0/29 Accuracy:  0.708428401157841 Loss:  2.5099413658886993 Val_accuracy:  0.6940888041405612 Val_cost:  2.5099413658886993 Val_accuracy:  0.6940888041405612 Val_Acc:  2.560876281660601\n",
      "Epoch number: 1022/10000step_number: 0/29 Accuracy:  0.7085986718883024 Loss:  2.509613679071706 Val_accuracy:  0.6940888041405612 Val_cost:  2.509613679071706 Val_accuracy:  0.6940888041405612 Val_Acc:  2.560586760359358\n",
      "Epoch number: 1023/10000step_number: 0/29 Accuracy:  0.7087689426187639 Loss:  2.509282150266602 Val_accuracy:  0.6942250068101334 Val_cost:  2.509282150266602 Val_accuracy:  0.6942250068101334 Val_Acc:  2.5602930955814123\n",
      "Epoch number: 1024/10000step_number: 0/29 Accuracy:  0.7090754299335944 Loss:  2.5089466138827574 Val_accuracy:  0.6947698174884228 Val_cost:  2.5089466138827574 Val_accuracy:  0.6947698174884228 Val_Acc:  2.5599951001775816\n",
      "Epoch number: 1025/10000step_number: 0/29 Accuracy:  0.7091775923718713 Loss:  2.5086068672682704 Val_accuracy:  0.6950422228275674 Val_cost:  2.5086068672682704 Val_accuracy:  0.6950422228275674 Val_Acc:  2.559692568339709\n",
      "Epoch number: 1026/10000step_number: 0/29 Accuracy:  0.7079175889664566 Loss:  2.5082626631550164 Val_accuracy:  0.6940888041405612 Val_cost:  2.5082626631550164 Val_accuracy:  0.6940888041405612 Val_Acc:  2.559385267176697\n",
      "Epoch number: 1027/10000step_number: 0/29 Accuracy:  0.708190022135195 Loss:  2.507913701643326 Val_accuracy:  0.6946336148188504 Val_cost:  2.507913701643326 Val_accuracy:  0.6946336148188504 Val_Acc:  2.559072928618025\n",
      "Epoch number: 1028/10000step_number: 0/29 Accuracy:  0.708190022135195 Loss:  2.5075596218588254 Val_accuracy:  0.6947698174884228 Val_cost:  2.5075596218588254 Val_accuracy:  0.6947698174884228 Val_Acc:  2.5587552418040835\n",
      "Epoch number: 1029/10000step_number: 0/29 Accuracy:  0.7084624553039333 Loss:  2.507199993634831 Val_accuracy:  0.6950422228275674 Val_cost:  2.507199993634831 Val_accuracy:  0.6950422228275674 Val_Acc:  2.5584318461570876\n",
      "Epoch number: 1030/10000step_number: 0/29 Accuracy:  0.7087348884726715 Loss:  2.506834309681185 Val_accuracy:  0.6954508308362843 Val_cost:  2.506834309681185 Val_accuracy:  0.6954508308362843 Val_Acc:  2.5581023252442687\n",
      "Epoch number: 1031/10000step_number: 0/29 Accuracy:  0.7088029967648561 Loss:  2.5064619786279074 Val_accuracy:  0.6958594388450013 Val_cost:  2.5064619786279074 Val_accuracy:  0.6958594388450013 Val_Acc:  2.557766201296794\n",
      "Epoch number: 1032/10000step_number: 0/29 Accuracy:  0.708905159203133 Loss:  2.5060823190823833 Val_accuracy:  0.6958594388450013 Val_cost:  2.5060823190823833 Val_accuracy:  0.6958594388450013 Val_Acc:  2.5574229298026836\n",
      "Epoch number: 1033/10000step_number: 0/29 Accuracy:  0.7092797548101482 Loss:  2.5056945546200198 Val_accuracy:  0.696131844184146 Val_cost:  2.5056945546200198 Val_accuracy:  0.696131844184146 Val_Acc:  2.557071893006887\n",
      "Epoch number: 1034/10000step_number: 0/29 Accuracy:  0.7092797548101482 Loss:  2.505297809953621 Val_accuracy:  0.6962680468537183 Val_cost:  2.505297809953621 Val_accuracy:  0.6962680468537183 Val_Acc:  2.5567123906148854\n",
      "Epoch number: 1035/10000step_number: 0/29 Accuracy:  0.7116975991827005 Loss:  2.50489111000736 Val_accuracy:  0.6983110868973031 Val_cost:  2.50489111000736 Val_accuracy:  0.6983110868973031 Val_Acc:  2.5563436257427425\n",
      "Epoch number: 1036/10000step_number: 0/29 Accuracy:  0.7116975991827005 Loss:  2.5044733862514224 Val_accuracy:  0.6981748842277309 Val_cost:  2.5044733862514224 Val_accuracy:  0.6981748842277309 Val_Acc:  2.555964684195456\n",
      "Epoch number: 1037/10000step_number: 0/29 Accuracy:  0.711629490890516 Loss:  2.504043496868753 Val_accuracy:  0.6981748842277309 Val_cost:  2.504043496868753 Val_accuracy:  0.6981748842277309 Val_Acc:  2.5555745050325185\n",
      "Epoch number: 1038/10000step_number: 0/29 Accuracy:  0.7126851694193768 Loss:  2.5036002653517913 Val_accuracy:  0.6992645055843094 Val_cost:  2.5036002653517913 Val_accuracy:  0.6992645055843094 Val_Acc:  2.5551718392774165\n",
      "Epoch number: 1039/10000step_number: 0/29 Accuracy:  0.7128554401498383 Loss:  2.5031425296144625 Val_accuracy:  0.6998093162625988 Val_cost:  2.5031425296144625 Val_accuracy:  0.6998093162625988 Val_Acc:  2.5547551906634554\n",
      "Epoch number: 1040/10000step_number: 0/29 Accuracy:  0.7129916567342074 Loss:  2.5026691623969737 Val_accuracy:  0.699945518932171 Val_cost:  2.5026691623969737 Val_accuracy:  0.699945518932171 Val_Acc:  2.5543227264885346\n",
      "Epoch number: 1041/10000step_number: 0/29 Accuracy:  0.7132640899029457 Loss:  2.502178970750498 Val_accuracy:  0.6996731135930264 Val_cost:  2.502178970750498 Val_accuracy:  0.6996731135930264 Val_Acc:  2.5538721368137365\n",
      "Epoch number: 1042/10000step_number: 0/29 Accuracy:  0.7135705772177763 Loss:  2.5016703331817394 Val_accuracy:  0.6996731135930264 Val_cost:  2.5016703331817394 Val_accuracy:  0.6996731135930264 Val_Acc:  2.553400408377436\n",
      "Epoch number: 1043/10000step_number: 0/29 Accuracy:  0.7136046313638685 Loss:  2.5011404694553994 Val_accuracy:  0.6998093162625988 Val_cost:  2.5011404694553994 Val_accuracy:  0.6998093162625988 Val_Acc:  2.5529034819241243\n",
      "Epoch number: 1044/10000step_number: 0/29 Accuracy:  0.7137408479482377 Loss:  2.500584459525594 Val_accuracy:  0.7000817216017434 Val_cost:  2.500584459525594 Val_accuracy:  0.7000817216017434 Val_Acc:  2.552375815214286\n",
      "Epoch number: 1045/10000step_number: 0/29 Accuracy:  0.7140473352630683 Loss:  2.499994476584486 Val_accuracy:  0.7002179242713157 Val_cost:  2.499994476584486 Val_accuracy:  0.7002179242713157 Val_Acc:  2.551810010074629\n",
      "Epoch number: 1046/10000step_number: 0/29 Accuracy:  0.7139451728247914 Loss:  2.499359886986958 Val_accuracy:  0.7002179242713157 Val_cost:  2.499359886986958 Val_accuracy:  0.7002179242713157 Val_Acc:  2.5511969008746758\n",
      "Epoch number: 1047/10000step_number: 0/29 Accuracy:  0.7141154435552528 Loss:  2.4986688478376453 Val_accuracy:  0.7004903296104603 Val_cost:  2.4986688478376453 Val_accuracy:  0.7004903296104603 Val_Acc:  2.550526987768228\n",
      "Epoch number: 1048/10000step_number: 0/29 Accuracy:  0.7141835518474374 Loss:  2.4979122827903715 Val_accuracy:  0.7002179242713157 Val_cost:  2.4979122827903715 Val_accuracy:  0.7002179242713157 Val_Acc:  2.5497949618650115\n",
      "Epoch number: 1049/10000step_number: 0/29 Accuracy:  0.7143878767239912 Loss:  2.4970909699940935 Val_accuracy:  0.7000817216017434 Val_cost:  2.4970909699940935 Val_accuracy:  0.7000817216017434 Val_Acc:  2.54900876529437\n",
      "Epoch number: 1050/10000step_number: 0/29 Accuracy:  0.7145922016005448 Loss:  2.4962227160815473 Val_accuracy:  0.700354126940888 Val_cost:  2.4962227160815473 Val_accuracy:  0.700354126940888 Val_Acc:  2.5481982897533055\n",
      "Epoch number: 1051/10000step_number: 0/29 Accuracy:  0.7151030137919292 Loss:  2.4953407804709573 Val_accuracy:  0.7007627349496051 Val_cost:  2.4953407804709573 Val_accuracy:  0.7007627349496051 Val_Acc:  2.54740841736055\n",
      "Epoch number: 1052/10000step_number: 0/29 Accuracy:  0.7154435552528521 Loss:  2.4944771626230904 Val_accuracy:  0.7010351402887497 Val_cost:  2.4944771626230904 Val_accuracy:  0.7010351402887497 Val_Acc:  2.5466693733456363\n",
      "Epoch number: 1053/10000step_number: 0/29 Accuracy:  0.7155797718372212 Loss:  2.493640491434535 Val_accuracy:  0.701171342958322 Val_cost:  2.493640491434535 Val_accuracy:  0.701171342958322 Val_Acc:  2.545971878142718\n",
      "Epoch number: 1054/10000step_number: 0/29 Accuracy:  0.7155797718372212 Loss:  2.492819093050982 Val_accuracy:  0.701171342958322 Val_cost:  2.492819093050982 Val_accuracy:  0.701171342958322 Val_Acc:  2.545286588852623\n",
      "Epoch number: 1055/10000step_number: 0/29 Accuracy:  0.7157159884215903 Loss:  2.492002834576151 Val_accuracy:  0.7010351402887497 Val_cost:  2.492002834576151 Val_accuracy:  0.7010351402887497 Val_Acc:  2.544604883051321\n",
      "Epoch number: 1056/10000step_number: 0/29 Accuracy:  0.7157840967137749 Loss:  2.4911754792410457 Val_accuracy:  0.7010351402887497 Val_cost:  2.4911754792410457 Val_accuracy:  0.7010351402887497 Val_Acc:  2.5439239816659485\n",
      "Epoch number: 1057/10000step_number: 0/29 Accuracy:  0.7163289630512515 Loss:  2.490340741249071 Val_accuracy:  0.7010351402887497 Val_cost:  2.490340741249071 Val_accuracy:  0.7010351402887497 Val_Acc:  2.5432337701789485\n",
      "Epoch number: 1058/10000step_number: 0/29 Accuracy:  0.7166354503660821 Loss:  2.4895256773434515 Val_accuracy:  0.7008989376191773 Val_cost:  2.4895256773434515 Val_accuracy:  0.7008989376191773 Val_Acc:  2.54253307629943\n",
      "Epoch number: 1059/10000step_number: 0/29 Accuracy:  0.7167716669504512 Loss:  2.4887225145655627 Val_accuracy:  0.7010351402887497 Val_cost:  2.4887225145655627 Val_accuracy:  0.7010351402887497 Val_Acc:  2.5418104202807856\n",
      "Epoch number: 1060/10000step_number: 0/29 Accuracy:  0.7174527498722969 Loss:  2.487910249068338 Val_accuracy:  0.701171342958322 Val_cost:  2.487910249068338 Val_accuracy:  0.701171342958322 Val_Acc:  2.5410514342928945\n",
      "Epoch number: 1061/10000step_number: 0/29 Accuracy:  0.7176570747488507 Loss:  2.4870682146950216 Val_accuracy:  0.701171342958322 Val_cost:  2.4870682146950216 Val_accuracy:  0.701171342958322 Val_Acc:  2.540243792695178\n",
      "Epoch number: 1062/10000step_number: 0/29 Accuracy:  0.7175549123105738 Loss:  2.486183098066195 Val_accuracy:  0.7008989376191773 Val_cost:  2.486183098066195 Val_accuracy:  0.7008989376191773 Val_Acc:  2.5393804654527554\n",
      "Epoch number: 1063/10000step_number: 0/29 Accuracy:  0.7177251830410353 Loss:  2.4852454891245497 Val_accuracy:  0.701171342958322 Val_cost:  2.4852454891245497 Val_accuracy:  0.701171342958322 Val_Acc:  2.5384556085616072\n",
      "Epoch number: 1064/10000step_number: 0/29 Accuracy:  0.7177932913332198 Loss:  2.4842518048638595 Val_accuracy:  0.7014437482974666 Val_cost:  2.4842518048638595 Val_accuracy:  0.7014437482974666 Val_Acc:  2.537465904909273\n",
      "Epoch number: 1065/10000step_number: 0/29 Accuracy:  0.7177932913332198 Loss:  2.4832036374308775 Val_accuracy:  0.7017161536366113 Val_cost:  2.4832036374308775 Val_accuracy:  0.7017161536366113 Val_Acc:  2.5364103620532825\n",
      "Epoch number: 1066/10000step_number: 0/29 Accuracy:  0.7177592371871275 Loss:  2.4820947323250486 Val_accuracy:  0.701579950967039 Val_cost:  2.4820947323250486 Val_accuracy:  0.701579950967039 Val_Acc:  2.5352833963465375\n",
      "Epoch number: 1067/10000step_number: 0/29 Accuracy:  0.7179976162097735 Loss:  2.480912519884359 Val_accuracy:  0.701988558975756 Val_cost:  2.480912519884359 Val_accuracy:  0.701988558975756 Val_Acc:  2.5340739913770034\n",
      "Epoch number: 1068/10000step_number: 0/29 Accuracy:  0.7179295079175889 Loss:  2.479646294245447 Val_accuracy:  0.701988558975756 Val_cost:  2.479646294245447 Val_accuracy:  0.701988558975756 Val_Acc:  2.5327705078791167\n",
      "Epoch number: 1069/10000step_number: 0/29 Accuracy:  0.7181338327941427 Loss:  2.478285511487466 Val_accuracy:  0.701988558975756 Val_cost:  2.478285511487466 Val_accuracy:  0.701988558975756 Val_Acc:  2.5313592007939985\n",
      "Epoch number: 1070/10000step_number: 0/29 Accuracy:  0.7191895113230036 Loss:  2.476817467516018 Val_accuracy:  0.701988558975756 Val_cost:  2.476817467516018 Val_accuracy:  0.701988558975756 Val_Acc:  2.529821950804875\n",
      "Epoch number: 1071/10000step_number: 0/29 Accuracy:  0.7192576196151882 Loss:  2.4752240148291618 Val_accuracy:  0.7023971669844729 Val_cost:  2.4752240148291618 Val_accuracy:  0.7023971669844729 Val_Acc:  2.528135353485918\n",
      "Epoch number: 1072/10000step_number: 0/29 Accuracy:  0.7195300527839265 Loss:  2.473478003401708 Val_accuracy:  0.7022609643149006 Val_cost:  2.473478003401708 Val_accuracy:  0.7022609643149006 Val_Acc:  2.5262657774777995\n",
      "Epoch number: 1073/10000step_number: 0/29 Accuracy:  0.7197343776604802 Loss:  2.4715427707160704 Val_accuracy:  0.7022609643149006 Val_cost:  2.4715427707160704 Val_accuracy:  0.7022609643149006 Val_Acc:  2.5241675459956214\n",
      "Epoch number: 1074/10000step_number: 0/29 Accuracy:  0.7199387025370338 Loss:  2.46937294959522 Val_accuracy:  0.701988558975756 Val_cost:  2.46937294959522 Val_accuracy:  0.701988558975756 Val_Acc:  2.5217833816316872\n",
      "Epoch number: 1075/10000step_number: 0/29 Accuracy:  0.7202792439979567 Loss:  2.4669136667388076 Val_accuracy:  0.701988558975756 Val_cost:  2.4669136667388076 Val_accuracy:  0.701988558975756 Val_Acc:  2.519044861537206\n",
      "Epoch number: 1076/10000step_number: 0/29 Accuracy:  0.7205176230206027 Loss:  2.4640990748107323 Val_accuracy:  0.7022609643149006 Val_cost:  2.4640990748107323 Val_accuracy:  0.7022609643149006 Val_Acc:  2.5158765377239867\n",
      "Epoch number: 1077/10000step_number: 0/29 Accuracy:  0.7206197854588796 Loss:  2.4608497586518405 Val_accuracy:  0.7026695723236176 Val_cost:  2.4608497586518405 Val_accuracy:  0.7026695723236176 Val_Acc:  2.512201902682387\n",
      "Epoch number: 1078/10000step_number: 0/29 Accuracy:  0.7231738464158011 Loss:  2.457074514731607 Val_accuracy:  0.705393625715064 Val_cost:  2.457074514731607 Val_accuracy:  0.705393625715064 Val_Acc:  2.5079498296190503\n",
      "Epoch number: 1079/10000step_number: 0/29 Accuracy:  0.7247403371360464 Loss:  2.4526973722926604 Val_accuracy:  0.7067556524107873 Val_cost:  2.4526973722926604 Val_accuracy:  0.7067556524107873 Val_Acc:  2.5030738168138233\n",
      "Epoch number: 1080/10000step_number: 0/29 Accuracy:  0.730767920994381 Loss:  2.447669319768469 Val_accuracy:  0.7128847725415418 Val_cost:  2.447669319768469 Val_accuracy:  0.7128847725415418 Val_Acc:  2.4975488754040285\n",
      "Epoch number: 1081/10000step_number: 0/29 Accuracy:  0.7316873829388728 Loss:  2.4418333203696876 Val_accuracy:  0.7134295832198311 Val_cost:  2.4418333203696876 Val_accuracy:  0.7134295832198311 Val_Acc:  2.4912147643453144\n",
      "Epoch number: 1082/10000step_number: 0/29 Accuracy:  0.7336284692661331 Loss:  2.434783803661412 Val_accuracy:  0.7160174339417053 Val_cost:  2.434783803661412 Val_accuracy:  0.7160174339417053 Val_Acc:  2.4836255007499486\n",
      "Epoch number: 1083/10000step_number: 0/29 Accuracy:  0.7342754980418866 Loss:  2.42605119989378 Val_accuracy:  0.7165622446199945 Val_cost:  2.42605119989378 Val_accuracy:  0.7165622446199945 Val_Acc:  2.4742601730648435\n",
      "Epoch number: 1084/10000step_number: 0/29 Accuracy:  0.7360463136386856 Loss:  2.415772478722067 Val_accuracy:  0.7190138926722964 Val_cost:  2.415772478722067 Val_accuracy:  0.7190138926722964 Val_Acc:  2.463136106613765\n",
      "Epoch number: 1085/10000step_number: 0/29 Accuracy:  0.7377830750893921 Loss:  2.4039737370914973 Val_accuracy:  0.7207845273767366 Val_cost:  2.4039737370914973 Val_accuracy:  0.7207845273767366 Val_Acc:  2.4501111196971483\n",
      "Epoch number: 1086/10000step_number: 0/29 Accuracy:  0.7431636301719734 Loss:  2.390209123985991 Val_accuracy:  0.7247344047943339 Val_cost:  2.390209123985991 Val_accuracy:  0.7247344047943339 Val_Acc:  2.4349385308232323\n",
      "Epoch number: 1087/10000step_number: 0/29 Accuracy:  0.7479652647709859 Loss:  2.3739611046967304 Val_accuracy:  0.7308635249250885 Val_cost:  2.3739611046967304 Val_accuracy:  0.7308635249250885 Val_Acc:  2.4172671930488745\n",
      "Epoch number: 1088/10000step_number: 0/29 Accuracy:  0.7590328622509791 Loss:  2.354804577745653 Val_accuracy:  0.7416235358213021 Val_cost:  2.354804577745653 Val_accuracy:  0.7416235358213021 Val_Acc:  2.396423399348348\n",
      "Epoch number: 1089/10000step_number: 0/29 Accuracy:  0.7650604461093138 Loss:  2.331725662247272 Val_accuracy:  0.7482974666303459 Val_cost:  2.331725662247272 Val_accuracy:  0.7482974666303459 Val_Acc:  2.3712133151607966\n",
      "Epoch number: 1090/10000step_number: 0/29 Accuracy:  0.7835518474374255 Loss:  2.300912880195496 Val_accuracy:  0.7721329338055026 Val_cost:  2.300912880195496 Val_accuracy:  0.7721329338055026 Val_Acc:  2.3372064290851435\n",
      "Epoch number: 1091/10000step_number: 0/29 Accuracy:  0.7917248424995743 Loss:  2.252740682468533 Val_accuracy:  0.7797602833015527 Val_cost:  2.252740682468533 Val_accuracy:  0.7797602833015527 Val_Acc:  2.2838893793743713\n",
      "Epoch number: 1092/10000step_number: 0/29 Accuracy:  0.8088200238379023 Loss:  2.1752283601465483 Val_accuracy:  0.7999182783982566 Val_cost:  2.1752283601465483 Val_accuracy:  0.7999182783982566 Val_Acc:  2.1997422339297827\n",
      "Epoch number: 1093/10000step_number: 0/29 Accuracy:  0.8142005789204836 Loss:  2.062040807673631 Val_accuracy:  0.8057749931898666 Val_cost:  2.062040807673631 Val_accuracy:  0.8057749931898666 Val_Acc:  2.0785846095482556\n",
      "Epoch number: 1094/10000step_number: 0/29 Accuracy:  0.8168568023156819 Loss:  1.939784898683026 Val_accuracy:  0.8113593026423318 Val_cost:  1.939784898683026 Val_accuracy:  0.8113593026423318 Val_Acc:  1.9645732174339634\n",
      "Epoch number: 1095/10000step_number: 0/29 Accuracy:  0.8168908564617742 Loss:  1.8199823958797288 Val_accuracy:  0.8124489239989103 Val_cost:  1.8199823958797288 Val_accuracy:  0.8124489239989103 Val_Acc:  1.8399388920045598\n",
      "Epoch number: 1096/10000step_number: 0/29 Accuracy:  0.8074919121403031 Loss:  1.6147717918687463 Val_accuracy:  0.8031871424679924 Val_cost:  1.6147717918687463 Val_accuracy:  0.8031871424679924 Val_Acc:  1.6625119259474126\n",
      "Epoch number: 1097/10000step_number: 0/29 Accuracy:  0.8106589477268857 Loss:  1.5714339145185185 Val_accuracy:  0.8070008172160175 Val_cost:  1.5714339145185185 Val_accuracy:  0.8070008172160175 Val_Acc:  1.6363987919896927\n",
      "Epoch number: 1098/10000step_number: 0/29 Accuracy:  0.8061297462966116 Loss:  1.5561170826623187 Val_accuracy:  0.8015527104331245 Val_cost:  1.5561170826623187 Val_accuracy:  0.8015527104331245 Val_Acc:  1.6250474348446233\n",
      "Epoch number: 1099/10000step_number: 0/29 Accuracy:  0.8064021794653499 Loss:  1.5470579479716802 Val_accuracy:  0.8027785344592754 Val_cost:  1.5470579479716802 Val_accuracy:  0.8027785344592754 Val_Acc:  1.6167337224823521\n",
      "Epoch number: 1100/10000step_number: 0/29 Accuracy:  0.8063681253192576 Loss:  1.5409830429850588 Val_accuracy:  0.8020975211114137 Val_cost:  1.5409830429850588 Val_accuracy:  0.8020975211114137 Val_Acc:  1.6104202380706796\n",
      "Epoch number: 1101/10000step_number: 0/29 Accuracy:  0.8056189341052273 Loss:  1.5357501199358965 Val_accuracy:  0.8020975211114137 Val_cost:  1.5357501199358965 Val_accuracy:  0.8020975211114137 Val_Acc:  1.6052462482937966\n",
      "Epoch number: 1102/10000step_number: 0/29 Accuracy:  0.8057892048356887 Loss:  1.5318260148127036 Val_accuracy:  0.8012803050939798 Val_cost:  1.5318260148127036 Val_accuracy:  0.8012803050939798 Val_Acc:  1.6008088792809065\n",
      "Epoch number: 1103/10000step_number: 0/29 Accuracy:  0.8056529882513196 Loss:  1.528702582152997 Val_accuracy:  0.8012803050939798 Val_cost:  1.528702582152997 Val_accuracy:  0.8012803050939798 Val_Acc:  1.5973136243804313\n",
      "Epoch number: 1104/10000step_number: 0/29 Accuracy:  0.8070832623871956 Loss:  1.526118262699287 Val_accuracy:  0.8010078997548352 Val_cost:  1.526118262699287 Val_accuracy:  0.8010078997548352 Val_Acc:  1.5940356919620464\n",
      "Epoch number: 1105/10000step_number: 0/29 Accuracy:  0.8070492082411034 Loss:  1.524069170881111 Val_accuracy:  0.8010078997548352 Val_cost:  1.524069170881111 Val_accuracy:  0.8010078997548352 Val_Acc:  1.5913852886697555\n",
      "Epoch number: 1106/10000step_number: 0/29 Accuracy:  0.8076962370168568 Loss:  1.5222308299309235 Val_accuracy:  0.8014165077635521 Val_cost:  1.5222308299309235 Val_accuracy:  0.8014165077635521 Val_Acc:  1.5888289382027732\n",
      "Epoch number: 1107/10000step_number: 0/29 Accuracy:  0.8083092116465179 Loss:  1.5207336099729674 Val_accuracy:  0.8012803050939798 Val_cost:  1.5207336099729674 Val_accuracy:  0.8012803050939798 Val_Acc:  1.5867241213842567\n",
      "Epoch number: 1108/10000step_number: 0/29 Accuracy:  0.8080367784777797 Loss:  1.5192806791886888 Val_accuracy:  0.8011441024244075 Val_cost:  1.5192806791886888 Val_accuracy:  0.8011441024244075 Val_Acc:  1.5846706571784168\n",
      "Epoch number: 1109/10000step_number: 0/29 Accuracy:  0.8082751575004257 Loss:  1.5180224054158102 Val_accuracy:  0.8015527104331245 Val_cost:  1.5180224054158102 Val_accuracy:  0.8015527104331245 Val_Acc:  1.5829635399515134\n",
      "Epoch number: 1110/10000step_number: 0/29 Accuracy:  0.8081389409160565 Loss:  1.5167483824008647 Val_accuracy:  0.8012803050939798 Val_cost:  1.5167483824008647 Val_accuracy:  0.8012803050939798 Val_Acc:  1.5813086945548587\n",
      "Epoch number: 1111/10000step_number: 0/29 Accuracy:  0.8096713774902095 Loss:  1.5156037684061585 Val_accuracy:  0.8026423317897031 Val_cost:  1.5156037684061585 Val_accuracy:  0.8026423317897031 Val_Acc:  1.5799001808690913\n",
      "Epoch number: 1112/10000step_number: 0/29 Accuracy:  0.8098416482206708 Loss:  1.5144672183849388 Val_accuracy:  0.8027785344592754 Val_cost:  1.5144672183849388 Val_accuracy:  0.8027785344592754 Val_Acc:  1.5785644011766855\n",
      "Epoch number: 1113/10000step_number: 0/29 Accuracy:  0.8110675974799932 Loss:  1.5134285713569455 Val_accuracy:  0.8044129664941433 Val_cost:  1.5134285713569455 Val_accuracy:  0.8044129664941433 Val_Acc:  1.5773783156631678\n",
      "Epoch number: 1114/10000step_number: 0/29 Accuracy:  0.8115784096713775 Loss:  1.5124372093439586 Val_accuracy:  0.8044129664941433 Val_cost:  1.5124372093439586 Val_accuracy:  0.8044129664941433 Val_Acc:  1.5762741154399347\n",
      "Epoch number: 1115/10000step_number: 0/29 Accuracy:  0.8116124638174698 Loss:  1.5115034480014389 Val_accuracy:  0.8046853718332879 Val_cost:  1.5115034480014389 Val_accuracy:  0.8046853718332879 Val_Acc:  1.5752631924795815\n",
      "Epoch number: 1116/10000step_number: 0/29 Accuracy:  0.8118167886940235 Loss:  1.5105945079780354 Val_accuracy:  0.8064560065377281 Val_cost:  1.5105945079780354 Val_accuracy:  0.8064560065377281 Val_Acc:  1.574326866590148\n",
      "Epoch number: 1117/10000step_number: 0/29 Accuracy:  0.8124978716158693 Loss:  1.5097119855084005 Val_accuracy:  0.8071370198855897 Val_cost:  1.5097119855084005 Val_accuracy:  0.8071370198855897 Val_Acc:  1.5734616893244933\n",
      "Epoch number: 1118/10000step_number: 0/29 Accuracy:  0.8128724672228844 Loss:  1.508867616187049 Val_accuracy:  0.8082266412421684 Val_cost:  1.508867616187049 Val_accuracy:  0.8082266412421684 Val_Acc:  1.572669197001121\n",
      "Epoch number: 1119/10000step_number: 0/29 Accuracy:  0.8130427379533458 Loss:  1.5080364970223823 Val_accuracy:  0.8087714519204576 Val_cost:  1.5080364970223823 Val_accuracy:  0.8087714519204576 Val_Acc:  1.5719349902992348\n",
      "Epoch number: 1120/10000step_number: 0/29 Accuracy:  0.8133151711220841 Loss:  1.5072068255934215 Val_accuracy:  0.8091800599291746 Val_cost:  1.5072068255934215 Val_accuracy:  0.8091800599291746 Val_Acc:  1.571250817465514\n",
      "Epoch number: 1121/10000step_number: 0/29 Accuracy:  0.8133832794142687 Loss:  1.5063780374007893 Val_accuracy:  0.8097248706074639 Val_cost:  1.5063780374007893 Val_accuracy:  0.8097248706074639 Val_Acc:  1.570590335723249\n",
      "Epoch number: 1122/10000step_number: 0/29 Accuracy:  0.8135194959986378 Loss:  1.5055536799108937 Val_accuracy:  0.8101334786161809 Val_cost:  1.5055536799108937 Val_accuracy:  0.8101334786161809 Val_Acc:  1.5699285529417035\n",
      "Epoch number: 1123/10000step_number: 0/29 Accuracy:  0.8138600374595607 Loss:  1.504763414446349 Val_accuracy:  0.8105420866248978 Val_cost:  1.504763414446349 Val_accuracy:  0.8105420866248978 Val_Acc:  1.5692882076639725\n",
      "Epoch number: 1124/10000step_number: 0/29 Accuracy:  0.8140643623361145 Loss:  1.5039923027770619 Val_accuracy:  0.8110868973031872 Val_cost:  1.5039923027770619 Val_accuracy:  0.8110868973031872 Val_Acc:  1.5686733584859816\n",
      "Epoch number: 1125/10000step_number: 0/29 Accuracy:  0.8145411203814065 Loss:  1.5032360891900958 Val_accuracy:  0.8114955053119041 Val_cost:  1.5032360891900958 Val_accuracy:  0.8114955053119041 Val_Acc:  1.5680849079941566\n",
      "Epoch number: 1126/10000step_number: 0/29 Accuracy:  0.8152562574493445 Loss:  1.5024963372745819 Val_accuracy:  0.8119041133206211 Val_cost:  1.5024963372745819 Val_accuracy:  0.8119041133206211 Val_Acc:  1.5675247230283282\n",
      "Epoch number: 1127/10000step_number: 0/29 Accuracy:  0.8157670696407288 Loss:  1.5017743962720038 Val_accuracy:  0.8120403159901934 Val_cost:  1.5017743962720038 Val_accuracy:  0.8120403159901934 Val_Acc:  1.5669926131758785\n",
      "Epoch number: 1128/10000step_number: 0/29 Accuracy:  0.8163119359782054 Loss:  1.5010703672058903 Val_accuracy:  0.8128575320076273 Val_cost:  1.5010703672058903 Val_accuracy:  0.8128575320076273 Val_Acc:  1.5664881005259133\n",
      "Epoch number: 1129/10000step_number: 0/29 Accuracy:  0.8166184232930359 Loss:  1.5003809372388297 Val_accuracy:  0.813129937346772 Val_cost:  1.5003809372388297 Val_accuracy:  0.813129937346772 Val_Acc:  1.5660113630073111\n",
      "Epoch number: 1130/10000step_number: 0/29 Accuracy:  0.8170611271922357 Loss:  1.4997020943691677 Val_accuracy:  0.8132661400163443 Val_cost:  1.4997020943691677 Val_accuracy:  0.8132661400163443 Val_Acc:  1.5655630896314445\n",
      "Epoch number: 1131/10000step_number: 0/29 Accuracy:  0.8168227481695897 Loss:  1.4990386372576587 Val_accuracy:  0.813538545355489 Val_cost:  1.4990386372576587 Val_accuracy:  0.813538545355489 Val_Acc:  1.5651395985252974\n",
      "Epoch number: 1132/10000step_number: 0/29 Accuracy:  0.8171292354844202 Loss:  1.4984109305504545 Val_accuracy:  0.813947153364206 Val_cost:  1.4984109305504545 Val_accuracy:  0.813947153364206 Val_Acc:  1.5647252463470755\n",
      "Epoch number: 1133/10000step_number: 0/29 Accuracy:  0.8175038310914354 Loss:  1.4978139659552325 Val_accuracy:  0.813947153364206 Val_cost:  1.4978139659552325 Val_accuracy:  0.813947153364206 Val_Acc:  1.5643267595054302\n",
      "Epoch number: 1134/10000step_number: 0/29 Accuracy:  0.8175378852375277 Loss:  1.4972242732158856 Val_accuracy:  0.813129937346772 Val_cost:  1.4972242732158856 Val_accuracy:  0.813129937346772 Val_Acc:  1.5639503312511192\n",
      "Epoch number: 1135/10000step_number: 0/29 Accuracy:  0.8178443725523582 Loss:  1.4966454684305244 Val_accuracy:  0.8138109506946336 Val_cost:  1.4966454684305244 Val_accuracy:  0.8138109506946336 Val_Acc:  1.5635902202274843\n",
      "Epoch number: 1136/10000step_number: 0/29 Accuracy:  0.8180146432828197 Loss:  1.4961010458698925 Val_accuracy:  0.8140833560337782 Val_cost:  1.4961010458698925 Val_accuracy:  0.8140833560337782 Val_Acc:  1.563247483182842\n",
      "Epoch number: 1137/10000step_number: 0/29 Accuracy:  0.8182530223054657 Loss:  1.4955526945533695 Val_accuracy:  0.8147643693816399 Val_cost:  1.4955526945533695 Val_accuracy:  0.8147643693816399 Val_Acc:  1.562913281867892\n",
      "Epoch number: 1138/10000step_number: 0/29 Accuracy:  0.8181508598671888 Loss:  1.4950010802836748 Val_accuracy:  0.8146281667120675 Val_cost:  1.4950010802836748 Val_accuracy:  0.8146281667120675 Val_Acc:  1.5625760639557142\n",
      "Epoch number: 1139/10000step_number: 0/29 Accuracy:  0.818048697428912 Loss:  1.494448590177603 Val_accuracy:  0.8144919640424952 Val_cost:  1.494448590177603 Val_accuracy:  0.8144919640424952 Val_Acc:  1.5622330816073173\n",
      "Epoch number: 1140/10000step_number: 0/29 Accuracy:  0.8185595096202962 Loss:  1.4938974304301031 Val_accuracy:  0.8144919640424952 Val_cost:  1.4938974304301031 Val_accuracy:  0.8144919640424952 Val_Acc:  1.5618887719639885\n",
      "Epoch number: 1141/10000step_number: 0/29 Accuracy:  0.8190362676655882 Loss:  1.493352928068402 Val_accuracy:  0.8149005720512122 Val_cost:  1.493352928068402 Val_accuracy:  0.8149005720512122 Val_Acc:  1.5615491433766788\n",
      "Epoch number: 1142/10000step_number: 0/29 Accuracy:  0.8192746466882342 Loss:  1.4928169274543623 Val_accuracy:  0.8149005720512122 Val_cost:  1.4928169274543623 Val_accuracy:  0.8149005720512122 Val_Acc:  1.561216061405614\n",
      "Epoch number: 1143/10000step_number: 0/29 Accuracy:  0.81995572961008 Loss:  1.4922897272128794 Val_accuracy:  0.8155815853990738 Val_cost:  1.4922897272128794 Val_accuracy:  0.8155815853990738 Val_Acc:  1.560889420979446\n",
      "Epoch number: 1144/10000step_number: 0/29 Accuracy:  0.8200238379022646 Loss:  1.4917714752413622 Val_accuracy:  0.8155815853990738 Val_cost:  1.4917714752413622 Val_accuracy:  0.8155815853990738 Val_Acc:  1.5605688649334422\n",
      "Epoch number: 1145/10000step_number: 0/29 Accuracy:  0.8202281627788183 Loss:  1.491262098987327 Val_accuracy:  0.8159901934077908 Val_cost:  1.491262098987327 Val_accuracy:  0.8159901934077908 Val_Acc:  1.5602539881718187\n",
      "Epoch number: 1146/10000step_number: 0/29 Accuracy:  0.8207389749702027 Loss:  1.4907614950144903 Val_accuracy:  0.8163988014165078 Val_cost:  1.4907614950144903 Val_accuracy:  0.8163988014165078 Val_Acc:  1.5599443545351623\n",
      "Epoch number: 1147/10000step_number: 0/29 Accuracy:  0.8210454622850332 Loss:  1.490269630313482 Val_accuracy:  0.81653500408608 Val_cost:  1.490269630313482 Val_accuracy:  0.81653500408608 Val_Acc:  1.5596395539388748\n",
      "Epoch number: 1148/10000step_number: 0/29 Accuracy:  0.8221011408138941 Loss:  1.4897865544333322 Val_accuracy:  0.8178970307818033 Val_cost:  1.4897865544333322 Val_accuracy:  0.8178970307818033 Val_Acc:  1.5593392482950479\n",
      "Epoch number: 1149/10000step_number: 0/29 Accuracy:  0.8227141154435552 Loss:  1.489312372394697 Val_accuracy:  0.8187142467992372 Val_cost:  1.489312372394697 Val_accuracy:  0.8187142467992372 Val_Acc:  1.5590431732945864\n",
      "Epoch number: 1150/10000step_number: 0/29 Accuracy:  0.8231908734888472 Loss:  1.488847196555416 Val_accuracy:  0.818986652138382 Val_cost:  1.488847196555416 Val_accuracy:  0.818986652138382 Val_Acc:  1.5587511237836504\n",
      "Epoch number: 1151/10000step_number: 0/29 Accuracy:  0.8236676315341392 Loss:  1.4883910983048467 Val_accuracy:  0.8198038681558159 Val_cost:  1.4883910983048467 Val_accuracy:  0.8198038681558159 Val_Acc:  1.558462936691264\n",
      "Epoch number: 1152/10000step_number: 0/29 Accuracy:  0.8239400647028776 Loss:  1.4879440683731469 Val_accuracy:  0.8202124761645329 Val_cost:  1.4879440683731469 Val_accuracy:  0.8202124761645329 Val_Acc:  1.5581784729137595\n",
      "Epoch number: 1153/10000step_number: 0/29 Accuracy:  0.8239060105567853 Loss:  1.4875059927843701 Val_accuracy:  0.8196676654862435 Val_cost:  1.4875059927843701 Val_accuracy:  0.8196676654862435 Val_Acc:  1.5578976029166254\n",
      "Epoch number: 1154/10000step_number: 0/29 Accuracy:  0.8240081729950621 Loss:  1.4870766471137813 Val_accuracy:  0.8199400708253882 Val_cost:  1.4870766471137813 Val_accuracy:  0.8199400708253882 Val_Acc:  1.5576201982483409\n",
      "Epoch number: 1155/10000step_number: 0/29 Accuracy:  0.824348714455985 Loss:  1.486655705896512 Val_accuracy:  0.8207572868428221 Val_cost:  1.486655705896512 Val_accuracy:  0.8207572868428221 Val_Acc:  1.5573461291250559\n",
      "Epoch number: 1156/10000step_number: 0/29 Accuracy:  0.824825472501277 Loss:  1.4862427612828828 Val_accuracy:  0.8211658948515391 Val_cost:  1.4862427612828828 Val_accuracy:  0.8211658948515391 Val_Acc:  1.5570752666916692\n",
      "Epoch number: 1157/10000step_number: 0/29 Accuracy:  0.8251319598161077 Loss:  1.485837344791397 Val_accuracy:  0.8211658948515391 Val_cost:  1.485837344791397 Val_accuracy:  0.8211658948515391 Val_Acc:  1.5568074880769842\n",
      "Epoch number: 1158/10000step_number: 0/29 Accuracy:  0.8252341222543844 Loss:  1.485438947652533 Val_accuracy:  0.8211658948515391 Val_cost:  1.485438947652533 Val_accuracy:  0.8211658948515391 Val_Acc:  1.556542682685645\n",
      "Epoch number: 1159/10000step_number: 0/29 Accuracy:  0.8252000681082922 Loss:  1.4850470374928988 Val_accuracy:  0.8213020975211114 Val_cost:  1.4850470374928988 Val_accuracy:  0.8213020975211114 Val_Acc:  1.5562807588809633\n",
      "Epoch number: 1160/10000step_number: 0/29 Accuracy:  0.8254384471309382 Loss:  1.4846610712414112 Val_accuracy:  0.821574502860256 Val_cost:  1.4846610712414112 Val_accuracy:  0.821574502860256 Val_Acc:  1.556021650875121\n",
      "Epoch number: 1161/10000step_number: 0/29 Accuracy:  0.8256087178613997 Loss:  1.4842805060280841 Val_accuracy:  0.8217107055298284 Val_cost:  1.4842805060280841 Val_accuracy:  0.8217107055298284 Val_Acc:  1.5557653260355258\n",
      "Epoch number: 1162/10000step_number: 0/29 Accuracy:  0.8257449344457688 Loss:  1.4839048117456928 Val_accuracy:  0.8221193135385454 Val_cost:  1.4839048117456928 Val_accuracy:  0.8221193135385454 Val_Acc:  1.555511792771364\n",
      "Epoch number: 1163/10000step_number: 0/29 Accuracy:  0.8266303422441682 Loss:  1.4835334909425624 Val_accuracy:  0.8225279215472623 Val_cost:  1.4835334909425624 Val_accuracy:  0.8225279215472623 Val_Acc:  1.5552611084328434\n",
      "Epoch number: 1164/10000step_number: 0/29 Accuracy:  0.8271411544355526 Loss:  1.4831661130167149 Val_accuracy:  0.82239171887769 Val_cost:  1.4831661130167149 Val_accuracy:  0.82239171887769 Val_Acc:  1.5550133848854986\n",
      "Epoch number: 1165/10000step_number: 0/29 Accuracy:  0.828503320279244 Loss:  1.4828023679122566 Val_accuracy:  0.8236175429038409 Val_cost:  1.4828023679122566 Val_accuracy:  0.8236175429038409 Val_Acc:  1.5547687865532\n",
      "Epoch number: 1166/10000step_number: 0/29 Accuracy:  0.8287757534479823 Loss:  1.4824421359048152 Val_accuracy:  0.8240261509125579 Val_cost:  1.4824421359048152 Val_accuracy:  0.8240261509125579 Val_Acc:  1.5545275131720735\n",
      "Epoch number: 1167/10000step_number: 0/29 Accuracy:  0.8286054827175209 Loss:  1.4820855512896043 Val_accuracy:  0.8241623535821302 Val_cost:  1.4820855512896043 Val_accuracy:  0.8241623535821302 Val_Acc:  1.5542897616369795\n",
      "Epoch number: 1168/10000step_number: 0/29 Accuracy:  0.8288779158862591 Loss:  1.4817330113068106 Val_accuracy:  0.8242985562517026 Val_cost:  1.4817330113068106 Val_accuracy:  0.8242985562517026 Val_Acc:  1.5540556728792876\n",
      "Epoch number: 1169/10000step_number: 0/29 Accuracy:  0.8290481866167206 Loss:  1.481385071316895 Val_accuracy:  0.8241623535821302 Val_cost:  1.481385071316895 Val_accuracy:  0.8241623535821302 Val_Acc:  1.5538252845795273\n",
      "Epoch number: 1170/10000step_number: 0/29 Accuracy:  0.8291503490549974 Loss:  1.481042225545356 Val_accuracy:  0.8245709615908472 Val_cost:  1.481042225545356 Val_accuracy:  0.8245709615908472 Val_Acc:  1.553598510314551\n",
      "Epoch number: 1171/10000step_number: 0/29 Accuracy:  0.8291844032010898 Loss:  1.480704696506309 Val_accuracy:  0.8245709615908472 Val_cost:  1.480704696506309 Val_accuracy:  0.8245709615908472 Val_Acc:  1.5533751509368625\n",
      "Epoch number: 1172/10000step_number: 0/29 Accuracy:  0.8295589988081049 Loss:  1.4803723900315655 Val_accuracy:  0.8248433669299918 Val_cost:  1.4803723900315655 Val_accuracy:  0.8248433669299918 Val_Acc:  1.55315493614245\n",
      "Epoch number: 1173/10000step_number: 0/29 Accuracy:  0.8298314319768432 Loss:  1.4800450189625218 Val_accuracy:  0.8252519749387088 Val_cost:  1.4800450189625218 Val_accuracy:  0.8252519749387088 Val_Acc:  1.5529375855533014\n",
      "Epoch number: 1174/10000step_number: 0/29 Accuracy:  0.8304103524604121 Loss:  1.479722252774433 Val_accuracy:  0.8253881776082811 Val_cost:  1.479722252774433 Val_accuracy:  0.8253881776082811 Val_Acc:  1.55272286409726\n",
      "Epoch number: 1175/10000step_number: 0/29 Accuracy:  0.8306827856291503 Loss:  1.4794037911665927 Val_accuracy:  0.8257967856169981 Val_cost:  1.4794037911665927 Val_accuracy:  0.8257967856169981 Val_Acc:  1.5525106135832822\n",
      "Epoch number: 1176/10000step_number: 0/29 Accuracy:  0.8308530563596118 Loss:  1.4790893721258522 Val_accuracy:  0.8259329882865705 Val_cost:  1.4790893721258522 Val_accuracy:  0.8259329882865705 Val_Acc:  1.552300760587962\n",
      "Epoch number: 1177/10000step_number: 0/29 Accuracy:  0.8311935978205347 Loss:  1.4787787616725125 Val_accuracy:  0.8260691909561427 Val_cost:  1.4787787616725125 Val_accuracy:  0.8260691909561427 Val_Acc:  1.5520933055979753\n",
      "Epoch number: 1178/10000step_number: 0/29 Accuracy:  0.8313638685509961 Loss:  1.4784717485931953 Val_accuracy:  0.8263415962952874 Val_cost:  1.4784717485931953 Val_accuracy:  0.8263415962952874 Val_Acc:  1.5518882989177012\n",
      "Epoch number: 1179/10000step_number: 0/29 Accuracy:  0.831466030989273 Loss:  1.4781681447455657 Val_accuracy:  0.826614001634432 Val_cost:  1.4781681447455657 Val_accuracy:  0.826614001634432 Val_Acc:  1.551685811991791\n",
      "Epoch number: 1180/10000step_number: 0/29 Accuracy:  0.8316703558658267 Loss:  1.477867785953806 Val_accuracy:  0.826614001634432 Val_cost:  1.477867785953806 Val_accuracy:  0.826614001634432 Val_Acc:  1.5514859128462155\n",
      "Epoch number: 1181/10000step_number: 0/29 Accuracy:  0.8317384641580112 Loss:  1.4775705307995801 Val_accuracy:  0.8264777989648597 Val_cost:  1.4775705307995801 Val_accuracy:  0.8264777989648597 Val_Acc:  1.5512886502419074\n",
      "Epoch number: 1182/10000step_number: 0/29 Accuracy:  0.8313638685509961 Loss:  1.4772762572406093 Val_accuracy:  0.8259329882865705 Val_cost:  1.4772762572406093 Val_accuracy:  0.8259329882865705 Val_Acc:  1.5510940465635334\n",
      "Epoch number: 1183/10000step_number: 0/29 Accuracy:  0.8316703558658267 Loss:  1.4769848580440508 Val_accuracy:  0.8262053936257151 Val_cost:  1.4769848580440508 Val_accuracy:  0.8262053936257151 Val_Acc:  1.5509020969839196\n",
      "Epoch number: 1184/10000step_number: 0/29 Accuracy:  0.8329303592712413 Loss:  1.4766962360382687 Val_accuracy:  0.8271588123127214 Val_cost:  1.4766962360382687 Val_accuracy:  0.8271588123127214 Val_Acc:  1.5507127721185783\n",
      "Epoch number: 1185/10000step_number: 0/29 Accuracy:  0.8330665758556104 Loss:  1.4764102998693345 Val_accuracy:  0.8277036229910106 Val_cost:  1.4764102998693345 Val_accuracy:  0.8277036229910106 Val_Acc:  1.5505260221230746\n",
      "Epoch number: 1186/10000step_number: 0/29 Accuracy:  0.8332027924399795 Loss:  1.4761269606242953 Val_accuracy:  0.8277036229910106 Val_cost:  1.4761269606242953 Val_accuracy:  0.8277036229910106 Val_Acc:  1.550341781067638\n",
      "Epoch number: 1187/10000step_number: 0/29 Accuracy:  0.8335092797548102 Loss:  1.475846129446898 Val_accuracy:  0.8277036229910106 Val_cost:  1.475846129446898 Val_accuracy:  0.8277036229910106 Val_Acc:  1.5501599710641165\n",
      "Epoch number: 1188/10000step_number: 0/29 Accuracy:  0.8337817129235484 Loss:  1.4755677161265666 Val_accuracy:  0.8277036229910106 Val_cost:  1.4755677161265666 Val_accuracy:  0.8277036229910106 Val_Acc:  1.5499805059809522\n",
      "Epoch number: 1189/10000step_number: 0/29 Accuracy:  0.8339179295079175 Loss:  1.4752916285626132 Val_accuracy:  0.8282484336692999 Val_cost:  1.4752916285626132 Val_accuracy:  0.8282484336692999 Val_Acc:  1.5498032947410774\n",
      "Epoch number: 1190/10000step_number: 0/29 Accuracy:  0.8341563085305636 Loss:  1.4750177729649776 Val_accuracy:  0.8283846363388723 Val_cost:  1.4750177729649776 Val_accuracy:  0.8283846363388723 Val_Acc:  1.5496282442383245\n",
      "Epoch number: 1191/10000step_number: 0/29 Accuracy:  0.8342925251149328 Loss:  1.4747460546311484 Val_accuracy:  0.8283846363388723 Val_cost:  1.4747460546311484 Val_accuracy:  0.8283846363388723 Val_Acc:  1.5494552618901323\n",
      "Epoch number: 1192/10000step_number: 0/29 Accuracy:  0.8346671207219479 Loss:  1.4744763791279603 Val_accuracy:  0.8283846363388723 Val_cost:  1.4744763791279603 Val_accuracy:  0.8283846363388723 Val_Acc:  1.5492842578064348\n",
      "Epoch number: 1193/10000step_number: 0/29 Accuracy:  0.8347692831602248 Loss:  1.4742086537059296 Val_accuracy:  0.8285208390084445 Val_cost:  1.4742086537059296 Val_accuracy:  0.8285208390084445 Val_Acc:  1.5491151465207595\n",
      "Epoch number: 1194/10000step_number: 0/29 Accuracy:  0.8350076621828708 Loss:  1.4739427887843872 Val_accuracy:  0.8287932443475892 Val_cost:  1.4739427887843872 Val_accuracy:  0.8287932443475892 Val_Acc:  1.5489478482145975\n",
      "Epoch number: 1195/10000step_number: 0/29 Accuracy:  0.835382257789886 Loss:  1.47367869936792 Val_accuracy:  0.8289294470171615 Val_cost:  1.47367869936792 Val_accuracy:  0.8289294470171615 Val_Acc:  1.5487822893760606\n",
      "Epoch number: 1196/10000step_number: 0/29 Accuracy:  0.8355525285203473 Loss:  1.4734163062846715 Val_accuracy:  0.8292018523563062 Val_cost:  1.4734163062846715 Val_accuracy:  0.8292018523563062 Val_Acc:  1.5486184028678474\n",
      "Epoch number: 1197/10000step_number: 0/29 Accuracy:  0.835859015835178 Loss:  1.4731555371677727 Val_accuracy:  0.8296104603650232 Val_cost:  1.4731555371677727 Val_accuracy:  0.8296104603650232 Val_Acc:  1.548456127431076\n",
      "Epoch number: 1198/10000step_number: 0/29 Accuracy:  0.8358930699812702 Loss:  1.472896327124727 Val_accuracy:  0.8297466630345954 Val_cost:  1.472896327124727 Val_accuracy:  0.8297466630345954 Val_Acc:  1.5482954067107235\n",
      "Epoch number: 1199/10000step_number: 0/29 Accuracy:  0.83633577388047 Loss:  1.4726386190510903 Val_accuracy:  0.8298828657041678 Val_cost:  1.4726386190510903 Val_accuracy:  0.8298828657041678 Val_Acc:  1.548136187944514\n",
      "Epoch number: 1200/10000step_number: 0/29 Accuracy:  0.8365060446109314 Loss:  1.4723823635449362 Val_accuracy:  0.8298828657041678 Val_cost:  1.4723823635449362 Val_accuracy:  0.8298828657041678 Val_Acc:  1.547978420500352\n",
      "Epoch number: 1201/10000step_number: 0/29 Accuracy:  0.8369828026562234 Loss:  1.472127518374799 Val_accuracy:  0.8304276763824571 Val_cost:  1.472127518374799 Val_accuracy:  0.8304276763824571 Val_Acc:  1.547822054470446\n",
      "Epoch number: 1202/10000step_number: 0/29 Accuracy:  0.8372211816788694 Loss:  1.4718740474584748 Val_accuracy:  0.8304276763824571 Val_cost:  1.4718740474584748 Val_accuracy:  0.8304276763824571 Val_Acc:  1.5476670395274221\n",
      "Epoch number: 1203/10000step_number: 0/29 Accuracy:  0.8371190192405925 Loss:  1.4716219193374778 Val_accuracy:  0.8304276763824571 Val_cost:  1.4716219193374778 Val_accuracy:  0.8304276763824571 Val_Acc:  1.5475133242162336\n",
      "Epoch number: 1204/10000step_number: 0/29 Accuracy:  0.8373233441171463 Loss:  1.4713711051917966 Val_accuracy:  0.8311086897303187 Val_cost:  1.4713711051917966 Val_accuracy:  0.8311086897303187 Val_Acc:  1.5473608557949488\n",
      "Epoch number: 1205/10000step_number: 0/29 Accuracy:  0.8374936148476076 Loss:  1.4711215765294694 Val_accuracy:  0.8312448923998911 Val_cost:  1.4711215765294694 Val_accuracy:  0.8312448923998911 Val_Acc:  1.547209580653377\n",
      "Epoch number: 1206/10000step_number: 0/29 Accuracy:  0.8378682104546229 Loss:  1.4708733027845713 Val_accuracy:  0.8313810950694633 Val_cost:  1.4708733027845713 Val_accuracy:  0.8313810950694633 Val_Acc:  1.5470594452450441\n",
      "Epoch number: 1207/10000step_number: 0/29 Accuracy:  0.8381065894772689 Loss:  1.4706262491279245 Val_accuracy:  0.831653500408608 Val_cost:  1.4706262491279245 Val_accuracy:  0.831653500408608 Val_Acc:  1.5469103973867093\n",
      "Epoch number: 1208/10000step_number: 0/29 Accuracy:  0.8382087519155457 Loss:  1.470380374798391 Val_accuracy:  0.8315172977390357 Val_cost:  1.470380374798391 Val_accuracy:  0.8315172977390357 Val_Acc:  1.5467623877299008\n",
      "Epoch number: 1209/10000step_number: 0/29 Accuracy:  0.8383449684999149 Loss:  1.4701356321824088 Val_accuracy:  0.831653500408608 Val_cost:  1.4701356321824088 Val_accuracy:  0.831653500408608 Val_Acc:  1.5466153711983552\n",
      "Epoch number: 1210/10000step_number: 0/29 Accuracy:  0.8385492933764686 Loss:  1.4698919667273485 Val_accuracy:  0.8317897030781803 Val_cost:  1.4698919667273485 Val_accuracy:  0.8317897030781803 Val_Acc:  1.5464693082081604\n",
      "Epoch number: 1211/10000step_number: 0/29 Accuracy:  0.8386855099608377 Loss:  1.4696493176225687 Val_accuracy:  0.8317897030781803 Val_cost:  1.4696493176225687 Val_accuracy:  0.8317897030781803 Val_Acc:  1.546324165532821\n",
      "Epoch number: 1212/10000step_number: 0/29 Accuracy:  0.8386855099608377 Loss:  1.4694076190745164 Val_accuracy:  0.8317897030781803 Val_cost:  1.4694076190745164 Val_accuracy:  0.8317897030781803 Val_Acc:  1.5461799167368306\n",
      "Epoch number: 1213/10000step_number: 0/29 Accuracy:  0.8388217265452069 Loss:  1.4691668019652844 Val_accuracy:  0.8317897030781803 Val_cost:  1.4691668019652844 Val_accuracy:  0.8317897030781803 Val_Acc:  1.5460365421736597\n",
      "Epoch number: 1214/10000step_number: 0/29 Accuracy:  0.8389238889834837 Loss:  1.468926795707508 Val_accuracy:  0.831653500408608 Val_cost:  1.468926795707508 Val_accuracy:  0.831653500408608 Val_Acc:  1.5458940286167144\n",
      "Epoch number: 1215/10000step_number: 0/29 Accuracy:  0.8393325387365912 Loss:  1.4686875301589861 Val_accuracy:  0.8317897030781803 Val_cost:  1.4686875301589861 Val_accuracy:  0.8317897030781803 Val_Acc:  1.5457523686476895\n",
      "Epoch number: 1216/10000step_number: 0/29 Accuracy:  0.839775242635791 Loss:  1.4684489375035332 Val_accuracy:  0.8319259057477526 Val_cost:  1.4684489375035332 Val_accuracy:  0.8319259057477526 Val_Acc:  1.5456115599500673\n",
      "Epoch number: 1217/10000step_number: 0/29 Accuracy:  0.8402179465349906 Loss:  1.4682109540224102 Val_accuracy:  0.8319259057477526 Val_cost:  1.4682109540224102 Val_accuracy:  0.8319259057477526 Val_Acc:  1.5454716046402046\n",
      "Epoch number: 1218/10000step_number: 0/29 Accuracy:  0.8405244338498212 Loss:  1.4679735216760756 Val_accuracy:  0.832062108417325 Val_cost:  1.4679735216760756 Val_accuracy:  0.832062108417325 Val_Acc:  1.5453325087228225\n",
      "Epoch number: 1219/10000step_number: 0/29 Accuracy:  0.8405584879959135 Loss:  1.4677365894056593 Val_accuracy:  0.8319259057477526 Val_cost:  1.4677365894056593 Val_accuracy:  0.8319259057477526 Val_Acc:  1.545194281698936\n",
      "Epoch number: 1220/10000step_number: 0/29 Accuracy:  0.8406606504341904 Loss:  1.4675001140657198 Val_accuracy:  0.832062108417325 Val_cost:  1.4675001140657198 Val_accuracy:  0.832062108417325 Val_Acc:  1.5450569363023032\n",
      "Epoch number: 1221/10000step_number: 0/29 Accuracy:  0.8401157840967137 Loss:  1.467264060923971 Val_accuracy:  0.831653500408608 Val_cost:  1.467264060923971 Val_accuracy:  0.831653500408608 Val_Acc:  1.544920488308579\n",
      "Epoch number: 1222/10000step_number: 0/29 Accuracy:  0.8402179465349906 Loss:  1.4670284037067673 Val_accuracy:  0.8317897030781803 Val_cost:  1.4670284037067673 Val_accuracy:  0.8317897030781803 Val_Acc:  1.5447849563542122\n",
      "Epoch number: 1223/10000step_number: 0/29 Accuracy:  0.8399455133662523 Loss:  1.4667931242193655 Val_accuracy:  0.832062108417325 Val_cost:  1.4667931242193655 Val_accuracy:  0.832062108417325 Val_Acc:  1.544650361713926\n",
      "Epoch number: 1224/10000step_number: 0/29 Accuracy:  0.8400476758045292 Loss:  1.4665582116133031 Val_accuracy:  0.8323345137564696 Val_cost:  1.4665582116133031 Val_accuracy:  0.8323345137564696 Val_Acc:  1.544516728007588\n",
      "Epoch number: 1225/10000step_number: 0/29 Accuracy:  0.8401838923888983 Loss:  1.466323661399803 Val_accuracy:  0.8323345137564696 Val_cost:  1.466323661399803 Val_accuracy:  0.8323345137564696 Val_Acc:  1.544384080830145\n",
      "Epoch number: 1226/10000step_number: 0/29 Accuracy:  0.8402860548271752 Loss:  1.4660894743151818 Val_accuracy:  0.8323345137564696 Val_cost:  1.4660894743151818 Val_accuracy:  0.8323345137564696 Val_Acc:  1.5442524473179007\n",
      "Epoch number: 1227/10000step_number: 0/29 Accuracy:  0.8404563255576366 Loss:  1.4658556551352369 Val_accuracy:  0.8323345137564696 Val_cost:  1.4658556551352369 Val_accuracy:  0.8323345137564696 Val_Acc:  1.544121855678516\n",
      "Epoch number: 1228/10000step_number: 0/29 Accuracy:  0.8404563255576366 Loss:  1.4656222115174269 Val_accuracy:  0.8323345137564696 Val_cost:  1.4656222115174269 Val_accuracy:  0.8323345137564696 Val_Acc:  1.5439923347179179\n",
      "Epoch number: 1229/10000step_number: 0/29 Accuracy:  0.8405244338498212 Loss:  1.4653891529289922 Val_accuracy:  0.832470716426042 Val_cost:  1.4653891529289922 Val_accuracy:  0.832470716426042 Val_Acc:  1.54386391339178\n",
      "Epoch number: 1230/10000step_number: 0/29 Accuracy:  0.8406606504341904 Loss:  1.4651564896996052 Val_accuracy:  0.832470716426042 Val_cost:  1.4651564896996052 Val_accuracy:  0.832470716426042 Val_Acc:  1.543736620394388\n",
      "Epoch number: 1231/10000step_number: 0/29 Accuracy:  0.839775242635791 Loss:  1.464924232219153 Val_accuracy:  0.832062108417325 Val_cost:  1.464924232219153 Val_accuracy:  0.832062108417325 Val_Acc:  1.5436104837835518\n",
      "Epoch number: 1232/10000step_number: 0/29 Accuracy:  0.8396049719053295 Loss:  1.4646923902849573 Val_accuracy:  0.8321983110868973 Val_cost:  1.4646923902849573 Val_accuracy:  0.8321983110868973 Val_Acc:  1.5434855306339175\n",
      "Epoch number: 1233/10000step_number: 0/29 Accuracy:  0.8403201089732675 Loss:  1.4644609725895288 Val_accuracy:  0.8331517297739036 Val_cost:  1.4644609725895288 Val_accuracy:  0.8331517297739036 Val_Acc:  1.5433617867121683\n",
      "Epoch number: 1234/10000step_number: 0/29 Accuracy:  0.8405244338498212 Loss:  1.464229986332173 Val_accuracy:  0.8335603377826205 Val_cost:  1.464229986332173 Val_accuracy:  0.8335603377826205 Val_Acc:  1.5432392761707099\n",
      "Epoch number: 1235/10000step_number: 0/29 Accuracy:  0.8405244338498212 Loss:  1.4639994369380043 Val_accuracy:  0.8335603377826205 Val_cost:  1.4639994369380043 Val_accuracy:  0.8335603377826205 Val_Acc:  1.5431180212595337\n",
      "Epoch number: 1236/10000step_number: 0/29 Accuracy:  0.840728758726375 Loss:  1.4637693278796415 Val_accuracy:  0.8338327431217651 Val_cost:  1.4637693278796415 Val_accuracy:  0.8338327431217651 Val_Acc:  1.542998042063798\n",
      "Epoch number: 1237/10000step_number: 0/29 Accuracy:  0.8408309211646517 Loss:  1.463539660622609 Val_accuracy:  0.8339689457913375 Val_cost:  1.463539660622609 Val_accuracy:  0.8339689457913375 Val_Acc:  1.5428793562931633\n",
      "Epoch number: 1238/10000step_number: 0/29 Accuracy:  0.8410352460412055 Loss:  1.4633104347505101 Val_accuracy:  0.8342413511304821 Val_cost:  1.4633104347505101 Val_accuracy:  0.8342413511304821 Val_Acc:  1.5427619791796376\n",
      "Epoch number: 1239/10000step_number: 0/29 Accuracy:  0.8413076792099438 Loss:  1.4630816483503126 Val_accuracy:  0.8349223644783438 Val_cost:  1.4630816483503126 Val_accuracy:  0.8349223644783438 Val_Acc:  1.542645923568958\n",
      "Epoch number: 1240/10000step_number: 0/29 Accuracy:  0.8413417333560361 Loss:  1.4628532987178 Val_accuracy:  0.8349223644783438 Val_cost:  1.4628532987178 Val_accuracy:  0.8349223644783438 Val_Acc:  1.542531200284009\n",
      "Epoch number: 1241/10000step_number: 0/29 Accuracy:  0.8406265962880981 Loss:  1.4626253833555547 Val_accuracy:  0.8334241351130482 Val_cost:  1.4626253833555547 Val_accuracy:  0.8334241351130482 Val_Acc:  1.5424178187675264\n",
      "Epoch number: 1242/10000step_number: 0/29 Accuracy:  0.8415460582325898 Loss:  1.4623979011069623 Val_accuracy:  0.8339689457913375 Val_cost:  1.4623979011069623 Val_accuracy:  0.8339689457913375 Val_Acc:  1.542305787888696\n",
      "Epoch number: 1243/10000step_number: 0/29 Accuracy:  0.841682274816959 Loss:  1.4621708531799489 Val_accuracy:  0.8345137564696268 Val_cost:  1.4621708531799489 Val_accuracy:  0.8345137564696268 Val_Acc:  1.5421951166968777\n",
      "Epoch number: 1244/10000step_number: 0/29 Accuracy:  0.8417844372552358 Loss:  1.4619442438369021 Val_accuracy:  0.8345137564696268 Val_cost:  1.4619442438369021 Val_accuracy:  0.8345137564696268 Val_Acc:  1.5420858149069725\n",
      "Epoch number: 1245/10000step_number: 0/29 Accuracy:  0.8418865996935126 Loss:  1.4617180806543042 Val_accuracy:  0.8349223644783438 Val_cost:  1.4617180806543042 Val_accuracy:  0.8349223644783438 Val_Acc:  1.54197789301159\n",
      "Epoch number: 1246/10000step_number: 0/29 Accuracy:  0.8421249787161587 Loss:  1.4614923744014445 Val_accuracy:  0.8349223644783438 Val_cost:  1.4614923744014445 Val_accuracy:  0.8349223644783438 Val_Acc:  1.541871362057911\n",
      "Epoch number: 1247/10000step_number: 0/29 Accuracy:  0.8422271411544355 Loss:  1.4612671386707365 Val_accuracy:  0.8351947698174884 Val_cost:  1.4612671386707365 Val_accuracy:  0.8351947698174884 Val_Acc:  1.5417662332152466\n",
      "Epoch number: 1248/10000step_number: 0/29 Accuracy:  0.8422952494466202 Loss:  1.4610423893950844 Val_accuracy:  0.8353309724870608 Val_cost:  1.4610423893950844 Val_accuracy:  0.8353309724870608 Val_Acc:  1.5416625172673386\n",
      "Epoch number: 1249/10000step_number: 0/29 Accuracy:  0.842635790907543 Loss:  1.4608181443446657 Val_accuracy:  0.83587578316535 Val_cost:  1.4608181443446657 Val_accuracy:  0.83587578316535 Val_Acc:  1.5415602241214703\n",
      "Epoch number: 1250/10000step_number: 0/29 Accuracy:  0.8427038991997275 Loss:  1.4605944226471397 Val_accuracy:  0.8357395804957777 Val_cost:  1.4605944226471397 Val_accuracy:  0.8357395804957777 Val_Acc:  1.5414593623763813\n",
      "Epoch number: 1251/10000step_number: 0/29 Accuracy:  0.8430784948067427 Loss:  1.460371244343471 Val_accuracy:  0.8361481885044947 Val_cost:  1.460371244343471 Val_accuracy:  0.8361481885044947 Val_Acc:  1.5413599389565305\n",
      "Epoch number: 1252/10000step_number: 0/29 Accuracy:  0.8435893069981271 Loss:  1.4601486299789883 Val_accuracy:  0.8364205938436393 Val_cost:  1.4601486299789883 Val_accuracy:  0.8364205938436393 Val_Acc:  1.5412619588055998\n",
      "Epoch number: 1253/10000step_number: 0/29 Accuracy:  0.8437255235824962 Loss:  1.4599266002298634 Val_accuracy:  0.8365567965132117 Val_cost:  1.4599266002298634 Val_accuracy:  0.8365567965132117 Val_Acc:  1.5411654246317372\n",
      "Epoch number: 1254/10000step_number: 0/29 Accuracy:  0.8439639026051422 Loss:  1.4597051755715607 Val_accuracy:  0.8368292018523563 Val_cost:  1.4597051755715607 Val_accuracy:  0.8368292018523563 Val_Acc:  1.5410703367032752\n",
      "Epoch number: 1255/10000step_number: 0/29 Accuracy:  0.8439639026051422 Loss:  1.4594843760026557 Val_accuracy:  0.837101607191501 Val_cost:  1.4594843760026557 Val_accuracy:  0.837101607191501 Val_Acc:  1.5409766927014064\n",
      "Epoch number: 1256/10000step_number: 0/29 Accuracy:  0.8441682274816958 Loss:  1.4592642208416944 Val_accuracy:  0.8372378098610733 Val_cost:  1.4592642208416944 Val_accuracy:  0.8372378098610733 Val_Acc:  1.540884487641618\n",
      "Epoch number: 1257/10000step_number: 0/29 Accuracy:  0.8443044440660651 Loss:  1.459044728615172 Val_accuracy:  0.837510215200218 Val_cost:  1.459044728615172 Val_accuracy:  0.837510215200218 Val_Acc:  1.5407937138775614\n",
      "Epoch number: 1258/10000step_number: 0/29 Accuracy:  0.8444066065043419 Loss:  1.4588259170510296 Val_accuracy:  0.8376464178697902 Val_cost:  1.4588259170510296 Val_accuracy:  0.8376464178697902 Val_Acc:  1.5407043611986533\n",
      "Epoch number: 1259/10000step_number: 0/29 Accuracy:  0.8444066065043419 Loss:  1.4586078031848924 Val_accuracy:  0.8376464178697902 Val_cost:  1.4586078031848924 Val_accuracy:  0.8376464178697902 Val_Acc:  1.5406164170268117\n",
      "Epoch number: 1260/10000step_number: 0/29 Accuracy:  0.8445087689426187 Loss:  1.45839040357658 Val_accuracy:  0.8376464178697902 Val_cost:  1.45839040357658 Val_accuracy:  0.8376464178697902 Val_Acc:  1.540529866709081\n",
      "Epoch number: 1261/10000step_number: 0/29 Accuracy:  0.8446449855269879 Loss:  1.458173734623511 Val_accuracy:  0.8377826205393626 Val_cost:  1.458173734623511 Val_accuracy:  0.8377826205393626 Val_Acc:  1.540444693892661\n",
      "Epoch number: 1262/10000step_number: 0/29 Accuracy:  0.8447812021113571 Loss:  1.4579578129467923 Val_accuracy:  0.8379188232089348 Val_cost:  1.4579578129467923 Val_accuracy:  0.8379188232089348 Val_Acc:  1.5403608809582354\n",
      "Epoch number: 1263/10000step_number: 0/29 Accuracy:  0.8450195811340031 Loss:  1.4577426558161175 Val_accuracy:  0.8381912285480796 Val_cost:  1.4577426558161175 Val_accuracy:  0.8381912285480796 Val_Acc:  1.5402784094775333\n",
      "Epoch number: 1264/10000step_number: 0/29 Accuracy:  0.8450195811340031 Loss:  1.457528281571881 Val_accuracy:  0.8381912285480796 Val_cost:  1.457528281571881 Val_accuracy:  0.8381912285480796 Val_Acc:  1.5401972606525347\n",
      "Epoch number: 1265/10000step_number: 0/29 Accuracy:  0.8449514728418185 Loss:  1.457314709997394 Val_accuracy:  0.8385998365567965 Val_cost:  1.457314709997394 Val_accuracy:  0.8385998365567965 Val_Acc:  1.5401174156870807\n",
      "Epoch number: 1266/10000step_number: 0/29 Accuracy:  0.8452920143027414 Loss:  1.4571019625906225 Val_accuracy:  0.8395532552438028 Val_cost:  1.4571019625906225 Val_accuracy:  0.8395532552438028 Val_Acc:  1.5400388560370462\n",
      "Epoch number: 1267/10000step_number: 0/29 Accuracy:  0.8453260684488336 Loss:  1.4568900626829682 Val_accuracy:  0.8396894579133751 Val_cost:  1.4568900626829682 Val_accuracy:  0.8396894579133751 Val_Acc:  1.5399615634830477\n",
      "Epoch number: 1268/10000step_number: 0/29 Accuracy:  0.8454963391792951 Loss:  1.4566790353517476 Val_accuracy:  0.8398256605829474 Val_cost:  1.4566790353517476 Val_accuracy:  0.8398256605829474 Val_Acc:  1.539885519969445\n",
      "Epoch number: 1269/10000step_number: 0/29 Accuracy:  0.8457347182019411 Loss:  1.4564689070729109 Val_accuracy:  0.8398256605829474 Val_cost:  1.4564689070729109 Val_accuracy:  0.8398256605829474 Val_Acc:  1.5398107071564577\n",
      "Epoch number: 1270/10000step_number: 0/29 Accuracy:  0.8458368806402179 Loss:  1.4562597050616435 Val_accuracy:  0.8398256605829474 Val_cost:  1.4562597050616435 Val_accuracy:  0.8398256605829474 Val_Acc:  1.5397371056388878\n",
      "Epoch number: 1271/10000step_number: 0/29 Accuracy:  0.8459049889324025 Loss:  1.4560514562522848 Val_accuracy:  0.8399618632525198 Val_cost:  1.4560514562522848 Val_accuracy:  0.8399618632525198 Val_Acc:  1.539664693797762\n",
      "Epoch number: 1272/10000step_number: 0/29 Accuracy:  0.8459390430784948 Loss:  1.4558441858785027 Val_accuracy:  0.8399618632525198 Val_cost:  1.4558441858785027 Val_accuracy:  0.8399618632525198 Val_Acc:  1.5395934462733034\n",
      "Epoch number: 1273/10000step_number: 0/29 Accuracy:  0.8461093138089563 Loss:  1.4556379156345072 Val_accuracy:  0.8403704712612368 Val_cost:  1.4556379156345072 Val_accuracy:  0.8403704712612368 Val_Acc:  1.5395233320827169\n",
      "Epoch number: 1274/10000step_number: 0/29 Accuracy:  0.8462455303933254 Loss:  1.4554326614344233 Val_accuracy:  0.8403704712612368 Val_cost:  1.4554326614344233 Val_accuracy:  0.8403704712612368 Val_Acc:  1.5394543124598026\n",
      "Epoch number: 1275/10000step_number: 0/29 Accuracy:  0.8463136386855099 Loss:  1.4552284308465309 Val_accuracy:  0.8407790792699537 Val_cost:  1.4552284308465309 Val_accuracy:  0.8407790792699537 Val_Acc:  1.5393863385680235\n",
      "Epoch number: 1276/10000step_number: 0/29 Accuracy:  0.8465179635620637 Loss:  1.4550252203672043 Val_accuracy:  0.8407790792699537 Val_cost:  1.4550252203672043 Val_accuracy:  0.8407790792699537 Val_Acc:  1.5393193493342192\n",
      "Epoch number: 1277/10000step_number: 0/29 Accuracy:  0.8465179635620637 Loss:  1.4548230128160193 Val_accuracy:  0.8407790792699537 Val_cost:  1.4548230128160193 Val_accuracy:  0.8407790792699537 Val_Acc:  1.539253269756338\n",
      "Epoch number: 1278/10000step_number: 0/29 Accuracy:  0.8464498552698791 Loss:  1.4546217752671855 Val_accuracy:  0.8407790792699537 Val_cost:  1.4546217752671855 Val_accuracy:  0.8407790792699537 Val_Acc:  1.539188010131798\n",
      "Epoch number: 1279/10000step_number: 0/29 Accuracy:  0.8466882342925252 Loss:  1.4544214580535149 Val_accuracy:  0.840915281939526 Val_cost:  1.4544214580535149 Val_accuracy:  0.840915281939526 Val_Acc:  1.5391234666917821\n",
      "Epoch number: 1280/10000step_number: 0/29 Accuracy:  0.8467222884386174 Loss:  1.4542219954355229 Val_accuracy:  0.840915281939526 Val_cost:  1.4542219954355229 Val_accuracy:  0.840915281939526 Val_Acc:  1.5390595240575986\n",
      "Epoch number: 1281/10000step_number: 0/29 Accuracy:  0.8474033713604632 Loss:  1.4540233084519536 Val_accuracy:  0.8417324979569599 Val_cost:  1.4540233084519536 Val_accuracy:  0.8417324979569599 Val_Acc:  1.5389960597088401\n",
      "Epoch number: 1282/10000step_number: 0/29 Accuracy:  0.8476076962370168 Loss:  1.4538253102004324 Val_accuracy:  0.8422773086352493 Val_cost:  1.4538253102004324 Val_accuracy:  0.8422773086352493 Val_Acc:  1.5389329502578966\n",
      "Epoch number: 1283/10000step_number: 0/29 Accuracy:  0.8479141835518474 Loss:  1.4536279133320464 Val_accuracy:  0.8425497139743939 Val_cost:  1.4536279133320464 Val_accuracy:  0.8425497139743939 Val_Acc:  1.538870078822127\n",
      "Epoch number: 1284/10000step_number: 0/29 Accuracy:  0.8482887791588626 Loss:  1.453431038971052 Val_accuracy:  0.8426859166439662 Val_cost:  1.453431038971052 Val_accuracy:  0.8426859166439662 Val_Acc:  1.5388073423225\n",
      "Epoch number: 1285/10000step_number: 0/29 Accuracy:  0.8484249957432317 Loss:  1.4532346257782591 Val_accuracy:  0.8426859166439662 Val_cost:  1.4532346257782591 Val_accuracy:  0.8426859166439662 Val_Acc:  1.5387446573213108\n",
      "Epoch number: 1286/10000step_number: 0/29 Accuracy:  0.8485271581815086 Loss:  1.4530386376820652 Val_accuracy:  0.8428221193135386 Val_cost:  1.4530386376820652 Val_accuracy:  0.8428221193135386 Val_Acc:  1.5386819632101463\n",
      "Epoch number: 1287/10000step_number: 0/29 Accuracy:  0.8485612123276008 Loss:  1.452843069030862 Val_accuracy:  0.8426859166439662 Val_cost:  1.452843069030862 Val_accuracy:  0.8426859166439662 Val_Acc:  1.5386192221973052\n",
      "Epoch number: 1288/10000step_number: 0/29 Accuracy:  0.8486974289119701 Loss:  1.4526479465115107 Val_accuracy:  0.8430945246526832 Val_cost:  1.4526479465115107 Val_accuracy:  0.8430945246526832 Val_Acc:  1.5385564164378007\n",
      "Epoch number: 1289/10000step_number: 0/29 Accuracy:  0.8487314830580623 Loss:  1.4524533278912695 Val_accuracy:  0.8432307273222556 Val_cost:  1.4524533278912695 Val_accuracy:  0.8432307273222556 Val_Acc:  1.538493543456633\n",
      "Epoch number: 1290/10000step_number: 0/29 Accuracy:  0.8487314830580623 Loss:  1.452259298193285 Val_accuracy:  0.8435031326614002 Val_cost:  1.452259298193285 Val_accuracy:  0.8435031326614002 Val_Acc:  1.5384306113863884\n",
      "Epoch number: 1291/10000step_number: 0/29 Accuracy:  0.8488676996424315 Loss:  1.4520659641498488 Val_accuracy:  0.8435031326614002 Val_cost:  1.4520659641498488 Val_accuracy:  0.8435031326614002 Val_Acc:  1.5383676352975844\n",
      "Epoch number: 1292/10000step_number: 0/29 Accuracy:  0.8489358079346161 Loss:  1.4518734477294943 Val_accuracy:  0.8439117406701171 Val_cost:  1.4518734477294943 Val_accuracy:  0.8439117406701171 Val_Acc:  1.5383046351626481\n",
      "Epoch number: 1293/10000step_number: 0/29 Accuracy:  0.8490039162268006 Loss:  1.451681879367759 Val_accuracy:  0.8437755380005448 Val_cost:  1.451681879367759 Val_accuracy:  0.8437755380005448 Val_Acc:  1.5382416351379131\n",
      "Epoch number: 1294/10000step_number: 0/29 Accuracy:  0.8491741869572621 Loss:  1.4514913913960432 Val_accuracy:  0.8436393353309725 Val_cost:  1.4514913913960432 Val_accuracy:  0.8436393353309725 Val_Acc:  1.5381786633107433\n",
      "Epoch number: 1295/10000step_number: 0/29 Accuracy:  0.8492082411033544 Loss:  1.4513021120937142 Val_accuracy:  0.8436393353309725 Val_cost:  1.4513021120937142 Val_accuracy:  0.8436393353309725 Val_Acc:  1.5381157510734593\n",
      "Epoch number: 1296/10000step_number: 0/29 Accuracy:  0.8493785118338157 Loss:  1.451114160721456 Val_accuracy:  0.8436393353309725 Val_cost:  1.451114160721456 Val_accuracy:  0.8436393353309725 Val_Acc:  1.538052931743455\n",
      "Epoch number: 1297/10000step_number: 0/29 Accuracy:  0.8494466201260004 Loss:  1.450927643759159 Val_accuracy:  0.8436393353309725 Val_cost:  1.450927643759159 Val_accuracy:  0.8436393353309725 Val_Acc:  1.5379902386029138\n",
      "Epoch number: 1298/10000step_number: 0/29 Accuracy:  0.8497190532947386 Loss:  1.4507426523689675 Val_accuracy:  0.8437755380005448 Val_cost:  1.4507426523689675 Val_accuracy:  0.8437755380005448 Val_Acc:  1.5379277028602258\n",
      "Epoch number: 1299/10000step_number: 0/29 Accuracy:  0.8499574323173846 Loss:  1.4505592608991902 Val_accuracy:  0.8436393353309725 Val_cost:  1.4505592608991902 Val_accuracy:  0.8436393353309725 Val_Acc:  1.5378653520347676\n",
      "Epoch number: 1300/10000step_number: 0/29 Accuracy:  0.8502298654861229 Loss:  1.4503775261126002 Val_accuracy:  0.8441841460092617 Val_cost:  1.4503775261126002 Val_accuracy:  0.8441841460092617 Val_Acc:  1.5378032090443159\n",
      "Epoch number: 1301/10000step_number: 0/29 Accuracy:  0.8502639196322153 Loss:  1.4501974867997591 Val_accuracy:  0.8441841460092617 Val_cost:  1.4501974867997591 Val_accuracy:  0.8441841460092617 Val_Acc:  1.5377412920069657\n",
      "Epoch number: 1302/10000step_number: 0/29 Accuracy:  0.8504682445087689 Loss:  1.450019163517124 Val_accuracy:  0.8441841460092617 Val_cost:  1.450019163517124 Val_accuracy:  0.8441841460092617 Val_Acc:  1.5376796145830833\n",
      "Epoch number: 1303/10000step_number: 0/29 Accuracy:  0.8506044610931381 Loss:  1.4498425583394843 Val_accuracy:  0.8440479433396895 Val_cost:  1.4498425583394843 Val_accuracy:  0.8440479433396895 Val_Acc:  1.5376181866121135\n",
      "Epoch number: 1304/10000step_number: 0/29 Accuracy:  0.8512514898688915 Loss:  1.4496676547015641 Val_accuracy:  0.8447289566875511 Val_cost:  1.4496676547015641 Val_accuracy:  0.8447289566875511 Val_Acc:  1.5375570148189708\n",
      "Epoch number: 1305/10000step_number: 0/29 Accuracy:  0.8513536523071684 Loss:  1.4494944175907896 Val_accuracy:  0.8450013620266957 Val_cost:  1.4494944175907896 Val_accuracy:  0.8450013620266957 Val_Acc:  1.537496103429572\n",
      "Epoch number: 1306/10000step_number: 0/29 Accuracy:  0.8515239230376298 Loss:  1.4493227945060494 Val_accuracy:  0.8452737673658404 Val_cost:  1.4493227945060494 Val_accuracy:  0.8452737673658404 Val_Acc:  1.5374354546051252\n",
      "Epoch number: 1307/10000step_number: 0/29 Accuracy:  0.8515239230376298 Loss:  1.4491527176704708 Val_accuracy:  0.845546172704985 Val_cost:  1.4491527176704708 Val_accuracy:  0.845546172704985 Val_Acc:  1.5373750686552947\n",
      "Epoch number: 1308/10000step_number: 0/29 Accuracy:  0.8516941937680913 Loss:  1.4489841079287709 Val_accuracy:  0.845546172704985 Val_cost:  1.4489841079287709 Val_accuracy:  0.845546172704985 Val_Acc:  1.537314944010378\n",
      "Epoch number: 1309/10000step_number: 0/29 Accuracy:  0.8519325727907373 Loss:  1.4488168805326156 Val_accuracy:  0.845546172704985 Val_cost:  1.4488168805326156 Val_accuracy:  0.845546172704985 Val_Acc:  1.5372550769262596\n",
      "Epoch number: 1310/10000step_number: 0/29 Accuracy:  0.852136897667291 Loss:  1.448650952623182 Val_accuracy:  0.845546172704985 Val_cost:  1.448650952623182 Val_accuracy:  0.845546172704985 Val_Acc:  1.5371954608818024\n",
      "Epoch number: 1311/10000step_number: 0/29 Accuracy:  0.8522390601055678 Loss:  1.448486251726523 Val_accuracy:  0.8456823753745574 Val_cost:  1.448486251726523 Val_accuracy:  0.8456823753745574 Val_Acc:  1.5371360856360332\n",
      "Epoch number: 1312/10000step_number: 0/29 Accuracy:  0.8523412225438447 Loss:  1.4483227241135548 Val_accuracy:  0.8460909833832743 Val_cost:  1.4483227241135548 Val_accuracy:  0.8460909833832743 Val_Acc:  1.5370769359718257\n",
      "Epoch number: 1313/10000step_number: 0/29 Accuracy:  0.8525455474203985 Loss:  1.4481603415954345 Val_accuracy:  0.846363388722419 Val_cost:  1.4481603415954345 Val_accuracy:  0.846363388722419 Val_Acc:  1.537017990273166\n",
      "Epoch number: 1314/10000step_number: 0/29 Accuracy:  0.852613655712583 Loss:  1.447999105353676 Val_accuracy:  0.846363388722419 Val_cost:  1.447999105353676 Val_accuracy:  0.846363388722419 Val_Acc:  1.5369592192422667\n",
      "Epoch number: 1315/10000step_number: 0/29 Accuracy:  0.8529201430274136 Loss:  1.4478390458113097 Val_accuracy:  0.8464995913919913 Val_cost:  1.4478390458113097 Val_accuracy:  0.8464995913919913 Val_Acc:  1.5369005852023767\n",
      "Epoch number: 1316/10000step_number: 0/29 Accuracy:  0.8530563596117827 Loss:  1.4476802183270183 Val_accuracy:  0.8466357940615636 Val_cost:  1.4476802183270183 Val_accuracy:  0.8466357940615636 Val_Acc:  1.5368420424768923\n",
      "Epoch number: 1317/10000step_number: 0/29 Accuracy:  0.853090413757875 Loss:  1.4475226955087783 Val_accuracy:  0.8466357940615636 Val_cost:  1.4475226955087783 Val_accuracy:  0.8466357940615636 Val_Acc:  1.5367835392157256\n",
      "Epoch number: 1318/10000step_number: 0/29 Accuracy:  0.8531925761961519 Loss:  1.4473665578941033 Val_accuracy:  0.8466357940615636 Val_cost:  1.4473665578941033 Val_accuracy:  0.8466357940615636 Val_Acc:  1.53672502073092\n",
      "Epoch number: 1319/10000step_number: 0/29 Accuracy:  0.8537374425336285 Loss:  1.4472118852003224 Val_accuracy:  0.8466357940615636 Val_cost:  1.4472118852003224 Val_accuracy:  0.8466357940615636 Val_Acc:  1.5366664339601326\n",
      "Epoch number: 1320/10000step_number: 0/29 Accuracy:  0.8538736591179976 Loss:  1.447058749989225 Val_accuracy:  0.8466357940615636 Val_cost:  1.447058749989225 Val_accuracy:  0.8466357940615636 Val_Acc:  1.5366077322442784\n",
      "Epoch number: 1321/10000step_number: 0/29 Accuracy:  0.854043929848459 Loss:  1.4469072145042328 Val_accuracy:  0.8471806047398529 Val_cost:  1.4469072145042328 Val_accuracy:  0.8471806047398529 Val_Acc:  1.536548879371405\n",
      "Epoch number: 1322/10000step_number: 0/29 Accuracy:  0.8541460922867359 Loss:  1.446757330173259 Val_accuracy:  0.8473168074094253 Val_cost:  1.446757330173259 Val_accuracy:  0.8473168074094253 Val_Acc:  1.536489851923826\n",
      "Epoch number: 1323/10000step_number: 0/29 Accuracy:  0.854282308871105 Loss:  1.4466091384968498 Val_accuracy:  0.8473168074094253 Val_cost:  1.4466091384968498 Val_accuracy:  0.8473168074094253 Val_Acc:  1.5364306393434317\n",
      "Epoch number: 1324/10000step_number: 0/29 Accuracy:  0.8543844713093819 Loss:  1.4464626721014069 Val_accuracy:  0.8473168074094253 Val_cost:  1.4464626721014069 Val_accuracy:  0.8473168074094253 Val_Acc:  1.5363712416512154\n",
      "Epoch number: 1325/10000step_number: 0/29 Accuracy:  0.8544866337476588 Loss:  1.4463179554764063 Val_accuracy:  0.8471806047398529 Val_cost:  1.4463179554764063 Val_accuracy:  0.8471806047398529 Val_Acc:  1.5363116652644266\n",
      "Epoch number: 1326/10000step_number: 0/29 Accuracy:  0.8548271752085816 Loss:  1.446175005859323 Val_accuracy:  0.8473168074094253 Val_cost:  1.446175005859323 Val_accuracy:  0.8473168074094253 Val_Acc:  1.5362519177599392\n",
      "Epoch number: 1327/10000step_number: 0/29 Accuracy:  0.8548952835007663 Loss:  1.4460338353841684 Val_accuracy:  0.8473168074094253 Val_cost:  1.4460338353841684 Val_accuracy:  0.8473168074094253 Val_Acc:  1.5361920026955087\n",
      "Epoch number: 1328/10000step_number: 0/29 Accuracy:  0.8550655542312277 Loss:  1.4458944556672542 Val_accuracy:  0.8475892127485699 Val_cost:  1.4458944556672542 Val_accuracy:  0.8475892127485699 Val_Acc:  1.5361319156757711\n",
      "Epoch number: 1329/10000step_number: 0/29 Accuracy:  0.855235824961689 Loss:  1.4457568854836433 Val_accuracy:  0.8479978207572868 Val_cost:  1.4457568854836433 Val_accuracy:  0.8479978207572868 Val_Acc:  1.536071642741783\n",
      "Epoch number: 1330/10000step_number: 0/29 Accuracy:  0.8556444747147965 Loss:  1.4456211613924566 Val_accuracy:  0.8478616180877145 Val_cost:  1.4456211613924566 Val_accuracy:  0.8478616180877145 Val_Acc:  1.536011162078424\n",
      "Epoch number: 1331/10000step_number: 0/29 Accuracy:  0.8558487995913503 Loss:  1.4454873503718586 Val_accuracy:  0.8484064287660038 Val_cost:  1.4454873503718586 Val_accuracy:  0.8484064287660038 Val_Acc:  1.535950450483364\n",
      "Epoch number: 1332/10000step_number: 0/29 Accuracy:  0.8559169078835348 Loss:  1.445355562365159 Val_accuracy:  0.8485426314355762 Val_cost:  1.445355562365159 Val_accuracy:  0.8485426314355762 Val_Acc:  1.5358894977035082\n",
      "Epoch number: 1333/10000step_number: 0/29 Accuracy:  0.8559850161757194 Loss:  1.4452259573885653 Val_accuracy:  0.8486788341051484 Val_cost:  1.4452259573885653 Val_accuracy:  0.8486788341051484 Val_Acc:  1.5358283348485395\n",
      "Epoch number: 1334/10000step_number: 0/29 Accuracy:  0.8557466371530734 Loss:  1.4450987329602272 Val_accuracy:  0.8485426314355762 Val_cost:  1.4450987329602272 Val_accuracy:  0.8485426314355762 Val_Acc:  1.5357670848905878\n",
      "Epoch number: 1335/10000step_number: 0/29 Accuracy:  0.8558828537374426 Loss:  1.4449740606890455 Val_accuracy:  0.8489512394442931 Val_cost:  1.4449740606890455 Val_accuracy:  0.8489512394442931 Val_Acc:  1.5357060303140095\n",
      "Epoch number: 1336/10000step_number: 0/29 Accuracy:  0.8560871786139963 Loss:  1.4448519338401598 Val_accuracy:  0.8489512394442931 Val_cost:  1.4448519338401598 Val_accuracy:  0.8489512394442931 Val_Acc:  1.5356456370390317\n",
      "Epoch number: 1337/10000step_number: 0/29 Accuracy:  0.8561552869061808 Loss:  1.444731967131268 Val_accuracy:  0.8490874421138654 Val_cost:  1.444731967131268 Val_accuracy:  0.8490874421138654 Val_Acc:  1.5355864037264992\n",
      "Epoch number: 1338/10000step_number: 0/29 Accuracy:  0.8561893410522731 Loss:  1.4446133927376619 Val_accuracy:  0.8490874421138654 Val_cost:  1.4446133927376619 Val_accuracy:  0.8490874421138654 Val_Acc:  1.5355285490635902\n",
      "Epoch number: 1339/10000step_number: 0/29 Accuracy:  0.8562574493444577 Loss:  1.4444954463928548 Val_accuracy:  0.8490874421138654 Val_cost:  1.4444954463928548 Val_accuracy:  0.8490874421138654 Val_Acc:  1.5354719011574645\n",
      "Epoch number: 1340/10000step_number: 0/29 Accuracy:  0.8563255576366423 Loss:  1.4443777940302285 Val_accuracy:  0.8490874421138654 Val_cost:  1.4443777940302285 Val_accuracy:  0.8490874421138654 Val_Acc:  1.5354161758921248\n",
      "Epoch number: 1341/10000step_number: 0/29 Accuracy:  0.8564277200749191 Loss:  1.444260580191331 Val_accuracy:  0.8492236447834377 Val_cost:  1.444260580191331 Val_accuracy:  0.8492236447834377 Val_Acc:  1.5353613022202843\n",
      "Epoch number: 1342/10000step_number: 0/29 Accuracy:  0.8564958283671037 Loss:  1.4441442048632167 Val_accuracy:  0.8493598474530101 Val_cost:  1.4441442048632167 Val_accuracy:  0.8493598474530101 Val_Acc:  1.5353075162978107\n",
      "Epoch number: 1343/10000step_number: 0/29 Accuracy:  0.8567342073897497 Loss:  1.44402910638541 Val_accuracy:  0.8494960501225824 Val_cost:  1.44402910638541 Val_accuracy:  0.8494960501225824 Val_Acc:  1.5352553069473804\n",
      "Epoch number: 1344/10000step_number: 0/29 Accuracy:  0.8568363698280266 Loss:  1.4439155816052482 Val_accuracy:  0.8496322527921547 Val_cost:  1.4439155816052482 Val_accuracy:  0.8496322527921547 Val_Acc:  1.5352052743960496\n",
      "Epoch number: 1345/10000step_number: 0/29 Accuracy:  0.8569385322663035 Loss:  1.4438035355707683 Val_accuracy:  0.8497684554617271 Val_cost:  1.4438035355707683 Val_accuracy:  0.8497684554617271 Val_Acc:  1.5351577888809012\n",
      "Epoch number: 1346/10000step_number: 0/29 Accuracy:  0.857006640558488 Loss:  1.4436924410441963 Val_accuracy:  0.8500408608008717 Val_cost:  1.4436924410441963 Val_accuracy:  0.8500408608008717 Val_Acc:  1.5351126715775902\n",
      "Epoch number: 1347/10000step_number: 0/29 Accuracy:  0.8571769112889495 Loss:  1.443581834899661 Val_accuracy:  0.8504494688095887 Val_cost:  1.443581834899661 Val_accuracy:  0.8504494688095887 Val_Acc:  1.5350692412610256\n",
      "Epoch number: 1348/10000step_number: 0/29 Accuracy:  0.8572109654350417 Loss:  1.443471832911389 Val_accuracy:  0.850585671479161 Val_cost:  1.443471832911389 Val_accuracy:  0.850585671479161 Val_Acc:  1.5350264729401066\n",
      "Epoch number: 1349/10000step_number: 0/29 Accuracy:  0.8573131278733186 Loss:  1.4433627836406386 Val_accuracy:  0.850585671479161 Val_cost:  1.4433627836406386 Val_accuracy:  0.850585671479161 Val_Acc:  1.5349830542937335\n",
      "Epoch number: 1350/10000step_number: 0/29 Accuracy:  0.8578239400647029 Loss:  1.4432545497834945 Val_accuracy:  0.851402887496595 Val_cost:  1.4432545497834945 Val_accuracy:  0.851402887496595 Val_Acc:  1.5349377347647535\n",
      "Epoch number: 1351/10000step_number: 0/29 Accuracy:  0.8578239400647029 Loss:  1.443146523208428 Val_accuracy:  0.8518114955053119 Val_cost:  1.443146523208428 Val_accuracy:  0.8518114955053119 Val_Acc:  1.5348900281378821\n",
      "Epoch number: 1352/10000step_number: 0/29 Accuracy:  0.8579261025029797 Loss:  1.4430378809419997 Val_accuracy:  0.8518114955053119 Val_cost:  1.4430378809419997 Val_accuracy:  0.8518114955053119 Val_Acc:  1.5348404040314023\n",
      "Epoch number: 1353/10000step_number: 0/29 Accuracy:  0.8580623190873489 Loss:  1.4429279467983698 Val_accuracy:  0.8518114955053119 Val_cost:  1.4429279467983698 Val_accuracy:  0.8518114955053119 Val_Acc:  1.5347897274312452\n",
      "Epoch number: 1354/10000step_number: 0/29 Accuracy:  0.8581644815256257 Loss:  1.4428167351181655 Val_accuracy:  0.8522201035140289 Val_cost:  1.4428167351181655 Val_accuracy:  0.8522201035140289 Val_Acc:  1.534738891480657\n",
      "Epoch number: 1355/10000step_number: 0/29 Accuracy:  0.8582325898178104 Loss:  1.4427045130732108 Val_accuracy:  0.8520839008444565 Val_cost:  1.4427045130732108 Val_accuracy:  0.8520839008444565 Val_Acc:  1.5346882903844712\n",
      "Epoch number: 1356/10000step_number: 0/29 Accuracy:  0.8586071854248255 Loss:  1.4425916227317817 Val_accuracy:  0.8520839008444565 Val_cost:  1.4425916227317817 Val_accuracy:  0.8520839008444565 Val_Acc:  1.5346381009428642\n",
      "Epoch number: 1357/10000step_number: 0/29 Accuracy:  0.85867529371701 Loss:  1.4424783916261499 Val_accuracy:  0.8520839008444565 Val_cost:  1.4424783916261499 Val_accuracy:  0.8520839008444565 Val_Acc:  1.5345884956029638\n",
      "Epoch number: 1358/10000step_number: 0/29 Accuracy:  0.858913672739656 Loss:  1.442364767281338 Val_accuracy:  0.8520839008444565 Val_cost:  1.442364767281338 Val_accuracy:  0.8520839008444565 Val_Acc:  1.5345391758662257\n",
      "Epoch number: 1359/10000step_number: 0/29 Accuracy:  0.8590498893240252 Loss:  1.442251201690436 Val_accuracy:  0.8522201035140289 Val_cost:  1.442251201690436 Val_accuracy:  0.8522201035140289 Val_Acc:  1.5344904935895256\n",
      "Epoch number: 1360/10000step_number: 0/29 Accuracy:  0.8590839434701175 Loss:  1.4421374854000268 Val_accuracy:  0.8524925088531735 Val_cost:  1.4421374854000268 Val_accuracy:  0.8524925088531735 Val_Acc:  1.5344420519805573\n",
      "Epoch number: 1361/10000step_number: 0/29 Accuracy:  0.859152051762302 Loss:  1.4420238755476433 Val_accuracy:  0.8524925088531735 Val_cost:  1.4420238755476433 Val_accuracy:  0.8524925088531735 Val_Acc:  1.5343940204512543\n",
      "Epoch number: 1362/10000step_number: 0/29 Accuracy:  0.8592201600544866 Loss:  1.4419107272400566 Val_accuracy:  0.8526287115227459 Val_cost:  1.4419107272400566 Val_accuracy:  0.8526287115227459 Val_Acc:  1.5343468680487802\n",
      "Epoch number: 1363/10000step_number: 0/29 Accuracy:  0.8592882683466712 Loss:  1.4417970626587604 Val_accuracy:  0.8526287115227459 Val_cost:  1.4417970626587604 Val_accuracy:  0.8526287115227459 Val_Acc:  1.5342993041017061\n",
      "Epoch number: 1364/10000step_number: 0/29 Accuracy:  0.859390430784948 Loss:  1.441684755412971 Val_accuracy:  0.8527649141923181 Val_cost:  1.441684755412971 Val_accuracy:  0.8527649141923181 Val_Acc:  1.5342536537514497\n",
      "Epoch number: 1365/10000step_number: 0/29 Accuracy:  0.8595607015154095 Loss:  1.4415713174673246 Val_accuracy:  0.8529011168618905 Val_cost:  1.4415713174673246 Val_accuracy:  0.8529011168618905 Val_Acc:  1.5342068682612355\n",
      "Epoch number: 1366/10000step_number: 0/29 Accuracy:  0.8595607015154095 Loss:  1.4414589535216373 Val_accuracy:  0.8530373195314628 Val_cost:  1.4414589535216373 Val_accuracy:  0.8530373195314628 Val_Acc:  1.5341614162487835\n",
      "Epoch number: 1367/10000step_number: 0/29 Accuracy:  0.8596969180997787 Loss:  1.4413474659617662 Val_accuracy:  0.8533097248706074 Val_cost:  1.4413474659617662 Val_accuracy:  0.8533097248706074 Val_Acc:  1.5341173879515788\n",
      "Epoch number: 1368/10000step_number: 0/29 Accuracy:  0.8597990805380555 Loss:  1.441232482717452 Val_accuracy:  0.8534459275401798 Val_cost:  1.441232482717452 Val_accuracy:  0.8534459275401798 Val_Acc:  1.53406887129114\n",
      "Epoch number: 1369/10000step_number: 0/29 Accuracy:  0.8600034054146092 Loss:  1.4411256477270742 Val_accuracy:  0.853990738218469 Val_cost:  1.4411256477270742 Val_accuracy:  0.853990738218469 Val_Acc:  1.5340306652925102\n",
      "Epoch number: 1370/10000step_number: 0/29 Accuracy:  0.8600374595607015 Loss:  1.4410065695533871 Val_accuracy:  0.8542631435576137 Val_cost:  1.4410065695533871 Val_accuracy:  0.8542631435576137 Val_Acc:  1.5339775932934305\n",
      "Epoch number: 1371/10000step_number: 0/29 Accuracy:  0.8603439468755321 Loss:  1.4409018485477672 Val_accuracy:  0.854399346227186 Val_cost:  1.4409018485477672 Val_accuracy:  0.854399346227186 Val_Acc:  1.533941692314582\n",
      "Epoch number: 1372/10000step_number: 0/29 Accuracy:  0.8603439468755321 Loss:  1.4407883478423773 Val_accuracy:  0.854399346227186 Val_cost:  1.4407883478423773 Val_accuracy:  0.854399346227186 Val_Acc:  1.5338966388727087\n",
      "Epoch number: 1373/10000step_number: 0/29 Accuracy:  0.8603780010216244 Loss:  1.4406643298699693 Val_accuracy:  0.8545355488967584 Val_cost:  1.4406643298699693 Val_accuracy:  0.8545355488967584 Val_Acc:  1.5338367768363559\n",
      "Epoch number: 1374/10000step_number: 0/29 Accuracy:  0.8604120551677167 Loss:  1.4405888496453572 Val_accuracy:  0.8546717515663307 Val_cost:  1.4405888496453572 Val_accuracy:  0.8546717515663307 Val_Acc:  1.5338394523456642\n",
      "Epoch number: 1375/10000step_number: 0/29 Accuracy:  0.8604801634599012 Loss:  1.4404040743596975 Val_accuracy:  0.8546717515663307 Val_cost:  1.4404040743596975 Val_accuracy:  0.8546717515663307 Val_Acc:  1.533706927882837\n",
      "Epoch number: 1376/10000step_number: 0/29 Accuracy:  0.8607866507747318 Loss:  1.4403989356454574 Val_accuracy:  0.85521656224462 Val_cost:  1.4403989356454574 Val_accuracy:  0.85521656224462 Val_Acc:  1.5337932534673344\n",
      "Epoch number: 1377/10000step_number: 0/29 Accuracy:  0.8608207049208241 Loss:  1.4401754410699528 Val_accuracy:  0.8553527649141923 Val_cost:  1.4401754410699528 Val_accuracy:  0.8553527649141923 Val_Acc:  1.533620795176588\n",
      "Epoch number: 1378/10000step_number: 0/29 Accuracy:  0.8608888132130087 Loss:  1.4401218928754733 Val_accuracy:  0.8557613729229093 Val_cost:  1.4401218928754733 Val_accuracy:  0.8557613729229093 Val_Acc:  1.5336368840203174\n",
      "Epoch number: 1379/10000step_number: 0/29 Accuracy:  0.8610250297973778 Loss:  1.440092708827574 Val_accuracy:  0.855625170253337 Val_cost:  1.440092708827574 Val_accuracy:  0.855625170253337 Val_Acc:  1.533717721438851\n",
      "Epoch number: 1380/10000step_number: 0/29 Accuracy:  0.8605823258981781 Loss:  1.4393801559153971 Val_accuracy:  0.8549441569054753 Val_cost:  1.4393801559153971 Val_accuracy:  0.8549441569054753 Val_Acc:  1.532891800266713\n",
      "Epoch number: 1381/10000step_number: 0/29 Accuracy:  0.8611953005278392 Loss:  1.4399820969968669 Val_accuracy:  0.8558975755924816 Val_cost:  1.4399820969968669 Val_accuracy:  0.8558975755924816 Val_Acc:  1.533869469794856\n",
      "Epoch number: 1382/10000step_number: 0/29 Accuracy:  0.861399625404393 Loss:  1.439890435648563 Val_accuracy:  0.8557613729229093 Val_cost:  1.439890435648563 Val_accuracy:  0.8557613729229093 Val_Acc:  1.5337126634464149\n",
      "Epoch number: 1383/10000step_number: 0/29 Accuracy:  0.8607525966286396 Loss:  1.4388051365017407 Val_accuracy:  0.8550803595750477 Val_cost:  1.4388051365017407 Val_accuracy:  0.8550803595750477 Val_Acc:  1.5323808897999776\n",
      "Epoch number: 1384/10000step_number: 0/29 Accuracy:  0.8614336795504852 Loss:  1.4396277653763907 Val_accuracy:  0.8561699809316262 Val_cost:  1.4396277653763907 Val_accuracy:  0.8561699809316262 Val_Acc:  1.5337922535198054\n",
      "Epoch number: 1385/10000step_number: 0/29 Accuracy:  0.8613655712583007 Loss:  1.4394020781457877 Val_accuracy:  0.856033778262054 Val_cost:  1.4394020781457877 Val_accuracy:  0.856033778262054 Val_Acc:  1.5335269716146576\n",
      "Epoch number: 1386/10000step_number: 0/29 Accuracy:  0.8614336795504852 Loss:  1.4394121248749312 Val_accuracy:  0.8561699809316262 Val_cost:  1.4394121248749312 Val_accuracy:  0.8561699809316262 Val_Acc:  1.533426101648558\n",
      "Epoch number: 1387/10000step_number: 0/29 Accuracy:  0.8615698961348545 Loss:  1.4392053546921597 Val_accuracy:  0.856033778262054 Val_cost:  1.4392053546921597 Val_accuracy:  0.856033778262054 Val_Acc:  1.5333881075336557\n",
      "Epoch number: 1388/10000step_number: 0/29 Accuracy:  0.861638004427039 Loss:  1.438615829209488 Val_accuracy:  0.856033778262054 Val_cost:  1.438615829209488 Val_accuracy:  0.856033778262054 Val_Acc:  1.5328500248350352\n",
      "Epoch number: 1389/10000step_number: 0/29 Accuracy:  0.861638004427039 Loss:  1.4388649542347582 Val_accuracy:  0.856442386270771 Val_cost:  1.4388649542347582 Val_accuracy:  0.856442386270771 Val_Acc:  1.5333181380940304\n",
      "Epoch number: 1390/10000step_number: 0/29 Accuracy:  0.8617061127192236 Loss:  1.4387768727499033 Val_accuracy:  0.856442386270771 Val_cost:  1.4387768727499033 Val_accuracy:  0.856442386270771 Val_Acc:  1.5332638872439748\n",
      "Epoch number: 1391/10000step_number: 0/29 Accuracy:  0.8617742210114081 Loss:  1.4385804137405926 Val_accuracy:  0.856442386270771 Val_cost:  1.4385804137405926 Val_accuracy:  0.856442386270771 Val_Acc:  1.5330864986150412\n",
      "Epoch number: 1392/10000step_number: 0/29 Accuracy:  0.8619785458879619 Loss:  1.4384697225327887 Val_accuracy:  0.8563061836011986 Val_cost:  1.4384697225327887 Val_accuracy:  0.8563061836011986 Val_Acc:  1.5331655060355114\n",
      "Epoch number: 1393/10000step_number: 0/29 Accuracy:  0.8624212497871616 Loss:  1.4380798900421197 Val_accuracy:  0.8573958049577771 Val_cost:  1.4380798900421197 Val_accuracy:  0.8573958049577771 Val_Acc:  1.532834724989879\n",
      "Epoch number: 1394/10000step_number: 0/29 Accuracy:  0.8621828707645156 Loss:  1.4383004837383984 Val_accuracy:  0.8563061836011986 Val_cost:  1.4383004837383984 Val_accuracy:  0.8563061836011986 Val_Acc:  1.5332019437666224\n",
      "Epoch number: 1395/10000step_number: 0/29 Accuracy:  0.8621488166184232 Loss:  1.4380919106113315 Val_accuracy:  0.856442386270771 Val_cost:  1.4380919106113315 Val_accuracy:  0.856442386270771 Val_Acc:  1.5330555539266078\n",
      "Epoch number: 1396/10000step_number: 0/29 Accuracy:  0.8624553039332539 Loss:  1.4376777270448688 Val_accuracy:  0.8575320076273495 Val_cost:  1.4376777270448688 Val_accuracy:  0.8575320076273495 Val_Acc:  1.5326997957721498\n",
      "Epoch number: 1397/10000step_number: 0/29 Accuracy:  0.862829899540269 Loss:  1.4378749444237138 Val_accuracy:  0.8573958049577771 Val_cost:  1.4378749444237138 Val_accuracy:  0.8573958049577771 Val_Acc:  1.5331139492906471\n",
      "Epoch number: 1398/10000step_number: 0/29 Accuracy:  0.8627277371019921 Loss:  1.4378220579819414 Val_accuracy:  0.8576682102969219 Val_cost:  1.4378220579819414 Val_accuracy:  0.8576682102969219 Val_Acc:  1.5330527933007845\n",
      "Epoch number: 1399/10000step_number: 0/29 Accuracy:  0.8625574663715307 Loss:  1.4369265007599266 Val_accuracy:  0.8575320076273495 Val_cost:  1.4369265007599266 Val_accuracy:  0.8575320076273495 Val_Acc:  1.5322201181623125\n",
      "Epoch number: 1400/10000step_number: 0/29 Accuracy:  0.8629661161246381 Loss:  1.437455851418585 Val_accuracy:  0.8582130209752111 Val_cost:  1.437455851418585 Val_accuracy:  0.8582130209752111 Val_Acc:  1.5330443812307022\n",
      "Epoch number: 1401/10000step_number: 0/29 Accuracy:  0.8632044951472841 Loss:  1.4373262274244334 Val_accuracy:  0.8580768183056388 Val_cost:  1.4373262274244334 Val_accuracy:  0.8580768183056388 Val_Acc:  1.5329417132848486\n",
      "Epoch number: 1402/10000step_number: 0/29 Accuracy:  0.8631363868550996 Loss:  1.4373685676660828 Val_accuracy:  0.8583492236447834 Val_cost:  1.4373685676660828 Val_accuracy:  0.8583492236447834 Val_Acc:  1.5328863281822926\n",
      "Epoch number: 1403/10000step_number: 0/29 Accuracy:  0.8634428741699302 Loss:  1.437075304171313 Val_accuracy:  0.8586216289839281 Val_cost:  1.437075304171313 Val_accuracy:  0.8586216289839281 Val_Acc:  1.5328618515182613\n",
      "Epoch number: 1404/10000step_number: 0/29 Accuracy:  0.8633747658777456 Loss:  1.4368513101518685 Val_accuracy:  0.8584854263143558 Val_cost:  1.4368513101518685 Val_accuracy:  0.8584854263143558 Val_Acc:  1.5326895986018887\n",
      "Epoch number: 1405/10000step_number: 0/29 Accuracy:  0.8635109824621148 Loss:  1.4368668250071994 Val_accuracy:  0.8584854263143558 Val_cost:  1.4368668250071994 Val_accuracy:  0.8584854263143558 Val_Acc:  1.5328299015144955\n",
      "Epoch number: 1406/10000step_number: 0/29 Accuracy:  0.8634428741699302 Loss:  1.4363089302291612 Val_accuracy:  0.8586216289839281 Val_cost:  1.4363089302291612 Val_accuracy:  0.8586216289839281 Val_Acc:  1.5324515942970294\n",
      "Epoch number: 1407/10000step_number: 0/29 Accuracy:  0.8638515239230377 Loss:  1.436630336379301 Val_accuracy:  0.859030236992645 Val_cost:  1.436630336379301 Val_accuracy:  0.859030236992645 Val_Acc:  1.5328059328444237\n",
      "Epoch number: 1408/10000step_number: 0/29 Accuracy:  0.8638855780691299 Loss:  1.4364660508838687 Val_accuracy:  0.8591664396622174 Val_cost:  1.4364660508838687 Val_accuracy:  0.8591664396622174 Val_Acc:  1.532753365694162\n",
      "Epoch number: 1409/10000step_number: 0/29 Accuracy:  0.8631363868550996 Loss:  1.4355351371517893 Val_accuracy:  0.8583492236447834 Val_cost:  1.4355351371517893 Val_accuracy:  0.8583492236447834 Val_Acc:  1.5318418290547584\n",
      "Epoch number: 1410/10000step_number: 0/29 Accuracy:  0.8639536863613145 Loss:  1.4361457100040766 Val_accuracy:  0.859030236992645 Val_cost:  1.4361457100040766 Val_accuracy:  0.859030236992645 Val_Acc:  1.5327985996890636\n",
      "Epoch number: 1411/10000step_number: 0/29 Accuracy:  0.8636812531925762 Loss:  1.4360135566497632 Val_accuracy:  0.859030236992645 Val_cost:  1.4360135566497632 Val_accuracy:  0.859030236992645 Val_Acc:  1.5326805427473862\n",
      "Epoch number: 1412/10000step_number: 0/29 Accuracy:  0.8639196322152222 Loss:  1.436018025041283 Val_accuracy:  0.8588940343230728 Val_cost:  1.436018025041283 Val_accuracy:  0.8588940343230728 Val_Acc:  1.5325877594394715\n",
      "Epoch number: 1413/10000step_number: 0/29 Accuracy:  0.8638855780691299 Loss:  1.4356758056639414 Val_accuracy:  0.859030236992645 Val_cost:  1.4356758056639414 Val_accuracy:  0.859030236992645 Val_Acc:  1.532532705233086\n",
      "Epoch number: 1414/10000step_number: 0/29 Accuracy:  0.864021794653499 Loss:  1.435730664244456 Val_accuracy:  0.8591664396622174 Val_cost:  1.435730664244456 Val_accuracy:  0.8591664396622174 Val_Acc:  1.5325743916454797\n",
      "Epoch number: 1415/10000step_number: 0/29 Accuracy:  0.8640558487995913 Loss:  1.4355355385605617 Val_accuracy:  0.8591664396622174 Val_cost:  1.4355355385605617 Val_accuracy:  0.8591664396622174 Val_Acc:  1.5325314172361244\n",
      "Epoch number: 1416/10000step_number: 0/29 Accuracy:  0.8640558487995913 Loss:  1.4348469341462111 Val_accuracy:  0.859438845001362 Val_cost:  1.4348469341462111 Val_accuracy:  0.859438845001362 Val_Acc:  1.5320314842295408\n",
      "Epoch number: 1417/10000step_number: 0/29 Accuracy:  0.8647709858675293 Loss:  1.435192176266503 Val_accuracy:  0.8597112503405067 Val_cost:  1.435192176266503 Val_accuracy:  0.8597112503405067 Val_Acc:  1.5325487155638515\n",
      "Epoch number: 1418/10000step_number: 0/29 Accuracy:  0.8643282819683297 Loss:  1.4350578515341823 Val_accuracy:  0.8595750476709344 Val_cost:  1.4350578515341823 Val_accuracy:  0.8595750476709344 Val_Acc:  1.5324619032363769\n",
      "Epoch number: 1419/10000step_number: 0/29 Accuracy:  0.8648050400136217 Loss:  1.435108946832934 Val_accuracy:  0.8597112503405067 Val_cost:  1.435108946832934 Val_accuracy:  0.8597112503405067 Val_Acc:  1.532443848329974\n",
      "Epoch number: 1420/10000step_number: 0/29 Accuracy:  0.8646347692831602 Loss:  1.4347851590802292 Val_accuracy:  0.8597112503405067 Val_cost:  1.4347851590802292 Val_accuracy:  0.8597112503405067 Val_Acc:  1.5324013152679012\n",
      "Epoch number: 1421/10000step_number: 0/29 Accuracy:  0.8650093648901753 Loss:  1.4341236461885556 Val_accuracy:  0.8601198583492237 Val_cost:  1.4341236461885556 Val_accuracy:  0.8601198583492237 Val_Acc:  1.531810965332902\n",
      "Epoch number: 1422/10000step_number: 0/29 Accuracy:  0.8651796356206368 Loss:  1.4344852016451974 Val_accuracy:  0.8599836556796513 Val_cost:  1.4344852016451974 Val_accuracy:  0.8599836556796513 Val_Acc:  1.5324626374192472\n",
      "Epoch number: 1423/10000step_number: 0/29 Accuracy:  0.8648731483058062 Loss:  1.4344044272251477 Val_accuracy:  0.859847453010079 Val_cost:  1.4344044272251477 Val_accuracy:  0.859847453010079 Val_Acc:  1.5323763456924622\n",
      "Epoch number: 1424/10000step_number: 0/29 Accuracy:  0.8652477439128213 Loss:  1.4344310862754615 Val_accuracy:  0.8599836556796513 Val_cost:  1.4344310862754615 Val_accuracy:  0.8599836556796513 Val_Acc:  1.5323244968949188\n",
      "Epoch number: 1425/10000step_number: 0/29 Accuracy:  0.8650434190362677 Loss:  1.4340886595575149 Val_accuracy:  0.859847453010079 Val_cost:  1.4340886595575149 Val_accuracy:  0.859847453010079 Val_Acc:  1.5322988826339667\n",
      "Epoch number: 1426/10000step_number: 0/29 Accuracy:  0.8652477439128213 Loss:  1.4334860221825643 Val_accuracy:  0.859847453010079 Val_cost:  1.4334860221825643 Val_accuracy:  0.859847453010079 Val_Acc:  1.5317956144547127\n",
      "Epoch number: 1427/10000step_number: 0/29 Accuracy:  0.8654861229354673 Loss:  1.4338288514442228 Val_accuracy:  0.8601198583492237 Val_cost:  1.4338288514442228 Val_accuracy:  0.8601198583492237 Val_Acc:  1.532341966462218\n",
      "Epoch number: 1428/10000step_number: 0/29 Accuracy:  0.8653499063510982 Loss:  1.4336405721441627 Val_accuracy:  0.8601198583492237 Val_cost:  1.4336405721441627 Val_accuracy:  0.8601198583492237 Val_Acc:  1.5322413847509027\n",
      "Epoch number: 1429/10000step_number: 0/29 Accuracy:  0.8656223395198366 Loss:  1.4337337816160736 Val_accuracy:  0.8597112503405067 Val_cost:  1.4337337816160736 Val_accuracy:  0.8597112503405067 Val_Acc:  1.5322508676925284\n",
      "Epoch number: 1430/10000step_number: 0/29 Accuracy:  0.8658266643963902 Loss:  1.433189777932521 Val_accuracy:  0.8601198583492237 Val_cost:  1.433189777932521 Val_accuracy:  0.8601198583492237 Val_Acc:  1.532071529134551\n",
      "Epoch number: 1431/10000step_number: 0/29 Accuracy:  0.8658607185424826 Loss:  1.4333305999462214 Val_accuracy:  0.8601198583492237 Val_cost:  1.4333305999462214 Val_accuracy:  0.8601198583492237 Val_Acc:  1.5322047645530281\n",
      "Epoch number: 1432/10000step_number: 0/29 Accuracy:  0.8658607185424826 Loss:  1.4328871082220662 Val_accuracy:  0.8601198583492237 Val_cost:  1.4328871082220662 Val_accuracy:  0.8601198583492237 Val_Acc:  1.5320344554981529\n",
      "Epoch number: 1433/10000step_number: 0/29 Accuracy:  0.8661331517112209 Loss:  1.4330393634482106 Val_accuracy:  0.8602560610187959 Val_cost:  1.4330393634482106 Val_accuracy:  0.8602560610187959 Val_Acc:  1.5321872015953366\n",
      "Epoch number: 1434/10000step_number: 0/29 Accuracy:  0.86626936829559 Loss:  1.4325024935214936 Val_accuracy:  0.8602560610187959 Val_cost:  1.4325024935214936 Val_accuracy:  0.8602560610187959 Val_Acc:  1.5319349296808717\n",
      "Epoch number: 1435/10000step_number: 0/29 Accuracy:  0.8661672058573131 Loss:  1.4328608944076031 Val_accuracy:  0.8602560610187959 Val_cost:  1.4328608944076031 Val_accuracy:  0.8602560610187959 Val_Acc:  1.532249916614114\n",
      "Epoch number: 1436/10000step_number: 0/29 Accuracy:  0.8666099097565129 Loss:  1.4320143971096946 Val_accuracy:  0.8602560610187959 Val_cost:  1.4320143971096946 Val_accuracy:  0.8602560610187959 Val_Acc:  1.531721223084491\n",
      "Epoch number: 1437/10000step_number: 0/29 Accuracy:  0.8663715307338669 Loss:  1.4326118418325022 Val_accuracy:  0.8606646690275129 Val_cost:  1.4326118418325022 Val_accuracy:  0.8606646690275129 Val_Acc:  1.5322824101092247\n",
      "Epoch number: 1438/10000step_number: 0/29 Accuracy:  0.8668142346330666 Loss:  1.432148473959169 Val_accuracy:  0.8609370743666576 Val_cost:  1.432148473959169 Val_accuracy:  0.8609370743666576 Val_Acc:  1.5321087654692722\n",
      "Epoch number: 1439/10000step_number: 0/29 Accuracy:  0.8664396390260514 Loss:  1.4313951574705717 Val_accuracy:  0.8602560610187959 Val_cost:  1.4313951574705717 Val_accuracy:  0.8602560610187959 Val_Acc:  1.531383028761174\n",
      "Epoch number: 1440/10000step_number: 0/29 Accuracy:  0.8669163970713434 Loss:  1.4320087283227758 Val_accuracy:  0.8608008716970853 Val_cost:  1.4320087283227758 Val_accuracy:  0.8608008716970853 Val_Acc:  1.5324259510959624\n",
      "Epoch number: 1441/10000step_number: 0/29 Accuracy:  0.8662353141494977 Loss:  1.4318151981592284 Val_accuracy:  0.8603922636883683 Val_cost:  1.4318151981592284 Val_accuracy:  0.8603922636883683 Val_Acc:  1.532154455710056\n",
      "Epoch number: 1442/10000step_number: 0/29 Accuracy:  0.8670866678018049 Loss:  1.431875261842645 Val_accuracy:  0.8610732770362299 Val_cost:  1.431875261842645 Val_accuracy:  0.8610732770362299 Val_Acc:  1.532124112177104\n",
      "Epoch number: 1443/10000step_number: 0/29 Accuracy:  0.8668823429252511 Loss:  1.431404054875233 Val_accuracy:  0.8610732770362299 Val_cost:  1.431404054875233 Val_accuracy:  0.8610732770362299 Val_Acc:  1.532045645097832\n",
      "Epoch number: 1444/10000step_number: 0/29 Accuracy:  0.8670185595096203 Loss:  1.43103372408721 Val_accuracy:  0.8608008716970853 Val_cost:  1.43103372408721 Val_accuracy:  0.8608008716970853 Val_Acc:  1.5318589078875848\n",
      "Epoch number: 1445/10000step_number: 0/29 Accuracy:  0.8671207219478971 Loss:  1.431183214328686 Val_accuracy:  0.8610732770362299 Val_cost:  1.431183214328686 Val_accuracy:  0.8610732770362299 Val_Acc:  1.5320998886174704\n",
      "Epoch number: 1446/10000step_number: 0/29 Accuracy:  0.8670526136557126 Loss:  1.430992816635939 Val_accuracy:  0.8610732770362299 Val_cost:  1.430992816635939 Val_accuracy:  0.8610732770362299 Val_Acc:  1.532137893493837\n",
      "Epoch number: 1447/10000step_number: 0/29 Accuracy:  0.8666780180486974 Loss:  1.4302247790907736 Val_accuracy:  0.8609370743666576 Val_cost:  1.4302247790907736 Val_accuracy:  0.8609370743666576 Val_Acc:  1.5313858901790554\n",
      "Epoch number: 1448/10000step_number: 0/29 Accuracy:  0.8671547760939894 Loss:  1.4307052611790583 Val_accuracy:  0.8612094797058022 Val_cost:  1.4307052611790583 Val_accuracy:  0.8612094797058022 Val_Acc:  1.5323902518697046\n",
      "Epoch number: 1449/10000step_number: 0/29 Accuracy:  0.8675634258470969 Loss:  1.4306194395143077 Val_accuracy:  0.8609370743666576 Val_cost:  1.4306194395143077 Val_accuracy:  0.8609370743666576 Val_Acc:  1.5321772781743848\n",
      "Epoch number: 1450/10000step_number: 0/29 Accuracy:  0.8671207219478971 Loss:  1.4306679796919168 Val_accuracy:  0.8610732770362299 Val_cost:  1.4306679796919168 Val_accuracy:  0.8610732770362299 Val_Acc:  1.5321400571129824\n",
      "Epoch number: 1451/10000step_number: 0/29 Accuracy:  0.8675634258470969 Loss:  1.4301467606174443 Val_accuracy:  0.8609370743666576 Val_cost:  1.4301467606174443 Val_accuracy:  0.8609370743666576 Val_Acc:  1.532060352675284\n",
      "Epoch number: 1452/10000step_number: 0/29 Accuracy:  0.8675293717010046 Loss:  1.4298956509804162 Val_accuracy:  0.8608008716970853 Val_cost:  1.4298956509804162 Val_accuracy:  0.8608008716970853 Val_Acc:  1.5320351613888237\n",
      "Epoch number: 1453/10000step_number: 0/29 Accuracy:  0.8671888302400818 Loss:  1.4300547712085645 Val_accuracy:  0.8610732770362299 Val_cost:  1.4300547712085645 Val_accuracy:  0.8610732770362299 Val_Acc:  1.5321756504303052\n",
      "Epoch number: 1454/10000step_number: 0/29 Accuracy:  0.8677677507236506 Loss:  1.4293955073107945 Val_accuracy:  0.8608008716970853 Val_cost:  1.4293955073107945 Val_accuracy:  0.8608008716970853 Val_Acc:  1.5320090044728112\n",
      "Epoch number: 1455/10000step_number: 0/29 Accuracy:  0.8682104546228503 Loss:  1.4297398535531 Val_accuracy:  0.8616180877145192 Val_cost:  1.4297398535531 Val_accuracy:  0.8616180877145192 Val_Acc:  1.5322755186230121\n",
      "Epoch number: 1456/10000step_number: 0/29 Accuracy:  0.8683126170611272 Loss:  1.4289796715658605 Val_accuracy:  0.8614818850449468 Val_cost:  1.4289796715658605 Val_accuracy:  0.8614818850449468 Val_Acc:  1.5319479467193053\n",
      "Epoch number: 1457/10000step_number: 0/29 Accuracy:  0.8682104546228503 Loss:  1.4294541753219188 Val_accuracy:  0.8617542903840916 Val_cost:  1.4294541753219188 Val_accuracy:  0.8617542903840916 Val_Acc:  1.5323597354376668\n",
      "Epoch number: 1458/10000step_number: 0/29 Accuracy:  0.8686191043759578 Loss:  1.4289561545252567 Val_accuracy:  0.8612094797058022 Val_cost:  1.4289561545252567 Val_accuracy:  0.8612094797058022 Val_Acc:  1.5322401617678127\n",
      "Epoch number: 1459/10000step_number: 0/29 Accuracy:  0.8685169419376809 Loss:  1.4284239614885172 Val_accuracy:  0.8614818850449468 Val_cost:  1.4284239614885172 Val_accuracy:  0.8614818850449468 Val_Acc:  1.5317969247929608\n",
      "Epoch number: 1460/10000step_number: 0/29 Accuracy:  0.8690277541290652 Loss:  1.4287294886405937 Val_accuracy:  0.8614818850449468 Val_cost:  1.4287294886405937 Val_accuracy:  0.8614818850449468 Val_Acc:  1.5325211304333255\n",
      "Epoch number: 1461/10000step_number: 0/29 Accuracy:  0.8687212668142347 Loss:  1.4286289730800468 Val_accuracy:  0.8612094797058022 Val_cost:  1.4286289730800468 Val_accuracy:  0.8612094797058022 Val_Acc:  1.532418572000837\n",
      "Epoch number: 1462/10000step_number: 0/29 Accuracy:  0.8690618082751576 Loss:  1.42869478704527 Val_accuracy:  0.8616180877145192 Val_cost:  1.42869478704527 Val_accuracy:  0.8616180877145192 Val_Acc:  1.5324958815709888\n",
      "Epoch number: 1463/10000step_number: 0/29 Accuracy:  0.8691639707134343 Loss:  1.4279879578549057 Val_accuracy:  0.8616180877145192 Val_cost:  1.4279879578549057 Val_accuracy:  0.8616180877145192 Val_Acc:  1.532310507128563\n",
      "Epoch number: 1464/10000step_number: 0/29 Accuracy:  0.8694364038821727 Loss:  1.4281547408733821 Val_accuracy:  0.8614818850449468 Val_cost:  1.4281547408733821 Val_accuracy:  0.8614818850449468 Val_Acc:  1.532603939929429\n",
      "Epoch number: 1465/10000step_number: 0/29 Accuracy:  0.8691299165673421 Loss:  1.4273765454565361 Val_accuracy:  0.8614818850449468 Val_cost:  1.4273765454565361 Val_accuracy:  0.8614818850449468 Val_Acc:  1.5321282629418334\n",
      "Epoch number: 1466/10000step_number: 0/29 Accuracy:  0.8695726204665418 Loss:  1.4277195018617685 Val_accuracy:  0.8617542903840916 Val_cost:  1.4277195018617685 Val_accuracy:  0.8617542903840916 Val_Acc:  1.5328003331502666\n",
      "Epoch number: 1467/10000step_number: 0/29 Accuracy:  0.8696747829048187 Loss:  1.4275744879461632 Val_accuracy:  0.8613456823753746 Val_cost:  1.4275744879461632 Val_accuracy:  0.8613456823753746 Val_Acc:  1.532751339502254\n",
      "Epoch number: 1468/10000step_number: 0/29 Accuracy:  0.8696066746126341 Loss:  1.4275430290036253 Val_accuracy:  0.8621628983928085 Val_cost:  1.4275430290036253 Val_accuracy:  0.8621628983928085 Val_Acc:  1.5328771132726329\n",
      "Epoch number: 1469/10000step_number: 0/29 Accuracy:  0.8693682955899881 Loss:  1.4266923362462423 Val_accuracy:  0.8618904930536638 Val_cost:  1.4266923362462423 Val_accuracy:  0.8618904930536638 Val_Acc:  1.5325821261017647\n",
      "Epoch number: 1470/10000step_number: 0/29 Accuracy:  0.8696407287587263 Loss:  1.427142224067624 Val_accuracy:  0.8621628983928085 Val_cost:  1.427142224067624 Val_accuracy:  0.8621628983928085 Val_Acc:  1.5331106137901518\n",
      "Epoch number: 1471/10000step_number: 0/29 Accuracy:  0.869708837050911 Loss:  1.426687148833858 Val_accuracy:  0.8617542903840916 Val_cost:  1.426687148833858 Val_accuracy:  0.8617542903840916 Val_Acc:  1.533049307373249\n",
      "Epoch number: 1472/10000step_number: 0/29 Accuracy:  0.8689596458368807 Loss:  1.4258205824337278 Val_accuracy:  0.8616180877145192 Val_cost:  1.4258205824337278 Val_accuracy:  0.8616180877145192 Val_Acc:  1.5323511536144074\n",
      "Epoch number: 1473/10000step_number: 0/29 Accuracy:  0.8697428911970032 Loss:  1.426371495760081 Val_accuracy:  0.8617542903840916 Val_cost:  1.426371495760081 Val_accuracy:  0.8617542903840916 Val_Acc:  1.5335599779073823\n",
      "Epoch number: 1474/10000step_number: 0/29 Accuracy:  0.870185595096203 Loss:  1.4260837573933611 Val_accuracy:  0.8625715064015255 Val_cost:  1.4260837573933611 Val_accuracy:  0.8625715064015255 Val_Acc:  1.5332628997194568\n",
      "Epoch number: 1475/10000step_number: 0/29 Accuracy:  0.8697428911970032 Loss:  1.4259145190696956 Val_accuracy:  0.8617542903840916 Val_cost:  1.4259145190696956 Val_accuracy:  0.8617542903840916 Val_Acc:  1.533106158674545\n",
      "Epoch number: 1476/10000step_number: 0/29 Accuracy:  0.8703218116805721 Loss:  1.4257800700455414 Val_accuracy:  0.8624353037319531 Val_cost:  1.4257800700455414 Val_accuracy:  0.8624353037319531 Val_Acc:  1.5334239800583198\n",
      "Epoch number: 1477/10000step_number: 0/29 Accuracy:  0.870423974118849 Loss:  1.4249955465829371 Val_accuracy:  0.8621628983928085 Val_cost:  1.4249955465829371 Val_accuracy:  0.8621628983928085 Val_Acc:  1.533385592824997\n",
      "Epoch number: 1478/10000step_number: 0/29 Accuracy:  0.8698450536352801 Loss:  1.4243101684854982 Val_accuracy:  0.8618904930536638 Val_cost:  1.4243101684854982 Val_accuracy:  0.8618904930536638 Val_Acc:  1.5334354914894868\n",
      "Epoch number: 1479/10000step_number: 0/29 Accuracy:  0.8702196492422952 Loss:  1.4244585443176685 Val_accuracy:  0.8621628983928085 Val_cost:  1.4244585443176685 Val_accuracy:  0.8621628983928085 Val_Acc:  1.533879535588734\n",
      "Epoch number: 1480/10000step_number: 0/29 Accuracy:  0.8707985697258641 Loss:  1.4240150421100526 Val_accuracy:  0.8625715064015255 Val_cost:  1.4240150421100526 Val_accuracy:  0.8625715064015255 Val_Acc:  1.5339387089469616\n",
      "Epoch number: 1481/10000step_number: 0/29 Accuracy:  0.8703899199727567 Loss:  1.4237907672008996 Val_accuracy:  0.8625715064015255 Val_cost:  1.4237907672008996 Val_accuracy:  0.8625715064015255 Val_Acc:  1.5341050273334842\n",
      "Epoch number: 1482/10000step_number: 0/29 Accuracy:  0.8711731653328793 Loss:  1.4232754587606018 Val_accuracy:  0.8631163170798147 Val_cost:  1.4232754587606018 Val_accuracy:  0.8631163170798147 Val_Acc:  1.5341287009999982\n",
      "Epoch number: 1483/10000step_number: 0/29 Accuracy:  0.871139111186787 Loss:  1.4228237996886892 Val_accuracy:  0.8637973304276764 Val_cost:  1.4228237996886892 Val_accuracy:  0.8637973304276764 Val_Acc:  1.5340646420373758\n",
      "Epoch number: 1484/10000step_number: 0/29 Accuracy:  0.8716499233781713 Loss:  1.4221467604635671 Val_accuracy:  0.8629801144102425 Val_cost:  1.4221467604635671 Val_accuracy:  0.8629801144102425 Val_Acc:  1.5338143830856792\n",
      "Epoch number: 1485/10000step_number: 0/29 Accuracy:  0.8716499233781713 Loss:  1.4212525832588059 Val_accuracy:  0.8622991010623808 Val_cost:  1.4212525832588059 Val_accuracy:  0.8622991010623808 Val_Acc:  1.53336780822765\n",
      "Epoch number: 1486/10000step_number: 0/29 Accuracy:  0.8716499233781713 Loss:  1.4201531444422777 Val_accuracy:  0.8621628983928085 Val_cost:  1.4201531444422777 Val_accuracy:  0.8621628983928085 Val_Acc:  1.532876063513083\n",
      "Epoch number: 1487/10000step_number: 0/29 Accuracy:  0.8724672228843862 Loss:  1.4180474879129534 Val_accuracy:  0.8624353037319531 Val_cost:  1.4180474879129534 Val_accuracy:  0.8624353037319531 Val_Acc:  1.5321428493644937\n",
      "Epoch number: 1488/10000step_number: 0/29 Accuracy:  0.8731483058062319 Loss:  1.4168633513484057 Val_accuracy:  0.8639335330972487 Val_cost:  1.4168633513484057 Val_accuracy:  0.8639335330972487 Val_Acc:  1.5316552056407797\n",
      "Epoch number: 1489/10000step_number: 0/29 Accuracy:  0.8720585731312788 Loss:  1.418600974418569 Val_accuracy:  0.8636611277581041 Val_cost:  1.418600974418569 Val_accuracy:  0.8636611277581041 Val_Acc:  1.529120714629932\n",
      "Epoch number: 1490/10000step_number: 0/29 Accuracy:  0.8715477609398944 Loss:  1.4193431311760194 Val_accuracy:  0.8635249250885317 Val_cost:  1.4193431311760194 Val_accuracy:  0.8635249250885317 Val_Acc:  1.5270213737866218\n",
      "Epoch number: 1491/10000step_number: 0/29 Accuracy:  0.8729439809296782 Loss:  1.4201420846947328 Val_accuracy:  0.864478343775538 Val_cost:  1.4201420846947328 Val_accuracy:  0.864478343775538 Val_Acc:  1.5257952728006383\n",
      "Epoch number: 1492/10000step_number: 0/29 Accuracy:  0.8736931721437085 Loss:  1.422247649455413 Val_accuracy:  0.8642059384363934 Val_cost:  1.422247649455413 Val_accuracy:  0.8642059384363934 Val_Acc:  1.525634429631741\n",
      "Epoch number: 1493/10000step_number: 0/29 Accuracy:  0.8725012770304784 Loss:  1.4235666200042985 Val_accuracy:  0.8650231544538273 Val_cost:  1.4235666200042985 Val_accuracy:  0.8650231544538273 Val_Acc:  1.526043720915465\n",
      "Epoch number: 1494/10000step_number: 0/29 Accuracy:  0.8721947897156479 Loss:  1.4236285019264514 Val_accuracy:  0.8662489784799782 Val_cost:  1.4236285019264514 Val_accuracy:  0.8662489784799782 Val_Acc:  1.5261909911383573\n",
      "Epoch number: 1495/10000step_number: 0/29 Accuracy:  0.8719904648390941 Loss:  1.423481443254542 Val_accuracy:  0.8661127758104059 Val_cost:  1.423481443254542 Val_accuracy:  0.8661127758104059 Val_Acc:  1.5263532008757585\n",
      "Epoch number: 1496/10000step_number: 0/29 Accuracy:  0.8717861399625404 Loss:  1.4231837298253505 Val_accuracy:  0.8658403704712613 Val_cost:  1.4231837298253505 Val_accuracy:  0.8658403704712613 Val_Acc:  1.526590834522008\n",
      "Epoch number: 1497/10000step_number: 0/29 Accuracy:  0.871615869232079 Loss:  1.4229089098293557 Val_accuracy:  0.8658403704712613 Val_cost:  1.4229089098293557 Val_accuracy:  0.8658403704712613 Val_Acc:  1.526823681892179\n",
      "Epoch number: 1498/10000step_number: 0/29 Accuracy:  0.8708326238719564 Loss:  1.4222184028165539 Val_accuracy:  0.8651593571233996 Val_cost:  1.4222184028165539 Val_accuracy:  0.8651593571233996 Val_Acc:  1.5269880442264152\n",
      "Epoch number: 1499/10000step_number: 0/29 Accuracy:  0.8704580282649412 Loss:  1.422319260523345 Val_accuracy:  0.8650231544538273 Val_cost:  1.422319260523345 Val_accuracy:  0.8650231544538273 Val_Acc:  1.5273714625821873\n",
      "Epoch number: 1500/10000step_number: 0/29 Accuracy:  0.8700493785118338 Loss:  1.4219808721870137 Val_accuracy:  0.864886951784255 Val_cost:  1.4219808721870137 Val_accuracy:  0.864886951784255 Val_Acc:  1.5276304445278255\n",
      "Epoch number: 1501/10000step_number: 0/29 Accuracy:  0.8701174868040183 Loss:  1.421823244474778 Val_accuracy:  0.864886951784255 Val_cost:  1.421823244474778 Val_accuracy:  0.864886951784255 Val_Acc:  1.5278689851623883\n",
      "Epoch number: 1502/10000step_number: 0/29 Accuracy:  0.8702196492422952 Loss:  1.4217357043547962 Val_accuracy:  0.8651593571233996 Val_cost:  1.4217357043547962 Val_accuracy:  0.8651593571233996 Val_Acc:  1.5280806148694286\n",
      "Epoch number: 1503/10000step_number: 0/29 Accuracy:  0.8701174868040183 Loss:  1.42163014756435 Val_accuracy:  0.8652955597929719 Val_cost:  1.42163014756435 Val_accuracy:  0.8652955597929719 Val_Acc:  1.5282241128759197\n",
      "Epoch number: 1504/10000step_number: 0/29 Accuracy:  0.8700153243657416 Loss:  1.421444330314985 Val_accuracy:  0.8650231544538273 Val_cost:  1.421444330314985 Val_accuracy:  0.8650231544538273 Val_Acc:  1.5282875983023643\n",
      "Epoch number: 1505/10000step_number: 0/29 Accuracy:  0.8703558658266644 Loss:  1.4215591984725422 Val_accuracy:  0.8652955597929719 Val_cost:  1.4215591984725422 Val_accuracy:  0.8652955597929719 Val_Acc:  1.5284615651508\n",
      "Epoch number: 1506/10000step_number: 0/29 Accuracy:  0.8705261365571259 Loss:  1.421373717009556 Val_accuracy:  0.8655679651321165 Val_cost:  1.421373717009556 Val_accuracy:  0.8655679651321165 Val_Acc:  1.5285382004259733\n",
      "Epoch number: 1507/10000step_number: 0/29 Accuracy:  0.8704920824110336 Loss:  1.421345049664018 Val_accuracy:  0.8657041678016889 Val_cost:  1.421345049664018 Val_accuracy:  0.8657041678016889 Val_Acc:  1.5286350712416867\n",
      "Epoch number: 1508/10000step_number: 0/29 Accuracy:  0.8703558658266644 Loss:  1.4210153934058725 Val_accuracy:  0.8659765731408335 Val_cost:  1.4210153934058725 Val_accuracy:  0.8659765731408335 Val_Acc:  1.5286591720563016\n",
      "Epoch number: 1509/10000step_number: 0/29 Accuracy:  0.8705261365571259 Loss:  1.4211523346165287 Val_accuracy:  0.8658403704712613 Val_cost:  1.4211523346165287 Val_accuracy:  0.8658403704712613 Val_Acc:  1.5288378448221027\n",
      "Epoch number: 1510/10000step_number: 0/29 Accuracy:  0.8706282989954027 Loss:  1.4210837053462975 Val_accuracy:  0.8662489784799782 Val_cost:  1.4210837053462975 Val_accuracy:  0.8662489784799782 Val_Acc:  1.5289604245206712\n",
      "Epoch number: 1511/10000step_number: 0/29 Accuracy:  0.8703899199727567 Loss:  1.4207021531913646 Val_accuracy:  0.8662489784799782 Val_cost:  1.4207021531913646 Val_accuracy:  0.8662489784799782 Val_Acc:  1.5289456902430867\n",
      "Epoch number: 1512/10000step_number: 0/29 Accuracy:  0.870662353141495 Loss:  1.4207989170509727 Val_accuracy:  0.8659765731408335 Val_cost:  1.4207989170509727 Val_accuracy:  0.8659765731408335 Val_Acc:  1.5291038714407823\n",
      "Epoch number: 1513/10000step_number: 0/29 Accuracy:  0.8709347863102332 Loss:  1.4207206250176914 Val_accuracy:  0.8662489784799782 Val_cost:  1.4207206250176914 Val_accuracy:  0.8662489784799782 Val_Acc:  1.529231930530817\n",
      "Epoch number: 1514/10000step_number: 0/29 Accuracy:  0.8709688404563256 Loss:  1.4202856410813232 Val_accuracy:  0.8665213838191228 Val_cost:  1.4202856410813232 Val_accuracy:  0.8665213838191228 Val_Acc:  1.5291883623725047\n",
      "Epoch number: 1515/10000step_number: 0/29 Accuracy:  0.8710710028946024 Loss:  1.4204013906000006 Val_accuracy:  0.8663851811495505 Val_cost:  1.4204013906000006 Val_accuracy:  0.8663851811495505 Val_Acc:  1.5293520033609\n",
      "Epoch number: 1516/10000step_number: 0/29 Accuracy:  0.8716839775242636 Loss:  1.4202887611033101 Val_accuracy:  0.8669299918278398 Val_cost:  1.4202887611033101 Val_accuracy:  0.8669299918278398 Val_Acc:  1.5294589272817347\n",
      "Epoch number: 1517/10000step_number: 0/29 Accuracy:  0.8717520858164481 Loss:  1.4202295221029468 Val_accuracy:  0.8673385998365568 Val_cost:  1.4202295221029468 Val_accuracy:  0.8673385998365568 Val_Acc:  1.529554881402631\n",
      "Epoch number: 1518/10000step_number: 0/29 Accuracy:  0.8713434360633407 Loss:  1.4193889184919266 Val_accuracy:  0.8666575864886952 Val_cost:  1.4193889184919266 Val_accuracy:  0.8666575864886952 Val_Acc:  1.529374329500487\n",
      "Epoch number: 1519/10000step_number: 0/29 Accuracy:  0.8714455985016176 Loss:  1.4200400211818989 Val_accuracy:  0.8669299918278398 Val_cost:  1.4200400211818989 Val_accuracy:  0.8669299918278398 Val_Acc:  1.5297478572570502\n",
      "Epoch number: 1520/10000step_number: 0/29 Accuracy:  0.871854248254725 Loss:  1.4196923260865406 Val_accuracy:  0.8673385998365568 Val_cost:  1.4196923260865406 Val_accuracy:  0.8673385998365568 Val_Acc:  1.5297097731847982\n",
      "Epoch number: 1521/10000step_number: 0/29 Accuracy:  0.8719223565469096 Loss:  1.4195914630232758 Val_accuracy:  0.8674748025061291 Val_cost:  1.4195914630232758 Val_accuracy:  0.8674748025061291 Val_Acc:  1.5297576662647756\n",
      "Epoch number: 1522/10000step_number: 0/29 Accuracy:  0.8719904648390941 Loss:  1.4194205729165692 Val_accuracy:  0.8676110051757014 Val_cost:  1.4194205729165692 Val_accuracy:  0.8676110051757014 Val_Acc:  1.529845722026829\n",
      "Epoch number: 1523/10000step_number: 0/29 Accuracy:  0.8720585731312788 Loss:  1.4192930233980705 Val_accuracy:  0.8676110051757014 Val_cost:  1.4192930233980705 Val_accuracy:  0.8676110051757014 Val_Acc:  1.5299143459827627\n",
      "Epoch number: 1524/10000step_number: 0/29 Accuracy:  0.8722628980078324 Loss:  1.4191632400539003 Val_accuracy:  0.8674748025061291 Val_cost:  1.4191632400539003 Val_accuracy:  0.8674748025061291 Val_Acc:  1.5299816217302526\n",
      "Epoch number: 1525/10000step_number: 0/29 Accuracy:  0.8730801975140473 Loss:  1.419056593408377 Val_accuracy:  0.8681558158539907 Val_cost:  1.419056593408377 Val_accuracy:  0.8681558158539907 Val_Acc:  1.5300524081608815\n",
      "Epoch number: 1526/10000step_number: 0/29 Accuracy:  0.8731823599523242 Loss:  1.4189762632339034 Val_accuracy:  0.8681558158539907 Val_cost:  1.4189762632339034 Val_accuracy:  0.8681558158539907 Val_Acc:  1.5301339944102346\n",
      "Epoch number: 1527/10000step_number: 0/29 Accuracy:  0.8735910097054317 Loss:  1.4188361828228597 Val_accuracy:  0.8677472078452738 Val_cost:  1.4188361828228597 Val_accuracy:  0.8677472078452738 Val_Acc:  1.5301892965131518\n",
      "Epoch number: 1528/10000step_number: 0/29 Accuracy:  0.8734547931210624 Loss:  1.418242982247549 Val_accuracy:  0.8676110051757014 Val_cost:  1.418242982247549 Val_accuracy:  0.8676110051757014 Val_Acc:  1.5300558065256729\n",
      "Epoch number: 1529/10000step_number: 0/29 Accuracy:  0.8742039843350928 Loss:  1.4185581641668221 Val_accuracy:  0.8687006265322801 Val_cost:  1.4185581641668221 Val_accuracy:  0.8687006265322801 Val_Acc:  1.530270846657621\n",
      "Epoch number: 1530/10000step_number: 0/29 Accuracy:  0.874340200919462 Loss:  1.4183510894272318 Val_accuracy:  0.8687006265322801 Val_cost:  1.4183510894272318 Val_accuracy:  0.8687006265322801 Val_Acc:  1.5302962894005436\n",
      "Epoch number: 1531/10000step_number: 0/29 Accuracy:  0.8742720926272773 Loss:  1.4182665479154999 Val_accuracy:  0.8685644238627077 Val_cost:  1.4182665479154999 Val_accuracy:  0.8685644238627077 Val_Acc:  1.5303413521177291\n",
      "Epoch number: 1532/10000step_number: 0/29 Accuracy:  0.8742720926272773 Loss:  1.4181401383999719 Val_accuracy:  0.8685644238627077 Val_cost:  1.4181401383999719 Val_accuracy:  0.8685644238627077 Val_Acc:  1.5304055492217785\n",
      "Epoch number: 1533/10000step_number: 0/29 Accuracy:  0.874340200919462 Loss:  1.418065719295275 Val_accuracy:  0.8685644238627077 Val_cost:  1.418065719295275 Val_accuracy:  0.8685644238627077 Val_Acc:  1.5304713095427747\n",
      "Epoch number: 1534/10000step_number: 0/29 Accuracy:  0.8750212838413077 Loss:  1.417965235859182 Val_accuracy:  0.8692454372105693 Val_cost:  1.417965235859182 Val_accuracy:  0.8692454372105693 Val_Acc:  1.5305310078648726\n",
      "Epoch number: 1535/10000step_number: 0/29 Accuracy:  0.8752596628639537 Loss:  1.4171690212943162 Val_accuracy:  0.8693816398801416 Val_cost:  1.4171690212943162 Val_accuracy:  0.8693816398801416 Val_Acc:  1.5303109838129445\n",
      "Epoch number: 1536/10000step_number: 0/29 Accuracy:  0.8749531755491231 Loss:  1.4177661012635354 Val_accuracy:  0.8693816398801416 Val_cost:  1.4177661012635354 Val_accuracy:  0.8693816398801416 Val_Acc:  1.5306135698607501\n",
      "Epoch number: 1537/10000step_number: 0/29 Accuracy:  0.874816958964754 Loss:  1.4174290742166162 Val_accuracy:  0.8693816398801416 Val_cost:  1.4174290742166162 Val_accuracy:  0.8693816398801416 Val_Acc:  1.5305668126697354\n",
      "Epoch number: 1538/10000step_number: 0/29 Accuracy:  0.8749872296952154 Loss:  1.417374236102477 Val_accuracy:  0.8693816398801416 Val_cost:  1.417374236102477 Val_accuracy:  0.8693816398801416 Val_Acc:  1.5306045272214783\n",
      "Epoch number: 1539/10000step_number: 0/29 Accuracy:  0.8752256087178614 Loss:  1.4172292231299388 Val_accuracy:  0.8693816398801416 Val_cost:  1.4172292231299388 Val_accuracy:  0.8693816398801416 Val_Acc:  1.5306647319575113\n",
      "Epoch number: 1540/10000step_number: 0/29 Accuracy:  0.8754639877405074 Loss:  1.4171203548469697 Val_accuracy:  0.8693816398801416 Val_cost:  1.4171203548469697 Val_accuracy:  0.8693816398801416 Val_Acc:  1.5306951767467882\n",
      "Epoch number: 1541/10000step_number: 0/29 Accuracy:  0.8755661501787843 Loss:  1.4170056911114477 Val_accuracy:  0.8696540452192864 Val_cost:  1.4170056911114477 Val_accuracy:  0.8696540452192864 Val_Acc:  1.5307387661551666\n",
      "Epoch number: 1542/10000step_number: 0/29 Accuracy:  0.8756683126170611 Loss:  1.416911505802541 Val_accuracy:  0.8696540452192864 Val_cost:  1.416911505802541 Val_accuracy:  0.8696540452192864 Val_Acc:  1.5307801630916136\n",
      "Epoch number: 1543/10000step_number: 0/29 Accuracy:  0.875770475055338 Loss:  1.4168380185032516 Val_accuracy:  0.8697902478888586 Val_cost:  1.4168380185032516 Val_accuracy:  0.8697902478888586 Val_Acc:  1.5308366544230394\n",
      "Epoch number: 1544/10000step_number: 0/29 Accuracy:  0.8759407457857994 Loss:  1.4167791945041168 Val_accuracy:  0.869926450558431 Val_cost:  1.4167791945041168 Val_accuracy:  0.869926450558431 Val_Acc:  1.5308956129140867\n",
      "Epoch number: 1545/10000step_number: 0/29 Accuracy:  0.8756002043248765 Loss:  1.4160847388575628 Val_accuracy:  0.869517842549714 Val_cost:  1.4160847388575628 Val_accuracy:  0.869517842549714 Val_Acc:  1.5307024677966306\n",
      "Epoch number: 1546/10000step_number: 0/29 Accuracy:  0.876008854077984 Loss:  1.4165078485053793 Val_accuracy:  0.869926450558431 Val_cost:  1.4165078485053793 Val_accuracy:  0.869926450558431 Val_Acc:  1.5309160581064385\n",
      "Epoch number: 1547/10000step_number: 0/29 Accuracy:  0.8759066916397071 Loss:  1.4162356107550464 Val_accuracy:  0.8700626532280032 Val_cost:  1.4162356107550464 Val_accuracy:  0.8700626532280032 Val_Acc:  1.5308962645066269\n",
      "Epoch number: 1548/10000step_number: 0/29 Accuracy:  0.8759407457857994 Loss:  1.41619034516023 Val_accuracy:  0.8697902478888586 Val_cost:  1.41619034516023 Val_accuracy:  0.8697902478888586 Val_Acc:  1.5309287925774389\n",
      "Epoch number: 1549/10000step_number: 0/29 Accuracy:  0.8760429082240763 Loss:  1.4160614935421656 Val_accuracy:  0.8700626532280032 Val_cost:  1.4160614935421656 Val_accuracy:  0.8700626532280032 Val_Acc:  1.5309844259898626\n",
      "Epoch number: 1550/10000step_number: 0/29 Accuracy:  0.8760429082240763 Loss:  1.4159706367855618 Val_accuracy:  0.8701988558975756 Val_cost:  1.4159706367855618 Val_accuracy:  0.8701988558975756 Val_Acc:  1.5310125872826932\n",
      "Epoch number: 1551/10000step_number: 0/29 Accuracy:  0.8761450706623531 Loss:  1.4158912196164175 Val_accuracy:  0.8703350585671479 Val_cost:  1.4158912196164175 Val_accuracy:  0.8703350585671479 Val_Acc:  1.5310670480545996\n",
      "Epoch number: 1552/10000step_number: 0/29 Accuracy:  0.8761110165162609 Loss:  1.4158448570691917 Val_accuracy:  0.8703350585671479 Val_cost:  1.4158448570691917 Val_accuracy:  0.8703350585671479 Val_Acc:  1.5311235165003128\n",
      "Epoch number: 1553/10000step_number: 0/29 Accuracy:  0.8763153413928145 Loss:  1.4154311286357824 Val_accuracy:  0.8701988558975756 Val_cost:  1.4154311286357824 Val_accuracy:  0.8701988558975756 Val_Acc:  1.531042710185555\n",
      "Epoch number: 1554/10000step_number: 0/29 Accuracy:  0.8763493955389069 Loss:  1.415651038704898 Val_accuracy:  0.8704712612367203 Val_cost:  1.415651038704898 Val_accuracy:  0.8704712612367203 Val_Acc:  1.5311819101133646\n",
      "Epoch number: 1555/10000step_number: 0/29 Accuracy:  0.8764515579771838 Loss:  1.4153760512137892 Val_accuracy:  0.8704712612367203 Val_cost:  1.4153760512137892 Val_accuracy:  0.8704712612367203 Val_Acc:  1.531173817150622\n",
      "Epoch number: 1556/10000step_number: 0/29 Accuracy:  0.8766218287076452 Loss:  1.4149563908938345 Val_accuracy:  0.8703350585671479 Val_cost:  1.4149563908938345 Val_accuracy:  0.8703350585671479 Val_Acc:  1.531059169743656\n",
      "Epoch number: 1557/10000step_number: 0/29 Accuracy:  0.8765537204154605 Loss:  1.4152052533756265 Val_accuracy:  0.8704712612367203 Val_cost:  1.4152052533756265 Val_accuracy:  0.8704712612367203 Val_Acc:  1.5312109720074503\n",
      "Epoch number: 1558/10000step_number: 0/29 Accuracy:  0.8765877745615529 Loss:  1.415025923186136 Val_accuracy:  0.8704712612367203 Val_cost:  1.415025923186136 Val_accuracy:  0.8704712612367203 Val_Acc:  1.531224731397791\n",
      "Epoch number: 1559/10000step_number: 0/29 Accuracy:  0.8765537204154605 Loss:  1.4150209316055675 Val_accuracy:  0.8707436665758649 Val_cost:  1.4150209316055675 Val_accuracy:  0.8707436665758649 Val_Acc:  1.5312866535803613\n",
      "Epoch number: 1560/10000step_number: 0/29 Accuracy:  0.8767920994381065 Loss:  1.4149013426162895 Val_accuracy:  0.8708798692454373 Val_cost:  1.4149013426162895 Val_accuracy:  0.8708798692454373 Val_Acc:  1.5313408755544198\n",
      "Epoch number: 1561/10000step_number: 0/29 Accuracy:  0.8773029116294909 Loss:  1.414081580522243 Val_accuracy:  0.8701988558975756 Val_cost:  1.414081580522243 Val_accuracy:  0.8701988558975756 Val_Acc:  1.5310998953240256\n",
      "Epoch number: 1562/10000step_number: 0/29 Accuracy:  0.8766558828537374 Loss:  1.4147902622485105 Val_accuracy:  0.8708798692454373 Val_cost:  1.4147902622485105 Val_accuracy:  0.8708798692454373 Val_Acc:  1.5313748374637572\n",
      "Epoch number: 1563/10000step_number: 0/29 Accuracy:  0.877200749191214 Loss:  1.4143599418787645 Val_accuracy:  0.8710160719150095 Val_cost:  1.4143599418787645 Val_accuracy:  0.8710160719150095 Val_Acc:  1.531300159232395\n",
      "Epoch number: 1564/10000step_number: 0/29 Accuracy:  0.8771666950451218 Loss:  1.4143407808443853 Val_accuracy:  0.8710160719150095 Val_cost:  1.4143407808443853 Val_accuracy:  0.8710160719150095 Val_Acc:  1.531312788465871\n",
      "Epoch number: 1565/10000step_number: 0/29 Accuracy:  0.8771326408990294 Loss:  1.4142046690208203 Val_accuracy:  0.8711522745845819 Val_cost:  1.4142046690208203 Val_accuracy:  0.8711522745845819 Val_Acc:  1.531393546733071\n",
      "Epoch number: 1566/10000step_number: 0/29 Accuracy:  0.87743912821386 Loss:  1.4140961216055774 Val_accuracy:  0.8714246799237265 Val_cost:  1.4140961216055774 Val_accuracy:  0.8714246799237265 Val_Acc:  1.5314039847999763\n",
      "Epoch number: 1567/10000step_number: 0/29 Accuracy:  0.8774731823599523 Loss:  1.4140039679426457 Val_accuracy:  0.8714246799237265 Val_cost:  1.4140039679426457 Val_accuracy:  0.8714246799237265 Val_Acc:  1.5314443259492523\n",
      "Epoch number: 1568/10000step_number: 0/29 Accuracy:  0.8774731823599523 Loss:  1.413905493092756 Val_accuracy:  0.8715608825932988 Val_cost:  1.413905493092756 Val_accuracy:  0.8715608825932988 Val_Acc:  1.5314779456561496\n",
      "Epoch number: 1569/10000step_number: 0/29 Accuracy:  0.8775072365060446 Loss:  1.413817362367764 Val_accuracy:  0.8715608825932988 Val_cost:  1.413817362367764 Val_accuracy:  0.8715608825932988 Val_Acc:  1.5315180145447922\n",
      "Epoch number: 1570/10000step_number: 0/29 Accuracy:  0.8776434530904138 Loss:  1.4137532912582897 Val_accuracy:  0.8714246799237265 Val_cost:  1.4137532912582897 Val_accuracy:  0.8714246799237265 Val_Acc:  1.5315704593000294\n",
      "Epoch number: 1571/10000step_number: 0/29 Accuracy:  0.8777456155286906 Loss:  1.4136972160242054 Val_accuracy:  0.8712884772541541 Val_cost:  1.4136972160242054 Val_accuracy:  0.8712884772541541 Val_Acc:  1.5316297568989095\n",
      "Epoch number: 1572/10000step_number: 0/29 Accuracy:  0.8774731823599523 Loss:  1.4130269672946616 Val_accuracy:  0.8712884772541541 Val_cost:  1.4130269672946616 Val_accuracy:  0.8712884772541541 Val_Acc:  1.5314449316465213\n",
      "Epoch number: 1573/10000step_number: 0/29 Accuracy:  0.8776775072365061 Loss:  1.4134452797336359 Val_accuracy:  0.8711522745845819 Val_cost:  1.4134452797336359 Val_accuracy:  0.8711522745845819 Val_Acc:  1.5316212026566187\n",
      "Epoch number: 1574/10000step_number: 0/29 Accuracy:  0.8786310233270901 Loss:  1.413174677545573 Val_accuracy:  0.8714246799237265 Val_cost:  1.413174677545573 Val_accuracy:  0.8714246799237265 Val_Acc:  1.5316197634629911\n",
      "Epoch number: 1575/10000step_number: 0/29 Accuracy:  0.8785969691809978 Loss:  1.4131077128398093 Val_accuracy:  0.8714246799237265 Val_cost:  1.4131077128398093 Val_accuracy:  0.8714246799237265 Val_Acc:  1.5316334566103171\n",
      "Epoch number: 1576/10000step_number: 0/29 Accuracy:  0.878733185765367 Loss:  1.413011191507551 Val_accuracy:  0.8715608825932988 Val_cost:  1.413011191507551 Val_accuracy:  0.8715608825932988 Val_Acc:  1.5316998481868584\n",
      "Epoch number: 1577/10000step_number: 0/29 Accuracy:  0.8786650774731823 Loss:  1.4129139449062227 Val_accuracy:  0.8716970852628712 Val_cost:  1.4129139449062227 Val_accuracy:  0.8716970852628712 Val_Acc:  1.531738741462999\n",
      "Epoch number: 1578/10000step_number: 0/29 Accuracy:  0.8786650774731823 Loss:  1.4128669342642506 Val_accuracy:  0.8716970852628712 Val_cost:  1.4128669342642506 Val_accuracy:  0.8716970852628712 Val_Acc:  1.5317974398494303\n",
      "Epoch number: 1579/10000step_number: 0/29 Accuracy:  0.8791418355184744 Loss:  1.4127591017198615 Val_accuracy:  0.8722418959411604 Val_cost:  1.4127591017198615 Val_accuracy:  0.8722418959411604 Val_Acc:  1.5318400947205286\n",
      "Epoch number: 1580/10000step_number: 0/29 Accuracy:  0.878256427720075 Loss:  1.4119809789394375 Val_accuracy:  0.8715608825932988 Val_cost:  1.4119809789394375 Val_accuracy:  0.8715608825932988 Val_Acc:  1.5315994698097926\n",
      "Epoch number: 1581/10000step_number: 0/29 Accuracy:  0.8801294057551506 Loss:  1.4126309901589034 Val_accuracy:  0.8733315172977391 Val_cost:  1.4126309901589034 Val_accuracy:  0.8733315172977391 Val_Acc:  1.531852603676094\n",
      "Epoch number: 1582/10000step_number: 0/29 Accuracy:  0.8792439979567512 Loss:  1.4122595118792833 Val_accuracy:  0.8723780986107328 Val_cost:  1.4122595118792833 Val_accuracy:  0.8723780986107328 Val_Acc:  1.531831726791411\n",
      "Epoch number: 1583/10000step_number: 0/29 Accuracy:  0.8803337306317044 Loss:  1.4121727017669878 Val_accuracy:  0.8733315172977391 Val_cost:  1.4121727017669878 Val_accuracy:  0.8733315172977391 Val_Acc:  1.5318233948512996\n",
      "Epoch number: 1584/10000step_number: 0/29 Accuracy:  0.8803337306317044 Loss:  1.4120721464655988 Val_accuracy:  0.8733315172977391 Val_cost:  1.4120721464655988 Val_accuracy:  0.8733315172977391 Val_Acc:  1.5318878054177116\n",
      "Epoch number: 1585/10000step_number: 0/29 Accuracy:  0.8806061638004427 Loss:  1.4119396564562912 Val_accuracy:  0.8738763279760283 Val_cost:  1.4119396564562912 Val_accuracy:  0.8738763279760283 Val_Acc:  1.5319161220377866\n",
      "Epoch number: 1586/10000step_number: 0/29 Accuracy:  0.8807423803848119 Loss:  1.4118345437090771 Val_accuracy:  0.8738763279760283 Val_cost:  1.4118345437090771 Val_accuracy:  0.8738763279760283 Val_Acc:  1.5319344789557938\n",
      "Epoch number: 1587/10000step_number: 0/29 Accuracy:  0.8809126511152733 Loss:  1.4117338319195363 Val_accuracy:  0.8738763279760283 Val_cost:  1.4117338319195363 Val_accuracy:  0.8738763279760283 Val_Acc:  1.53196748297402\n",
      "Epoch number: 1588/10000step_number: 0/29 Accuracy:  0.8810488676996424 Loss:  1.41161685965541 Val_accuracy:  0.8737401253064561 Val_cost:  1.41161685965541 Val_accuracy:  0.8737401253064561 Val_Acc:  1.531997066747177\n",
      "Epoch number: 1589/10000step_number: 0/29 Accuracy:  0.8812531925761962 Loss:  1.4115021561140417 Val_accuracy:  0.8738763279760283 Val_cost:  1.4115021561140417 Val_accuracy:  0.8738763279760283 Val_Acc:  1.5320202488473704\n",
      "Epoch number: 1590/10000step_number: 0/29 Accuracy:  0.8813213008683807 Loss:  1.4113914928176987 Val_accuracy:  0.8738763279760283 Val_cost:  1.4113914928176987 Val_accuracy:  0.8738763279760283 Val_Acc:  1.5320477246092492\n",
      "Epoch number: 1591/10000step_number: 0/29 Accuracy:  0.8816618423293036 Loss:  1.4112753911927192 Val_accuracy:  0.8746935439934622 Val_cost:  1.4112753911927192 Val_accuracy:  0.8746935439934622 Val_Acc:  1.532075384297364\n",
      "Epoch number: 1592/10000step_number: 0/29 Accuracy:  0.8816958964753959 Loss:  1.4111588410671083 Val_accuracy:  0.87455734132389 Val_cost:  1.4111588410671083 Val_accuracy:  0.87455734132389 Val_Acc:  1.5321013514460806\n",
      "Epoch number: 1593/10000step_number: 0/29 Accuracy:  0.8817980589136727 Loss:  1.4110439093504121 Val_accuracy:  0.87455734132389 Val_cost:  1.4110439093504121 Val_accuracy:  0.87455734132389 Val_Acc:  1.5321287425720043\n",
      "Epoch number: 1594/10000step_number: 0/29 Accuracy:  0.8820023837902264 Loss:  1.4109278785325696 Val_accuracy:  0.874965949332607 Val_cost:  1.4109278785325696 Val_accuracy:  0.874965949332607 Val_Acc:  1.5321571911867522\n",
      "Epoch number: 1595/10000step_number: 0/29 Accuracy:  0.8820704920824111 Loss:  1.4108114114059243 Val_accuracy:  0.8751021520021792 Val_cost:  1.4108114114059243 Val_accuracy:  0.8751021520021792 Val_Acc:  1.53218580288658\n",
      "Epoch number: 1596/10000step_number: 0/29 Accuracy:  0.8821386003745956 Loss:  1.4106955855420829 Val_accuracy:  0.8751021520021792 Val_cost:  1.4106955855420829 Val_accuracy:  0.8751021520021792 Val_Acc:  1.5322153208246605\n",
      "Epoch number: 1597/10000step_number: 0/29 Accuracy:  0.8822407628128724 Loss:  1.410579682695084 Val_accuracy:  0.8751021520021792 Val_cost:  1.410579682695084 Val_accuracy:  0.8751021520021792 Val_Acc:  1.5322459050782384\n",
      "Epoch number: 1598/10000step_number: 0/29 Accuracy:  0.8822748169589647 Loss:  1.4104635429065642 Val_accuracy:  0.8752383546717516 Val_cost:  1.4104635429065642 Val_accuracy:  0.8752383546717516 Val_Acc:  1.5322771588290902\n",
      "Epoch number: 1599/10000step_number: 0/29 Accuracy:  0.8823088711050571 Loss:  1.4103475554731482 Val_accuracy:  0.8752383546717516 Val_cost:  1.4103475554731482 Val_accuracy:  0.8752383546717516 Val_Acc:  1.5323091714751687\n",
      "Epoch number: 1600/10000step_number: 0/29 Accuracy:  0.8822748169589647 Loss:  1.4102315637561942 Val_accuracy:  0.8752383546717516 Val_cost:  1.4102315637561942 Val_accuracy:  0.8752383546717516 Val_Acc:  1.5323420459696337\n",
      "Epoch number: 1601/10000step_number: 0/29 Accuracy:  0.8822748169589647 Loss:  1.4101153561924853 Val_accuracy:  0.8753745573413239 Val_cost:  1.4101153561924853 Val_accuracy:  0.8753745573413239 Val_Acc:  1.5323756324865583\n",
      "Epoch number: 1602/10000step_number: 0/29 Accuracy:  0.8822748169589647 Loss:  1.4099989791690395 Val_accuracy:  0.8753745573413239 Val_cost:  1.4099989791690395 Val_accuracy:  0.8753745573413239 Val_Acc:  1.5324098761693863\n",
      "Epoch number: 1603/10000step_number: 0/29 Accuracy:  0.8823429252511493 Loss:  1.4098823598200039 Val_accuracy:  0.8755107600108962 Val_cost:  1.4098823598200039 Val_accuracy:  0.8755107600108962 Val_Acc:  1.5324448018345302\n",
      "Epoch number: 1604/10000step_number: 0/29 Accuracy:  0.8825813042737953 Loss:  1.4097653132603705 Val_accuracy:  0.8755107600108962 Val_cost:  1.4097653132603705 Val_accuracy:  0.8755107600108962 Val_Acc:  1.5324803476288629\n",
      "Epoch number: 1605/10000step_number: 0/29 Accuracy:  0.88264941256598 Loss:  1.4096477358233381 Val_accuracy:  0.8757831653500409 Val_cost:  1.4096477358233381 Val_accuracy:  0.8757831653500409 Val_Acc:  1.5325164481486244\n",
      "Epoch number: 1606/10000step_number: 0/29 Accuracy:  0.8826153584198876 Loss:  1.4095295204766016 Val_accuracy:  0.8757831653500409 Val_cost:  1.4095295204766016 Val_accuracy:  0.8757831653500409 Val_Acc:  1.5325530860725234\n",
      "Epoch number: 1607/10000step_number: 0/29 Accuracy:  0.8826153584198876 Loss:  1.4094104942441719 Val_accuracy:  0.8759193680196132 Val_cost:  1.4094104942441719 Val_accuracy:  0.8759193680196132 Val_Acc:  1.5325902278556793\n",
      "Epoch number: 1608/10000step_number: 0/29 Accuracy:  0.8826153584198876 Loss:  1.4092904930457433 Val_accuracy:  0.8760555706891855 Val_cost:  1.4092904930457433 Val_accuracy:  0.8760555706891855 Val_Acc:  1.532627825808892\n",
      "Epoch number: 1609/10000step_number: 0/29 Accuracy:  0.8828537374425336 Loss:  1.4091693649853467 Val_accuracy:  0.8761917733587579 Val_cost:  1.4091693649853467 Val_accuracy:  0.8761917733587579 Val_Acc:  1.5326658545114888\n",
      "Epoch number: 1610/10000step_number: 0/29 Accuracy:  0.8828537374425336 Loss:  1.4090469289479373 Val_accuracy:  0.8761917733587579 Val_cost:  1.4090469289479373 Val_accuracy:  0.8761917733587579 Val_Acc:  1.5327042958413588\n",
      "Epoch number: 1611/10000step_number: 0/29 Accuracy:  0.8828196832964413 Loss:  1.4089229928818727 Val_accuracy:  0.8763279760283301 Val_cost:  1.4089229928818727 Val_accuracy:  0.8763279760283301 Val_Acc:  1.532743128112043\n",
      "Epoch number: 1612/10000step_number: 0/29 Accuracy:  0.8830580623190873 Loss:  1.4087973719309657 Val_accuracy:  0.8764641786979025 Val_cost:  1.4087973719309657 Val_accuracy:  0.8764641786979025 Val_Acc:  1.5327823439471329\n",
      "Epoch number: 1613/10000step_number: 0/29 Accuracy:  0.883126170611272 Loss:  1.408669873764461 Val_accuracy:  0.8767365840370471 Val_cost:  1.408669873764461 Val_accuracy:  0.8767365840370471 Val_Acc:  1.5328219545048052\n",
      "Epoch number: 1614/10000step_number: 0/29 Accuracy:  0.8832283330495487 Loss:  1.4085403007753117 Val_accuracy:  0.8767365840370471 Val_cost:  1.4085403007753117 Val_accuracy:  0.8767365840370471 Val_Acc:  1.532861984871667\n",
      "Epoch number: 1615/10000step_number: 0/29 Accuracy:  0.8832283330495487 Loss:  1.408408466898584 Val_accuracy:  0.8767365840370471 Val_cost:  1.408408466898584 Val_accuracy:  0.8767365840370471 Val_Acc:  1.532902484127681\n",
      "Epoch number: 1616/10000step_number: 0/29 Accuracy:  0.8834326579261025 Loss:  1.4082742014402465 Val_accuracy:  0.8771451920457641 Val_cost:  1.4082742014402465 Val_accuracy:  0.8771451920457641 Val_Acc:  1.532943536688176\n",
      "Epoch number: 1617/10000step_number: 0/29 Accuracy:  0.8835348203643794 Loss:  1.4081373548635547 Val_accuracy:  0.8772813947153364 Val_cost:  1.4081373548635547 Val_accuracy:  0.8772813947153364 Val_Acc:  1.532985267234082\n",
      "Epoch number: 1618/10000step_number: 0/29 Accuracy:  0.8835688745104716 Loss:  1.407997817196309 Val_accuracy:  0.8772813947153364 Val_cost:  1.407997817196309 Val_accuracy:  0.8772813947153364 Val_Acc:  1.533027851930186\n",
      "Epoch number: 1619/10000step_number: 0/29 Accuracy:  0.8835348203643794 Loss:  1.4078555354085225 Val_accuracy:  0.8774175973849088 Val_cost:  1.4078555354085225 Val_accuracy:  0.8774175973849088 Val_Acc:  1.533071535232543\n",
      "Epoch number: 1620/10000step_number: 0/29 Accuracy:  0.883602928656564 Loss:  1.4077105298749644 Val_accuracy:  0.8772813947153364 Val_cost:  1.4077105298749644 Val_accuracy:  0.8772813947153364 Val_Acc:  1.533116645080014\n",
      "Epoch number: 1621/10000step_number: 0/29 Accuracy:  0.8836710369487485 Loss:  1.4075629177303886 Val_accuracy:  0.8771451920457641 Val_cost:  1.4075629177303886 Val_accuracy:  0.8771451920457641 Val_Acc:  1.533163611046053\n",
      "Epoch number: 1622/10000step_number: 0/29 Accuracy:  0.8837050910948407 Loss:  1.4074129371387731 Val_accuracy:  0.8774175973849088 Val_cost:  1.4074129371387731 Val_accuracy:  0.8774175973849088 Val_Acc:  1.5332129876893807\n",
      "Epoch number: 1623/10000step_number: 0/29 Accuracy:  0.8837731993870254 Loss:  1.4072609666520939 Val_accuracy:  0.8772813947153364 Val_cost:  1.4072609666520939 Val_accuracy:  0.8772813947153364 Val_Acc:  1.5332654780251211\n",
      "Epoch number: 1624/10000step_number: 0/29 Accuracy:  0.8838753618253022 Loss:  1.407107539730945 Val_accuracy:  0.877553800054481 Val_cost:  1.407107539730945 Val_accuracy:  0.877553800054481 Val_Acc:  1.5333219563549068\n",
      "Epoch number: 1625/10000step_number: 0/29 Accuracy:  0.88384130767921 Loss:  1.4069533477746299 Val_accuracy:  0.877553800054481 Val_cost:  1.4069533477746299 Val_accuracy:  0.877553800054481 Val_Acc:  1.533383490193985\n",
      "Epoch number: 1626/10000step_number: 0/29 Accuracy:  0.884079686701856 Loss:  1.4067992210376103 Val_accuracy:  0.8772813947153364 Val_cost:  1.4067992210376103 Val_accuracy:  0.8772813947153364 Val_Acc:  1.5334513553113003\n",
      "Epoch number: 1627/10000step_number: 0/29 Accuracy:  0.8841818491401328 Loss:  1.406646079520252 Val_accuracy:  0.8772813947153364 Val_cost:  1.406646079520252 Val_accuracy:  0.8772813947153364 Val_Acc:  1.5335270376171386\n",
      "Epoch number: 1628/10000step_number: 0/29 Accuracy:  0.8842159032862251 Loss:  1.406494844319678 Val_accuracy:  0.8772813947153364 Val_cost:  1.406494844319678 Val_accuracy:  0.8772813947153364 Val_Acc:  1.5336122151552511\n",
      "Epoch number: 1629/10000step_number: 0/29 Accuracy:  0.8842159032862251 Loss:  1.4063462990427038 Val_accuracy:  0.8772813947153364 Val_cost:  1.4063462990427038 Val_accuracy:  0.8772813947153364 Val_Acc:  1.5337087086593855\n",
      "Epoch number: 1630/10000step_number: 0/29 Accuracy:  0.8842840115784096 Loss:  1.4062008952981429 Val_accuracy:  0.877553800054481 Val_cost:  1.4062008952981429 Val_accuracy:  0.877553800054481 Val_Acc:  1.5338183863028112\n",
      "Epoch number: 1631/10000step_number: 0/29 Accuracy:  0.884318065724502 Loss:  1.4060585006783752 Val_accuracy:  0.877553800054481 Val_cost:  1.4060585006783752 Val_accuracy:  0.877553800054481 Val_Acc:  1.533943006549294\n",
      "Epoch number: 1632/10000step_number: 0/29 Accuracy:  0.8843861740166865 Loss:  1.4059180934864954 Val_accuracy:  0.877553800054481 Val_cost:  1.4059180934864954 Val_accuracy:  0.877553800054481 Val_Acc:  1.534083982066558\n",
      "Epoch number: 1633/10000step_number: 0/29 Accuracy:  0.8845223906010556 Loss:  1.4057774206264662 Val_accuracy:  0.8778262053936258 Val_cost:  1.4057774206264662 Val_accuracy:  0.8778262053936258 Val_Acc:  1.5342420542911217\n",
      "Epoch number: 1634/10000step_number: 0/29 Accuracy:  0.8845904988932403 Loss:  1.4056326566369293 Val_accuracy:  0.877962408063198 Val_cost:  1.4056326566369293 Val_accuracy:  0.877962408063198 Val_Acc:  1.5344168874046498\n",
      "Epoch number: 1635/10000step_number: 0/29 Accuracy:  0.8844202281627788 Loss:  1.4054781377505097 Val_accuracy:  0.8778262053936258 Val_cost:  1.4054781377505097 Val_accuracy:  0.8778262053936258 Val_Acc:  1.5346066243468195\n",
      "Epoch number: 1636/10000step_number: 0/29 Accuracy:  0.8845223906010556 Loss:  1.4053062918889527 Val_accuracy:  0.8776900027240534 Val_cost:  1.4053062918889527 Val_accuracy:  0.8776900027240534 Val_Acc:  1.5348074914627756\n",
      "Epoch number: 1637/10000step_number: 0/29 Accuracy:  0.8847267154776094 Loss:  1.4051079200074859 Val_accuracy:  0.8778262053936258 Val_cost:  1.4051079200074859 Val_accuracy:  0.8778262053936258 Val_Acc:  1.5350135744858429\n",
      "Epoch number: 1638/10000step_number: 0/29 Accuracy:  0.884794823769794 Loss:  1.404872966318813 Val_accuracy:  0.877962408063198 Val_cost:  1.404872966318813 Val_accuracy:  0.877962408063198 Val_Acc:  1.5352168881281292\n",
      "Epoch number: 1639/10000step_number: 0/29 Accuracy:  0.8848288779158863 Loss:  1.404591825217186 Val_accuracy:  0.877962408063198 Val_cost:  1.404591825217186 Val_accuracy:  0.877962408063198 Val_Acc:  1.5354077905223484\n",
      "Epoch number: 1640/10000step_number: 0/29 Accuracy:  0.8846245530393325 Loss:  1.404257149821653 Val_accuracy:  0.8778262053936258 Val_cost:  1.404257149821653 Val_accuracy:  0.8778262053936258 Val_Acc:  1.5355756162653555\n",
      "Epoch number: 1641/10000step_number: 0/29 Accuracy:  0.8846926613315171 Loss:  1.4038662744924337 Val_accuracy:  0.8776900027240534 Val_cost:  1.4038662744924337 Val_accuracy:  0.8776900027240534 Val_Acc:  1.535709059310933\n",
      "Epoch number: 1642/10000step_number: 0/29 Accuracy:  0.8853396901072705 Loss:  1.4034248792372812 Val_accuracy:  0.878371016071915 Val_cost:  1.4034248792372812 Val_accuracy:  0.878371016071915 Val_Acc:  1.5357949892247964\n",
      "Epoch number: 1643/10000step_number: 0/29 Accuracy:  0.8854077983994552 Loss:  1.4029524388323125 Val_accuracy:  0.8787796240806319 Val_cost:  1.4029524388323125 Val_accuracy:  0.8787796240806319 Val_Acc:  1.5358115272020392\n",
      "Epoch number: 1644/10000step_number: 0/29 Accuracy:  0.8855440149838243 Loss:  1.4024849541865587 Val_accuracy:  0.8786434214110597 Val_cost:  1.4024849541865587 Val_accuracy:  0.8786434214110597 Val_Acc:  1.5357039997000552\n",
      "Epoch number: 1645/10000step_number: 0/29 Accuracy:  0.8861569896134854 Loss:  1.4020587841941323 Val_accuracy:  0.8791882320893489 Val_cost:  1.4020587841941323 Val_accuracy:  0.8791882320893489 Val_Acc:  1.5353354366276615\n",
      "Epoch number: 1646/10000step_number: 0/29 Accuracy:  0.8854418525455474 Loss:  1.4016973989828656 Val_accuracy:  0.8780986107327704 Val_cost:  1.4016973989828656 Val_accuracy:  0.8780986107327704 Val_Acc:  1.5344992591004583\n",
      "Epoch number: 1647/10000step_number: 0/29 Accuracy:  0.8862591520517623 Loss:  1.401491349262873 Val_accuracy:  0.8791882320893489 Val_cost:  1.401491349262873 Val_accuracy:  0.8791882320893489 Val_Acc:  1.533136669340542\n",
      "Epoch number: 1648/10000step_number: 0/29 Accuracy:  0.8864294227822237 Loss:  1.4016578977055723 Val_accuracy:  0.8789158267502043 Val_cost:  1.4016578977055723 Val_accuracy:  0.8789158267502043 Val_Acc:  1.531392513439472\n",
      "Epoch number: 1649/10000step_number: 0/29 Accuracy:  0.8874169930189001 Loss:  1.4028495567618324 Val_accuracy:  0.8805502587850722 Val_cost:  1.4028495567618324 Val_accuracy:  0.8805502587850722 Val_Acc:  1.5297169214116837\n",
      "Epoch number: 1650/10000step_number: 0/29 Accuracy:  0.8846926613315171 Loss:  1.4060928905720684 Val_accuracy:  0.8786434214110597 Val_cost:  1.4060928905720684 Val_accuracy:  0.8786434214110597 Val_Acc:  1.5295992572539248\n",
      "Epoch number: 1651/10000step_number: 0/29 Accuracy:  0.8841477949940405 Loss:  1.4088842156454986 Val_accuracy:  0.8797330427676382 Val_cost:  1.4088842156454986 Val_accuracy:  0.8797330427676382 Val_Acc:  1.5312357713136446\n",
      "Epoch number: 1652/10000step_number: 0/29 Accuracy:  0.884556444747148 Loss:  1.4087111500364995 Val_accuracy:  0.8801416507763552 Val_cost:  1.4087111500364995 Val_accuracy:  0.8801416507763552 Val_Acc:  1.5324160819872363\n",
      "Epoch number: 1653/10000step_number: 0/29 Accuracy:  0.8841477949940405 Loss:  1.4089580253815492 Val_accuracy:  0.8794606374284936 Val_cost:  1.4089580253815492 Val_accuracy:  0.8794606374284936 Val_Acc:  1.5336162769597688\n",
      "Epoch number: 1654/10000step_number: 0/29 Accuracy:  0.8843861740166865 Loss:  1.4080211601267334 Val_accuracy:  0.8798692454372106 Val_cost:  1.4080211601267334 Val_accuracy:  0.8798692454372106 Val_Acc:  1.533573842497855\n",
      "Epoch number: 1655/10000step_number: 0/29 Accuracy:  0.8834326579261025 Loss:  1.4077684195145634 Val_accuracy:  0.8785072187414873 Val_cost:  1.4077684195145634 Val_accuracy:  0.8785072187414873 Val_Acc:  1.5334517695754042\n",
      "Epoch number: 1656/10000step_number: 0/29 Accuracy:  0.883126170611272 Loss:  1.408525909043637 Val_accuracy:  0.8782348134023427 Val_cost:  1.408525909043637 Val_accuracy:  0.8782348134023427 Val_Acc:  1.5338984562285634\n",
      "Epoch number: 1657/10000step_number: 0/29 Accuracy:  0.8827856291503491 Loss:  1.4086642030357703 Val_accuracy:  0.8780986107327704 Val_cost:  1.4086642030357703 Val_accuracy:  0.8780986107327704 Val_Acc:  1.5340690289315386\n",
      "Epoch number: 1658/10000step_number: 0/29 Accuracy:  0.88264941256598 Loss:  1.4087453917447237 Val_accuracy:  0.8776900027240534 Val_cost:  1.4087453917447237 Val_accuracy:  0.8776900027240534 Val_Acc:  1.5341689388167365\n",
      "Epoch number: 1659/10000step_number: 0/29 Accuracy:  0.8819683296441342 Loss:  1.4087286225082225 Val_accuracy:  0.8772813947153364 Val_cost:  1.4087286225082225 Val_accuracy:  0.8772813947153364 Val_Acc:  1.534142255410505\n",
      "Epoch number: 1660/10000step_number: 0/29 Accuracy:  0.8819002213519496 Loss:  1.4086823927517966 Val_accuracy:  0.8771451920457641 Val_cost:  1.4086823927517966 Val_accuracy:  0.8771451920457641 Val_Acc:  1.5341029449358938\n",
      "Epoch number: 1661/10000step_number: 0/29 Accuracy:  0.8816618423293036 Loss:  1.4086311632174544 Val_accuracy:  0.8770089893761918 Val_cost:  1.4086311632174544 Val_accuracy:  0.8770089893761918 Val_Acc:  1.5340707050346096\n",
      "Epoch number: 1662/10000step_number: 0/29 Accuracy:  0.881593734037119 Loss:  1.4085331129685028 Val_accuracy:  0.8770089893761918 Val_cost:  1.4085331129685028 Val_accuracy:  0.8770089893761918 Val_Acc:  1.5340415726684762\n",
      "Epoch number: 1663/10000step_number: 0/29 Accuracy:  0.8817299506214882 Loss:  1.4084237163096407 Val_accuracy:  0.8771451920457641 Val_cost:  1.4084237163096407 Val_accuracy:  0.8771451920457641 Val_Acc:  1.5340255050343028\n",
      "Epoch number: 1664/10000step_number: 0/29 Accuracy:  0.8819342754980419 Loss:  1.4082897242986807 Val_accuracy:  0.8770089893761918 Val_cost:  1.4082897242986807 Val_accuracy:  0.8770089893761918 Val_Acc:  1.5340153712377236\n",
      "Epoch number: 1665/10000step_number: 0/29 Accuracy:  0.8820364379363187 Loss:  1.4081466908492297 Val_accuracy:  0.8770089893761918 Val_cost:  1.4081466908492297 Val_accuracy:  0.8770089893761918 Val_Acc:  1.5340151608468413\n",
      "Epoch number: 1666/10000step_number: 0/29 Accuracy:  0.8819683296441342 Loss:  1.4079914943543197 Val_accuracy:  0.8768727867066195 Val_cost:  1.4079914943543197 Val_accuracy:  0.8768727867066195 Val_Acc:  1.5340207611134518\n",
      "Epoch number: 1667/10000step_number: 0/29 Accuracy:  0.8819342754980419 Loss:  1.4078293465011553 Val_accuracy:  0.8770089893761918 Val_cost:  1.4078293465011553 Val_accuracy:  0.8770089893761918 Val_Acc:  1.5340328418562967\n",
      "Epoch number: 1668/10000step_number: 0/29 Accuracy:  0.881832113059765 Loss:  1.407660715879023 Val_accuracy:  0.8770089893761918 Val_cost:  1.407660715879023 Val_accuracy:  0.8770089893761918 Val_Acc:  1.5340498115167431\n",
      "Epoch number: 1669/10000step_number: 0/29 Accuracy:  0.8818661672058573 Loss:  1.4074876680447224 Val_accuracy:  0.8770089893761918 Val_cost:  1.4074876680447224 Val_accuracy:  0.8770089893761918 Val_Acc:  1.5340717592052624\n",
      "Epoch number: 1670/10000step_number: 0/29 Accuracy:  0.8816618423293036 Loss:  1.4073115210123046 Val_accuracy:  0.8768727867066195 Val_cost:  1.4073115210123046 Val_accuracy:  0.8768727867066195 Val_Acc:  1.5340982191279566\n",
      "Epoch number: 1671/10000step_number: 0/29 Accuracy:  0.881832113059765 Loss:  1.4071337240431923 Val_accuracy:  0.8768727867066195 Val_cost:  1.4071337240431923 Val_accuracy:  0.8768727867066195 Val_Acc:  1.534129150879863\n",
      "Epoch number: 1672/10000step_number: 0/29 Accuracy:  0.8819002213519496 Loss:  1.4069556874266427 Val_accuracy:  0.8770089893761918 Val_cost:  1.4069556874266427 Val_accuracy:  0.8770089893761918 Val_Acc:  1.5341644194932231\n",
      "Epoch number: 1673/10000step_number: 0/29 Accuracy:  0.8817980589136727 Loss:  1.4067787545175898 Val_accuracy:  0.8770089893761918 Val_cost:  1.4067787545175898 Val_accuracy:  0.8770089893761918 Val_Acc:  1.534203894302952\n",
      "Epoch number: 1674/10000step_number: 0/29 Accuracy:  0.8817980589136727 Loss:  1.4066041994250253 Val_accuracy:  0.8768727867066195 Val_cost:  1.4066041994250253 Val_accuracy:  0.8768727867066195 Val_Acc:  1.534247355304401\n",
      "Epoch number: 1675/10000step_number: 0/29 Accuracy:  0.8817640047675804 Loss:  1.4064331291585082 Val_accuracy:  0.8766003813674748 Val_cost:  1.4064331291585082 Val_accuracy:  0.8766003813674748 Val_Acc:  1.5342944643752041\n",
      "Epoch number: 1676/10000step_number: 0/29 Accuracy:  0.8819342754980419 Loss:  1.4062664301664145 Val_accuracy:  0.8766003813674748 Val_cost:  1.4062664301664145 Val_accuracy:  0.8766003813674748 Val_Acc:  1.5343447650999256\n",
      "Epoch number: 1677/10000step_number: 0/29 Accuracy:  0.8825813042737953 Loss:  1.4061047115981375 Val_accuracy:  0.8767365840370471 Val_cost:  1.4061047115981375 Val_accuracy:  0.8767365840370471 Val_Acc:  1.5343976909454218\n",
      "Epoch number: 1678/10000step_number: 0/29 Accuracy:  0.8827175208581645 Loss:  1.405948292340173 Val_accuracy:  0.8763279760283301 Val_cost:  1.405948292340173 Val_accuracy:  0.8763279760283301 Val_Acc:  1.534452603409837\n",
      "Epoch number: 1679/10000step_number: 0/29 Accuracy:  0.8825813042737953 Loss:  1.405797225161408 Val_accuracy:  0.8763279760283301 Val_cost:  1.405797225161408 Val_accuracy:  0.8763279760283301 Val_Acc:  1.534508836684699\n",
      "Epoch number: 1680/10000step_number: 0/29 Accuracy:  0.8827515750042567 Loss:  1.4056513515219198 Val_accuracy:  0.8763279760283301 Val_cost:  1.4056513515219198 Val_accuracy:  0.8763279760283301 Val_Acc:  1.5345657500350283\n",
      "Epoch number: 1681/10000step_number: 0/29 Accuracy:  0.8835007662182871 Loss:  1.4055103696247297 Val_accuracy:  0.8764641786979025 Val_cost:  1.4055103696247297 Val_accuracy:  0.8764641786979025 Val_Acc:  1.5346227763479732\n",
      "Epoch number: 1682/10000step_number: 0/29 Accuracy:  0.8834667120721947 Loss:  1.4053738982470227 Val_accuracy:  0.8764641786979025 Val_cost:  1.4053738982470227 Val_accuracy:  0.8764641786979025 Val_Acc:  1.5346794602310694\n",
      "Epoch number: 1683/10000step_number: 0/29 Accuracy:  0.8837050910948407 Loss:  1.40524152614885 Val_accuracy:  0.8761917733587579 Val_cost:  1.40524152614885 Val_accuracy:  0.8761917733587579 Val_Acc:  1.5347354739531907\n",
      "Epoch number: 1684/10000step_number: 0/29 Accuracy:  0.8837391452409331 Loss:  1.4051128470762166 Val_accuracy:  0.8759193680196132 Val_cost:  1.4051128470762166 Val_accuracy:  0.8759193680196132 Val_Acc:  1.5347906041672095\n",
      "Epoch number: 1685/10000step_number: 0/29 Accuracy:  0.8837050910948407 Loss:  1.404987485745508 Val_accuracy:  0.8756469626804685 Val_cost:  1.404987485745508 Val_accuracy:  0.8756469626804685 Val_Acc:  1.5348447177753914\n",
      "Epoch number: 1686/10000step_number: 0/29 Accuracy:  0.8839775242635791 Loss:  1.4048651160576788 Val_accuracy:  0.8759193680196132 Val_cost:  1.4048651160576788 Val_accuracy:  0.8759193680196132 Val_Acc:  1.5348977286843066\n",
      "Epoch number: 1687/10000step_number: 0/29 Accuracy:  0.8854759066916397 Loss:  1.4047454681842086 Val_accuracy:  0.8768727867066195 Val_cost:  1.4047454681842086 Val_accuracy:  0.8768727867066195 Val_Acc:  1.5349495797846082\n",
      "Epoch number: 1688/10000step_number: 0/29 Accuracy:  0.8856461774221012 Loss:  1.404628324870143 Val_accuracy:  0.8770089893761918 Val_cost:  1.404628324870143 Val_accuracy:  0.8770089893761918 Val_Acc:  1.5350002379444032\n",
      "Epoch number: 1689/10000step_number: 0/29 Accuracy:  0.8857142857142857 Loss:  1.4045135121229235 Val_accuracy:  0.8772813947153364 Val_cost:  1.4045135121229235 Val_accuracy:  0.8772813947153364 Val_Acc:  1.535049693281079\n",
      "Epoch number: 1690/10000step_number: 0/29 Accuracy:  0.8856802315681934 Loss:  1.404400889051444 Val_accuracy:  0.8770089893761918 Val_cost:  1.404400889051444 Val_accuracy:  0.8770089893761918 Val_Acc:  1.5350979572748467\n",
      "Epoch number: 1691/10000step_number: 0/29 Accuracy:  0.885748339860378 Loss:  1.4042903390933048 Val_accuracy:  0.8770089893761918 Val_cost:  1.4042903390933048 Val_accuracy:  0.8770089893761918 Val_Acc:  1.5351450587338302\n",
      "Epoch number: 1692/10000step_number: 0/29 Accuracy:  0.8862250979056701 Loss:  1.404181763234784 Val_accuracy:  0.877553800054481 Val_cost:  1.404181763234784 Val_accuracy:  0.877553800054481 Val_Acc:  1.5351910388820955\n",
      "Epoch number: 1693/10000step_number: 0/29 Accuracy:  0.8867018559509621 Loss:  1.4040750749835782 Val_accuracy:  0.8776900027240534 Val_cost:  1.4040750749835782 Val_accuracy:  0.8776900027240534 Val_Acc:  1.5352359470491206\n",
      "Epoch number: 1694/10000step_number: 0/29 Accuracy:  0.8868040183892388 Loss:  1.4039701964197064 Val_accuracy:  0.877962408063198 Val_cost:  1.4039701964197064 Val_accuracy:  0.877962408063198 Val_Acc:  1.5352798377249544\n",
      "Epoch number: 1695/10000step_number: 0/29 Accuracy:  0.8868040183892388 Loss:  1.4038670545575018 Val_accuracy:  0.8780986107327704 Val_cost:  1.4038670545575018 Val_accuracy:  0.8780986107327704 Val_Acc:  1.5353227689976676\n",
      "Epoch number: 1696/10000step_number: 0/29 Accuracy:  0.8868040183892388 Loss:  1.4037655774772075 Val_accuracy:  0.877962408063198 Val_cost:  1.4037655774772075 Val_accuracy:  0.877962408063198 Val_Acc:  1.5353648019375081\n",
      "Epoch number: 1697/10000step_number: 0/29 Accuracy:  0.8867699642431466 Loss:  1.403665690154937 Val_accuracy:  0.8780986107327704 Val_cost:  1.403665690154937 Val_accuracy:  0.8780986107327704 Val_Acc:  1.5354060003596137\n",
      "Epoch number: 1698/10000step_number: 0/29 Accuracy:  0.8873148305806232 Loss:  1.403567310438982 Val_accuracy:  0.8785072187414873 Val_cost:  1.403567310438982 Val_accuracy:  0.8785072187414873 Val_Acc:  1.5354464305424145\n",
      "Epoch number: 1699/10000step_number: 0/29 Accuracy:  0.8875532096032692 Loss:  1.4034703459336424 Val_accuracy:  0.8786434214110597 Val_cost:  1.4034703459336424 Val_accuracy:  0.8786434214110597 Val_Acc:  1.5354861607662798\n",
      "Epoch number: 1700/10000step_number: 0/29 Accuracy:  0.8876894261876384 Loss:  1.4033746925093455 Val_accuracy:  0.8786434214110597 Val_cost:  1.4033746925093455 Val_accuracy:  0.8786434214110597 Val_Acc:  1.5355252607846466\n",
      "Epoch number: 1701/10000step_number: 0/29 Accuracy:  0.8876894261876384 Loss:  1.4032802347853768 Val_accuracy:  0.8786434214110597 Val_cost:  1.4032802347853768 Val_accuracy:  0.8786434214110597 Val_Acc:  1.5355638014214155\n",
      "Epoch number: 1702/10000step_number: 0/29 Accuracy:  0.8877234803337306 Loss:  1.403186848405966 Val_accuracy:  0.8789158267502043 Val_cost:  1.403186848405966 Val_accuracy:  0.8789158267502043 Val_Acc:  1.5356018543991652\n",
      "Epoch number: 1703/10000step_number: 0/29 Accuracy:  0.8878256427720075 Loss:  1.4030944034861101 Val_accuracy:  0.8790520294197767 Val_cost:  1.4030944034861101 Val_accuracy:  0.8790520294197767 Val_Acc:  1.5356394923426573\n",
      "Epoch number: 1704/10000step_number: 0/29 Accuracy:  0.8878256427720075 Loss:  1.40300276841041 Val_accuracy:  0.8791882320893489 Val_cost:  1.40300276841041 Val_accuracy:  0.8791882320893489 Val_Acc:  1.5356767888007619\n",
      "Epoch number: 1705/10000step_number: 0/29 Accuracy:  0.8877915886259152 Loss:  1.4029118132553677 Val_accuracy:  0.8790520294197767 Val_cost:  1.4029118132553677 Val_accuracy:  0.8790520294197767 Val_Acc:  1.535713818128491\n",
      "Epoch number: 1706/10000step_number: 0/29 Accuracy:  0.8865656393665928 Loss:  1.4028214123758784 Val_accuracy:  0.8780986107327704 Val_cost:  1.4028214123758784 Val_accuracy:  0.8780986107327704 Val_Acc:  1.535750655153424\n",
      "Epoch number: 1707/10000step_number: 0/29 Accuracy:  0.8866678018048697 Loss:  1.4027314460077573 Val_accuracy:  0.8782348134023427 Val_cost:  1.4027314460077573 Val_accuracy:  0.8782348134023427 Val_Acc:  1.535787374645704\n",
      "Epoch number: 1708/10000step_number: 0/29 Accuracy:  0.8868380725353312 Loss:  1.4026418009816137 Val_accuracy:  0.8782348134023427 Val_cost:  1.4026418009816137 Val_accuracy:  0.8782348134023427 Val_Acc:  1.5358240506786498\n",
      "Epoch number: 1709/10000step_number: 0/29 Accuracy:  0.8868040183892388 Loss:  1.402552370776734 Val_accuracy:  0.8782348134023427 Val_cost:  1.402552370776734 Val_accuracy:  0.8782348134023427 Val_Acc:  1.5358607559845738\n",
      "Epoch number: 1710/10000step_number: 0/29 Accuracy:  0.8869061808275157 Loss:  1.4024630551772639 Val_accuracy:  0.8780986107327704 Val_cost:  1.4024630551772639 Val_accuracy:  0.8780986107327704 Val_Acc:  1.5358975613998567\n",
      "Epoch number: 1711/10000step_number: 0/29 Accuracy:  0.8869061808275157 Loss:  1.4023737597613686 Val_accuracy:  0.877962408063198 Val_cost:  1.4023737597613686 Val_accuracy:  0.877962408063198 Val_Acc:  1.535934535456818\n",
      "Epoch number: 1712/10000step_number: 0/29 Accuracy:  0.8868721266814235 Loss:  1.402284395392307 Val_accuracy:  0.877962408063198 Val_cost:  1.402284395392307 Val_accuracy:  0.877962408063198 Val_Acc:  1.5359717441509426\n",
      "Epoch number: 1713/10000step_number: 0/29 Accuracy:  0.8869061808275157 Loss:  1.4021948778135738 Val_accuracy:  0.877962408063198 Val_cost:  1.4021948778135738 Val_accuracy:  0.877962408063198 Val_Acc:  1.5360092508826435\n",
      "Epoch number: 1714/10000step_number: 0/29 Accuracy:  0.8869402349736081 Loss:  1.4021051273923626 Val_accuracy:  0.8776900027240534 Val_cost:  1.4021051273923626 Val_accuracy:  0.8776900027240534 Val_Acc:  1.536047116555427\n",
      "Epoch number: 1715/10000step_number: 0/29 Accuracy:  0.8869402349736081 Loss:  1.4020150690118498 Val_accuracy:  0.877553800054481 Val_cost:  1.4020150690118498 Val_accuracy:  0.877553800054481 Val_Acc:  1.5360853998022412\n",
      "Epoch number: 1716/10000step_number: 0/29 Accuracy:  0.8869402349736081 Loss:  1.4019246320837657 Val_accuracy:  0.877553800054481 Val_cost:  1.4019246320837657 Val_accuracy:  0.877553800054481 Val_Acc:  1.5361241573096573\n",
      "Epoch number: 1717/10000step_number: 0/29 Accuracy:  0.8869742891197003 Loss:  1.4018337506363814 Val_accuracy:  0.8774175973849088 Val_cost:  1.4018337506363814 Val_accuracy:  0.8774175973849088 Val_Acc:  1.5361634442063763\n",
      "Epoch number: 1718/10000step_number: 0/29 Accuracy:  0.8871105057040695 Loss:  1.4017423634269544 Val_accuracy:  0.8774175973849088 Val_cost:  1.4017423634269544 Val_accuracy:  0.8774175973849088 Val_Acc:  1.5362033144872176\n",
      "Epoch number: 1719/10000step_number: 0/29 Accuracy:  0.8871786139962541 Loss:  1.4016504140293575 Val_accuracy:  0.8774175973849088 Val_cost:  1.4016504140293575 Val_accuracy:  0.8774175973849088 Val_Acc:  1.5362438214433598\n",
      "Epoch number: 1720/10000step_number: 0/29 Accuracy:  0.8872467222884386 Loss:  1.4015578508550444 Val_accuracy:  0.8774175973849088 Val_cost:  1.4015578508550444 Val_accuracy:  0.8774175973849088 Val_Acc:  1.5362850180699532\n",
      "Epoch number: 1721/10000step_number: 0/29 Accuracy:  0.8872126681423463 Loss:  1.401464627077081 Val_accuracy:  0.8771451920457641 Val_cost:  1.401464627077081 Val_accuracy:  0.8771451920457641 Val_Acc:  1.5363269574216438\n",
      "Epoch number: 1722/10000step_number: 0/29 Accuracy:  0.8873829388728077 Loss:  1.4013707004412905 Val_accuracy:  0.877553800054481 Val_cost:  1.4013707004412905 Val_accuracy:  0.877553800054481 Val_Acc:  1.536369692880601\n",
      "Epoch number: 1723/10000step_number: 0/29 Accuracy:  0.8874510471649923 Loss:  1.401276032964356 Val_accuracy:  0.877553800054481 Val_cost:  1.401276032964356 Val_accuracy:  0.877553800054481 Val_Acc:  1.5364132782958697\n",
      "Epoch number: 1724/10000step_number: 0/29 Accuracy:  0.8875872637493615 Loss:  1.4011805905342458 Val_accuracy:  0.877553800054481 Val_cost:  1.4011805905342458 Val_accuracy:  0.877553800054481 Val_Acc:  1.5364577679455185\n",
      "Epoch number: 1725/10000step_number: 0/29 Accuracy:  0.8876213178954537 Loss:  1.401084342441003 Val_accuracy:  0.877553800054481 Val_cost:  1.401084342441003 Val_accuracy:  0.877553800054481 Val_Acc:  1.536503216269764\n",
      "Epoch number: 1726/10000step_number: 0/29 Accuracy:  0.8876553720415461 Loss:  1.4009872608720042 Val_accuracy:  0.877553800054481 Val_cost:  1.4009872608720042 Val_accuracy:  0.877553800054481 Val_Acc:  1.5365496773294214\n",
      "Epoch number: 1727/10000step_number: 0/29 Accuracy:  0.8877234803337306 Loss:  1.4008893204000101 Val_accuracy:  0.8776900027240534 Val_cost:  1.4008893204000101 Val_accuracy:  0.8776900027240534 Val_Acc:  1.5365972039729565\n",
      "Epoch number: 1728/10000step_number: 0/29 Accuracy:  0.887757534479823 Loss:  1.4007904974697327 Val_accuracy:  0.877553800054481 Val_cost:  1.4007904974697327 Val_accuracy:  0.877553800054481 Val_Acc:  1.5366458467572421\n",
      "Epoch number: 1729/10000step_number: 0/29 Accuracy:  0.8878256427720075 Loss:  1.4006907698473856 Val_accuracy:  0.8776900027240534 Val_cost:  1.4006907698473856 Val_accuracy:  0.8776900027240534 Val_Acc:  1.536695652770014\n",
      "Epoch number: 1730/10000step_number: 0/29 Accuracy:  0.8883364549633918 Loss:  1.4005901159452083 Val_accuracy:  0.8778262053936258 Val_cost:  1.4005901159452083 Val_accuracy:  0.8778262053936258 Val_Acc:  1.5367466646464958\n",
      "Epoch number: 1731/10000step_number: 0/29 Accuracy:  0.8884386174016686 Loss:  1.4004885138901815 Val_accuracy:  0.8778262053936258 Val_cost:  1.4004885138901815 Val_accuracy:  0.8778262053936258 Val_Acc:  1.5367989202225723\n",
      "Epoch number: 1732/10000step_number: 0/29 Accuracy:  0.8885067256938532 Loss:  1.4003859402054109 Val_accuracy:  0.8778262053936258 Val_cost:  1.4003859402054109 Val_accuracy:  0.8778262053936258 Val_Acc:  1.5368524533634274\n",
      "Epoch number: 1733/10000step_number: 0/29 Accuracy:  0.8887791588625915 Loss:  1.4002823680410683 Val_accuracy:  0.877962408063198 Val_cost:  1.4002823680410683 Val_accuracy:  0.877962408063198 Val_Acc:  1.5369072964765105\n",
      "Epoch number: 1734/10000step_number: 0/29 Accuracy:  0.8887791588625915 Loss:  1.400177765023922 Val_accuracy:  0.877962408063198 Val_cost:  1.400177765023922 Val_accuracy:  0.877962408063198 Val_Acc:  1.5369634849898437\n",
      "Epoch number: 1735/10000step_number: 0/29 Accuracy:  0.8887451047164993 Loss:  1.4000720909351163 Val_accuracy:  0.877962408063198 Val_cost:  1.4000720909351163 Val_accuracy:  0.877962408063198 Val_Acc:  1.5370210636826847\n",
      "Epoch number: 1736/10000step_number: 0/29 Accuracy:  0.8888472671547761 Loss:  1.3999652954911723 Val_accuracy:  0.877962408063198 Val_cost:  1.3999652954911723 Val_accuracy:  0.877962408063198 Val_Acc:  1.5370800942998475\n",
      "Epoch number: 1737/10000step_number: 0/29 Accuracy:  0.8888813213008684 Loss:  1.3998573164396335 Val_accuracy:  0.8780986107327704 Val_cost:  1.3998573164396335 Val_accuracy:  0.8780986107327704 Val_Acc:  1.5371406635315918\n",
      "Epoch number: 1738/10000step_number: 0/29 Accuracy:  0.8889153754469606 Loss:  1.3997480780167262 Val_accuracy:  0.8782348134023427 Val_cost:  1.3997480780167262 Val_accuracy:  0.8782348134023427 Val_Acc:  1.5372028903251855\n",
      "Epoch number: 1739/10000step_number: 0/29 Accuracy:  0.8889834837391453 Loss:  1.3996374896505548 Val_accuracy:  0.878371016071915 Val_cost:  1.3996374896505548 Val_accuracy:  0.878371016071915 Val_Acc:  1.537266931598673\n",
      "Epoch number: 1740/10000step_number: 0/29 Accuracy:  0.8889834837391453 Loss:  1.3995254447350771 Val_accuracy:  0.878371016071915 Val_cost:  1.3995254447350771 Val_accuracy:  0.878371016071915 Val_Acc:  1.537332985593263\n",
      "Epoch number: 1741/10000step_number: 0/29 Accuracy:  0.8890175378852375 Loss:  1.3994118193951726 Val_accuracy:  0.878371016071915 Val_cost:  1.3994118193951726 Val_accuracy:  0.878371016071915 Val_Acc:  1.537401292129815\n",
      "Epoch number: 1742/10000step_number: 0/29 Accuracy:  0.8890856461774221 Loss:  1.3992964713959104 Val_accuracy:  0.8785072187414873 Val_cost:  1.3992964713959104 Val_accuracy:  0.8785072187414873 Val_Acc:  1.5374721287519049\n",
      "Epoch number: 1743/10000step_number: 0/29 Accuracy:  0.8890856461774221 Loss:  1.3991792396781897 Val_accuracy:  0.8785072187414873 Val_cost:  1.3991792396781897 Val_accuracy:  0.8785072187414873 Val_Acc:  1.5375458011336405\n",
      "Epoch number: 1744/10000step_number: 0/29 Accuracy:  0.8890515920313298 Loss:  1.3990599453889812 Val_accuracy:  0.8785072187414873 Val_cost:  1.3990599453889812 Val_accuracy:  0.8785072187414873 Val_Acc:  1.537622625363441\n",
      "Epoch number: 1745/10000step_number: 0/29 Accuracy:  0.8890856461774221 Loss:  1.3989383956595476 Val_accuracy:  0.8787796240806319 Val_cost:  1.3989383956595476 Val_accuracy:  0.8787796240806319 Val_Acc:  1.537702899203928\n",
      "Epoch number: 1746/10000step_number: 0/29 Accuracy:  0.889187808615699 Loss:  1.3988143916232945 Val_accuracy:  0.8787796240806319 Val_cost:  1.3988143916232945 Val_accuracy:  0.8787796240806319 Val_Acc:  1.5377868599092241\n",
      "Epoch number: 1747/10000step_number: 0/29 Accuracy:  0.8892899710539758 Loss:  1.3986877419547945 Val_accuracy:  0.8787796240806319 Val_cost:  1.3986877419547945 Val_accuracy:  0.8787796240806319 Val_Acc:  1.5378746286421745\n",
      "Epoch number: 1748/10000step_number: 0/29 Accuracy:  0.8893921334922527 Loss:  1.3985582821701679 Val_accuracy:  0.8786434214110597 Val_cost:  1.3985582821701679 Val_accuracy:  0.8786434214110597 Val_Acc:  1.5379661468234458\n",
      "Epoch number: 1749/10000step_number: 0/29 Accuracy:  0.8894602417844373 Loss:  1.3984258980219566 Val_accuracy:  0.8786434214110597 Val_cost:  1.3984258980219566 Val_accuracy:  0.8786434214110597 Val_Acc:  1.5380611174692083\n",
      "Epoch number: 1750/10000step_number: 0/29 Accuracy:  0.8898348373914524 Loss:  1.398290549599855 Val_accuracy:  0.8787796240806319 Val_cost:  1.398290549599855 Val_accuracy:  0.8787796240806319 Val_Acc:  1.5381589718495183\n",
      "Epoch number: 1751/10000step_number: 0/29 Accuracy:  0.8898348373914524 Loss:  1.398152293362041 Val_accuracy:  0.8786434214110597 Val_cost:  1.398152293362041 Val_accuracy:  0.8786434214110597 Val_Acc:  1.5382588832190358\n",
      "Epoch number: 1752/10000step_number: 0/29 Accuracy:  0.8898688915375447 Loss:  1.3980113031042791 Val_accuracy:  0.8786434214110597 Val_cost:  1.3980113031042791 Val_accuracy:  0.8786434214110597 Val_Acc:  1.53835983997393\n",
      "Epoch number: 1753/10000step_number: 0/29 Accuracy:  0.8898688915375447 Loss:  1.397867893708042 Val_accuracy:  0.8787796240806319 Val_cost:  1.397867893708042 Val_accuracy:  0.8787796240806319 Val_Acc:  1.5384607710260807\n",
      "Epoch number: 1754/10000step_number: 0/29 Accuracy:  0.889902945683637 Loss:  1.3977225463763747 Val_accuracy:  0.8789158267502043 Val_cost:  1.3977225463763747 Val_accuracy:  0.8789158267502043 Val_Acc:  1.5385606950811002\n",
      "Epoch number: 1755/10000step_number: 0/29 Accuracy:  0.8901072705601907 Loss:  1.3975759217120443 Val_accuracy:  0.8789158267502043 Val_cost:  1.3975759217120443 Val_accuracy:  0.8789158267502043 Val_Acc:  1.5386588546252309\n",
      "Epoch number: 1756/10000step_number: 0/29 Accuracy:  0.890141324706283 Loss:  1.3974288407791207 Val_accuracy:  0.8789158267502043 Val_cost:  1.3974288407791207 Val_accuracy:  0.8789158267502043 Val_Acc:  1.5387548008583702\n",
      "Epoch number: 1757/10000step_number: 0/29 Accuracy:  0.8902094329984676 Loss:  1.3972822252117276 Val_accuracy:  0.8789158267502043 Val_cost:  1.3972822252117276 Val_accuracy:  0.8789158267502043 Val_Acc:  1.5388484137430438\n",
      "Epoch number: 1758/10000step_number: 0/29 Accuracy:  0.8902434871445598 Loss:  1.397137007474017 Val_accuracy:  0.8790520294197767 Val_cost:  1.397137007474017 Val_accuracy:  0.8790520294197767 Val_Acc:  1.538939862222863\n",
      "Epoch number: 1759/10000step_number: 0/29 Accuracy:  0.8903115954367444 Loss:  1.396994033587806 Val_accuracy:  0.8791882320893489 Val_cost:  1.396994033587806 Val_accuracy:  0.8791882320893489 Val_Acc:  1.5390295247354262\n",
      "Epoch number: 1760/10000step_number: 0/29 Accuracy:  0.8902775412906522 Loss:  1.3968539775493574 Val_accuracy:  0.8791882320893489 Val_cost:  1.3968539775493574 Val_accuracy:  0.8791882320893489 Val_Acc:  1.5391178950660471\n",
      "Epoch number: 1761/10000step_number: 0/29 Accuracy:  0.8902775412906522 Loss:  1.396717278745239 Val_accuracy:  0.8791882320893489 Val_cost:  1.396717278745239 Val_accuracy:  0.8791882320893489 Val_Acc:  1.539205494437787\n",
      "Epoch number: 1762/10000step_number: 0/29 Accuracy:  0.8904137578750213 Loss:  1.3965841086803716 Val_accuracy:  0.8791882320893489 Val_cost:  1.3965841086803716 Val_accuracy:  0.8791882320893489 Val_Acc:  1.5392928025905488\n",
      "Epoch number: 1763/10000step_number: 0/29 Accuracy:  0.8904478120211136 Loss:  1.396454369284696 Val_accuracy:  0.8793244347589213 Val_cost:  1.396454369284696 Val_accuracy:  0.8793244347589213 Val_Acc:  1.539380213332161\n",
      "Epoch number: 1764/10000step_number: 0/29 Accuracy:  0.8903456495828367 Loss:  1.3963277189142604 Val_accuracy:  0.8793244347589213 Val_cost:  1.3963277189142604 Val_accuracy:  0.8793244347589213 Val_Acc:  1.5394680149200668\n",
      "Epoch number: 1765/10000step_number: 0/29 Accuracy:  0.8901753788523753 Loss:  1.3962036165729845 Val_accuracy:  0.8793244347589213 Val_cost:  1.3962036165729845 Val_accuracy:  0.8793244347589213 Val_Acc:  1.5395563916873622\n",
      "Epoch number: 1766/10000step_number: 0/29 Accuracy:  0.8901072705601907 Loss:  1.3960813735733575 Val_accuracy:  0.8793244347589213 Val_cost:  1.3960813735733575 Val_accuracy:  0.8793244347589213 Val_Acc:  1.5396454405167455\n",
      "Epoch number: 1767/10000step_number: 0/29 Accuracy:  0.8900391622680062 Loss:  1.3959602041546184 Val_accuracy:  0.8791882320893489 Val_cost:  1.3959602041546184 Val_accuracy:  0.8791882320893489 Val_Acc:  1.539735194984557\n",
      "Epoch number: 1768/10000step_number: 0/29 Accuracy:  0.8899710539758215 Loss:  1.3958392696229234 Val_accuracy:  0.8791882320893489 Val_cost:  1.3958392696229234 Val_accuracy:  0.8791882320893489 Val_Acc:  1.539825651135637\n",
      "Epoch number: 1769/10000step_number: 0/29 Accuracy:  0.8900391622680062 Loss:  1.3957177132771672 Val_accuracy:  0.8791882320893489 Val_cost:  1.3957177132771672 Val_accuracy:  0.8791882320893489 Val_Acc:  1.5399167907381135\n",
      "Epoch number: 1770/10000step_number: 0/29 Accuracy:  0.8900391622680062 Loss:  1.3955946858465984 Val_accuracy:  0.8791882320893489 Val_cost:  1.3955946858465984 Val_accuracy:  0.8791882320893489 Val_Acc:  1.5400085997601267\n",
      "Epoch number: 1771/10000step_number: 0/29 Accuracy:  0.8900051081219138 Loss:  1.3954693627998018 Val_accuracy:  0.8791882320893489 Val_cost:  1.3954693627998018 Val_accuracy:  0.8791882320893489 Val_Acc:  1.5401010815853262\n",
      "Epoch number: 1772/10000step_number: 0/29 Accuracy:  0.8898348373914524 Loss:  1.3953409551413998 Val_accuracy:  0.8793244347589213 Val_cost:  1.3953409551413998 Val_accuracy:  0.8793244347589213 Val_Acc:  1.5401942658394636\n",
      "Epoch number: 1773/10000step_number: 0/29 Accuracy:  0.8897667290992678 Loss:  1.3952087148568137 Val_accuracy:  0.8794606374284936 Val_cost:  1.3952087148568137 Val_accuracy:  0.8794606374284936 Val_Acc:  1.5402882142103893\n",
      "Epoch number: 1774/10000step_number: 0/29 Accuracy:  0.8897667290992678 Loss:  1.3950719359107624 Val_accuracy:  0.8794606374284936 Val_cost:  1.3950719359107624 Val_accuracy:  0.8794606374284936 Val_Acc:  1.5403830244273466\n",
      "Epoch number: 1775/10000step_number: 0/29 Accuracy:  0.8898007832453602 Loss:  1.3949299516392275 Val_accuracy:  0.8794606374284936 Val_cost:  1.3949299516392275 Val_accuracy:  0.8794606374284936 Val_Acc:  1.5404788330904668\n",
      "Epoch number: 1776/10000step_number: 0/29 Accuracy:  0.889902945683637 Loss:  1.3947821291162792 Val_accuracy:  0.8795968400980659 Val_cost:  1.3947821291162792 Val_accuracy:  0.8795968400980659 Val_Acc:  1.5405758175795072\n",
      "Epoch number: 1777/10000step_number: 0/29 Accuracy:  0.889902945683637 Loss:  1.3946278607537999 Val_accuracy:  0.8793244347589213 Val_cost:  1.3946278607537999 Val_accuracy:  0.8793244347589213 Val_Acc:  1.5406741967795878\n",
      "Epoch number: 1778/10000step_number: 0/29 Accuracy:  0.8899369998297293 Loss:  1.3944665533185898 Val_accuracy:  0.8790520294197767 Val_cost:  1.3944665533185898 Val_accuracy:  0.8790520294197767 Val_Acc:  1.5407742299576124\n",
      "Epoch number: 1779/10000step_number: 0/29 Accuracy:  0.8897667290992678 Loss:  1.3942976146569876 Val_accuracy:  0.8789158267502043 Val_cost:  1.3942976146569876 Val_accuracy:  0.8789158267502043 Val_Acc:  1.54087621296175\n",
      "Epoch number: 1780/10000step_number: 0/29 Accuracy:  0.8903456495828367 Loss:  1.3941204385021593 Val_accuracy:  0.8795968400980659 Val_cost:  1.3941204385021593 Val_accuracy:  0.8795968400980659 Val_Acc:  1.5409804709413868\n",
      "Epoch number: 1781/10000step_number: 0/29 Accuracy:  0.8905159203132982 Loss:  1.393934387866299 Val_accuracy:  0.8798692454372106 Val_cost:  1.393934387866299 Val_accuracy:  0.8798692454372106 Val_Acc:  1.5410873467494672\n",
      "Epoch number: 1782/10000step_number: 0/29 Accuracy:  0.8905159203132982 Loss:  1.3937387777459667 Val_accuracy:  0.8798692454372106 Val_cost:  1.3937387777459667 Val_accuracy:  0.8798692454372106 Val_Acc:  1.5411971839330754\n",
      "Epoch number: 1783/10000step_number: 0/29 Accuracy:  0.8906521368976673 Loss:  1.3935328578705475 Val_accuracy:  0.8798692454372106 Val_cost:  1.3935328578705475 Val_accuracy:  0.8798692454372106 Val_Acc:  1.5413103027067052\n",
      "Epoch number: 1784/10000step_number: 0/29 Accuracy:  0.890379703728929 Loss:  1.3933157954100213 Val_accuracy:  0.8798692454372106 Val_cost:  1.3933157954100213 Val_accuracy:  0.8798692454372106 Val_Acc:  1.5414269661804525\n",
      "Epoch number: 1785/10000step_number: 0/29 Accuracy:  0.8901072705601907 Loss:  1.3930866551381715 Val_accuracy:  0.8801416507763552 Val_cost:  1.3930866551381715 Val_accuracy:  0.8801416507763552 Val_Acc:  1.5415473316726278\n",
      "Epoch number: 1786/10000step_number: 0/29 Accuracy:  0.889902945683637 Loss:  1.3928443690908978 Val_accuracy:  0.8801416507763552 Val_cost:  1.3928443690908978 Val_accuracy:  0.8801416507763552 Val_Acc:  1.5416713768483505\n",
      "Epoch number: 1787/10000step_number: 0/29 Accuracy:  0.8898007832453602 Loss:  1.3925876769300392 Val_accuracy:  0.8798692454372106 Val_cost:  1.3925876769300392 Val_accuracy:  0.8798692454372106 Val_Acc:  1.5417987801868758\n",
      "Epoch number: 1788/10000step_number: 0/29 Accuracy:  0.8911288949429593 Loss:  1.3923149995929052 Val_accuracy:  0.8808226641242168 Val_cost:  1.3923149995929052 Val_accuracy:  0.8808226641242168 Val_Acc:  1.5419287152851557\n",
      "Epoch number: 1789/10000step_number: 0/29 Accuracy:  0.8912651115273285 Loss:  1.3920241822468666 Val_accuracy:  0.8806864614546445 Val_cost:  1.3920241822468666 Val_accuracy:  0.8806864614546445 Val_Acc:  1.5420594824877452\n",
      "Epoch number: 1790/10000step_number: 0/29 Accuracy:  0.8913672739656053 Loss:  1.3917120151365994 Val_accuracy:  0.8806864614546445 Val_cost:  1.3917120151365994 Val_accuracy:  0.8806864614546445 Val_Acc:  1.5421878465056413\n",
      "Epoch number: 1791/10000step_number: 0/29 Accuracy:  0.8914353822577898 Loss:  1.3913734317675708 Val_accuracy:  0.8806864614546445 Val_cost:  1.3913734317675708 Val_accuracy:  0.8806864614546445 Val_Acc:  1.542307896546456\n",
      "Epoch number: 1792/10000step_number: 0/29 Accuracy:  0.8913332198195131 Loss:  1.3910002976249256 Val_accuracy:  0.8806864614546445 Val_cost:  1.3910002976249256 Val_accuracy:  0.8806864614546445 Val_Acc:  1.5424093084007413\n",
      "Epoch number: 1793/10000step_number: 0/29 Accuracy:  0.8911970032351438 Loss:  1.3905795249231319 Val_accuracy:  0.8808226641242168 Val_cost:  1.3905795249231319 Val_accuracy:  0.8808226641242168 Val_Acc:  1.5424754378141552\n",
      "Epoch number: 1794/10000step_number: 0/29 Accuracy:  0.8913332198195131 Loss:  1.3900886627643536 Val_accuracy:  0.8809588667937892 Val_cost:  1.3900886627643536 Val_accuracy:  0.8809588667937892 Val_Acc:  1.5424838147513666\n",
      "Epoch number: 1795/10000step_number: 0/29 Accuracy:  0.8925251149327431 Loss:  1.3894803481610545 Val_accuracy:  0.8817760828112231 Val_cost:  1.3894803481610545 Val_accuracy:  0.8817760828112231 Val_Acc:  1.542420173802107\n",
      "Epoch number: 1796/10000step_number: 0/29 Accuracy:  0.8926613315171122 Loss:  1.388638482229355 Val_accuracy:  0.8813674748025061 Val_cost:  1.388638482229355 Val_accuracy:  0.8813674748025061 Val_Acc:  1.5423631482517786\n",
      "Epoch number: 1797/10000step_number: 0/29 Accuracy:  0.8923207900561894 Loss:  1.3874686147960154 Val_accuracy:  0.8813674748025061 Val_cost:  1.3874686147960154 Val_accuracy:  0.8813674748025061 Val_Acc:  1.542907060560792\n",
      "Epoch number: 1798/10000step_number: 0/29 Accuracy:  0.8926272773710199 Loss:  1.3867182830261928 Val_accuracy:  0.882593298828657 Val_cost:  1.3867182830261928 Val_accuracy:  0.882593298828657 Val_Acc:  1.5447112528912497\n",
      "Epoch number: 1799/10000step_number: 0/29 Accuracy:  0.8911970032351438 Loss:  1.3852913158617757 Val_accuracy:  0.8817760828112231 Val_cost:  1.3852913158617757 Val_accuracy:  0.8817760828112231 Val_Acc:  1.543124798285073\n",
      "Epoch number: 1800/10000step_number: 0/29 Accuracy:  0.8923888983483739 Loss:  1.3852491130098152 Val_accuracy:  0.8835467175156633 Val_cost:  1.3852491130098152 Val_accuracy:  0.8835467175156633 Val_Acc:  1.5416810051855296\n",
      "Epoch number: 1801/10000step_number: 0/29 Accuracy:  0.8928316022475736 Loss:  1.3841260433719753 Val_accuracy:  0.8836829201852356 Val_cost:  1.3841260433719753 Val_accuracy:  0.8836829201852356 Val_Acc:  1.5377433294541487\n",
      "Epoch number: 1802/10000step_number: 0/29 Accuracy:  0.8936489017537885 Loss:  1.3849654874419968 Val_accuracy:  0.8843639335330973 Val_cost:  1.3849654874419968 Val_accuracy:  0.8843639335330973 Val_Acc:  1.5340064679928993\n",
      "Epoch number: 1803/10000step_number: 0/29 Accuracy:  0.8943299846756343 Loss:  1.3919414188668338 Val_accuracy:  0.8870879869245437 Val_cost:  1.3919414188668338 Val_accuracy:  0.8870879869245437 Val_Acc:  1.5343303608333292\n",
      "Epoch number: 1804/10000step_number: 0/29 Accuracy:  0.895964583688064 Loss:  1.3932459579698693 Val_accuracy:  0.8881776082811224 Val_cost:  1.3932459579698693 Val_accuracy:  0.8881776082811224 Val_Acc:  1.5366765228572599\n",
      "Epoch number: 1805/10000step_number: 0/29 Accuracy:  0.8948067427209263 Loss:  1.3930532024581113 Val_accuracy:  0.887632797602833 Val_cost:  1.3930532024581113 Val_accuracy:  0.887632797602833 Val_Acc:  1.5382058709804747\n",
      "Epoch number: 1806/10000step_number: 0/29 Accuracy:  0.8934786310233271 Loss:  1.3923265650570797 Val_accuracy:  0.8859983655679652 Val_cost:  1.3923265650570797 Val_accuracy:  0.8859983655679652 Val_Acc:  1.5378793024250024\n",
      "Epoch number: 1807/10000step_number: 0/29 Accuracy:  0.8924910607866507 Loss:  1.392614805248994 Val_accuracy:  0.8854535548896758 Val_cost:  1.392614805248994 Val_accuracy:  0.8854535548896758 Val_Acc:  1.5380600228433294\n",
      "Epoch number: 1808/10000step_number: 0/29 Accuracy:  0.8920143027413587 Loss:  1.392970906390587 Val_accuracy:  0.8847725415418142 Val_cost:  1.392970906390587 Val_accuracy:  0.8847725415418142 Val_Acc:  1.5385305348539677\n",
      "Epoch number: 1809/10000step_number: 0/29 Accuracy:  0.8908564617742211 Loss:  1.393160773397597 Val_accuracy:  0.8836829201852356 Val_cost:  1.393160773397597 Val_accuracy:  0.8836829201852356 Val_Acc:  1.5386296323114426\n",
      "Epoch number: 1810/10000step_number: 0/29 Accuracy:  0.8906180827515751 Loss:  1.3930146092646583 Val_accuracy:  0.8835467175156633 Val_cost:  1.3930146092646583 Val_accuracy:  0.8835467175156633 Val_Acc:  1.5388185830655958\n",
      "Epoch number: 1811/10000step_number: 0/29 Accuracy:  0.8902434871445598 Loss:  1.3931677381130894 Val_accuracy:  0.883410514846091 Val_cost:  1.3931677381130894 Val_accuracy:  0.883410514846091 Val_Acc:  1.5389373173409908\n",
      "Epoch number: 1812/10000step_number: 0/29 Accuracy:  0.8902434871445598 Loss:  1.3932104235720066 Val_accuracy:  0.8832743121765186 Val_cost:  1.3932104235720066 Val_accuracy:  0.8832743121765186 Val_Acc:  1.5391096361450005\n",
      "Epoch number: 1813/10000step_number: 0/29 Accuracy:  0.8901753788523753 Loss:  1.3932509175091827 Val_accuracy:  0.8831381095069464 Val_cost:  1.3932509175091827 Val_accuracy:  0.8831381095069464 Val_Acc:  1.5392447576068202\n",
      "Epoch number: 1814/10000step_number: 0/29 Accuracy:  0.8902434871445598 Loss:  1.3932938451831465 Val_accuracy:  0.8831381095069464 Val_cost:  1.3932938451831465 Val_accuracy:  0.8831381095069464 Val_Acc:  1.5393776200630132\n",
      "Epoch number: 1815/10000step_number: 0/29 Accuracy:  0.8902094329984676 Loss:  1.3932859291252948 Val_accuracy:  0.8828657041678016 Val_cost:  1.3932859291252948 Val_accuracy:  0.8828657041678016 Val_Acc:  1.5395063021832425\n",
      "Epoch number: 1816/10000step_number: 0/29 Accuracy:  0.8903456495828367 Loss:  1.393301460024637 Val_accuracy:  0.883001906837374 Val_cost:  1.393301460024637 Val_accuracy:  0.883001906837374 Val_Acc:  1.5396222880867116\n",
      "Epoch number: 1817/10000step_number: 0/29 Accuracy:  0.8903456495828367 Loss:  1.3932746103785008 Val_accuracy:  0.8828657041678016 Val_cost:  1.3932746103785008 Val_accuracy:  0.8828657041678016 Val_Acc:  1.5397377682633695\n",
      "Epoch number: 1818/10000step_number: 0/29 Accuracy:  0.890379703728929 Loss:  1.3932528323314 Val_accuracy:  0.8828657041678016 Val_cost:  1.3932528323314 Val_accuracy:  0.8828657041678016 Val_Acc:  1.539840480717854\n",
      "Epoch number: 1819/10000step_number: 0/29 Accuracy:  0.890379703728929 Loss:  1.3932123837417094 Val_accuracy:  0.8831381095069464 Val_cost:  1.3932123837417094 Val_accuracy:  0.8831381095069464 Val_Acc:  1.5399418247634415\n",
      "Epoch number: 1820/10000step_number: 0/29 Accuracy:  0.8902434871445598 Loss:  1.3931657971903524 Val_accuracy:  0.8831381095069464 Val_cost:  1.3931657971903524 Val_accuracy:  0.8831381095069464 Val_Acc:  1.5400349593657356\n",
      "Epoch number: 1821/10000step_number: 0/29 Accuracy:  0.8903115954367444 Loss:  1.393111952129199 Val_accuracy:  0.8831381095069464 Val_cost:  1.393111952129199 Val_accuracy:  0.8831381095069464 Val_Acc:  1.5401247328180478\n",
      "Epoch number: 1822/10000step_number: 0/29 Accuracy:  0.8903456495828367 Loss:  1.393050912070384 Val_accuracy:  0.8831381095069464 Val_cost:  1.393050912070384 Val_accuracy:  0.8831381095069464 Val_Acc:  1.5402097489191362\n",
      "Epoch number: 1823/10000step_number: 0/29 Accuracy:  0.8904478120211136 Loss:  1.3929857461644883 Val_accuracy:  0.883001906837374 Val_cost:  1.3929857461644883 Val_accuracy:  0.883001906837374 Val_Acc:  1.5402911057915423\n",
      "Epoch number: 1824/10000step_number: 0/29 Accuracy:  0.8904478120211136 Loss:  1.3929154477167567 Val_accuracy:  0.8828657041678016 Val_cost:  1.3929154477167567 Val_accuracy:  0.8828657041678016 Val_Acc:  1.5403694671498842\n",
      "Epoch number: 1825/10000step_number: 0/29 Accuracy:  0.8906521368976673 Loss:  1.392841722399172 Val_accuracy:  0.8828657041678016 Val_cost:  1.392841722399172 Val_accuracy:  0.8828657041678016 Val_Acc:  1.5404450274319779\n",
      "Epoch number: 1826/10000step_number: 0/29 Accuracy:  0.8907202451898518 Loss:  1.392764473474004 Val_accuracy:  0.883001906837374 Val_cost:  1.392764473474004 Val_accuracy:  0.883001906837374 Val_Acc:  1.5405186594304354\n",
      "Epoch number: 1827/10000step_number: 0/29 Accuracy:  0.8907883534820364 Loss:  1.3926841607407054 Val_accuracy:  0.883410514846091 Val_cost:  1.3926841607407054 Val_accuracy:  0.883410514846091 Val_Acc:  1.540590678887864\n",
      "Epoch number: 1828/10000step_number: 0/29 Accuracy:  0.8915375446960667 Loss:  1.392600891252736 Val_accuracy:  0.8836829201852356 Val_cost:  1.392600891252736 Val_accuracy:  0.8836829201852356 Val_Acc:  1.5406617190939962\n",
      "Epoch number: 1829/10000step_number: 0/29 Accuracy:  0.8914694364038822 Loss:  1.392514583878572 Val_accuracy:  0.8836829201852356 Val_cost:  1.392514583878572 Val_accuracy:  0.8836829201852356 Val_Acc:  1.54073221866344\n",
      "Epoch number: 1830/10000step_number: 0/29 Accuracy:  0.8917418695726205 Loss:  1.3924250863931422 Val_accuracy:  0.8836829201852356 Val_cost:  1.3924250863931422 Val_accuracy:  0.8836829201852356 Val_Acc:  1.540802627003275\n",
      "Epoch number: 1831/10000step_number: 0/29 Accuracy:  0.8917078154265282 Loss:  1.392332063776008 Val_accuracy:  0.883410514846091 Val_cost:  1.392332063776008 Val_accuracy:  0.883410514846091 Val_Acc:  1.5408733495234201\n",
      "Epoch number: 1832/10000step_number: 0/29 Accuracy:  0.8916737612804359 Loss:  1.3922351367559793 Val_accuracy:  0.8832743121765186 Val_cost:  1.3922351367559793 Val_accuracy:  0.8832743121765186 Val_Acc:  1.5409447253436495\n",
      "Epoch number: 1833/10000step_number: 0/29 Accuracy:  0.8917759237187127 Loss:  1.3921339056912672 Val_accuracy:  0.8831381095069464 Val_cost:  1.3921339056912672 Val_accuracy:  0.8831381095069464 Val_Acc:  1.5410170501723988\n",
      "Epoch number: 1834/10000step_number: 0/29 Accuracy:  0.8918440320108973 Loss:  1.3920280581091438 Val_accuracy:  0.882593298828657 Val_cost:  1.3920280581091438 Val_accuracy:  0.882593298828657 Val_Acc:  1.5410905362243736\n",
      "Epoch number: 1835/10000step_number: 0/29 Accuracy:  0.8917078154265282 Loss:  1.391917496735171 Val_accuracy:  0.8824570961590847 Val_cost:  1.391917496735171 Val_accuracy:  0.8824570961590847 Val_Acc:  1.5411653030481824\n",
      "Epoch number: 1836/10000step_number: 0/29 Accuracy:  0.8918099778648051 Loss:  1.391802502022054 Val_accuracy:  0.882593298828657 Val_cost:  1.391802502022054 Val_accuracy:  0.882593298828657 Val_Acc:  1.5412413480026197\n",
      "Epoch number: 1837/10000step_number: 0/29 Accuracy:  0.8918440320108973 Loss:  1.3916839103234575 Val_accuracy:  0.8828657041678016 Val_cost:  1.3916839103234575 Val_accuracy:  0.8828657041678016 Val_Acc:  1.5413185253118935\n",
      "Epoch number: 1838/10000step_number: 0/29 Accuracy:  0.8917759237187127 Loss:  1.3915632281180657 Val_accuracy:  0.8828657041678016 Val_cost:  1.3915632281180657 Val_accuracy:  0.8828657041678016 Val_Acc:  1.5413965245837806\n",
      "Epoch number: 1839/10000step_number: 0/29 Accuracy:  0.8922186276179125 Loss:  1.3914425452970984 Val_accuracy:  0.8828657041678016 Val_cost:  1.3914425452970984 Val_accuracy:  0.8828657041678016 Val_Acc:  1.5414748375982763\n",
      "Epoch number: 1840/10000step_number: 0/29 Accuracy:  0.8924910607866507 Loss:  1.391324107773226 Val_accuracy:  0.8827295014982294 Val_cost:  1.391324107773226 Val_accuracy:  0.8827295014982294 Val_Acc:  1.5415527034063743\n",
      "Epoch number: 1841/10000step_number: 0/29 Accuracy:  0.8927294398092968 Loss:  1.3912095960465813 Val_accuracy:  0.883001906837374 Val_cost:  1.3912095960465813 Val_accuracy:  0.883001906837374 Val_Acc:  1.5416290614957335\n",
      "Epoch number: 1842/10000step_number: 0/29 Accuracy:  0.8925591690788354 Loss:  1.3910995353040603 Val_accuracy:  0.8827295014982294 Val_cost:  1.3910995353040603 Val_accuracy:  0.8827295014982294 Val_Acc:  1.541702619290038\n",
      "Epoch number: 1843/10000step_number: 0/29 Accuracy:  0.8925251149327431 Loss:  1.3909934602375984 Val_accuracy:  0.882593298828657 Val_cost:  1.3909934602375984 Val_accuracy:  0.882593298828657 Val_Acc:  1.5417721562952011\n",
      "Epoch number: 1844/10000step_number: 0/29 Accuracy:  0.8925591690788354 Loss:  1.3908909682425314 Val_accuracy:  0.882593298828657 Val_cost:  1.3908909682425314 Val_accuracy:  0.882593298828657 Val_Acc:  1.5418370194810551\n",
      "Epoch number: 1845/10000step_number: 0/29 Accuracy:  0.8925251149327431 Loss:  1.3907928416025697 Val_accuracy:  0.882593298828657 Val_cost:  1.3907928416025697 Val_accuracy:  0.882593298828657 Val_Acc:  1.5418974983946252\n",
      "Epoch number: 1846/10000step_number: 0/29 Accuracy:  0.8925591690788354 Loss:  1.3907011264180993 Val_accuracy:  0.8823208934895124 Val_cost:  1.3907011264180993 Val_accuracy:  0.8823208934895124 Val_Acc:  1.5419547312625945\n",
      "Epoch number: 1847/10000step_number: 0/29 Accuracy:  0.8925932232249276 Loss:  1.3906179996986867 Val_accuracy:  0.8821846908199401 Val_cost:  1.3906179996986867 Val_accuracy:  0.8821846908199401 Val_Acc:  1.542010142347894\n",
      "Epoch number: 1848/10000step_number: 0/29 Accuracy:  0.8926272773710199 Loss:  1.3905444125724784 Val_accuracy:  0.8819122854807955 Val_cost:  1.3905444125724784 Val_accuracy:  0.8819122854807955 Val_Acc:  1.5420648142676399\n",
      "Epoch number: 1849/10000step_number: 0/29 Accuracy:  0.8926953856632045 Loss:  1.3904795509681598 Val_accuracy:  0.8819122854807955 Val_cost:  1.3904795509681598 Val_accuracy:  0.8819122854807955 Val_Acc:  1.5421192059844357\n",
      "Epoch number: 1850/10000step_number: 0/29 Accuracy:  0.8926272773710199 Loss:  1.3904212610181335 Val_accuracy:  0.8819122854807955 Val_cost:  1.3904212610181335 Val_accuracy:  0.8819122854807955 Val_Acc:  1.5421732687978171\n",
      "Epoch number: 1851/10000step_number: 0/29 Accuracy:  0.8925251149327431 Loss:  1.390366896733541 Val_accuracy:  0.8815036774720785 Val_cost:  1.390366896733541 Val_accuracy:  0.8815036774720785 Val_Acc:  1.5422267291086376\n",
      "Epoch number: 1852/10000step_number: 0/29 Accuracy:  0.8924570066405585 Loss:  1.3903140586661331 Val_accuracy:  0.8815036774720785 Val_cost:  1.3903140586661331 Val_accuracy:  0.8815036774720785 Val_Acc:  1.5422793232750904\n",
      "Epoch number: 1853/10000step_number: 0/29 Accuracy:  0.8928997105397583 Loss:  1.390261011024087 Val_accuracy:  0.8816398801416507 Val_cost:  1.390261011024087 Val_accuracy:  0.8816398801416507 Val_Acc:  1.5423309179972284\n",
      "Epoch number: 1854/10000step_number: 0/29 Accuracy:  0.8928656563936659 Loss:  1.3902067889350294 Val_accuracy:  0.8816398801416507 Val_cost:  1.3902067889350294 Val_accuracy:  0.8816398801416507 Val_Acc:  1.5423815373504535\n",
      "Epoch number: 1855/10000step_number: 0/29 Accuracy:  0.8929678188319428 Loss:  1.3901510841414548 Val_accuracy:  0.8815036774720785 Val_cost:  1.3901510841414548 Val_accuracy:  0.8815036774720785 Val_Acc:  1.5424313302250088\n",
      "Epoch number: 1856/10000step_number: 0/29 Accuracy:  0.8928656563936659 Loss:  1.3900940093131453 Val_accuracy:  0.8816398801416507 Val_cost:  1.3900940093131453 Val_accuracy:  0.8816398801416507 Val_Acc:  1.5424805053802049\n",
      "Epoch number: 1857/10000step_number: 0/29 Accuracy:  0.8929337646858505 Loss:  1.3900358360302958 Val_accuracy:  0.8816398801416507 Val_cost:  1.3900358360302958 Val_accuracy:  0.8816398801416507 Val_Acc:  1.5425292603203473\n",
      "Epoch number: 1858/10000step_number: 0/29 Accuracy:  0.8928997105397583 Loss:  1.3899767830218972 Val_accuracy:  0.8813674748025061 Val_cost:  1.3899767830218972 Val_accuracy:  0.8813674748025061 Val_Acc:  1.542577728396563\n",
      "Epoch number: 1859/10000step_number: 0/29 Accuracy:  0.8928997105397583 Loss:  1.3899168967603945 Val_accuracy:  0.8815036774720785 Val_cost:  1.3899168967603945 Val_accuracy:  0.8815036774720785 Val_Acc:  1.5426259582947528\n",
      "Epoch number: 1860/10000step_number: 0/29 Accuracy:  0.8930699812702196 Loss:  1.3898560264460842 Val_accuracy:  0.8816398801416507 Val_cost:  1.3898560264460842 Val_accuracy:  0.8816398801416507 Val_Acc:  1.5426739248443242\n",
      "Epoch number: 1861/10000step_number: 0/29 Accuracy:  0.8931721437084965 Loss:  1.3897938666002179 Val_accuracy:  0.8815036774720785 Val_cost:  1.3897938666002179 Val_accuracy:  0.8815036774720785 Val_Acc:  1.5427215587220258\n",
      "Epoch number: 1862/10000step_number: 0/29 Accuracy:  0.8933424144389579 Loss:  1.389730031188405 Val_accuracy:  0.8816398801416507 Val_cost:  1.389730031188405 Val_accuracy:  0.8816398801416507 Val_Acc:  1.5427687799683463\n",
      "Epoch number: 1863/10000step_number: 0/29 Accuracy:  0.8933424144389579 Loss:  1.3896641292032679 Val_accuracy:  0.8816398801416507 Val_cost:  1.3896641292032679 Val_accuracy:  0.8816398801416507 Val_Acc:  1.5428155243700141\n",
      "Epoch number: 1864/10000step_number: 0/29 Accuracy:  0.8933424144389579 Loss:  1.389595823560672 Val_accuracy:  0.8816398801416507 Val_cost:  1.389595823560672 Val_accuracy:  0.8816398801416507 Val_Acc:  1.5428617579681623\n",
      "Epoch number: 1865/10000step_number: 0/29 Accuracy:  0.8933424144389579 Loss:  1.389524866019569 Val_accuracy:  0.8815036774720785 Val_cost:  1.389524866019569 Val_accuracy:  0.8815036774720785 Val_Acc:  1.542907479796007\n",
      "Epoch number: 1866/10000step_number: 0/29 Accuracy:  0.8933424144389579 Loss:  1.3894511081831014 Val_accuracy:  0.8815036774720785 Val_cost:  1.3894511081831014 Val_accuracy:  0.8815036774720785 Val_Acc:  1.5429527155890166\n",
      "Epoch number: 1867/10000step_number: 0/29 Accuracy:  0.8933424144389579 Loss:  1.389374492868944 Val_accuracy:  0.8815036774720785 Val_cost:  1.389374492868944 Val_accuracy:  0.8815036774720785 Val_Acc:  1.542997506115644\n",
      "Epoch number: 1868/10000step_number: 0/29 Accuracy:  0.8933424144389579 Loss:  1.3892950322563975 Val_accuracy:  0.8815036774720785 Val_cost:  1.3892950322563975 Val_accuracy:  0.8815036774720785 Val_Acc:  1.543041893743817\n",
      "Epoch number: 1869/10000step_number: 0/29 Accuracy:  0.8932743061467734 Loss:  1.3892127798404135 Val_accuracy:  0.8815036774720785 Val_cost:  1.3892127798404135 Val_accuracy:  0.8815036774720785 Val_Acc:  1.5430859103039902\n",
      "Epoch number: 1870/10000step_number: 0/29 Accuracy:  0.8932402520006811 Loss:  1.389127802624335 Val_accuracy:  0.8812312721329338 Val_cost:  1.389127802624335 Val_accuracy:  0.8812312721329338 Val_Acc:  1.543129568414867\n",
      "Epoch number: 1871/10000step_number: 0/29 Accuracy:  0.8934445768772348 Loss:  1.3890401584488667 Val_accuracy:  0.8817760828112231 Val_cost:  1.3890401584488667 Val_accuracy:  0.8817760828112231 Val_Acc:  1.5431728573643886\n",
      "Epoch number: 1872/10000step_number: 0/29 Accuracy:  0.8934445768772348 Loss:  1.3889498813283727 Val_accuracy:  0.8817760828112231 Val_cost:  1.3889498813283727 Val_accuracy:  0.8817760828112231 Val_Acc:  1.543215743581604\n",
      "Epoch number: 1873/10000step_number: 0/29 Accuracy:  0.8934786310233271 Loss:  1.388856975653051 Val_accuracy:  0.8817760828112231 Val_cost:  1.388856975653051 Val_accuracy:  0.8817760828112231 Val_Acc:  1.5432581748738405\n",
      "Epoch number: 1874/10000step_number: 0/29 Accuracy:  0.8935126851694194 Loss:  1.3887614185108696 Val_accuracy:  0.8817760828112231 Val_cost:  1.3887614185108696 Val_accuracy:  0.8817760828112231 Val_Acc:  1.5433000871181208\n",
      "Epoch number: 1875/10000step_number: 0/29 Accuracy:  0.8934445768772348 Loss:  1.3886631683642292 Val_accuracy:  0.8817760828112231 Val_cost:  1.3886631683642292 Val_accuracy:  0.8817760828112231 Val_Acc:  1.5433414119595932\n",
      "Epoch number: 1876/10000step_number: 0/29 Accuracy:  0.8934445768772348 Loss:  1.3885621778572854 Val_accuracy:  0.8817760828112231 Val_cost:  1.3885621778572854 Val_accuracy:  0.8817760828112231 Val_Acc:  1.543382084238042\n",
      "Epoch number: 1877/10000step_number: 0/29 Accuracy:  0.8935467393155117 Loss:  1.3884584084877087 Val_accuracy:  0.8817760828112231 Val_cost:  1.3884584084877087 Val_accuracy:  0.8817760828112231 Val_Acc:  1.5434220481928829\n",
      "Epoch number: 1878/10000step_number: 0/29 Accuracy:  0.8935807934616039 Loss:  1.3883518450880925 Val_accuracy:  0.8817760828112231 Val_cost:  1.3883518450880925 Val_accuracy:  0.8817760828112231 Val_Acc:  1.5434612618639185\n",
      "Epoch number: 1879/10000step_number: 0/29 Accuracy:  0.8936148476076963 Loss:  1.3882425084048586 Val_accuracy:  0.8819122854807955 Val_cost:  1.3882425084048586 Val_accuracy:  0.8819122854807955 Val_Acc:  1.5434996994413113\n",
      "Epoch number: 1880/10000step_number: 0/29 Accuracy:  0.8935467393155117 Loss:  1.3881304644709966 Val_accuracy:  0.8819122854807955 Val_cost:  1.3881304644709966 Val_accuracy:  0.8819122854807955 Val_Acc:  1.5435373515853068\n",
      "Epoch number: 1881/10000step_number: 0/29 Accuracy:  0.8937170100459731 Loss:  1.3880158299182273 Val_accuracy:  0.8823208934895124 Val_cost:  1.3880158299182273 Val_accuracy:  0.8823208934895124 Val_Acc:  1.5435742239383976\n",
      "Epoch number: 1882/10000step_number: 0/29 Accuracy:  0.8937170100459731 Loss:  1.3878987728519292 Val_accuracy:  0.8823208934895124 Val_cost:  1.3878987728519292 Val_accuracy:  0.8823208934895124 Val_Acc:  1.5436103342007759\n",
      "Epoch number: 1883/10000step_number: 0/29 Accuracy:  0.8936829558998808 Loss:  1.3877795093964582 Val_accuracy:  0.8821846908199401 Val_cost:  1.3877795093964582 Val_accuracy:  0.8821846908199401 Val_Acc:  1.5436457082635096\n",
      "Epoch number: 1884/10000step_number: 0/29 Accuracy:  0.8936829558998808 Loss:  1.3876582964699247 Val_accuracy:  0.8823208934895124 Val_cost:  1.3876582964699247 Val_accuracy:  0.8823208934895124 Val_Acc:  1.54368037597258\n",
      "Epoch number: 1885/10000step_number: 0/29 Accuracy:  0.8937170100459731 Loss:  1.3875354217155418 Val_accuracy:  0.8824570961590847 Val_cost:  1.3875354217155418 Val_accuracy:  0.8824570961590847 Val_Acc:  1.543714367131176\n",
      "Epoch number: 1886/10000step_number: 0/29 Accuracy:  0.8937510641920654 Loss:  1.387411191754853 Val_accuracy:  0.8823208934895124 Val_cost:  1.387411191754853 Val_accuracy:  0.8823208934895124 Val_Acc:  1.5437477083414455\n",
      "Epoch number: 1887/10000step_number: 0/29 Accuracy:  0.8943640388217265 Loss:  1.3872859200089185 Val_accuracy:  0.8828657041678016 Val_cost:  1.3872859200089185 Val_accuracy:  0.8828657041678016 Val_Acc:  1.5437804211915804\n",
      "Epoch number: 1888/10000step_number: 0/29 Accuracy:  0.8944321471139112 Loss:  1.3871599152578684 Val_accuracy:  0.8828657041678016 Val_cost:  1.3871599152578684 Val_accuracy:  0.8828657041678016 Val_Acc:  1.5438125221430936\n",
      "Epoch number: 1889/10000step_number: 0/29 Accuracy:  0.8944321471139112 Loss:  1.3870334719054305 Val_accuracy:  0.8828657041678016 Val_cost:  1.3870334719054305 Val_accuracy:  0.8828657041678016 Val_Acc:  1.543844024281074\n",
      "Epoch number: 1890/10000step_number: 0/29 Accuracy:  0.8944662012600034 Loss:  1.38690686263082 Val_accuracy:  0.8828657041678016 Val_cost:  1.38690686263082 Val_accuracy:  0.8828657041678016 Val_Acc:  1.5438749408538317\n",
      "Epoch number: 1891/10000step_number: 0/29 Accuracy:  0.8945683636982803 Loss:  1.3867803337995865 Val_accuracy:  0.883001906837374 Val_cost:  1.3867803337995865 Val_accuracy:  0.883001906837374 Val_Acc:  1.5439052903204098\n",
      "Epoch number: 1892/10000step_number: 0/29 Accuracy:  0.8945683636982803 Loss:  1.38665410371501 Val_accuracy:  0.8831381095069464 Val_cost:  1.38665410371501 Val_accuracy:  0.8831381095069464 Val_Acc:  1.5439351024310775\n",
      "Epoch number: 1893/10000step_number: 0/29 Accuracy:  0.8945683636982803 Loss:  1.386528363554431 Val_accuracy:  0.8831381095069464 Val_cost:  1.386528363554431 Val_accuracy:  0.8831381095069464 Val_Acc:  1.5439644247515656\n",
      "Epoch number: 1894/10000step_number: 0/29 Accuracy:  0.8945683636982803 Loss:  1.3864032806634834 Val_accuracy:  0.8831381095069464 Val_cost:  1.3864032806634834 Val_accuracy:  0.8831381095069464 Val_Acc:  1.5439933289759813\n",
      "Epoch number: 1895/10000step_number: 0/29 Accuracy:  0.8945683636982803 Loss:  1.3862790037710346 Val_accuracy:  0.8831381095069464 Val_cost:  1.3862790037710346 Val_accuracy:  0.8831381095069464 Val_Acc:  1.54402191635978\n",
      "Epoch number: 1896/10000step_number: 0/29 Accuracy:  0.8945343095521879 Loss:  1.3861556696209336 Val_accuracy:  0.883001906837374 Val_cost:  1.3861556696209336 Val_accuracy:  0.883001906837374 Val_Acc:  1.5440503216480161\n",
      "Epoch number: 1897/10000step_number: 0/29 Accuracy:  0.8946024178443726 Loss:  1.3860334104685668 Val_accuracy:  0.883001906837374 Val_cost:  1.3860334104685668 Val_accuracy:  0.883001906837374 Val_Acc:  1.5440787148907489\n",
      "Epoch number: 1898/10000step_number: 0/29 Accuracy:  0.8945683636982803 Loss:  1.3859123618343039 Val_accuracy:  0.883001906837374 Val_cost:  1.3859123618343039 Val_accuracy:  0.883001906837374 Val_Acc:  1.5441073005815158\n",
      "Epoch number: 1899/10000step_number: 0/29 Accuracy:  0.8946024178443726 Loss:  1.385792669820467 Val_accuracy:  0.8831381095069464 Val_cost:  1.385792669820467 Val_accuracy:  0.8831381095069464 Val_Acc:  1.5441363135513793\n",
      "Epoch number: 1900/10000step_number: 0/29 Accuracy:  0.8945343095521879 Loss:  1.3856744971738548 Val_accuracy:  0.8831381095069464 Val_cost:  1.3856744971738548 Val_accuracy:  0.8831381095069464 Val_Acc:  1.544166011092435\n",
      "Epoch number: 1901/10000step_number: 0/29 Accuracy:  0.8945683636982803 Loss:  1.385558027122385 Val_accuracy:  0.8831381095069464 Val_cost:  1.385558027122385 Val_accuracy:  0.8831381095069464 Val_Acc:  1.5441966608575808\n",
      "Epoch number: 1902/10000step_number: 0/29 Accuracy:  0.8946024178443726 Loss:  1.3854434638706146 Val_accuracy:  0.8831381095069464 Val_cost:  1.3854434638706146 Val_accuracy:  0.8831381095069464 Val_Acc:  1.5442285243497873\n",
      "Epoch number: 1903/10000step_number: 0/29 Accuracy:  0.8945343095521879 Loss:  1.385331028572745 Val_accuracy:  0.883001906837374 Val_cost:  1.385331028572745 Val_accuracy:  0.883001906837374 Val_Acc:  1.5442618362876976\n",
      "Epoch number: 1904/10000step_number: 0/29 Accuracy:  0.8946024178443726 Loss:  1.3852209496970114 Val_accuracy:  0.883001906837374 Val_cost:  1.3852209496970114 Val_accuracy:  0.883001906837374 Val_Acc:  1.5442967809666805\n",
      "Epoch number: 1905/10000step_number: 0/29 Accuracy:  0.8946024178443726 Loss:  1.3851134470173816 Val_accuracy:  0.8828657041678016 Val_cost:  1.3851134470173816 Val_accuracy:  0.8828657041678016 Val_Acc:  1.544333467880827\n",
      "Epoch number: 1906/10000step_number: 0/29 Accuracy:  0.8946024178443726 Loss:  1.3850087090114651 Val_accuracy:  0.8828657041678016 Val_cost:  1.3850087090114651 Val_accuracy:  0.8828657041678016 Val_Acc:  1.5443719102267124\n",
      "Epoch number: 1907/10000step_number: 0/29 Accuracy:  0.8946364719904648 Loss:  1.3849068640831848 Val_accuracy:  0.8828657041678016 Val_cost:  1.3849068640831848 Val_accuracy:  0.8828657041678016 Val_Acc:  1.544412011170051\n",
      "Epoch number: 1908/10000step_number: 0/29 Accuracy:  0.8946364719904648 Loss:  1.3848079465132674 Val_accuracy:  0.883001906837374 Val_cost:  1.3848079465132674 Val_accuracy:  0.883001906837374 Val_Acc:  1.5444535634441026\n",
      "Epoch number: 1909/10000step_number: 0/29 Accuracy:  0.8947045802826494 Loss:  1.38471185805541 Val_accuracy:  0.8828657041678016 Val_cost:  1.38471185805541 Val_accuracy:  0.8828657041678016 Val_Acc:  1.5444962674628482\n",
      "Epoch number: 1910/10000step_number: 0/29 Accuracy:  0.8947386344287417 Loss:  1.3846183254159854 Val_accuracy:  0.8828657041678016 Val_cost:  1.3846183254159854 Val_accuracy:  0.8828657041678016 Val_Acc:  1.5445397713707258\n",
      "Epoch number: 1911/10000step_number: 0/29 Accuracy:  0.8947726885748339 Loss:  1.3845268525931569 Val_accuracy:  0.883001906837374 Val_cost:  1.3845268525931569 Val_accuracy:  0.883001906837374 Val_Acc:  1.5445837334979386\n",
      "Epoch number: 1912/10000step_number: 0/29 Accuracy:  0.8947726885748339 Loss:  1.3844366660239262 Val_accuracy:  0.883001906837374 Val_cost:  1.3844366660239262 Val_accuracy:  0.883001906837374 Val_Acc:  1.5446279044741464\n",
      "Epoch number: 1913/10000step_number: 0/29 Accuracy:  0.8947386344287417 Loss:  1.3843466517008345 Val_accuracy:  0.883001906837374 Val_cost:  1.3843466517008345 Val_accuracy:  0.883001906837374 Val_Acc:  1.5446722243548903\n",
      "Epoch number: 1914/10000step_number: 0/29 Accuracy:  0.8947386344287417 Loss:  1.3842552903969718 Val_accuracy:  0.8828657041678016 Val_cost:  1.3842552903969718 Val_accuracy:  0.8828657041678016 Val_Acc:  1.5447169314595548\n",
      "Epoch number: 1915/10000step_number: 0/29 Accuracy:  0.8945343095521879 Loss:  1.384160614248331 Val_accuracy:  0.8828657041678016 Val_cost:  1.384160614248331 Val_accuracy:  0.8828657041678016 Val_Acc:  1.5447626853159286\n",
      "Epoch number: 1916/10000step_number: 0/29 Accuracy:  0.8945343095521879 Loss:  1.3840602375970257 Val_accuracy:  0.8828657041678016 Val_cost:  1.3840602375970257 Val_accuracy:  0.8828657041678016 Val_Acc:  1.5448107142610594\n",
      "Epoch number: 1917/10000step_number: 0/29 Accuracy:  0.8945683636982803 Loss:  1.383951552516105 Val_accuracy:  0.8831381095069464 Val_cost:  1.383951552516105 Val_accuracy:  0.8831381095069464 Val_Acc:  1.544862999521708\n",
      "Epoch number: 1918/10000step_number: 0/29 Accuracy:  0.8945002554060957 Loss:  1.3838322069184013 Val_accuracy:  0.883410514846091 Val_cost:  1.3838322069184013 Val_accuracy:  0.883410514846091 Val_Acc:  1.5449224795228282\n",
      "Epoch number: 1919/10000step_number: 0/29 Accuracy:  0.8946364719904648 Loss:  1.3837009624740066 Val_accuracy:  0.8832743121765186 Val_cost:  1.3837009624740066 Val_accuracy:  0.8832743121765186 Val_Acc:  1.5449931603556322\n",
      "Epoch number: 1920/10000step_number: 0/29 Accuracy:  0.8943299846756343 Loss:  1.3835588928195608 Val_accuracy:  0.883001906837374 Val_cost:  1.3835588928195608 Val_accuracy:  0.883001906837374 Val_Acc:  1.5450798024225985\n",
      "Epoch number: 1921/10000step_number: 0/29 Accuracy:  0.8941937680912652 Loss:  1.3834105439795603 Val_accuracy:  0.883001906837374 Val_cost:  1.3834105439795603 Val_accuracy:  0.883001906837374 Val_Acc:  1.5451865318405464\n",
      "Epoch number: 1922/10000step_number: 0/29 Accuracy:  0.8942278222373574 Loss:  1.3832641872235805 Val_accuracy:  0.8832743121765186 Val_cost:  1.3832641872235805 Val_accuracy:  0.8832743121765186 Val_Acc:  1.5453135886971454\n",
      "Epoch number: 1923/10000step_number: 0/29 Accuracy:  0.8941597139451728 Loss:  1.383130262560198 Val_accuracy:  0.8832743121765186 Val_cost:  1.383130262560198 Val_accuracy:  0.8832743121765186 Val_Acc:  1.5454522870213772\n",
      "Epoch number: 1924/10000step_number: 0/29 Accuracy:  0.8940575515068959 Loss:  1.3830187103665936 Val_accuracy:  0.8832743121765186 Val_cost:  1.3830187103665936 Val_accuracy:  0.8832743121765186 Val_Acc:  1.5455807040760723\n",
      "Epoch number: 1925/10000step_number: 0/29 Accuracy:  0.8941256597990805 Loss:  1.3829390067546796 Val_accuracy:  0.8832743121765186 Val_cost:  1.3829390067546796 Val_accuracy:  0.8832743121765186 Val_Acc:  1.5456644704626188\n",
      "Epoch number: 1926/10000step_number: 0/29 Accuracy:  0.8940234973608037 Loss:  1.3829145181765203 Val_accuracy:  0.883001906837374 Val_cost:  1.3829145181765203 Val_accuracy:  0.883001906837374 Val_Acc:  1.545665134310143\n",
      "Epoch number: 1927/10000step_number: 0/29 Accuracy:  0.8940575515068959 Loss:  1.3830621616108767 Val_accuracy:  0.883001906837374 Val_cost:  1.3830621616108767 Val_accuracy:  0.883001906837374 Val_Acc:  1.5455682311645278\n",
      "Epoch number: 1928/10000step_number: 0/29 Accuracy:  0.8946024178443726 Loss:  1.3837862732022754 Val_accuracy:  0.8832743121765186 Val_cost:  1.3837862732022754 Val_accuracy:  0.8832743121765186 Val_Acc:  1.5455150291301945\n",
      "Epoch number: 1929/10000step_number: 0/29 Accuracy:  0.8943640388217265 Loss:  1.3843306131279625 Val_accuracy:  0.883001906837374 Val_cost:  1.3843306131279625 Val_accuracy:  0.883001906837374 Val_Acc:  1.545586105286731\n",
      "Epoch number: 1930/10000step_number: 0/29 Accuracy:  0.8947726885748339 Loss:  1.383324761049581 Val_accuracy:  0.8831381095069464 Val_cost:  1.383324761049581 Val_accuracy:  0.8831381095069464 Val_Acc:  1.5452915759966173\n",
      "Epoch number: 1931/10000step_number: 0/29 Accuracy:  0.895249446620126 Loss:  1.3842141222507616 Val_accuracy:  0.882593298828657 Val_cost:  1.3842141222507616 Val_accuracy:  0.882593298828657 Val_Acc:  1.5449813033826083\n",
      "Epoch number: 1932/10000step_number: 0/29 Accuracy:  0.8952153924740337 Loss:  1.3819246352927272 Val_accuracy:  0.8832743121765186 Val_cost:  1.3819246352927272 Val_accuracy:  0.8832743121765186 Val_Acc:  1.5447362622752916\n",
      "Epoch number: 1933/10000step_number: 0/29 Accuracy:  0.8947386344287417 Loss:  1.3809399700692635 Val_accuracy:  0.8847725415418142 Val_cost:  1.3809399700692635 Val_accuracy:  0.8847725415418142 Val_Acc:  1.5462126221249497\n",
      "Epoch number: 1934/10000step_number: 0/29 Accuracy:  0.8950791758896646 Loss:  1.3806129838778949 Val_accuracy:  0.8847725415418142 Val_cost:  1.3806129838778949 Val_accuracy:  0.8847725415418142 Val_Acc:  1.5467380260686956\n",
      "Epoch number: 1935/10000step_number: 0/29 Accuracy:  0.8951472841818492 Loss:  1.3809723899826758 Val_accuracy:  0.8839553255243803 Val_cost:  1.3809723899826758 Val_accuracy:  0.8839553255243803 Val_Acc:  1.546080381082495\n",
      "Epoch number: 1936/10000step_number: 0/29 Accuracy:  0.8945002554060957 Loss:  1.3804164548690128 Val_accuracy:  0.883001906837374 Val_cost:  1.3804164548690128 Val_accuracy:  0.883001906837374 Val_Acc:  1.5454563042243246\n",
      "Epoch number: 1937/10000step_number: 0/29 Accuracy:  0.8946024178443726 Loss:  1.3798232423202121 Val_accuracy:  0.8839553255243803 Val_cost:  1.3798232423202121 Val_accuracy:  0.8839553255243803 Val_Acc:  1.5453903243344156\n",
      "Epoch number: 1938/10000step_number: 0/29 Accuracy:  0.8941256597990805 Loss:  1.3794514574693704 Val_accuracy:  0.8832743121765186 Val_cost:  1.3794514574693704 Val_accuracy:  0.8832743121765186 Val_Acc:  1.5455483223798572\n",
      "Epoch number: 1939/10000step_number: 0/29 Accuracy:  0.8944321471139112 Loss:  1.379276958761907 Val_accuracy:  0.8839553255243803 Val_cost:  1.379276958761907 Val_accuracy:  0.8839553255243803 Val_Acc:  1.5456593451925016\n",
      "Epoch number: 1940/10000step_number: 0/29 Accuracy:  0.8948067427209263 Loss:  1.3792176645504748 Val_accuracy:  0.8840915281939526 Val_cost:  1.3792176645504748 Val_accuracy:  0.8840915281939526 Val_Acc:  1.5448743919740777\n",
      "Epoch number: 1941/10000step_number: 0/29 Accuracy:  0.8950791758896646 Loss:  1.3789294456056314 Val_accuracy:  0.8839553255243803 Val_cost:  1.3789294456056314 Val_accuracy:  0.8839553255243803 Val_Acc:  1.5435983318917477\n",
      "Epoch number: 1942/10000step_number: 0/29 Accuracy:  0.8966456666099097 Loss:  1.378388848356401 Val_accuracy:  0.8853173522201035 Val_cost:  1.378388848356401 Val_accuracy:  0.8853173522201035 Val_Acc:  1.5423281886305866\n",
      "Epoch number: 1943/10000step_number: 0/29 Accuracy:  0.8961348544185255 Loss:  1.3785881647088032 Val_accuracy:  0.8859983655679652 Val_cost:  1.3785881647088032 Val_accuracy:  0.8859983655679652 Val_Acc:  1.5414762005083147\n",
      "Epoch number: 1944/10000step_number: 0/29 Accuracy:  0.8959305295419717 Loss:  1.3801411505762184 Val_accuracy:  0.8857259602288204 Val_cost:  1.3801411505762184 Val_accuracy:  0.8857259602288204 Val_Acc:  1.5403212047479624\n",
      "Epoch number: 1945/10000step_number: 0/29 Accuracy:  0.8966456666099097 Loss:  1.3830312727662235 Val_accuracy:  0.8864069735766821 Val_cost:  1.3830312727662235 Val_accuracy:  0.8864069735766821 Val_Acc:  1.5396449329730448\n",
      "Epoch number: 1946/10000step_number: 0/29 Accuracy:  0.8978375617231398 Loss:  1.3854677909401765 Val_accuracy:  0.8879052029419776 Val_cost:  1.3854677909401765 Val_accuracy:  0.8879052029419776 Val_Acc:  1.5400606652571818\n",
      "Epoch number: 1947/10000step_number: 0/29 Accuracy:  0.8995062148816618 Loss:  1.3867711141479877 Val_accuracy:  0.8899482429855625 Val_cost:  1.3867711141479877 Val_accuracy:  0.8899482429855625 Val_Acc:  1.541781101340759\n",
      "Epoch number: 1948/10000step_number: 0/29 Accuracy:  0.9017537885237528 Loss:  1.387134491605545 Val_accuracy:  0.892672296377009 Val_cost:  1.387134491605545 Val_accuracy:  0.892672296377009 Val_Acc:  1.543934426363267\n",
      "Epoch number: 1949/10000step_number: 0/29 Accuracy:  0.8994721607355696 Loss:  1.385942581650589 Val_accuracy:  0.8887224189594116 Val_cost:  1.385942581650589 Val_accuracy:  0.8887224189594116 Val_Acc:  1.5443217511940133\n",
      "Epoch number: 1950/10000step_number: 0/29 Accuracy:  0.8982802656223395 Loss:  1.3832207667567984 Val_accuracy:  0.8888586216289839 Val_cost:  1.3832207667567984 Val_accuracy:  0.8888586216289839 Val_Acc:  1.541841058636342\n",
      "Epoch number: 1951/10000step_number: 0/29 Accuracy:  0.8985186446449855 Loss:  1.3838796655945511 Val_accuracy:  0.8881776082811224 Val_cost:  1.3838796655945511 Val_accuracy:  0.8881776082811224 Val_Acc:  1.5428211166400871\n",
      "Epoch number: 1952/10000step_number: 0/29 Accuracy:  0.8977694534309553 Loss:  1.3848688390171742 Val_accuracy:  0.887632797602833 Val_cost:  1.3848688390171742 Val_accuracy:  0.887632797602833 Val_Acc:  1.5432903376900877\n",
      "Epoch number: 1953/10000step_number: 0/29 Accuracy:  0.8977013451387706 Loss:  1.3845181182592328 Val_accuracy:  0.88804140561155 Val_cost:  1.3845181182592328 Val_accuracy:  0.88804140561155 Val_Acc:  1.543546355522196\n",
      "Epoch number: 1954/10000step_number: 0/29 Accuracy:  0.8975991827004938 Loss:  1.3845918536908148 Val_accuracy:  0.8881776082811224 Val_cost:  1.3845918536908148 Val_accuracy:  0.8881776082811224 Val_Acc:  1.543528676544698\n",
      "Epoch number: 1955/10000step_number: 0/29 Accuracy:  0.8974629661161246 Loss:  1.3846793851423609 Val_accuracy:  0.8881776082811224 Val_cost:  1.3846793851423609 Val_accuracy:  0.8881776082811224 Val_Acc:  1.5439067920846608\n",
      "Epoch number: 1956/10000step_number: 0/29 Accuracy:  0.8972926953856633 Loss:  1.3845985227434572 Val_accuracy:  0.8881776082811224 Val_cost:  1.3845985227434572 Val_accuracy:  0.8881776082811224 Val_Acc:  1.5439831711281329\n",
      "Epoch number: 1957/10000step_number: 0/29 Accuracy:  0.8967137749020944 Loss:  1.3847426870484514 Val_accuracy:  0.8879052029419776 Val_cost:  1.3847426870484514 Val_accuracy:  0.8879052029419776 Val_Acc:  1.544189127187255\n",
      "Epoch number: 1958/10000step_number: 0/29 Accuracy:  0.8966116124638175 Loss:  1.384694063341812 Val_accuracy:  0.8883138109506946 Val_cost:  1.384694063341812 Val_accuracy:  0.8883138109506946 Val_Acc:  1.5443301807777015\n",
      "Epoch number: 1959/10000step_number: 0/29 Accuracy:  0.8966456666099097 Loss:  1.3846781255791811 Val_accuracy:  0.8881776082811224 Val_cost:  1.3846781255791811 Val_accuracy:  0.8881776082811224 Val_Acc:  1.5444485822922016\n",
      "Epoch number: 1960/10000step_number: 0/29 Accuracy:  0.8965435041716329 Loss:  1.3846699743427298 Val_accuracy:  0.88804140561155 Val_cost:  1.3846699743427298 Val_accuracy:  0.88804140561155 Val_Acc:  1.5445771764302136\n",
      "Epoch number: 1961/10000step_number: 0/29 Accuracy:  0.8965435041716329 Loss:  1.3846018719389361 Val_accuracy:  0.88804140561155 Val_cost:  1.3846018719389361 Val_accuracy:  0.88804140561155 Val_Acc:  1.5446751263767051\n",
      "Epoch number: 1962/10000step_number: 0/29 Accuracy:  0.8966456666099097 Loss:  1.3845703986103362 Val_accuracy:  0.88804140561155 Val_cost:  1.3845703986103362 Val_accuracy:  0.88804140561155 Val_Acc:  1.5447671911051533\n",
      "Epoch number: 1963/10000step_number: 0/29 Accuracy:  0.8965775583177252 Loss:  1.3845015155457712 Val_accuracy:  0.887632797602833 Val_cost:  1.3845015155457712 Val_accuracy:  0.887632797602833 Val_Acc:  1.5448570432232414\n",
      "Epoch number: 1964/10000step_number: 0/29 Accuracy:  0.896441341733356 Loss:  1.384433136980223 Val_accuracy:  0.8874965949332607 Val_cost:  1.384433136980223 Val_accuracy:  0.8874965949332607 Val_Acc:  1.544924094436072\n",
      "Epoch number: 1965/10000step_number: 0/29 Accuracy:  0.8964072875872637 Loss:  1.3843637626616636 Val_accuracy:  0.8868155815853991 Val_cost:  1.3843637626616636 Val_accuracy:  0.8868155815853991 Val_Acc:  1.5449964490857857\n",
      "Epoch number: 1966/10000step_number: 0/29 Accuracy:  0.8964072875872637 Loss:  1.3842819883306952 Val_accuracy:  0.8868155815853991 Val_cost:  1.3842819883306952 Val_accuracy:  0.8868155815853991 Val_Acc:  1.5450549049973674\n",
      "Epoch number: 1967/10000step_number: 0/29 Accuracy:  0.89620296271071 Loss:  1.3842025210115712 Val_accuracy:  0.8868155815853991 Val_cost:  1.3842025210115712 Val_accuracy:  0.8868155815853991 Val_Acc:  1.545109917327647\n",
      "Epoch number: 1968/10000step_number: 0/29 Accuracy:  0.8962710710028946 Loss:  1.3841186710096243 Val_accuracy:  0.8870879869245437 Val_cost:  1.3841186710096243 Val_accuracy:  0.8870879869245437 Val_Acc:  1.5451612615491483\n",
      "Epoch number: 1969/10000step_number: 0/29 Accuracy:  0.8964753958794484 Loss:  1.3840329798588045 Val_accuracy:  0.8872241895941161 Val_cost:  1.3840329798588045 Val_accuracy:  0.8872241895941161 Val_Acc:  1.5452075359372475\n",
      "Epoch number: 1970/10000step_number: 0/29 Accuracy:  0.8965775583177252 Loss:  1.3839470671473146 Val_accuracy:  0.8870879869245437 Val_cost:  1.3839470671473146 Val_accuracy:  0.8870879869245437 Val_Acc:  1.545252381182836\n",
      "Epoch number: 1971/10000step_number: 0/29 Accuracy:  0.8963732334411715 Loss:  1.3838592549616373 Val_accuracy:  0.8868155815853991 Val_cost:  1.3838592549616373 Val_accuracy:  0.8868155815853991 Val_Acc:  1.5452952108920084\n",
      "Epoch number: 1972/10000step_number: 0/29 Accuracy:  0.8962370168568023 Loss:  1.3837704599481038 Val_accuracy:  0.8865431762462544 Val_cost:  1.3837704599481038 Val_accuracy:  0.8865431762462544 Val_Acc:  1.545337299210215\n",
      "Epoch number: 1973/10000step_number: 0/29 Accuracy:  0.8966456666099097 Loss:  1.3836801253108637 Val_accuracy:  0.8866793789158267 Val_cost:  1.3836801253108637 Val_accuracy:  0.8866793789158267 Val_Acc:  1.5453796600551002\n",
      "Epoch number: 1974/10000step_number: 0/29 Accuracy:  0.8966456666099097 Loss:  1.3835880051922413 Val_accuracy:  0.8865431762462544 Val_cost:  1.3835880051922413 Val_accuracy:  0.8865431762462544 Val_Acc:  1.545422839399525\n",
      "Epoch number: 1975/10000step_number: 0/29 Accuracy:  0.8965775583177252 Loss:  1.3834943986822539 Val_accuracy:  0.8866793789158267 Val_cost:  1.3834943986822539 Val_accuracy:  0.8866793789158267 Val_Acc:  1.5454678521137344\n",
      "Epoch number: 1976/10000step_number: 0/29 Accuracy:  0.896918099778648 Loss:  1.3833996770100463 Val_accuracy:  0.8866793789158267 Val_cost:  1.3833996770100463 Val_accuracy:  0.8866793789158267 Val_Acc:  1.5455154721107416\n",
      "Epoch number: 1977/10000step_number: 0/29 Accuracy:  0.8969521539247404 Loss:  1.383304752289197 Val_accuracy:  0.8865431762462544 Val_cost:  1.383304752289197 Val_accuracy:  0.8865431762462544 Val_Acc:  1.5455665260617595\n",
      "Epoch number: 1978/10000step_number: 0/29 Accuracy:  0.8968499914864635 Loss:  1.3832108635029157 Val_accuracy:  0.8862707709071098 Val_cost:  1.3832108635029157 Val_accuracy:  0.8862707709071098 Val_Acc:  1.5456218000863022\n",
      "Epoch number: 1979/10000step_number: 0/29 Accuracy:  0.8968840456325557 Loss:  1.3831195504354492 Val_accuracy:  0.8862707709071098 Val_cost:  1.3831195504354492 Val_accuracy:  0.8862707709071098 Val_Acc:  1.5456819358397753\n",
      "Epoch number: 1980/10000step_number: 0/29 Accuracy:  0.8967818831942789 Loss:  1.383032680884206 Val_accuracy:  0.8861345682375374 Val_cost:  1.383032680884206 Val_accuracy:  0.8861345682375374 Val_Acc:  1.5457474344536701\n",
      "Epoch number: 1981/10000step_number: 0/29 Accuracy:  0.8967818831942789 Loss:  1.382952432687828 Val_accuracy:  0.8861345682375374 Val_cost:  1.382952432687828 Val_accuracy:  0.8861345682375374 Val_Acc:  1.5458185664821338\n",
      "Epoch number: 1982/10000step_number: 0/29 Accuracy:  0.8967478290481866 Loss:  1.3828813703587235 Val_accuracy:  0.8861345682375374 Val_cost:  1.3828813703587235 Val_accuracy:  0.8861345682375374 Val_Acc:  1.5458953265397128\n",
      "Epoch number: 1983/10000step_number: 0/29 Accuracy:  0.896679720756002 Loss:  1.3828224067224355 Val_accuracy:  0.8862707709071098 Val_cost:  1.3828224067224355 Val_accuracy:  0.8862707709071098 Val_Acc:  1.545977335412689\n",
      "Epoch number: 1984/10000step_number: 0/29 Accuracy:  0.8968840456325557 Loss:  1.382778367591997 Val_accuracy:  0.8865431762462544 Val_cost:  1.382778367591997 Val_accuracy:  0.8865431762462544 Val_Acc:  1.5460636449866048\n",
      "Epoch number: 1985/10000step_number: 0/29 Accuracy:  0.8968159373403712 Loss:  1.3827506420583062 Val_accuracy:  0.8865431762462544 Val_cost:  1.3827506420583062 Val_accuracy:  0.8865431762462544 Val_Acc:  1.5461523761143843\n",
      "Epoch number: 1986/10000step_number: 0/29 Accuracy:  0.8969862080708326 Loss:  1.3827367384727869 Val_accuracy:  0.8865431762462544 Val_cost:  1.3827367384727869 Val_accuracy:  0.8865431762462544 Val_Acc:  1.5462402425749928\n",
      "Epoch number: 1987/10000step_number: 0/29 Accuracy:  0.896918099778648 Loss:  1.3827281819863395 Val_accuracy:  0.8862707709071098 Val_cost:  1.3827281819863395 Val_accuracy:  0.8862707709071098 Val_Acc:  1.5463224996101772\n",
      "Epoch number: 1988/10000step_number: 0/29 Accuracy:  0.8969521539247404 Loss:  1.3827120174146381 Val_accuracy:  0.8862707709071098 Val_cost:  1.3827120174146381 Val_accuracy:  0.8862707709071098 Val_Acc:  1.5463941657475742\n",
      "Epoch number: 1989/10000step_number: 0/29 Accuracy:  0.896918099778648 Loss:  1.3826775704361909 Val_accuracy:  0.8861345682375374 Val_cost:  1.3826775704361909 Val_accuracy:  0.8861345682375374 Val_Acc:  1.546452549102259\n",
      "Epoch number: 1990/10000step_number: 0/29 Accuracy:  0.8967818831942789 Loss:  1.382624484132804 Val_accuracy:  0.8861345682375374 Val_cost:  1.382624484132804 Val_accuracy:  0.8861345682375374 Val_Acc:  1.5464996074168593\n",
      "Epoch number: 1991/10000step_number: 0/29 Accuracy:  0.896679720756002 Loss:  1.3825653728013767 Val_accuracy:  0.8862707709071098 Val_cost:  1.3825653728013767 Val_accuracy:  0.8862707709071098 Val_Acc:  1.546542418329756\n",
      "Epoch number: 1992/10000step_number: 0/29 Accuracy:  0.8967818831942789 Loss:  1.3825197931149547 Val_accuracy:  0.8862707709071098 Val_cost:  1.3825197931149547 Val_accuracy:  0.8862707709071098 Val_Acc:  1.5465905036139835\n",
      "Epoch number: 1993/10000step_number: 0/29 Accuracy:  0.8967137749020944 Loss:  1.3825025674342342 Val_accuracy:  0.8861345682375374 Val_cost:  1.3825025674342342 Val_accuracy:  0.8861345682375374 Val_Acc:  1.5466504338669573\n",
      "Epoch number: 1994/10000step_number: 0/29 Accuracy:  0.8965775583177252 Loss:  1.3825160430899195 Val_accuracy:  0.8861345682375374 Val_cost:  1.3825160430899195 Val_accuracy:  0.8861345682375374 Val_Acc:  1.5467221568527045\n",
      "Epoch number: 1995/10000step_number: 0/29 Accuracy:  0.8968840456325557 Loss:  1.3825524254980877 Val_accuracy:  0.8862707709071098 Val_cost:  1.3825524254980877 Val_accuracy:  0.8862707709071098 Val_Acc:  1.5468007345852772\n",
      "Epoch number: 1996/10000step_number: 0/29 Accuracy:  0.897156478801294 Loss:  1.3826007897324717 Val_accuracy:  0.8866793789158267 Val_cost:  1.3826007897324717 Val_accuracy:  0.8866793789158267 Val_Acc:  1.5468805995351493\n",
      "Epoch number: 1997/10000step_number: 0/29 Accuracy:  0.897156478801294 Loss:  1.38265176642674 Val_accuracy:  0.8866793789158267 Val_cost:  1.38265176642674 Val_accuracy:  0.8866793789158267 Val_Acc:  1.5469580340890894\n",
      "Epoch number: 1998/10000step_number: 0/29 Accuracy:  0.8969521539247404 Loss:  1.382698990281114 Val_accuracy:  0.8865431762462544 Val_cost:  1.382698990281114 Val_accuracy:  0.8865431762462544 Val_Acc:  1.547031470405491\n",
      "Epoch number: 1999/10000step_number: 0/29 Accuracy:  0.8970202622169249 Loss:  1.3827389859798955 Val_accuracy:  0.8865431762462544 Val_cost:  1.3827389859798955 Val_accuracy:  0.8865431762462544 Val_Acc:  1.5471009108478606\n",
      "Epoch number: 2000/10000step_number: 0/29 Accuracy:  0.8971224246552018 Loss:  1.382770655503151 Val_accuracy:  0.8868155815853991 Val_cost:  1.382770655503151 Val_accuracy:  0.8868155815853991 Val_Acc:  1.547167289874693\n",
      "Epoch number: 2001/10000step_number: 0/29 Accuracy:  0.8971905329473864 Loss:  1.3827947591885275 Val_accuracy:  0.8869517842549713 Val_cost:  1.3827947591885275 Val_accuracy:  0.8869517842549713 Val_Acc:  1.5472320431911273\n",
      "Epoch number: 2002/10000step_number: 0/29 Accuracy:  0.8971905329473864 Loss:  1.3828133487512329 Val_accuracy:  0.8868155815853991 Val_cost:  1.3828133487512329 Val_accuracy:  0.8868155815853991 Val_Acc:  1.547296797372003\n",
      "Epoch number: 2003/10000step_number: 0/29 Accuracy:  0.8972245870934786 Loss:  1.382829037748604 Val_accuracy:  0.8869517842549713 Val_cost:  1.382829037748604 Val_accuracy:  0.8869517842549713 Val_Acc:  1.547363066368487\n",
      "Epoch number: 2004/10000step_number: 0/29 Accuracy:  0.8971905329473864 Loss:  1.3828442277840765 Val_accuracy:  0.8869517842549713 Val_cost:  1.3828442277840765 Val_accuracy:  0.8869517842549713 Val_Acc:  1.5474319736221684\n",
      "Epoch number: 2005/10000step_number: 0/29 Accuracy:  0.8972586412395709 Loss:  1.3828605455623006 Val_accuracy:  0.8870879869245437 Val_cost:  1.3828605455623006 Val_accuracy:  0.8870879869245437 Val_Acc:  1.5475041032856818\n",
      "Epoch number: 2006/10000step_number: 0/29 Accuracy:  0.8972926953856633 Loss:  1.382878619520534 Val_accuracy:  0.8870879869245437 Val_cost:  1.382878619520534 Val_accuracy:  0.8870879869245437 Val_Acc:  1.547579526859322\n",
      "Epoch number: 2007/10000step_number: 0/29 Accuracy:  0.897633236846586 Loss:  1.3828981399675697 Val_accuracy:  0.8873603922636883 Val_cost:  1.3828981399675697 Val_accuracy:  0.8873603922636883 Val_Acc:  1.5476579481000403\n",
      "Epoch number: 2008/10000step_number: 0/29 Accuracy:  0.8975651285544015 Loss:  1.3829180658913869 Val_accuracy:  0.8874965949332607 Val_cost:  1.3829180658913869 Val_accuracy:  0.8874965949332607 Val_Acc:  1.5477388755422166\n",
      "Epoch number: 2009/10000step_number: 0/29 Accuracy:  0.8975651285544015 Loss:  1.3829368630993268 Val_accuracy:  0.8872241895941161 Val_cost:  1.3829368630993268 Val_accuracy:  0.8872241895941161 Val_Acc:  1.5478217587912595\n",
      "Epoch number: 2010/10000step_number: 0/29 Accuracy:  0.8978035075770475 Loss:  1.3829527217493829 Val_accuracy:  0.887632797602833 Val_cost:  1.3829527217493829 Val_accuracy:  0.887632797602833 Val_Acc:  1.5479060714969612\n",
      "Epoch number: 2011/10000step_number: 0/29 Accuracy:  0.8978375617231398 Loss:  1.3829637475521626 Val_accuracy:  0.8874965949332607 Val_cost:  1.3829637475521626 Val_accuracy:  0.8874965949332607 Val_Acc:  1.5479913549315687\n",
      "Epoch number: 2012/10000step_number: 0/29 Accuracy:  0.897871615869232 Loss:  1.3829681350514849 Val_accuracy:  0.8874965949332607 Val_cost:  1.3829681350514849 Val_accuracy:  0.8874965949332607 Val_Acc:  1.5480772422180504\n",
      "Epoch number: 2013/10000step_number: 0/29 Accuracy:  0.8979397241614167 Loss:  1.3829643253113422 Val_accuracy:  0.887632797602833 Val_cost:  1.3829643253113422 Val_accuracy:  0.887632797602833 Val_Acc:  1.5481634757589189\n",
      "Epoch number: 2014/10000step_number: 0/29 Accuracy:  0.8980418865996935 Loss:  1.3829511367066485 Val_accuracy:  0.887632797602833 Val_cost:  1.3829511367066485 Val_accuracy:  0.887632797602833 Val_Acc:  1.5482499192004262\n",
      "Epoch number: 2015/10000step_number: 0/29 Accuracy:  0.8983143197684318 Loss:  1.3829278467443549 Val_accuracy:  0.8877690002724054 Val_cost:  1.3829278467443549 Val_accuracy:  0.8877690002724054 Val_Acc:  1.5483365579887942\n",
      "Epoch number: 2016/10000step_number: 0/29 Accuracy:  0.8984164822067087 Loss:  1.3828942018209323 Val_accuracy:  0.8877690002724054 Val_cost:  1.3828942018209323 Val_accuracy:  0.8877690002724054 Val_Acc:  1.548423481652834\n",
      "Epoch number: 2017/10000step_number: 0/29 Accuracy:  0.8986548612293547 Loss:  1.3828503442066367 Val_accuracy:  0.8877690002724054 Val_cost:  1.3828503442066367 Val_accuracy:  0.8877690002724054 Val_Acc:  1.5485108450842118\n",
      "Epoch number: 2018/10000step_number: 0/29 Accuracy:  0.8987229695215393 Loss:  1.3827966677083396 Val_accuracy:  0.88804140561155 Val_cost:  1.3827966677083396 Val_accuracy:  0.88804140561155 Val_Acc:  1.5485988129747266\n",
      "Epoch number: 2019/10000step_number: 0/29 Accuracy:  0.8988251319598161 Loss:  1.382733634058451 Val_accuracy:  0.8883138109506946 Val_cost:  1.382733634058451 Val_accuracy:  0.8883138109506946 Val_Acc:  1.54868749768208\n",
      "Epoch number: 2020/10000step_number: 0/29 Accuracy:  0.8988591861059084 Loss:  1.3826615904499122 Val_accuracy:  0.8883138109506946 Val_cost:  1.3826615904499122 Val_accuracy:  0.8883138109506946 Val_Acc:  1.5487769031120358\n",
      "Epoch number: 2021/10000step_number: 0/29 Accuracy:  0.8989954026902776 Loss:  1.382580622608582 Val_accuracy:  0.8881776082811224 Val_cost:  1.382580622608582 Val_accuracy:  0.8881776082811224 Val_Acc:  1.548866884867347\n",
      "Epoch number: 2022/10000step_number: 0/29 Accuracy:  0.8990294568363698 Loss:  1.3824904635840927 Val_accuracy:  0.8883138109506946 Val_cost:  1.3824904635840927 Val_accuracy:  0.8883138109506946 Val_Acc:  1.5489571316285304\n",
      "Epoch number: 2023/10000step_number: 0/29 Accuracy:  0.8991316192746467 Loss:  1.3823904641945415 Val_accuracy:  0.8883138109506946 Val_cost:  1.3823904641945415 Val_accuracy:  0.8883138109506946 Val_Acc:  1.549047167467718\n",
      "Epoch number: 2024/10000step_number: 0/29 Accuracy:  0.8999489187808616 Loss:  1.382279621442475 Val_accuracy:  0.8889948242985563 Val_cost:  1.382279621442475 Val_accuracy:  0.8889948242985563 Val_Acc:  1.5491363716667232\n",
      "Epoch number: 2025/10000step_number: 0/29 Accuracy:  0.9000170270730461 Loss:  1.3821566566086516 Val_accuracy:  0.8891310269681286 Val_cost:  1.3821566566086516 Val_accuracy:  0.8891310269681286 Val_Acc:  1.5492240118384855\n",
      "Epoch number: 2026/10000step_number: 0/29 Accuracy:  0.9001532436574153 Loss:  1.3820201330599635 Val_accuracy:  0.8892672296377009 Val_cost:  1.3820201330599635 Val_accuracy:  0.8892672296377009 Val_Acc:  1.5493092864382474\n",
      "Epoch number: 2027/10000step_number: 0/29 Accuracy:  0.9003235143878767 Loss:  1.3818686026626796 Val_accuracy:  0.8889948242985563 Val_cost:  1.3818686026626796 Val_accuracy:  0.8889948242985563 Val_Acc:  1.5493913724587087\n",
      "Epoch number: 2028/10000step_number: 0/29 Accuracy:  0.9002554060956921 Loss:  1.3817007676328077 Val_accuracy:  0.8889948242985563 Val_cost:  1.3817007676328077 Val_accuracy:  0.8889948242985563 Val_Acc:  1.5494694728921081\n",
      "Epoch number: 2029/10000step_number: 0/29 Accuracy:  0.9003235143878767 Loss:  1.3815156417639474 Val_accuracy:  0.8887224189594116 Val_cost:  1.3815156417639474 Val_accuracy:  0.8887224189594116 Val_Acc:  1.5495428584274888\n",
      "Epoch number: 2030/10000step_number: 0/29 Accuracy:  0.9002213519495998 Loss:  1.3813126926820438 Val_accuracy:  0.8885862162898392 Val_cost:  1.3813126926820438 Val_accuracy:  0.8885862162898392 Val_Acc:  1.5496109024736342\n",
      "Epoch number: 2031/10000step_number: 0/29 Accuracy:  0.9002213519495998 Loss:  1.3810919467628087 Val_accuracy:  0.8885862162898392 Val_cost:  1.3810919467628087 Val_accuracy:  0.8885862162898392 Val_Acc:  1.5496731181653247\n",
      "Epoch number: 2032/10000step_number: 0/29 Accuracy:  0.9002554060956921 Loss:  1.3808540412667707 Val_accuracy:  0.8887224189594116 Val_cost:  1.3808540412667707 Val_accuracy:  0.8887224189594116 Val_Acc:  1.549729212379216\n",
      "Epoch number: 2033/10000step_number: 0/29 Accuracy:  0.9002894602417845 Loss:  1.3806002141666138 Val_accuracy:  0.8887224189594116 Val_cost:  1.3806002141666138 Val_accuracy:  0.8887224189594116 Val_Acc:  1.5497791632581694\n",
      "Epoch number: 2034/10000step_number: 0/29 Accuracy:  0.9003916226800613 Loss:  1.3803322311717203 Val_accuracy:  0.8887224189594116 Val_cost:  1.3803322311717203 Val_accuracy:  0.8887224189594116 Val_Acc:  1.5498233048066539\n",
      "Epoch number: 2035/10000step_number: 0/29 Accuracy:  0.9005618934105227 Loss:  1.3800522594383078 Val_accuracy:  0.8888586216289839 Val_cost:  1.3800522594383078 Val_accuracy:  0.8888586216289839 Val_Acc:  1.5498623827472169\n",
      "Epoch number: 2036/10000step_number: 0/29 Accuracy:  0.900595947556615 Loss:  1.3797627060181208 Val_accuracy:  0.8887224189594116 Val_cost:  1.3797627060181208 Val_accuracy:  0.8887224189594116 Val_Acc:  1.549897548198045\n",
      "Epoch number: 2037/10000step_number: 0/29 Accuracy:  0.900595947556615 Loss:  1.3794660525839018 Val_accuracy:  0.8885862162898392 Val_cost:  1.3794660525839018 Val_accuracy:  0.8885862162898392 Val_Acc:  1.5499302787295193\n",
      "Epoch number: 2038/10000step_number: 0/29 Accuracy:  0.900357568533969 Loss:  1.3791647419037798 Val_accuracy:  0.8883138109506946 Val_cost:  1.3791647419037798 Val_accuracy:  0.8883138109506946 Val_Acc:  1.549962239694175\n",
      "Epoch number: 2039/10000step_number: 0/29 Accuracy:  0.9002894602417845 Loss:  1.3788611827682271 Val_accuracy:  0.8883138109506946 Val_cost:  1.3788611827682271 Val_accuracy:  0.8883138109506946 Val_Acc:  1.5499950999044667\n",
      "Epoch number: 2040/10000step_number: 0/29 Accuracy:  0.9001872978035076 Loss:  1.3785578938104701 Val_accuracy:  0.888450013620267 Val_cost:  1.3785578938104701 Val_accuracy:  0.888450013620267 Val_Acc:  1.5500302888071238\n",
      "Epoch number: 2041/10000step_number: 0/29 Accuracy:  0.9000851353652307 Loss:  1.378257684953353 Val_accuracy:  0.8887224189594116 Val_cost:  1.378257684953353 Val_accuracy:  0.8887224189594116 Val_Acc:  1.5500686513047013\n",
      "Epoch number: 2042/10000step_number: 0/29 Accuracy:  0.9004256768261536 Loss:  1.3779636293404334 Val_accuracy:  0.8887224189594116 Val_cost:  1.3779636293404334 Val_accuracy:  0.8887224189594116 Val_Acc:  1.5501099796577755\n",
      "Epoch number: 2043/10000step_number: 0/29 Accuracy:  0.9003235143878767 Loss:  1.3776785636801354 Val_accuracy:  0.888450013620267 Val_cost:  1.3776785636801354 Val_accuracy:  0.888450013620267 Val_Acc:  1.550152539129476\n",
      "Epoch number: 2044/10000step_number: 0/29 Accuracy:  0.9003235143878767 Loss:  1.3774041716356824 Val_accuracy:  0.8885862162898392 Val_cost:  1.3774041716356824 Val_accuracy:  0.8885862162898392 Val_Acc:  1.5501929009557192\n",
      "Epoch number: 2045/10000step_number: 0/29 Accuracy:  0.9002213519495998 Loss:  1.377140237107773 Val_accuracy:  0.8887224189594116 Val_cost:  1.377140237107773 Val_accuracy:  0.8887224189594116 Val_Acc:  1.5502263821295854\n",
      "Epoch number: 2046/10000step_number: 0/29 Accuracy:  0.9002554060956921 Loss:  1.3768847941365203 Val_accuracy:  0.8885862162898392 Val_cost:  1.3768847941365203 Val_accuracy:  0.8885862162898392 Val_Acc:  1.5502479357267587\n",
      "Epoch number: 2047/10000step_number: 0/29 Accuracy:  0.9003916226800613 Loss:  1.376635498580673 Val_accuracy:  0.8887224189594116 Val_cost:  1.376635498580673 Val_accuracy:  0.8887224189594116 Val_Acc:  1.5502528200160028\n",
      "Epoch number: 2048/10000step_number: 0/29 Accuracy:  0.9003916226800613 Loss:  1.3763922800007562 Val_accuracy:  0.888450013620267 Val_cost:  1.3763922800007562 Val_accuracy:  0.888450013620267 Val_Acc:  1.5502366098543905\n",
      "Epoch number: 2049/10000step_number: 0/29 Accuracy:  0.900595947556615 Loss:  1.3761608907207012 Val_accuracy:  0.888450013620267 Val_cost:  1.3761608907207012 Val_accuracy:  0.888450013620267 Val_Acc:  1.5501948901978289\n",
      "Epoch number: 2050/10000step_number: 0/29 Accuracy:  0.9004937851183381 Loss:  1.3759553456085847 Val_accuracy:  0.888450013620267 Val_cost:  1.3759553456085847 Val_accuracy:  0.888450013620267 Val_Acc:  1.550122977051966\n",
      "Epoch number: 2051/10000step_number: 0/29 Accuracy:  0.9004256768261536 Loss:  1.3757963694189956 Val_accuracy:  0.8885862162898392 Val_cost:  1.3757963694189956 Val_accuracy:  0.8885862162898392 Val_Acc:  1.5500166777478417\n",
      "Epoch number: 2052/10000step_number: 0/29 Accuracy:  0.9001872978035076 Loss:  1.375706783984302 Val_accuracy:  0.888450013620267 Val_cost:  1.375706783984302 Val_accuracy:  0.888450013620267 Val_Acc:  1.5498724125610492\n",
      "Epoch number: 2053/10000step_number: 0/29 Accuracy:  0.9003916226800613 Loss:  1.375709070587705 Val_accuracy:  0.8885862162898392 Val_cost:  1.375709070587705 Val_accuracy:  0.8885862162898392 Val_Acc:  1.549687606898807\n",
      "Epoch number: 2054/10000step_number: 0/29 Accuracy:  0.9002894602417845 Loss:  1.3758077973719596 Val_accuracy:  0.8881776082811224 Val_cost:  1.3758077973719596 Val_accuracy:  0.8881776082811224 Val_Acc:  1.5494714100851827\n",
      "Epoch number: 2055/10000step_number: 0/29 Accuracy:  0.899880810488677 Loss:  1.3759301731041955 Val_accuracy:  0.888450013620267 Val_cost:  1.3759301731041955 Val_accuracy:  0.888450013620267 Val_Acc:  1.5492478752747016\n",
      "Epoch number: 2056/10000step_number: 0/29 Accuracy:  0.8999148646347693 Loss:  1.375970127614864 Val_accuracy:  0.8885862162898392 Val_cost:  1.375970127614864 Val_accuracy:  0.8885862162898392 Val_Acc:  1.5490483617079112\n",
      "Epoch number: 2057/10000step_number: 0/29 Accuracy:  0.8997786480504001 Loss:  1.3762031809638393 Val_accuracy:  0.8885862162898392 Val_cost:  1.3762031809638393 Val_accuracy:  0.8885862162898392 Val_Acc:  1.5489315943331294\n",
      "Epoch number: 2058/10000step_number: 0/29 Accuracy:  0.8985526987910778 Loss:  1.3770304044206292 Val_accuracy:  0.8879052029419776 Val_cost:  1.3770304044206292 Val_accuracy:  0.8879052029419776 Val_Acc:  1.5488959532597666\n",
      "Epoch number: 2059/10000step_number: 0/29 Accuracy:  0.8989613485441853 Loss:  1.3772526776165026 Val_accuracy:  0.888450013620267 Val_cost:  1.3772526776165026 Val_accuracy:  0.888450013620267 Val_Acc:  1.5484987024385772\n",
      "Epoch number: 2060/10000step_number: 0/29 Accuracy:  0.8989613485441853 Loss:  1.3763796676592583 Val_accuracy:  0.8881776082811224 Val_cost:  1.3763796676592583 Val_accuracy:  0.8881776082811224 Val_Acc:  1.548003521379804\n",
      "Epoch number: 2061/10000step_number: 0/29 Accuracy:  0.8998127021964925 Loss:  1.3753129987571862 Val_accuracy:  0.8889948242985563 Val_cost:  1.3753129987571862 Val_accuracy:  0.8889948242985563 Val_Acc:  1.5466679974801079\n",
      "Epoch number: 2062/10000step_number: 0/29 Accuracy:  0.9005278392644305 Loss:  1.3753433613639685 Val_accuracy:  0.8895396349768455 Val_cost:  1.3753433613639685 Val_accuracy:  0.8895396349768455 Val_Acc:  1.5479129883532168\n",
      "Epoch number: 2063/10000step_number: 0/29 Accuracy:  0.900119189511323 Loss:  1.3754686162570076 Val_accuracy:  0.8891310269681286 Val_cost:  1.3754686162570076 Val_accuracy:  0.8891310269681286 Val_Acc:  1.5495822267935635\n",
      "Epoch number: 2064/10000step_number: 0/29 Accuracy:  0.9000510812191385 Loss:  1.3761885694283265 Val_accuracy:  0.887632797602833 Val_cost:  1.3761885694283265 Val_accuracy:  0.887632797602833 Val_Acc:  1.5483845094596194\n",
      "Epoch number: 2065/10000step_number: 0/29 Accuracy:  0.9012089221862761 Loss:  1.37599811587965 Val_accuracy:  0.8906292563334242 Val_cost:  1.37599811587965 Val_accuracy:  0.8906292563334242 Val_Acc:  1.5477019774695693\n",
      "Epoch number: 2066/10000step_number: 0/29 Accuracy:  0.9002894602417845 Loss:  1.3767922602043814 Val_accuracy:  0.888450013620267 Val_cost:  1.3767922602043814 Val_accuracy:  0.888450013620267 Val_Acc:  1.5491759110573158\n",
      "Epoch number: 2067/10000step_number: 0/29 Accuracy:  0.9000851353652307 Loss:  1.37723345185457 Val_accuracy:  0.8879052029419776 Val_cost:  1.37723345185457 Val_accuracy:  0.8879052029419776 Val_Acc:  1.549000415068628\n",
      "Epoch number: 2068/10000step_number: 0/29 Accuracy:  0.899880810488677 Loss:  1.3774084849826327 Val_accuracy:  0.8879052029419776 Val_cost:  1.3774084849826327 Val_accuracy:  0.8879052029419776 Val_Acc:  1.5492752293327843\n",
      "Epoch number: 2069/10000step_number: 0/29 Accuracy:  0.8997786480504001 Loss:  1.3773452052550157 Val_accuracy:  0.8879052029419776 Val_cost:  1.3773452052550157 Val_accuracy:  0.8879052029419776 Val_Acc:  1.5492693590426097\n",
      "Epoch number: 2070/10000step_number: 0/29 Accuracy:  0.9002213519495998 Loss:  1.3773861155591278 Val_accuracy:  0.8881776082811224 Val_cost:  1.3773861155591278 Val_accuracy:  0.8881776082811224 Val_Acc:  1.5493084505327497\n",
      "Epoch number: 2071/10000step_number: 0/29 Accuracy:  0.9001532436574153 Loss:  1.377371699672754 Val_accuracy:  0.8881776082811224 Val_cost:  1.377371699672754 Val_accuracy:  0.8881776082811224 Val_Acc:  1.5493139571762362\n",
      "Epoch number: 2072/10000step_number: 0/29 Accuracy:  0.9005278392644305 Loss:  1.377435504731759 Val_accuracy:  0.888450013620267 Val_cost:  1.377435504731759 Val_accuracy:  0.888450013620267 Val_Acc:  1.5494184363167498\n",
      "Epoch number: 2073/10000step_number: 0/29 Accuracy:  0.9005278392644305 Loss:  1.3775242425728136 Val_accuracy:  0.8887224189594116 Val_cost:  1.3775242425728136 Val_accuracy:  0.8887224189594116 Val_Acc:  1.5495248424422197\n",
      "Epoch number: 2074/10000step_number: 0/29 Accuracy:  0.9003916226800613 Loss:  1.377532605365027 Val_accuracy:  0.8885862162898392 Val_cost:  1.377532605365027 Val_accuracy:  0.8885862162898392 Val_Acc:  1.5496323751933592\n",
      "Epoch number: 2075/10000step_number: 0/29 Accuracy:  0.9002554060956921 Loss:  1.3776457542709164 Val_accuracy:  0.888450013620267 Val_cost:  1.3776457542709164 Val_accuracy:  0.888450013620267 Val_Acc:  1.5497675646862783\n",
      "Epoch number: 2076/10000step_number: 0/29 Accuracy:  0.9004937851183381 Loss:  1.377677045048155 Val_accuracy:  0.8891310269681286 Val_cost:  1.377677045048155 Val_accuracy:  0.8891310269681286 Val_Acc:  1.5499108369282943\n",
      "Epoch number: 2077/10000step_number: 0/29 Accuracy:  0.9007321641409841 Loss:  1.3777688570891173 Val_accuracy:  0.8887224189594116 Val_cost:  1.3777688570891173 Val_accuracy:  0.8887224189594116 Val_Acc:  1.5500577157189939\n",
      "Epoch number: 2078/10000step_number: 0/29 Accuracy:  0.9006300017027074 Loss:  1.3778365565954684 Val_accuracy:  0.8885862162898392 Val_cost:  1.3778365565954684 Val_accuracy:  0.8885862162898392 Val_Acc:  1.5502578559959366\n",
      "Epoch number: 2079/10000step_number: 0/29 Accuracy:  0.9006300017027074 Loss:  1.3779068152506162 Val_accuracy:  0.888450013620267 Val_cost:  1.3779068152506162 Val_accuracy:  0.888450013620267 Val_Acc:  1.5504576288356318\n",
      "Epoch number: 2080/10000step_number: 0/29 Accuracy:  0.9009024348714456 Loss:  1.3779714225218145 Val_accuracy:  0.8888586216289839 Val_cost:  1.3779714225218145 Val_accuracy:  0.8888586216289839 Val_Acc:  1.5506957569667488\n",
      "Epoch number: 2081/10000step_number: 0/29 Accuracy:  0.9013451387706454 Loss:  1.37802294826187 Val_accuracy:  0.8894034323072733 Val_cost:  1.37802294826187 Val_accuracy:  0.8894034323072733 Val_Acc:  1.5509580410466945\n",
      "Epoch number: 2082/10000step_number: 0/29 Accuracy:  0.901549463647199 Loss:  1.3780544368388472 Val_accuracy:  0.8892672296377009 Val_cost:  1.3780544368388472 Val_accuracy:  0.8892672296377009 Val_Acc:  1.5512366529276342\n",
      "Epoch number: 2083/10000step_number: 0/29 Accuracy:  0.9015835177932914 Loss:  1.378065567371466 Val_accuracy:  0.8894034323072733 Val_cost:  1.378065567371466 Val_accuracy:  0.8894034323072733 Val_Acc:  1.5515525314354208\n",
      "Epoch number: 2084/10000step_number: 0/29 Accuracy:  0.9016175719393836 Loss:  1.3780409036641121 Val_accuracy:  0.8894034323072733 Val_cost:  1.3780409036641121 Val_accuracy:  0.8894034323072733 Val_Acc:  1.5518804003215556\n",
      "Epoch number: 2085/10000step_number: 0/29 Accuracy:  0.9019240592542141 Loss:  1.3779782590745668 Val_accuracy:  0.8891310269681286 Val_cost:  1.3779782590745668 Val_accuracy:  0.8891310269681286 Val_Acc:  1.5522370747133887\n",
      "Epoch number: 2086/10000step_number: 0/29 Accuracy:  0.902264600715137 Loss:  1.3778649312848825 Val_accuracy:  0.8892672296377009 Val_cost:  1.3778649312848825 Val_accuracy:  0.8892672296377009 Val_Acc:  1.55260482366571\n",
      "Epoch number: 2087/10000step_number: 0/29 Accuracy:  0.902264600715137 Loss:  1.3776918224138648 Val_accuracy:  0.8889948242985563 Val_cost:  1.3776918224138648 Val_accuracy:  0.8889948242985563 Val_Acc:  1.552983748470549\n",
      "Epoch number: 2088/10000step_number: 0/29 Accuracy:  0.9024689255916908 Loss:  1.3774492375953682 Val_accuracy:  0.8888586216289839 Val_cost:  1.3774492375953682 Val_accuracy:  0.8888586216289839 Val_Acc:  1.5533639544826827\n",
      "Epoch number: 2089/10000step_number: 0/29 Accuracy:  0.9025710880299677 Loss:  1.3771259974309864 Val_accuracy:  0.8889948242985563 Val_cost:  1.3771259974309864 Val_accuracy:  0.8889948242985563 Val_Acc:  1.5537368717359488\n",
      "Epoch number: 2090/10000step_number: 0/29 Accuracy:  0.9029456836369828 Loss:  1.376713413849746 Val_accuracy:  0.8896758376464179 Val_cost:  1.376713413849746 Val_accuracy:  0.8896758376464179 Val_Acc:  1.5540941897482878\n",
      "Epoch number: 2091/10000step_number: 0/29 Accuracy:  0.9030478460752597 Loss:  1.3762032071860597 Val_accuracy:  0.8898120403159901 Val_cost:  1.3762032071860597 Val_accuracy:  0.8898120403159901 Val_Acc:  1.5544271218578585\n",
      "Epoch number: 2092/10000step_number: 0/29 Accuracy:  0.9031500085135366 Loss:  1.3755903260647757 Val_accuracy:  0.8899482429855625 Val_cost:  1.3755903260647757 Val_accuracy:  0.8899482429855625 Val_Acc:  1.554729398089289\n",
      "Epoch number: 2093/10000step_number: 0/29 Accuracy:  0.9033883875361826 Loss:  1.3748732283987324 Val_accuracy:  0.8898120403159901 Val_cost:  1.3748732283987324 Val_accuracy:  0.8898120403159901 Val_Acc:  1.5549969580407987\n",
      "Epoch number: 2094/10000step_number: 0/29 Accuracy:  0.9033202792439979 Loss:  1.3740554404675718 Val_accuracy:  0.8903568509942795 Val_cost:  1.3740554404675718 Val_accuracy:  0.8903568509942795 Val_Acc:  1.555226573395869\n",
      "Epoch number: 2095/10000step_number: 0/29 Accuracy:  0.9034224416822748 Loss:  1.373147280610289 Val_accuracy:  0.8907654590029964 Val_cost:  1.373147280610289 Val_accuracy:  0.8907654590029964 Val_Acc:  1.5554110629829883\n",
      "Epoch number: 2096/10000step_number: 0/29 Accuracy:  0.9032862250979057 Loss:  1.3721693095196614 Val_accuracy:  0.891037864342141 Val_cost:  1.3721693095196614 Val_accuracy:  0.891037864342141 Val_Acc:  1.5555313529714732\n",
      "Epoch number: 2097/10000step_number: 0/29 Accuracy:  0.9034224416822748 Loss:  1.3711589410088583 Val_accuracy:  0.8913102696812858 Val_cost:  1.3711589410088583 Val_accuracy:  0.8913102696812858 Val_Acc:  1.555538146780869\n",
      "Epoch number: 2098/10000step_number: 0/29 Accuracy:  0.9034905499744594 Loss:  1.3701734284866238 Val_accuracy:  0.8917188776900027 Val_cost:  1.3701734284866238 Val_accuracy:  0.8917188776900027 Val_Acc:  1.5552927910508783\n",
      "Epoch number: 2099/10000step_number: 0/29 Accuracy:  0.9032521709518134 Loss:  1.369269427106936 Val_accuracy:  0.8921274856987197 Val_cost:  1.369269427106936 Val_accuracy:  0.8921274856987197 Val_Acc:  1.5545134077534444\n",
      "Epoch number: 2100/10000step_number: 0/29 Accuracy:  0.90379703728929 Loss:  1.3685255320602978 Val_accuracy:  0.8919912830291473 Val_cost:  1.3685255320602978 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5529645472412332\n",
      "Epoch number: 2101/10000step_number: 0/29 Accuracy:  0.9048186616720586 Loss:  1.3683399671922367 Val_accuracy:  0.8928084990465813 Val_cost:  1.3683399671922367 Val_accuracy:  0.8928084990465813 Val_Acc:  1.550808622191428\n",
      "Epoch number: 2102/10000step_number: 0/29 Accuracy:  0.9057381236165503 Loss:  1.3694969292073542 Val_accuracy:  0.8937619177335876 Val_cost:  1.3694969292073542 Val_accuracy:  0.8937619177335876 Val_Acc:  1.548509792048718\n",
      "Epoch number: 2103/10000step_number: 0/29 Accuracy:  0.9055678528860889 Loss:  1.3723069353786146 Val_accuracy:  0.8943067284118769 Val_cost:  1.3723069353786146 Val_accuracy:  0.8943067284118769 Val_Acc:  1.5467800965324967\n",
      "Epoch number: 2104/10000step_number: 0/29 Accuracy:  0.9091775923718712 Loss:  1.3759758186207942 Val_accuracy:  0.897303187142468 Val_cost:  1.3759758186207942 Val_accuracy:  0.897303187142468 Val_Acc:  1.5469850653501684\n",
      "Epoch number: 2105/10000step_number: 0/29 Accuracy:  0.9109484079686702 Loss:  1.3788330736780592 Val_accuracy:  0.8994824298556252 Val_cost:  1.3788330736780592 Val_accuracy:  0.8994824298556252 Val_Acc:  1.5507066463973285\n",
      "Epoch number: 2106/10000step_number: 0/29 Accuracy:  0.9109824621147625 Loss:  1.3750111417799813 Val_accuracy:  0.8988014165077636 Val_cost:  1.3750111417799813 Val_accuracy:  0.8988014165077636 Val_Acc:  1.5509361299430415\n",
      "Epoch number: 2107/10000step_number: 0/29 Accuracy:  0.9080878596969181 Loss:  1.3705307171215306 Val_accuracy:  0.8947153364205939 Val_cost:  1.3705307171215306 Val_accuracy:  0.8947153364205939 Val_Acc:  1.5457805128467994\n",
      "Epoch number: 2108/10000step_number: 0/29 Accuracy:  0.9079175889664567 Loss:  1.3737932991993316 Val_accuracy:  0.896077363116317 Val_cost:  1.3737932991993316 Val_accuracy:  0.896077363116317 Val_Acc:  1.5503579614317793\n",
      "Epoch number: 2109/10000step_number: 0/29 Accuracy:  0.9053975821556275 Loss:  1.3732306438178372 Val_accuracy:  0.8932171070552983 Val_cost:  1.3732306438178372 Val_accuracy:  0.8932171070552983 Val_Acc:  1.5498687293799172\n",
      "Epoch number: 2110/10000step_number: 0/29 Accuracy:  0.9044440660650435 Loss:  1.3729902178432423 Val_accuracy:  0.8938981204031599 Val_cost:  1.3729902178432423 Val_accuracy:  0.8938981204031599 Val_Acc:  1.550795362903332\n",
      "Epoch number: 2111/10000step_number: 0/29 Accuracy:  0.904035416311936 Loss:  1.3735916414455056 Val_accuracy:  0.8932171070552983 Val_cost:  1.3735916414455056 Val_accuracy:  0.8932171070552983 Val_Acc:  1.5510147914994896\n",
      "Epoch number: 2112/10000step_number: 0/29 Accuracy:  0.904750553379874 Loss:  1.373437728819989 Val_accuracy:  0.893489512394443 Val_cost:  1.373437728819989 Val_accuracy:  0.893489512394443 Val_Acc:  1.551226853125272\n",
      "Epoch number: 2113/10000step_number: 0/29 Accuracy:  0.9045462285033202 Loss:  1.3735642524547056 Val_accuracy:  0.8932171070552983 Val_cost:  1.3735642524547056 Val_accuracy:  0.8932171070552983 Val_Acc:  1.5512242241602847\n",
      "Epoch number: 2114/10000step_number: 0/29 Accuracy:  0.904750553379874 Loss:  1.3735508412453958 Val_accuracy:  0.8932171070552983 Val_cost:  1.3735508412453958 Val_accuracy:  0.8932171070552983 Val_Acc:  1.5512442968408802\n",
      "Epoch number: 2115/10000step_number: 0/29 Accuracy:  0.9044100119189511 Loss:  1.37345594629955 Val_accuracy:  0.8929447017161536 Val_cost:  1.37345594629955 Val_accuracy:  0.8929447017161536 Val_Acc:  1.55121035260751\n",
      "Epoch number: 2116/10000step_number: 0/29 Accuracy:  0.9036948748510131 Loss:  1.3733844015261025 Val_accuracy:  0.892672296377009 Val_cost:  1.3733844015261025 Val_accuracy:  0.892672296377009 Val_Acc:  1.5512409154450637\n",
      "Epoch number: 2117/10000step_number: 0/29 Accuracy:  0.9034564958283671 Loss:  1.3732359886665104 Val_accuracy:  0.8921274856987197 Val_cost:  1.3732359886665104 Val_accuracy:  0.8921274856987197 Val_Acc:  1.5512374456865292\n",
      "Epoch number: 2118/10000step_number: 0/29 Accuracy:  0.9034224416822748 Loss:  1.3731525337746038 Val_accuracy:  0.8917188776900027 Val_cost:  1.3731525337746038 Val_accuracy:  0.8917188776900027 Val_Acc:  1.551257041749938\n",
      "Epoch number: 2119/10000step_number: 0/29 Accuracy:  0.9033543333900902 Loss:  1.3729983175785296 Val_accuracy:  0.8917188776900027 Val_cost:  1.3729983175785296 Val_accuracy:  0.8917188776900027 Val_Acc:  1.5512598945616667\n",
      "Epoch number: 2120/10000step_number: 0/29 Accuracy:  0.9033543333900902 Loss:  1.3728875687827213 Val_accuracy:  0.8921274856987197 Val_cost:  1.3728875687827213 Val_accuracy:  0.8921274856987197 Val_Acc:  1.5512671356602326\n",
      "Epoch number: 2121/10000step_number: 0/29 Accuracy:  0.9030819002213519 Loss:  1.3727678626390785 Val_accuracy:  0.8922636883682921 Val_cost:  1.3727678626390785 Val_accuracy:  0.8922636883682921 Val_Acc:  1.5512722563590915\n",
      "Epoch number: 2122/10000step_number: 0/29 Accuracy:  0.902979737783075 Loss:  1.3726940776993641 Val_accuracy:  0.8922636883682921 Val_cost:  1.3726940776993641 Val_accuracy:  0.8922636883682921 Val_Acc:  1.551288599559189\n",
      "Epoch number: 2123/10000step_number: 0/29 Accuracy:  0.9030478460752597 Loss:  1.372604119140534 Val_accuracy:  0.892672296377009 Val_cost:  1.372604119140534 Val_accuracy:  0.892672296377009 Val_Acc:  1.551298016194367\n",
      "Epoch number: 2124/10000step_number: 0/29 Accuracy:  0.9028775753447982 Loss:  1.3725462949963483 Val_accuracy:  0.892672296377009 Val_cost:  1.3725462949963483 Val_accuracy:  0.892672296377009 Val_Acc:  1.5513147652597092\n",
      "Epoch number: 2125/10000step_number: 0/29 Accuracy:  0.9028094670526137 Loss:  1.372481906739847 Val_accuracy:  0.892672296377009 Val_cost:  1.372481906739847 Val_accuracy:  0.892672296377009 Val_Acc:  1.551326009545111\n",
      "Epoch number: 2126/10000step_number: 0/29 Accuracy:  0.902741358760429 Loss:  1.3724499406003607 Val_accuracy:  0.8923998910378643 Val_cost:  1.3724499406003607 Val_accuracy:  0.8923998910378643 Val_Acc:  1.5513466454449725\n",
      "Epoch number: 2127/10000step_number: 0/29 Accuracy:  0.9028094670526137 Loss:  1.372414118946835 Val_accuracy:  0.8919912830291473 Val_cost:  1.372414118946835 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5513647017891294\n",
      "Epoch number: 2128/10000step_number: 0/29 Accuracy:  0.9027073046143368 Loss:  1.3724049545479597 Val_accuracy:  0.8917188776900027 Val_cost:  1.3724049545479597 Val_accuracy:  0.8917188776900027 Val_Acc:  1.5513908310839066\n",
      "Epoch number: 2129/10000step_number: 0/29 Accuracy:  0.9026391963221522 Loss:  1.3723907438588785 Val_accuracy:  0.8918550803595751 Val_cost:  1.3723907438588785 Val_accuracy:  0.8918550803595751 Val_Acc:  1.5514163372691423\n",
      "Epoch number: 2130/10000step_number: 0/29 Accuracy:  0.9026391963221522 Loss:  1.372394466686644 Val_accuracy:  0.8917188776900027 Val_cost:  1.372394466686644 Val_accuracy:  0.8917188776900027 Val_Acc:  1.5514486416231397\n",
      "Epoch number: 2131/10000step_number: 0/29 Accuracy:  0.9025370338838754 Loss:  1.3723914290109303 Val_accuracy:  0.8917188776900027 Val_cost:  1.3723914290109303 Val_accuracy:  0.8917188776900027 Val_Acc:  1.5514826893228892\n",
      "Epoch number: 2132/10000step_number: 0/29 Accuracy:  0.9024348714455985 Loss:  1.3723968815517746 Val_accuracy:  0.891446472350858 Val_cost:  1.3723968815517746 Val_accuracy:  0.891446472350858 Val_Acc:  1.5515222256414962\n",
      "Epoch number: 2133/10000step_number: 0/29 Accuracy:  0.9032862250979057 Loss:  1.3723949424516388 Val_accuracy:  0.8919912830291473 Val_cost:  1.3723949424516388 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5515650891504191\n",
      "Epoch number: 2134/10000step_number: 0/29 Accuracy:  0.9033883875361826 Loss:  1.3723941255009486 Val_accuracy:  0.8919912830291473 Val_cost:  1.3723941255009486 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5516124406324088\n",
      "Epoch number: 2135/10000step_number: 0/29 Accuracy:  0.9032862250979057 Loss:  1.3723864002624186 Val_accuracy:  0.8919912830291473 Val_cost:  1.3723864002624186 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5516635781378982\n",
      "Epoch number: 2136/10000step_number: 0/29 Accuracy:  0.9031840626596288 Loss:  1.372375616966347 Val_accuracy:  0.8918550803595751 Val_cost:  1.372375616966347 Val_accuracy:  0.8918550803595751 Val_Acc:  1.551718525384164\n",
      "Epoch number: 2137/10000step_number: 0/29 Accuracy:  0.9034564958283671 Loss:  1.3723588842474885 Val_accuracy:  0.8921274856987197 Val_cost:  1.3723588842474885 Val_accuracy:  0.8921274856987197 Val_Acc:  1.55177696920733\n",
      "Epoch number: 2138/10000step_number: 0/29 Accuracy:  0.9033883875361826 Loss:  1.3723377919008253 Val_accuracy:  0.8921274856987197 Val_cost:  1.3723377919008253 Val_accuracy:  0.8921274856987197 Val_Acc:  1.5518386860894222\n",
      "Epoch number: 2139/10000step_number: 0/29 Accuracy:  0.9035246041205517 Loss:  1.3723118405126389 Val_accuracy:  0.8921274856987197 Val_cost:  1.3723118405126389 Val_accuracy:  0.8921274856987197 Val_Acc:  1.551903391460828\n",
      "Epoch number: 2140/10000step_number: 0/29 Accuracy:  0.9035586582666439 Loss:  1.3722818369450998 Val_accuracy:  0.8922636883682921 Val_cost:  1.3722818369450998 Val_accuracy:  0.8922636883682921 Val_Acc:  1.5519708795171754\n",
      "Epoch number: 2141/10000step_number: 0/29 Accuracy:  0.9034564958283671 Loss:  1.372248093013944 Val_accuracy:  0.8922636883682921 Val_cost:  1.372248093013944 Val_accuracy:  0.8922636883682921 Val_Acc:  1.5520409185392476\n",
      "Epoch number: 2142/10000step_number: 0/29 Accuracy:  0.9035246041205517 Loss:  1.3722111664060008 Val_accuracy:  0.8919912830291473 Val_cost:  1.3722111664060008 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5521133624302386\n",
      "Epoch number: 2143/10000step_number: 0/29 Accuracy:  0.9033883875361826 Loss:  1.3721715413231053 Val_accuracy:  0.8917188776900027 Val_cost:  1.3721715413231053 Val_accuracy:  0.8917188776900027 Val_Acc:  1.552188053925554\n",
      "Epoch number: 2144/10000step_number: 0/29 Accuracy:  0.9033202792439979 Loss:  1.372129660531927 Val_accuracy:  0.8917188776900027 Val_cost:  1.372129660531927 Val_accuracy:  0.8917188776900027 Val_Acc:  1.5522649061177576\n",
      "Epoch number: 2145/10000step_number: 0/29 Accuracy:  0.9032862250979057 Loss:  1.3720859694184873 Val_accuracy:  0.8915826750204304 Val_cost:  1.3720859694184873 Val_accuracy:  0.8915826750204304 Val_Acc:  1.552343819221075\n",
      "Epoch number: 2146/10000step_number: 0/29 Accuracy:  0.9030819002213519 Loss:  1.3720408193664853 Val_accuracy:  0.8915826750204304 Val_cost:  1.3720408193664853 Val_accuracy:  0.8915826750204304 Val_Acc:  1.5524247371823552\n",
      "Epoch number: 2147/10000step_number: 0/29 Accuracy:  0.902979737783075 Loss:  1.3719945608627109 Val_accuracy:  0.891446472350858 Val_cost:  1.3719945608627109 Val_accuracy:  0.891446472350858 Val_Acc:  1.5525075878665584\n",
      "Epoch number: 2148/10000step_number: 0/29 Accuracy:  0.9031159543674442 Loss:  1.371947464277654 Val_accuracy:  0.891446472350858 Val_cost:  1.371947464277654 Val_accuracy:  0.891446472350858 Val_Acc:  1.552592313306266\n",
      "Epoch number: 2149/10000step_number: 0/29 Accuracy:  0.9030819002213519 Loss:  1.3718997873305179 Val_accuracy:  0.8915826750204304 Val_cost:  1.3718997873305179 Val_accuracy:  0.8915826750204304 Val_Acc:  1.5526788362992685\n",
      "Epoch number: 2150/10000step_number: 0/29 Accuracy:  0.9030478460752597 Loss:  1.3718517336051828 Val_accuracy:  0.8917188776900027 Val_cost:  1.3718517336051828 Val_accuracy:  0.8917188776900027 Val_Acc:  1.5527670717227262\n",
      "Epoch number: 2151/10000step_number: 0/29 Accuracy:  0.9030819002213519 Loss:  1.3718034903490826 Val_accuracy:  0.8918550803595751 Val_cost:  1.3718034903490826 Val_accuracy:  0.8918550803595751 Val_Acc:  1.5528569127634908\n",
      "Epoch number: 2152/10000step_number: 0/29 Accuracy:  0.9029456836369828 Loss:  1.3717552126180725 Val_accuracy:  0.8917188776900027 Val_cost:  1.3717552126180725 Val_accuracy:  0.8917188776900027 Val_Acc:  1.5529482344424068\n",
      "Epoch number: 2153/10000step_number: 0/29 Accuracy:  0.9031159543674442 Loss:  1.371707041807957 Val_accuracy:  0.8918550803595751 Val_cost:  1.371707041807957 Val_accuracy:  0.8918550803595751 Val_Acc:  1.5530408907076083\n",
      "Epoch number: 2154/10000step_number: 0/29 Accuracy:  0.9030819002213519 Loss:  1.3716591016951942 Val_accuracy:  0.8915826750204304 Val_cost:  1.3716591016951942 Val_accuracy:  0.8915826750204304 Val_Acc:  1.5531347164551992\n",
      "Epoch number: 2155/10000step_number: 0/29 Accuracy:  0.9031500085135366 Loss:  1.3716115066509142 Val_accuracy:  0.8913102696812858 Val_cost:  1.3716115066509142 Val_accuracy:  0.8913102696812858 Val_Acc:  1.5532295296709586\n",
      "Epoch number: 2156/10000step_number: 0/29 Accuracy:  0.9032181168057211 Loss:  1.3715643611300807 Val_accuracy:  0.891446472350858 Val_cost:  1.3715643611300807 Val_accuracy:  0.891446472350858 Val_Acc:  1.5533251337445306\n",
      "Epoch number: 2157/10000step_number: 0/29 Accuracy:  0.9031840626596288 Loss:  1.3715177623184693 Val_accuracy:  0.8915826750204304 Val_cost:  1.3715177623184693 Val_accuracy:  0.8915826750204304 Val_Acc:  1.553421321340354\n",
      "Epoch number: 2158/10000step_number: 0/29 Accuracy:  0.9031159543674442 Loss:  1.3714717993503898 Val_accuracy:  0.8915826750204304 Val_cost:  1.3714717993503898 Val_accuracy:  0.8915826750204304 Val_Acc:  1.5535178772185438\n",
      "Epoch number: 2159/10000step_number: 0/29 Accuracy:  0.9030819002213519 Loss:  1.371426552753741 Val_accuracy:  0.8915826750204304 Val_cost:  1.371426552753741 Val_accuracy:  0.8915826750204304 Val_Acc:  1.553614582366334\n",
      "Epoch number: 2160/10000step_number: 0/29 Accuracy:  0.902979737783075 Loss:  1.3713820924748015 Val_accuracy:  0.8915826750204304 Val_cost:  1.3713820924748015 Val_accuracy:  0.8915826750204304 Val_Acc:  1.5537112171819683\n",
      "Epoch number: 2161/10000step_number: 0/29 Accuracy:  0.902741358760429 Loss:  1.3713384756747886 Val_accuracy:  0.8915826750204304 Val_cost:  1.3713384756747886 Val_accuracy:  0.8915826750204304 Val_Acc:  1.5538075654665162\n",
      "Epoch number: 2162/10000step_number: 0/29 Accuracy:  0.902741358760429 Loss:  1.371295744143936 Val_accuracy:  0.8915826750204304 Val_cost:  1.371295744143936 Val_accuracy:  0.8915826750204304 Val_Acc:  1.5539034178407272\n",
      "Epoch number: 2163/10000step_number: 0/29 Accuracy:  0.9028435211987059 Loss:  1.3712539219265476 Val_accuracy:  0.8915826750204304 Val_cost:  1.3712539219265476 Val_accuracy:  0.8915826750204304 Val_Acc:  1.5539985755835373\n",
      "Epoch number: 2164/10000step_number: 0/29 Accuracy:  0.9026391963221522 Loss:  1.3712130133510732 Val_accuracy:  0.8913102696812858 Val_cost:  1.3712130133510732 Val_accuracy:  0.8913102696812858 Val_Acc:  1.5540928541391437\n",
      "Epoch number: 2165/10000step_number: 0/29 Accuracy:  0.9026391963221522 Loss:  1.3711730018764197 Val_accuracy:  0.8913102696812858 Val_cost:  1.3711730018764197 Val_accuracy:  0.8913102696812858 Val_Acc:  1.5541860867045019\n",
      "Epoch number: 2166/10000step_number: 0/29 Accuracy:  0.902979737783075 Loss:  1.371133849915978 Val_accuracy:  0.8913102696812858 Val_cost:  1.371133849915978 Val_accuracy:  0.8913102696812858 Val_Acc:  1.5542781274220265\n",
      "Epoch number: 2167/10000step_number: 0/29 Accuracy:  0.9029116294908905 Loss:  1.3710954998661364 Val_accuracy:  0.891446472350858 Val_cost:  1.3710954998661364 Val_accuracy:  0.891446472350858 Val_Acc:  1.5543688541560017\n",
      "Epoch number: 2168/10000step_number: 0/29 Accuracy:  0.9028435211987059 Loss:  1.3710578763355936 Val_accuracy:  0.891446472350858 Val_cost:  1.3710578763355936 Val_accuracy:  0.891446472350858 Val_Acc:  1.5544581704044023\n",
      "Epoch number: 2169/10000step_number: 0/29 Accuracy:  0.9028094670526137 Loss:  1.3710208895894511 Val_accuracy:  0.891446472350858 Val_cost:  1.3710208895894511 Val_accuracy:  0.891446472350858 Val_Acc:  1.554546006059934\n",
      "Epoch number: 2170/10000step_number: 0/29 Accuracy:  0.9027754129065214 Loss:  1.3709844400195543 Val_accuracy:  0.891446472350858 Val_cost:  1.3709844400195543 Val_accuracy:  0.891446472350858 Val_Acc:  1.5546323165805158\n",
      "Epoch number: 2171/10000step_number: 0/29 Accuracy:  0.9027073046143368 Loss:  1.3709484234252014 Val_accuracy:  0.891446472350858 Val_cost:  1.3709484234252014 Val_accuracy:  0.891446472350858 Val_Acc:  1.5547170803459547\n",
      "Epoch number: 2172/10000step_number: 0/29 Accuracy:  0.9028775753447982 Loss:  1.370912736666141 Val_accuracy:  0.8915826750204304 Val_cost:  1.370912736666141 Val_accuracy:  0.8915826750204304 Val_Acc:  1.5548002941285144\n",
      "Epoch number: 2173/10000step_number: 0/29 Accuracy:  0.9028775753447982 Loss:  1.3708772831318425 Val_accuracy:  0.8915826750204304 Val_cost:  1.3708772831318425 Val_accuracy:  0.8915826750204304 Val_Acc:  1.5548819670064256\n",
      "Epoch number: 2174/10000step_number: 0/29 Accuracy:  0.9029116294908905 Loss:  1.3708419772518805 Val_accuracy:  0.8917188776900027 Val_cost:  1.3708419772518805 Val_accuracy:  0.8917188776900027 Val_Acc:  1.5549621134241332\n",
      "Epoch number: 2175/10000step_number: 0/29 Accuracy:  0.9028435211987059 Loss:  1.3708067472527568 Val_accuracy:  0.8917188776900027 Val_cost:  1.3708067472527568 Val_accuracy:  0.8917188776900027 Val_Acc:  1.555040746438154\n",
      "Epoch number: 2176/10000step_number: 0/29 Accuracy:  0.9029456836369828 Loss:  1.3707715354812915 Val_accuracy:  0.8915826750204304 Val_cost:  1.3707715354812915 Val_accuracy:  0.8915826750204304 Val_Acc:  1.5551178723028587\n",
      "Epoch number: 2177/10000step_number: 0/29 Accuracy:  0.9030137919291674 Loss:  1.370736296041399 Val_accuracy:  0.8917188776900027 Val_cost:  1.370736296041399 Val_accuracy:  0.8917188776900027 Val_Acc:  1.555193487333528\n",
      "Epoch number: 2178/10000step_number: 0/29 Accuracy:  0.902741358760429 Loss:  1.3707009900359466 Val_accuracy:  0.891446472350858 Val_cost:  1.3707009900359466 Val_accuracy:  0.891446472350858 Val_Acc:  1.5552675775007467\n",
      "Epoch number: 2179/10000step_number: 0/29 Accuracy:  0.902741358760429 Loss:  1.3706655792666076 Val_accuracy:  0.8913102696812858 Val_cost:  1.3706655792666076 Val_accuracy:  0.8913102696812858 Val_Acc:  1.5553401205580533\n",
      "Epoch number: 2180/10000step_number: 0/29 Accuracy:  0.9028094670526137 Loss:  1.3706300195496544 Val_accuracy:  0.8913102696812858 Val_cost:  1.3706300195496544 Val_accuracy:  0.8913102696812858 Val_Acc:  1.555411089955286\n",
      "Epoch number: 2181/10000step_number: 0/29 Accuracy:  0.9029116294908905 Loss:  1.3705942548089447 Val_accuracy:  0.8913102696812858 Val_cost:  1.3705942548089447 Val_accuracy:  0.8913102696812858 Val_Acc:  1.5554804594832605\n",
      "Epoch number: 2182/10000step_number: 0/29 Accuracy:  0.9029116294908905 Loss:  1.3705582128113152 Val_accuracy:  0.8913102696812858 Val_cost:  1.3705582128113152 Val_accuracy:  0.8913102696812858 Val_Acc:  1.5555482076577214\n",
      "Epoch number: 2183/10000step_number: 0/29 Accuracy:  0.9028775753447982 Loss:  1.37052180299265 Val_accuracy:  0.8913102696812858 Val_cost:  1.37052180299265 Val_accuracy:  0.8913102696812858 Val_Acc:  1.5556143211183044\n",
      "Epoch number: 2184/10000step_number: 0/29 Accuracy:  0.9029116294908905 Loss:  1.370484916416147 Val_accuracy:  0.8913102696812858 Val_cost:  1.370484916416147 Val_accuracy:  0.8913102696812858 Val_Acc:  1.5556787967761492\n",
      "Epoch number: 2185/10000step_number: 0/29 Accuracy:  0.902979737783075 Loss:  1.3704474276272498 Val_accuracy:  0.8913102696812858 Val_cost:  1.3704474276272498 Val_accuracy:  0.8913102696812858 Val_Acc:  1.5557416428725788\n",
      "Epoch number: 2186/10000step_number: 0/29 Accuracy:  0.9031159543674442 Loss:  1.3704091980378965 Val_accuracy:  0.8913102696812858 Val_cost:  1.3704091980378965 Val_accuracy:  0.8913102696812858 Val_Acc:  1.555802879404719\n",
      "Epoch number: 2187/10000step_number: 0/29 Accuracy:  0.9031500085135366 Loss:  1.3703700804721057 Val_accuracy:  0.8911740670117134 Val_cost:  1.3703700804721057 Val_accuracy:  0.8911740670117134 Val_Acc:  1.5558625385695781\n",
      "Epoch number: 2188/10000step_number: 0/29 Accuracy:  0.9031840626596288 Loss:  1.3703299245774085 Val_accuracy:  0.8911740670117134 Val_cost:  1.3703299245774085 Val_accuracy:  0.8911740670117134 Val_Acc:  1.555920665854836\n",
      "Epoch number: 2189/10000step_number: 0/29 Accuracy:  0.9032521709518134 Loss:  1.3702885828993694 Val_accuracy:  0.8911740670117134 Val_cost:  1.3702885828993694 Val_accuracy:  0.8911740670117134 Val_Acc:  1.55597732222172\n",
      "Epoch number: 2190/10000step_number: 0/29 Accuracy:  0.9032521709518134 Loss:  1.3702459174740915 Val_accuracy:  0.8911740670117134 Val_cost:  1.3702459174740915 Val_accuracy:  0.8911740670117134 Val_Acc:  1.5560325875362875\n",
      "Epoch number: 2191/10000step_number: 0/29 Accuracy:  0.9032521709518134 Loss:  1.370201806780058 Val_accuracy:  0.891037864342141 Val_cost:  1.370201806780058 Val_accuracy:  0.891037864342141 Val_Acc:  1.55608656493444\n",
      "Epoch number: 2192/10000step_number: 0/29 Accuracy:  0.9032862250979057 Loss:  1.370156152786438 Val_accuracy:  0.8911740670117134 Val_cost:  1.370156152786438 Val_accuracy:  0.8911740670117134 Val_Acc:  1.5561393853606134\n",
      "Epoch number: 2193/10000step_number: 0/29 Accuracy:  0.9033883875361826 Loss:  1.370108887651333 Val_accuracy:  0.8913102696812858 Val_cost:  1.370108887651333 Val_accuracy:  0.8913102696812858 Val_Acc:  1.5561912110170835\n",
      "Epoch number: 2194/10000step_number: 0/29 Accuracy:  0.9033883875361826 Loss:  1.3700599794071955 Val_accuracy:  0.8913102696812858 Val_cost:  1.3700599794071955 Val_accuracy:  0.8913102696812858 Val_Acc:  1.5562422361975792\n",
      "Epoch number: 2195/10000step_number: 0/29 Accuracy:  0.9033883875361826 Loss:  1.370009435807413 Val_accuracy:  0.8913102696812858 Val_cost:  1.370009435807413 Val_accuracy:  0.8913102696812858 Val_Acc:  1.5562926840085838\n",
      "Epoch number: 2196/10000step_number: 0/29 Accuracy:  0.9033202792439979 Loss:  1.3699573055030951 Val_accuracy:  0.8913102696812858 Val_cost:  1.3699573055030951 Val_accuracy:  0.8913102696812858 Val_Acc:  1.5563427980288411\n",
      "Epoch number: 2197/10000step_number: 0/29 Accuracy:  0.9035927124127362 Loss:  1.3699036759533165 Val_accuracy:  0.891446472350858 Val_cost:  1.3699036759533165 Val_accuracy:  0.891446472350858 Val_Acc:  1.5563928289824736\n",
      "Epoch number: 2198/10000step_number: 0/29 Accuracy:  0.90379703728929 Loss:  1.369848667947624 Val_accuracy:  0.8915826750204304 Val_cost:  1.369848667947624 Val_accuracy:  0.8915826750204304 Val_Acc:  1.5564430178439157\n",
      "Epoch number: 2199/10000step_number: 0/29 Accuracy:  0.90379703728929 Loss:  1.3697924272289221 Val_accuracy:  0.8915826750204304 Val_cost:  1.3697924272289221 Val_accuracy:  0.8915826750204304 Val_Acc:  1.55649357799157\n",
      "Epoch number: 2200/10000step_number: 0/29 Accuracy:  0.904512174357228 Loss:  1.3697351142600105 Val_accuracy:  0.8921274856987197 Val_cost:  1.3697351142600105 Val_accuracy:  0.8921274856987197 Val_Acc:  1.5565446796133624\n",
      "Epoch number: 2201/10000step_number: 0/29 Accuracy:  0.9044440660650435 Loss:  1.369676893494082 Val_accuracy:  0.8922636883682921 Val_cost:  1.369676893494082 Val_accuracy:  0.8922636883682921 Val_Acc:  1.5565964392038534\n",
      "Epoch number: 2202/10000step_number: 0/29 Accuracy:  0.904750553379874 Loss:  1.3696179234963226 Val_accuracy:  0.8923998910378643 Val_cost:  1.3696179234963226 Val_accuracy:  0.8923998910378643 Val_Acc:  1.5566489158142727\n",
      "Epoch number: 2203/10000step_number: 0/29 Accuracy:  0.9048186616720586 Loss:  1.3695583489554142 Val_accuracy:  0.8922636883682921 Val_cost:  1.3695583489554142 Val_accuracy:  0.8922636883682921 Val_Acc:  1.5567021140972082\n",
      "Epoch number: 2204/10000step_number: 0/29 Accuracy:  0.9048186616720586 Loss:  1.3694982951488057 Val_accuracy:  0.8922636883682921 Val_cost:  1.3694982951488057 Val_accuracy:  0.8922636883682921 Val_Acc:  1.5567559927457848\n",
      "Epoch number: 2205/10000step_number: 0/29 Accuracy:  0.9048867699642431 Loss:  1.3694378649411254 Val_accuracy:  0.8922636883682921 Val_cost:  1.3694378649411254 Val_accuracy:  0.8922636883682921 Val_Acc:  1.5568104760618013\n",
      "Epoch number: 2206/10000step_number: 0/29 Accuracy:  0.9049208241103355 Loss:  1.369377138027362 Val_accuracy:  0.8922636883682921 Val_cost:  1.369377138027362 Val_accuracy:  0.8922636883682921 Val_Acc:  1.5568654662601111\n",
      "Epoch number: 2207/10000step_number: 0/29 Accuracy:  0.9048527158181509 Loss:  1.3693161719418854 Val_accuracy:  0.8922636883682921 Val_cost:  1.3693161719418854 Val_accuracy:  0.8922636883682921 Val_Acc:  1.5569208545947264\n",
      "Epoch number: 2208/10000step_number: 0/29 Accuracy:  0.9048867699642431 Loss:  1.3692550043276455 Val_accuracy:  0.8922636883682921 Val_cost:  1.3692550043276455 Val_accuracy:  0.8922636883682921 Val_Acc:  1.5569765301515546\n",
      "Epoch number: 2209/10000step_number: 0/29 Accuracy:  0.9048867699642431 Loss:  1.3691936560315299 Val_accuracy:  0.8922636883682921 Val_cost:  1.3691936560315299 Val_accuracy:  0.8922636883682921 Val_Acc:  1.557032385922562\n",
      "Epoch number: 2210/10000step_number: 0/29 Accuracy:  0.9048867699642431 Loss:  1.3691321346852114 Val_accuracy:  0.8922636883682921 Val_cost:  1.3691321346852114 Val_accuracy:  0.8922636883682921 Val_Acc:  1.55708832238759\n",
      "Epoch number: 2211/10000step_number: 0/29 Accuracy:  0.9051932572790737 Loss:  1.3690704384972687 Val_accuracy:  0.8923998910378643 Val_cost:  1.3690704384972687 Val_accuracy:  0.8923998910378643 Val_Acc:  1.5571442491079872\n",
      "Epoch number: 2212/10000step_number: 0/29 Accuracy:  0.905227311425166 Loss:  1.3690085600121256 Val_accuracy:  0.8923998910378643 Val_cost:  1.3690085600121256 Val_accuracy:  0.8923998910378643 Val_Acc:  1.5572000849678884\n",
      "Epoch number: 2213/10000step_number: 0/29 Accuracy:  0.905227311425166 Loss:  1.3689464896010417 Val_accuracy:  0.8923998910378643 Val_cost:  1.3689464896010417 Val_accuracy:  0.8923998910378643 Val_Acc:  1.5572557575906223\n",
      "Epoch number: 2214/10000step_number: 0/29 Accuracy:  0.9052954197173506 Loss:  1.3688842184599863 Val_accuracy:  0.8922636883682921 Val_cost:  1.3688842184599863 Val_accuracy:  0.8922636883682921 Val_Acc:  1.5573112023522326\n",
      "Epoch number: 2215/10000step_number: 0/29 Accuracy:  0.9053975821556275 Loss:  1.3688217409093442 Val_accuracy:  0.8923998910378643 Val_cost:  1.3688217409093442 Val_accuracy:  0.8923998910378643 Val_Acc:  1.557366361239429\n",
      "Epoch number: 2216/10000step_number: 0/29 Accuracy:  0.9055337987399966 Loss:  1.368759055821382 Val_accuracy:  0.8925360937074367 Val_cost:  1.368759055821382 Val_accuracy:  0.8925360937074367 Val_Acc:  1.5574211816648833\n",
      "Epoch number: 2217/10000step_number: 0/29 Accuracy:  0.9055337987399966 Loss:  1.3686961670379874 Val_accuracy:  0.8925360937074367 Val_cost:  1.3686961670379874 Val_accuracy:  0.8925360937074367 Val_Acc:  1.5574756152829\n",
      "Epoch number: 2218/10000step_number: 0/29 Accuracy:  0.905465690447812 Loss:  1.3686330826780186 Val_accuracy:  0.8925360937074367 Val_cost:  1.3686330826780186 Val_accuracy:  0.8925360937074367 Val_Acc:  1.5575296167469117\n",
      "Epoch number: 2219/10000step_number: 0/29 Accuracy:  0.9054997445939043 Loss:  1.3685698132671713 Val_accuracy:  0.8925360937074367 Val_cost:  1.3685698132671713 Val_accuracy:  0.8925360937074367 Val_Acc:  1.5575831423437543\n",
      "Epoch number: 2220/10000step_number: 0/29 Accuracy:  0.9056359611782735 Loss:  1.3685063686533665 Val_accuracy:  0.8925360937074367 Val_cost:  1.3685063686533665 Val_accuracy:  0.8925360937074367 Val_Acc:  1.5576361484097796\n",
      "Epoch number: 2221/10000step_number: 0/29 Accuracy:  0.9056700153243658 Loss:  1.368442753700966 Val_accuracy:  0.892672296377009 Val_cost:  1.368442753700966 Val_accuracy:  0.892672296377009 Val_Acc:  1.5576885894404795\n",
      "Epoch number: 2222/10000step_number: 0/29 Accuracy:  0.9057721777626426 Loss:  1.368378962795113 Val_accuracy:  0.892672296377009 Val_cost:  1.368378962795113 Val_accuracy:  0.892672296377009 Val_Acc:  1.55774041581537\n",
      "Epoch number: 2223/10000step_number: 0/29 Accuracy:  0.9057721777626426 Loss:  1.3683149732440543 Val_accuracy:  0.892672296377009 Val_cost:  1.3683149732440543 Val_accuracy:  0.892672296377009 Val_Acc:  1.5577915710911299\n",
      "Epoch number: 2224/10000step_number: 0/29 Accuracy:  0.9057721777626426 Loss:  1.368250737755484 Val_accuracy:  0.892672296377009 Val_cost:  1.368250737755484 Val_accuracy:  0.892672296377009 Val_Acc:  1.5578419888709991\n",
      "Epoch number: 2225/10000step_number: 0/29 Accuracy:  0.9058062319087349 Loss:  1.3681861762961371 Val_accuracy:  0.892672296377009 Val_cost:  1.3681861762961371 Val_accuracy:  0.892672296377009 Val_Acc:  1.5578915893026228\n",
      "Epoch number: 2226/10000step_number: 0/29 Accuracy:  0.9058402860548271 Loss:  1.3681211678326826 Val_accuracy:  0.892672296377009 Val_cost:  1.3681211678326826 Val_accuracy:  0.892672296377009 Val_Acc:  1.5579402753959064\n",
      "Epoch number: 2227/10000step_number: 0/29 Accuracy:  0.905942448493104 Loss:  1.3680555426994794 Val_accuracy:  0.8925360937074367 Val_cost:  1.3680555426994794 Val_accuracy:  0.8925360937074367 Val_Acc:  1.5579879294189887\n",
      "Epoch number: 2228/10000step_number: 0/29 Accuracy:  0.9053294738634429 Loss:  1.3679890766337788 Val_accuracy:  0.8919912830291473 Val_cost:  1.3679890766337788 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5580344098379861\n",
      "Epoch number: 2229/10000step_number: 0/29 Accuracy:  0.9053294738634429 Loss:  1.3679214878274564 Val_accuracy:  0.8919912830291473 Val_cost:  1.3679214878274564 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5580795493575925\n",
      "Epoch number: 2230/10000step_number: 0/29 Accuracy:  0.9053294738634429 Loss:  1.3678524386023059 Val_accuracy:  0.8919912830291473 Val_cost:  1.3678524386023059 Val_accuracy:  0.8919912830291473 Val_Acc:  1.558123154789982\n",
      "Epoch number: 2231/10000step_number: 0/29 Accuracy:  0.9053294738634429 Loss:  1.367781543427699 Val_accuracy:  0.8919912830291473 Val_cost:  1.367781543427699 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5581650095407351\n",
      "Epoch number: 2232/10000step_number: 0/29 Accuracy:  0.9052954197173506 Loss:  1.3677083848484366 Val_accuracy:  0.8919912830291473 Val_cost:  1.3677083848484366 Val_accuracy:  0.8919912830291473 Val_Acc:  1.558204879460748\n",
      "Epoch number: 2233/10000step_number: 0/29 Accuracy:  0.9053294738634429 Loss:  1.3676325383686654 Val_accuracy:  0.8919912830291473 Val_cost:  1.3676325383686654 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5582425226582866\n",
      "Epoch number: 2234/10000step_number: 0/29 Accuracy:  0.9053635280095351 Loss:  1.3675536063909857 Val_accuracy:  0.8919912830291473 Val_cost:  1.3675536063909857 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5582777035158006\n",
      "Epoch number: 2235/10000step_number: 0/29 Accuracy:  0.9053635280095351 Loss:  1.3674712599924757 Val_accuracy:  0.8919912830291473 Val_cost:  1.3674712599924757 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5583102106770739\n",
      "Epoch number: 2236/10000step_number: 0/29 Accuracy:  0.9053294738634429 Loss:  1.3673852858266242 Val_accuracy:  0.8919912830291473 Val_cost:  1.3673852858266242 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5583398781914035\n",
      "Epoch number: 2237/10000step_number: 0/29 Accuracy:  0.9053975821556275 Loss:  1.3672956340993787 Val_accuracy:  0.8921274856987197 Val_cost:  1.3672956340993787 Val_accuracy:  0.8921274856987197 Val_Acc:  1.558366608420541\n",
      "Epoch number: 2238/10000step_number: 0/29 Accuracy:  0.9054316363017197 Loss:  1.3672024627659205 Val_accuracy:  0.8919912830291473 Val_cost:  1.3672024627659205 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5583903948202875\n",
      "Epoch number: 2239/10000step_number: 0/29 Accuracy:  0.9054316363017197 Loss:  1.3671061731688479 Val_accuracy:  0.8919912830291473 Val_cost:  1.3671061731688479 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5584113424980028\n",
      "Epoch number: 2240/10000step_number: 0/29 Accuracy:  0.9054316363017197 Loss:  1.3670074334529432 Val_accuracy:  0.8919912830291473 Val_cost:  1.3670074334529432 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5584296844608618\n",
      "Epoch number: 2241/10000step_number: 0/29 Accuracy:  0.9054316363017197 Loss:  1.3669071881603805 Val_accuracy:  0.8919912830291473 Val_cost:  1.3669071881603805 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5584457918376555\n",
      "Epoch number: 2242/10000step_number: 0/29 Accuracy:  0.9053294738634429 Loss:  1.3668066550769502 Val_accuracy:  0.8919912830291473 Val_cost:  1.3668066550769502 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5584601769797946\n",
      "Epoch number: 2243/10000step_number: 0/29 Accuracy:  0.9053635280095351 Loss:  1.3667073131093417 Val_accuracy:  0.8921274856987197 Val_cost:  1.3667073131093417 Val_accuracy:  0.8921274856987197 Val_Acc:  1.5584734889242533\n",
      "Epoch number: 2244/10000step_number: 0/29 Accuracy:  0.9054316363017197 Loss:  1.3666108871412208 Val_accuracy:  0.8921274856987197 Val_cost:  1.3666108871412208 Val_accuracy:  0.8921274856987197 Val_Acc:  1.5584865010793063\n",
      "Epoch number: 2245/10000step_number: 0/29 Accuracy:  0.9054316363017197 Loss:  1.3665193370816802 Val_accuracy:  0.8921274856987197 Val_cost:  1.3665193370816802 Val_accuracy:  0.8921274856987197 Val_Acc:  1.5585000907164406\n",
      "Epoch number: 2246/10000step_number: 0/29 Accuracy:  0.9054997445939043 Loss:  1.3664348587748856 Val_accuracy:  0.8919912830291473 Val_cost:  1.3664348587748856 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5585152090100873\n",
      "Epoch number: 2247/10000step_number: 0/29 Accuracy:  0.905465690447812 Loss:  1.3663599046377672 Val_accuracy:  0.8919912830291473 Val_cost:  1.3663599046377672 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5585328394923477\n",
      "Epoch number: 2248/10000step_number: 0/29 Accuracy:  0.9055337987399966 Loss:  1.3662972324702858 Val_accuracy:  0.8921274856987197 Val_cost:  1.3662972324702858 Val_accuracy:  0.8921274856987197 Val_Acc:  1.558553944280128\n",
      "Epoch number: 2249/10000step_number: 0/29 Accuracy:  0.9055678528860889 Loss:  1.3662499918029112 Val_accuracy:  0.8921274856987197 Val_cost:  1.3662499918029112 Val_accuracy:  0.8921274856987197 Val_Acc:  1.5585794060438782\n",
      "Epoch number: 2250/10000step_number: 0/29 Accuracy:  0.9056019070321811 Loss:  1.3662218568426092 Val_accuracy:  0.8921274856987197 Val_cost:  1.3662218568426092 Val_accuracy:  0.8921274856987197 Val_Acc:  1.558609996846938\n",
      "Epoch number: 2251/10000step_number: 0/29 Accuracy:  0.9055337987399966 Loss:  1.3662172093564933 Val_accuracy:  0.8919912830291473 Val_cost:  1.3662172093564933 Val_accuracy:  0.8919912830291473 Val_Acc:  1.558646446237336\n",
      "Epoch number: 2252/10000step_number: 0/29 Accuracy:  0.9055337987399966 Loss:  1.3662413523388195 Val_accuracy:  0.8918550803595751 Val_cost:  1.3662413523388195 Val_accuracy:  0.8918550803595751 Val_Acc:  1.558689720735075\n",
      "Epoch number: 2253/10000step_number: 0/29 Accuracy:  0.9056019070321811 Loss:  1.3663006609747317 Val_accuracy:  0.8919912830291473 Val_cost:  1.3663006609747317 Val_accuracy:  0.8919912830291473 Val_Acc:  1.5587415903222082\n",
      "Epoch number: 2254/10000step_number: 0/29 Accuracy:  0.905942448493104 Loss:  1.3664023516575248 Val_accuracy:  0.8922636883682921 Val_cost:  1.3664023516575248 Val_accuracy:  0.8922636883682921 Val_Acc:  1.558805289469807\n",
      "Epoch number: 2255/10000step_number: 0/29 Accuracy:  0.9060105567852886 Loss:  1.3665529312505837 Val_accuracy:  0.8922636883682921 Val_cost:  1.3665529312505837 Val_accuracy:  0.8922636883682921 Val_Acc:  1.5588853861256844\n",
      "Epoch number: 2256/10000step_number: 0/29 Accuracy:  0.9059083943470118 Loss:  1.3667531252304976 Val_accuracy:  0.8925360937074367 Val_cost:  1.3667531252304976 Val_accuracy:  0.8925360937074367 Val_Acc:  1.5589850082968317\n",
      "Epoch number: 2257/10000step_number: 0/29 Accuracy:  0.9055337987399966 Loss:  1.3669871215192944 Val_accuracy:  0.8922636883682921 Val_cost:  1.3669871215192944 Val_accuracy:  0.8922636883682921 Val_Acc:  1.5590994464429515\n",
      "Epoch number: 2258/10000step_number: 0/29 Accuracy:  0.9056019070321811 Loss:  1.3672135482287509 Val_accuracy:  0.8922636883682921 Val_cost:  1.3672135482287509 Val_accuracy:  0.8922636883682921 Val_Acc:  1.5592121027274768\n",
      "Epoch number: 2259/10000step_number: 0/29 Accuracy:  0.9058402860548271 Loss:  1.3673800000661835 Val_accuracy:  0.8925360937074367 Val_cost:  1.3673800000661835 Val_accuracy:  0.8925360937074367 Val_Acc:  1.5593034231676808\n",
      "Epoch number: 2260/10000step_number: 0/29 Accuracy:  0.9058062319087349 Loss:  1.367456316961453 Val_accuracy:  0.8923998910378643 Val_cost:  1.367456316961453 Val_accuracy:  0.8923998910378643 Val_Acc:  1.5593643341353192\n",
      "Epoch number: 2261/10000step_number: 0/29 Accuracy:  0.9058743402009195 Loss:  1.3674384628998946 Val_accuracy:  0.8925360937074367 Val_cost:  1.3674384628998946 Val_accuracy:  0.8925360937074367 Val_Acc:  1.5593946052781325\n",
      "Epoch number: 2262/10000step_number: 0/29 Accuracy:  0.9059083943470118 Loss:  1.3673234003984394 Val_accuracy:  0.8925360937074367 Val_cost:  1.3673234003984394 Val_accuracy:  0.8925360937074367 Val_Acc:  1.5593917654844303\n",
      "Epoch number: 2263/10000step_number: 0/29 Accuracy:  0.9059083943470118 Loss:  1.3671067369306107 Val_accuracy:  0.8925360937074367 Val_cost:  1.3671067369306107 Val_accuracy:  0.8925360937074367 Val_Acc:  1.559348507626689\n",
      "Epoch number: 2264/10000step_number: 0/29 Accuracy:  0.9057381236165503 Loss:  1.3668020964817889 Val_accuracy:  0.8922636883682921 Val_cost:  1.3668020964817889 Val_accuracy:  0.8922636883682921 Val_Acc:  1.5592644659361947\n",
      "Epoch number: 2265/10000step_number: 0/29 Accuracy:  0.90618082751575 Loss:  1.3664512581718933 Val_accuracy:  0.893080904385726 Val_cost:  1.3664512581718933 Val_accuracy:  0.893080904385726 Val_Acc:  1.5591594120223495\n",
      "Epoch number: 2266/10000step_number: 0/29 Accuracy:  0.9060105567852886 Loss:  1.3660973230666058 Val_accuracy:  0.8928084990465813 Val_cost:  1.3660973230666058 Val_accuracy:  0.8928084990465813 Val_Acc:  1.559064279174218\n",
      "Epoch number: 2267/10000step_number: 0/29 Accuracy:  0.905942448493104 Loss:  1.3657467034608348 Val_accuracy:  0.8925360937074367 Val_cost:  1.3657467034608348 Val_accuracy:  0.8925360937074367 Val_Acc:  1.5589987057880814\n",
      "Epoch number: 2268/10000step_number: 0/29 Accuracy:  0.9063170441001192 Loss:  1.3654085690930702 Val_accuracy:  0.8929447017161536 Val_cost:  1.3654085690930702 Val_accuracy:  0.8929447017161536 Val_Acc:  1.5590124498172928\n",
      "Epoch number: 2269/10000step_number: 0/29 Accuracy:  0.9062829899540269 Loss:  1.3651244929785549 Val_accuracy:  0.893080904385726 Val_cost:  1.3651244929785549 Val_accuracy:  0.893080904385726 Val_Acc:  1.5592713694880316\n",
      "Epoch number: 2270/10000step_number: 0/29 Accuracy:  0.9064873148305806 Loss:  1.3648814130901499 Val_accuracy:  0.8929447017161536 Val_cost:  1.3648814130901499 Val_accuracy:  0.8929447017161536 Val_Acc:  1.56011486100887\n",
      "Epoch number: 2271/10000step_number: 0/29 Accuracy:  0.90737272262898 Loss:  1.364960829016786 Val_accuracy:  0.8937619177335876 Val_cost:  1.364960829016786 Val_accuracy:  0.8937619177335876 Val_Acc:  1.5615254004942385\n",
      "Epoch number: 2272/10000step_number: 0/29 Accuracy:  0.9064532606844883 Loss:  1.36463610684334 Val_accuracy:  0.8923998910378643 Val_cost:  1.36463610684334 Val_accuracy:  0.8923998910378643 Val_Acc:  1.5623556322719467\n",
      "Epoch number: 2273/10000step_number: 0/29 Accuracy:  0.9077473182359952 Loss:  1.3631878059797216 Val_accuracy:  0.8929447017161536 Val_cost:  1.3631878059797216 Val_accuracy:  0.8929447017161536 Val_Acc:  1.560539873431697\n",
      "Epoch number: 2274/10000step_number: 0/29 Accuracy:  0.908666780180487 Loss:  1.3634150994821799 Val_accuracy:  0.8947153364205939 Val_cost:  1.3634150994821799 Val_accuracy:  0.8947153364205939 Val_Acc:  1.5588877907293213\n",
      "Epoch number: 2275/10000step_number: 0/29 Accuracy:  0.9085986718883025 Loss:  1.363554030703323 Val_accuracy:  0.8947153364205939 Val_cost:  1.363554030703323 Val_accuracy:  0.8947153364205939 Val_Acc:  1.5592735157977504\n",
      "Epoch number: 2276/10000step_number: 0/29 Accuracy:  0.9088711050570407 Loss:  1.3635302353018757 Val_accuracy:  0.8948515390901661 Val_cost:  1.3635302353018757 Val_accuracy:  0.8948515390901661 Val_Acc:  1.5593575682588394\n",
      "Epoch number: 2277/10000step_number: 0/29 Accuracy:  0.9072365060446109 Loss:  1.3667386957741683 Val_accuracy:  0.8929447017161536 Val_cost:  1.3667386957741683 Val_accuracy:  0.8929447017161536 Val_Acc:  1.559034489053453\n",
      "Epoch number: 2278/10000step_number: 0/29 Accuracy:  0.906895964583688 Loss:  1.3631581307912943 Val_accuracy:  0.892672296377009 Val_cost:  1.3631581307912943 Val_accuracy:  0.892672296377009 Val_Acc:  1.5584014155644903\n",
      "Epoch number: 2279/10000step_number: 0/29 Accuracy:  0.9075089392133492 Loss:  1.3665353224092243 Val_accuracy:  0.8936257150640152 Val_cost:  1.3665353224092243 Val_accuracy:  0.8936257150640152 Val_Acc:  1.5599223539158562\n",
      "Epoch number: 2280/10000step_number: 0/29 Accuracy:  0.9076451557977183 Loss:  1.3672125556169985 Val_accuracy:  0.8941705257423046 Val_cost:  1.3672125556169985 Val_accuracy:  0.8941705257423046 Val_Acc:  1.5594046970783129\n",
      "Epoch number: 2281/10000step_number: 0/29 Accuracy:  0.9088370509109485 Loss:  1.3648774550158924 Val_accuracy:  0.8943067284118769 Val_cost:  1.3648774550158924 Val_accuracy:  0.8943067284118769 Val_Acc:  1.5580865309672434\n",
      "Epoch number: 2282/10000step_number: 0/29 Accuracy:  0.9080197514047336 Loss:  1.36285655064334 Val_accuracy:  0.8944429310814492 Val_cost:  1.36285655064334 Val_accuracy:  0.8944429310814492 Val_Acc:  1.557951513057504\n",
      "Epoch number: 2283/10000step_number: 0/29 Accuracy:  0.9079175889664567 Loss:  1.3654944618660083 Val_accuracy:  0.8936257150640152 Val_cost:  1.3654944618660083 Val_accuracy:  0.8936257150640152 Val_Acc:  1.5627957378807322\n",
      "Epoch number: 2284/10000step_number: 0/29 Accuracy:  0.9092457006640559 Loss:  1.3588261007740816 Val_accuracy:  0.8958049577771724 Val_cost:  1.3588261007740816 Val_accuracy:  0.8958049577771724 Val_Acc:  1.555878309881143\n",
      "Epoch number: 2285/10000step_number: 0/29 Accuracy:  0.9074748850672569 Loss:  1.3640242246133838 Val_accuracy:  0.8936257150640152 Val_cost:  1.3640242246133838 Val_accuracy:  0.8936257150640152 Val_Acc:  1.5613247068980731\n",
      "Epoch number: 2286/10000step_number: 0/29 Accuracy:  0.9084624553039332 Loss:  1.3637717022025373 Val_accuracy:  0.8953963497684555 Val_cost:  1.3637717022025373 Val_accuracy:  0.8953963497684555 Val_Acc:  1.5584426614401854\n",
      "Epoch number: 2287/10000step_number: 0/29 Accuracy:  0.9070321811680572 Loss:  1.3631021703949542 Val_accuracy:  0.8933533097248706 Val_cost:  1.3631021703949542 Val_accuracy:  0.8933533097248706 Val_Acc:  1.5592045643621162\n",
      "Epoch number: 2288/10000step_number: 0/29 Accuracy:  0.9070321811680572 Loss:  1.3637448379308692 Val_accuracy:  0.8938981204031599 Val_cost:  1.3637448379308692 Val_accuracy:  0.8938981204031599 Val_Acc:  1.5599791418455466\n",
      "Epoch number: 2289/10000step_number: 0/29 Accuracy:  0.9071002894602418 Loss:  1.3637640019175077 Val_accuracy:  0.893489512394443 Val_cost:  1.3637640019175077 Val_accuracy:  0.893489512394443 Val_Acc:  1.5598049303445962\n",
      "Epoch number: 2290/10000step_number: 0/29 Accuracy:  0.9069640728758727 Loss:  1.3638492329768934 Val_accuracy:  0.8933533097248706 Val_cost:  1.3638492329768934 Val_accuracy:  0.8933533097248706 Val_Acc:  1.55973154755095\n",
      "Epoch number: 2291/10000step_number: 0/29 Accuracy:  0.9069640728758727 Loss:  1.3637009081049036 Val_accuracy:  0.8932171070552983 Val_cost:  1.3637009081049036 Val_accuracy:  0.8932171070552983 Val_Acc:  1.5598233908095038\n",
      "Epoch number: 2292/10000step_number: 0/29 Accuracy:  0.9070321811680572 Loss:  1.3637962269574309 Val_accuracy:  0.8932171070552983 Val_cost:  1.3637962269574309 Val_accuracy:  0.8932171070552983 Val_Acc:  1.5602866968300537\n",
      "Epoch number: 2293/10000step_number: 0/29 Accuracy:  0.9071683977524263 Loss:  1.3638257872708677 Val_accuracy:  0.893489512394443 Val_cost:  1.3638257872708677 Val_accuracy:  0.893489512394443 Val_Acc:  1.5605039497034896\n",
      "Epoch number: 2294/10000step_number: 0/29 Accuracy:  0.907134343606334 Loss:  1.363883018479592 Val_accuracy:  0.893489512394443 Val_cost:  1.363883018479592 Val_accuracy:  0.893489512394443 Val_Acc:  1.5605889077743162\n",
      "Epoch number: 2295/10000step_number: 0/29 Accuracy:  0.9072705601907032 Loss:  1.363905849033536 Val_accuracy:  0.8936257150640152 Val_cost:  1.363905849033536 Val_accuracy:  0.8936257150640152 Val_Acc:  1.5605934604330023\n",
      "Epoch number: 2296/10000step_number: 0/29 Accuracy:  0.9068278562915035 Loss:  1.363867596341192 Val_accuracy:  0.893489512394443 Val_cost:  1.363867596341192 Val_accuracy:  0.893489512394443 Val_Acc:  1.56069962352849\n",
      "Epoch number: 2297/10000step_number: 0/29 Accuracy:  0.9067597479993189 Loss:  1.3638720700242049 Val_accuracy:  0.8933533097248706 Val_cost:  1.3638720700242049 Val_accuracy:  0.8933533097248706 Val_Acc:  1.5608424976384148\n",
      "Epoch number: 2298/10000step_number: 0/29 Accuracy:  0.9065894772688575 Loss:  1.3638902704543967 Val_accuracy:  0.8933533097248706 Val_cost:  1.3638902704543967 Val_accuracy:  0.8933533097248706 Val_Acc:  1.561026843423152\n",
      "Epoch number: 2299/10000step_number: 0/29 Accuracy:  0.9066235314149498 Loss:  1.3639087078655308 Val_accuracy:  0.8933533097248706 Val_cost:  1.3639087078655308 Val_accuracy:  0.8933533097248706 Val_Acc:  1.5611537632723267\n",
      "Epoch number: 2300/10000step_number: 0/29 Accuracy:  0.9067597479993189 Loss:  1.3639265285557713 Val_accuracy:  0.8932171070552983 Val_cost:  1.3639265285557713 Val_accuracy:  0.8932171070552983 Val_Acc:  1.5612658768851042\n",
      "Epoch number: 2301/10000step_number: 0/29 Accuracy:  0.906895964583688 Loss:  1.3639364496462485 Val_accuracy:  0.8932171070552983 Val_cost:  1.3639364496462485 Val_accuracy:  0.8932171070552983 Val_Acc:  1.5613572853368656\n",
      "Epoch number: 2302/10000step_number: 0/29 Accuracy:  0.9069300187297803 Loss:  1.3639353312357203 Val_accuracy:  0.893489512394443 Val_cost:  1.3639353312357203 Val_accuracy:  0.893489512394443 Val_Acc:  1.5614695020020217\n",
      "Epoch number: 2303/10000step_number: 0/29 Accuracy:  0.9071683977524263 Loss:  1.3639384736208724 Val_accuracy:  0.8937619177335876 Val_cost:  1.3639384736208724 Val_accuracy:  0.8937619177335876 Val_Acc:  1.5615970443034157\n",
      "Epoch number: 2304/10000step_number: 0/29 Accuracy:  0.9072024518985187 Loss:  1.363944303320701 Val_accuracy:  0.8937619177335876 Val_cost:  1.363944303320701 Val_accuracy:  0.8937619177335876 Val_Acc:  1.5617466665791908\n",
      "Epoch number: 2305/10000step_number: 0/29 Accuracy:  0.9071683977524263 Loss:  1.3639569632767197 Val_accuracy:  0.8938981204031599 Val_cost:  1.3639569632767197 Val_accuracy:  0.8938981204031599 Val_Acc:  1.5618936235255705\n",
      "Epoch number: 2306/10000step_number: 0/29 Accuracy:  0.9078835348203643 Loss:  1.3639712451404407 Val_accuracy:  0.8944429310814492 Val_cost:  1.3639712451404407 Val_accuracy:  0.8944429310814492 Val_Acc:  1.562035647356595\n",
      "Epoch number: 2307/10000step_number: 0/29 Accuracy:  0.9080538055508258 Loss:  1.363985720809751 Val_accuracy:  0.8944429310814492 Val_cost:  1.363985720809751 Val_accuracy:  0.8944429310814492 Val_Acc:  1.5621702674865294\n",
      "Epoch number: 2308/10000step_number: 0/29 Accuracy:  0.9081219138430103 Loss:  1.3639950661461926 Val_accuracy:  0.8945791337510215 Val_cost:  1.3639950661461926 Val_accuracy:  0.8945791337510215 Val_Acc:  1.562309912608985\n",
      "Epoch number: 2309/10000step_number: 0/29 Accuracy:  0.9081559679891027 Loss:  1.364000826165172 Val_accuracy:  0.8948515390901661 Val_cost:  1.364000826165172 Val_accuracy:  0.8948515390901661 Val_Acc:  1.562459950478021\n",
      "Epoch number: 2310/10000step_number: 0/29 Accuracy:  0.9082921845734718 Loss:  1.364001999426228 Val_accuracy:  0.8948515390901661 Val_cost:  1.364001999426228 Val_accuracy:  0.8948515390901661 Val_Acc:  1.5626257629207816\n",
      "Epoch number: 2311/10000step_number: 0/29 Accuracy:  0.9083602928656564 Loss:  1.36400080285324 Val_accuracy:  0.8948515390901661 Val_cost:  1.36400080285324 Val_accuracy:  0.8948515390901661 Val_Acc:  1.5628046084513614\n",
      "Epoch number: 2312/10000step_number: 0/29 Accuracy:  0.9086327260343947 Loss:  1.363995991213113 Val_accuracy:  0.8949877417597385 Val_cost:  1.363995991213113 Val_accuracy:  0.8949877417597385 Val_Acc:  1.5629937810246664\n",
      "Epoch number: 2313/10000step_number: 0/29 Accuracy:  0.9085986718883025 Loss:  1.363985965606268 Val_accuracy:  0.8949877417597385 Val_cost:  1.363985965606268 Val_accuracy:  0.8949877417597385 Val_Acc:  1.5631900436424313\n",
      "Epoch number: 2314/10000step_number: 0/29 Accuracy:  0.908666780180487 Loss:  1.3639661830901777 Val_accuracy:  0.8948515390901661 Val_cost:  1.3639661830901777 Val_accuracy:  0.8948515390901661 Val_Acc:  1.5633937692267592\n",
      "Epoch number: 2315/10000step_number: 0/29 Accuracy:  0.908905159203133 Loss:  1.3639326321072038 Val_accuracy:  0.8951239444293109 Val_cost:  1.3639326321072038 Val_accuracy:  0.8951239444293109 Val_Acc:  1.5636069456078063\n",
      "Epoch number: 2316/10000step_number: 0/29 Accuracy:  0.9089732674953176 Loss:  1.3638804011001675 Val_accuracy:  0.8953963497684555 Val_cost:  1.3638804011001675 Val_accuracy:  0.8953963497684555 Val_Acc:  1.5638330215578038\n",
      "Epoch number: 2317/10000step_number: 0/29 Accuracy:  0.9091094840796867 Loss:  1.3638051939345728 Val_accuracy:  0.8955325524380278 Val_cost:  1.3638051939345728 Val_accuracy:  0.8955325524380278 Val_Acc:  1.5640749983937752\n",
      "Epoch number: 2318/10000step_number: 0/29 Accuracy:  0.9091775923718712 Loss:  1.3637020158442474 Val_accuracy:  0.8955325524380278 Val_cost:  1.3637020158442474 Val_accuracy:  0.8955325524380278 Val_Acc:  1.5643347005274626\n",
      "Epoch number: 2319/10000step_number: 0/29 Accuracy:  0.909381917248425 Loss:  1.3635652316619444 Val_accuracy:  0.8955325524380278 Val_cost:  1.3635652316619444 Val_accuracy:  0.8955325524380278 Val_Acc:  1.5646119409658552\n",
      "Epoch number: 2320/10000step_number: 0/29 Accuracy:  0.9094159713945172 Loss:  1.3633873297203984 Val_accuracy:  0.8956687551076001 Val_cost:  1.3633873297203984 Val_accuracy:  0.8956687551076001 Val_Acc:  1.5649048068521345\n",
      "Epoch number: 2321/10000step_number: 0/29 Accuracy:  0.9096543504171632 Loss:  1.3631587191641006 Val_accuracy:  0.8955325524380278 Val_cost:  1.3631587191641006 Val_accuracy:  0.8955325524380278 Val_Acc:  1.565210317811086\n",
      "Epoch number: 2322/10000step_number: 0/29 Accuracy:  0.9099267835859016 Loss:  1.3628672591569053 Val_accuracy:  0.8955325524380278 Val_cost:  1.3628672591569053 Val_accuracy:  0.8955325524380278 Val_Acc:  1.5655249986551767\n",
      "Epoch number: 2323/10000step_number: 0/29 Accuracy:  0.9102332709007321 Loss:  1.3624983997960818 Val_accuracy:  0.8959411604467448 Val_cost:  1.3624983997960818 Val_accuracy:  0.8959411604467448 Val_Acc:  1.5658449365201217\n",
      "Epoch number: 2324/10000step_number: 0/29 Accuracy:  0.9103013791929168 Loss:  1.3620351633474908 Val_accuracy:  0.8959411604467448 Val_cost:  1.3620351633474908 Val_accuracy:  0.8959411604467448 Val_Acc:  1.5661652201210168\n",
      "Epoch number: 2325/10000step_number: 0/29 Accuracy:  0.9102673250468245 Loss:  1.3614582874083638 Val_accuracy:  0.896077363116317 Val_cost:  1.3614582874083638 Val_accuracy:  0.896077363116317 Val_Acc:  1.5664788359080408\n",
      "Epoch number: 2326/10000step_number: 0/29 Accuracy:  0.9103013791929168 Loss:  1.3607463488708624 Val_accuracy:  0.8958049577771724 Val_cost:  1.3607463488708624 Val_accuracy:  0.8958049577771724 Val_Acc:  1.5667749672646487\n",
      "Epoch number: 2327/10000step_number: 0/29 Accuracy:  0.910335433339009 Loss:  1.359876373101305 Val_accuracy:  0.8955325524380278 Val_cost:  1.359876373101305 Val_accuracy:  0.8955325524380278 Val_Acc:  1.5670369077988076\n",
      "Epoch number: 2328/10000step_number: 0/29 Accuracy:  0.9103694874851013 Loss:  1.3588255536611638 Val_accuracy:  0.8958049577771724 Val_cost:  1.3588255536611638 Val_accuracy:  0.8958049577771724 Val_Acc:  1.567239904729396\n",
      "Epoch number: 2329/10000step_number: 0/29 Accuracy:  0.910335433339009 Loss:  1.3575754632237562 Val_accuracy:  0.896077363116317 Val_cost:  1.3575754632237562 Val_accuracy:  0.896077363116317 Val_Acc:  1.567349792723261\n",
      "Epoch number: 2330/10000step_number: 0/29 Accuracy:  0.9104716499233781 Loss:  1.356120860234214 Val_accuracy:  0.8959411604467448 Val_cost:  1.356120860234214 Val_accuracy:  0.8959411604467448 Val_Acc:  1.5673241884332205\n",
      "Epoch number: 2331/10000step_number: 0/29 Accuracy:  0.9119019240592542 Loss:  1.3544849525899645 Val_accuracy:  0.897303187142468 Val_cost:  1.3544849525899645 Val_accuracy:  0.897303187142468 Val_Acc:  1.5671195833699922\n",
      "Epoch number: 2332/10000step_number: 0/29 Accuracy:  0.9122424655201771 Loss:  1.3527380728073586 Val_accuracy:  0.8981204031599019 Val_cost:  1.3527380728073586 Val_accuracy:  0.8981204031599019 Val_Acc:  1.5667081153376492\n",
      "Epoch number: 2333/10000step_number: 0/29 Accuracy:  0.9135024689255917 Loss:  1.351005400702516 Val_accuracy:  0.8993462271860528 Val_cost:  1.351005400702516 Val_accuracy:  0.8993462271860528 Val_Acc:  1.5661044115855551\n",
      "Epoch number: 2334/10000step_number: 0/29 Accuracy:  0.9134343606334071 Loss:  1.3494397687204587 Val_accuracy:  0.8992100245164806 Val_cost:  1.3494397687204587 Val_accuracy:  0.8992100245164806 Val_Acc:  1.5653893161631354\n",
      "Epoch number: 2335/10000step_number: 0/29 Accuracy:  0.9134684147794994 Loss:  1.3481527415153356 Val_accuracy:  0.8993462271860528 Val_cost:  1.3481527415153356 Val_accuracy:  0.8993462271860528 Val_Acc:  1.5646804162586254\n",
      "Epoch number: 2336/10000step_number: 0/29 Accuracy:  0.9130938191724842 Loss:  1.3471829932576775 Val_accuracy:  0.8986652138381912 Val_cost:  1.3471829932576775 Val_accuracy:  0.8986652138381912 Val_Acc:  1.5640427549363756\n",
      "Epoch number: 2337/10000step_number: 0/29 Accuracy:  0.913059765026392 Loss:  1.3465869929044199 Val_accuracy:  0.8993462271860528 Val_cost:  1.3465869929044199 Val_accuracy:  0.8993462271860528 Val_Acc:  1.5636004638654002\n",
      "Epoch number: 2338/10000step_number: 0/29 Accuracy:  0.9141835518474374 Loss:  1.3464118152131637 Val_accuracy:  0.9004358485426315 Val_cost:  1.3464118152131637 Val_accuracy:  0.9004358485426315 Val_Acc:  1.5635328391222314\n",
      "Epoch number: 2339/10000step_number: 0/29 Accuracy:  0.9131278733185766 Loss:  1.346708428838118 Val_accuracy:  0.8990738218469082 Val_cost:  1.346708428838118 Val_accuracy:  0.8990738218469082 Val_Acc:  1.563613264979103\n",
      "Epoch number: 2340/10000step_number: 0/29 Accuracy:  0.9134684147794994 Loss:  1.3474174790305675 Val_accuracy:  0.8992100245164806 Val_cost:  1.3474174790305675 Val_accuracy:  0.8992100245164806 Val_Acc:  1.5630297383075151\n",
      "Epoch number: 2341/10000step_number: 0/29 Accuracy:  0.9147965264770986 Loss:  1.3489779111354023 Val_accuracy:  0.9004358485426315 Val_cost:  1.3489779111354023 Val_accuracy:  0.9004358485426315 Val_Acc:  1.5614192063863075\n",
      "Epoch number: 2342/10000step_number: 0/29 Accuracy:  0.9150349054997446 Loss:  1.3511904386931346 Val_accuracy:  0.9012530645600654 Val_cost:  1.3511904386931346 Val_accuracy:  0.9012530645600654 Val_Acc:  1.5590883226659342\n",
      "Epoch number: 2343/10000step_number: 0/29 Accuracy:  0.9162949089051592 Loss:  1.3535817369877936 Val_accuracy:  0.9016616725687824 Val_cost:  1.3535817369877936 Val_accuracy:  0.9016616725687824 Val_Acc:  1.5569493538298087\n",
      "Epoch number: 2344/10000step_number: 0/29 Accuracy:  0.918167886940235 Loss:  1.3569651556721405 Val_accuracy:  0.9043857259602288 Val_cost:  1.3569651556721405 Val_accuracy:  0.9043857259602288 Val_Acc:  1.5558370685869196\n",
      "Epoch number: 2345/10000step_number: 0/29 Accuracy:  0.9197003235143879 Loss:  1.3617454814938974 Val_accuracy:  0.9050667393080905 Val_cost:  1.3617454814938974 Val_accuracy:  0.9050667393080905 Val_Acc:  1.5575961241976195\n",
      "Epoch number: 2346/10000step_number: 0/29 Accuracy:  0.9210284352119871 Loss:  1.3685727490513022 Val_accuracy:  0.9064287660038137 Val_cost:  1.3685727490513022 Val_accuracy:  0.9064287660038137 Val_Acc:  1.5624070134068793\n",
      "Epoch number: 2347/10000step_number: 0/29 Accuracy:  0.9226630342244169 Loss:  1.3591609097411226 Val_accuracy:  0.906564968673386 Val_cost:  1.3591609097411226 Val_accuracy:  0.906564968673386 Val_Acc:  1.5618714004895273\n",
      "Epoch number: 2348/10000step_number: 0/29 Accuracy:  0.9198705942448493 Loss:  1.3502484122851555 Val_accuracy:  0.9054753473168075 Val_cost:  1.3502484122851555 Val_accuracy:  0.9054753473168075 Val_Acc:  1.5503484313924056\n",
      "Epoch number: 2349/10000step_number: 0/29 Accuracy:  0.9248084454282309 Loss:  1.3806612666898133 Val_accuracy:  0.9095614274039772 Val_cost:  1.3806612666898133 Val_accuracy:  0.9095614274039772 Val_Acc:  1.5777132112072054\n",
      "Epoch number: 2350/10000step_number: 0/29 Accuracy:  0.9188149157159884 Loss:  1.366450290031326 Val_accuracy:  0.9027512939253609 Val_cost:  1.366450290031326 Val_accuracy:  0.9027512939253609 Val_Acc:  1.573424743383175\n",
      "Epoch number: 2351/10000step_number: 0/29 Accuracy:  0.9276008854077984 Loss:  1.3577267202431693 Val_accuracy:  0.9109234540997003 Val_cost:  1.3577267202431693 Val_accuracy:  0.9109234540997003 Val_Acc:  1.557546067162299\n",
      "Epoch number: 2352/10000step_number: 0/29 Accuracy:  0.9194278903456495 Loss:  1.3469351968780212 Val_accuracy:  0.9050667393080905 Val_cost:  1.3469351968780212 Val_accuracy:  0.9050667393080905 Val_Acc:  1.5450229789581404\n",
      "Epoch number: 2353/10000step_number: 0/29 Accuracy:  0.9207560020432488 Loss:  1.3452371625547803 Val_accuracy:  0.9058839553255243 Val_cost:  1.3452371625547803 Val_accuracy:  0.9058839553255243 Val_Acc:  1.5423923071529564\n",
      "Epoch number: 2354/10000step_number: 0/29 Accuracy:  0.9195300527839264 Loss:  1.346998435696948 Val_accuracy:  0.9062925633342414 Val_cost:  1.346998435696948 Val_accuracy:  0.9062925633342414 Val_Acc:  1.5437697991886108\n",
      "Epoch number: 2355/10000step_number: 0/29 Accuracy:  0.9173846415801123 Loss:  1.348572519841412 Val_accuracy:  0.9041133206210842 Val_cost:  1.348572519841412 Val_accuracy:  0.9041133206210842 Val_Acc:  1.5457189332734007\n",
      "Epoch number: 2356/10000step_number: 0/29 Accuracy:  0.9176570747488507 Loss:  1.3493237282623909 Val_accuracy:  0.9038409152819395 Val_cost:  1.3493237282623909 Val_accuracy:  0.9038409152819395 Val_Acc:  1.5464778109020283\n",
      "Epoch number: 2357/10000step_number: 0/29 Accuracy:  0.9171803167035587 Loss:  1.3497148815474567 Val_accuracy:  0.9035685099427949 Val_cost:  1.3497148815474567 Val_accuracy:  0.9035685099427949 Val_Acc:  1.546821681143657\n",
      "Epoch number: 2358/10000step_number: 0/29 Accuracy:  0.9171122084113741 Loss:  1.3500727153311751 Val_accuracy:  0.9034323072732225 Val_cost:  1.3500727153311751 Val_accuracy:  0.9034323072732225 Val_Acc:  1.5471654211398358\n",
      "Epoch number: 2359/10000step_number: 0/29 Accuracy:  0.917214370849651 Loss:  1.3502772296074694 Val_accuracy:  0.9031599019340779 Val_cost:  1.3502772296074694 Val_accuracy:  0.9031599019340779 Val_Acc:  1.5473768883638452\n",
      "Epoch number: 2360/10000step_number: 0/29 Accuracy:  0.9170441001191895 Loss:  1.3504458531488674 Val_accuracy:  0.9032961046036503 Val_cost:  1.3504458531488674 Val_accuracy:  0.9032961046036503 Val_Acc:  1.547549852107487\n",
      "Epoch number: 2361/10000step_number: 0/29 Accuracy:  0.9170781542652818 Loss:  1.3505555496837611 Val_accuracy:  0.9032961046036503 Val_cost:  1.3505555496837611 Val_accuracy:  0.9032961046036503 Val_Acc:  1.5476708168806002\n",
      "Epoch number: 2362/10000step_number: 0/29 Accuracy:  0.9170441001191895 Loss:  1.3506430761468924 Val_accuracy:  0.9028874965949333 Val_cost:  1.3506430761468924 Val_accuracy:  0.9028874965949333 Val_Acc:  1.547771324477587\n",
      "Epoch number: 2363/10000step_number: 0/29 Accuracy:  0.9169419376809127 Loss:  1.3507077485056442 Val_accuracy:  0.9031599019340779 Val_cost:  1.3507077485056442 Val_accuracy:  0.9031599019340779 Val_Acc:  1.547854614729569\n",
      "Epoch number: 2364/10000step_number: 0/29 Accuracy:  0.9168397752426358 Loss:  1.350758112669576 Val_accuracy:  0.9031599019340779 Val_cost:  1.350758112669576 Val_accuracy:  0.9031599019340779 Val_Acc:  1.5479293355364119\n",
      "Epoch number: 2365/10000step_number: 0/29 Accuracy:  0.9168057210965435 Loss:  1.350796778453721 Val_accuracy:  0.9032961046036503 Val_cost:  1.350796778453721 Val_accuracy:  0.9032961046036503 Val_Acc:  1.5479986945237334\n",
      "Epoch number: 2366/10000step_number: 0/29 Accuracy:  0.9166695045121743 Loss:  1.3508264944236692 Val_accuracy:  0.9032961046036503 Val_cost:  1.3508264944236692 Val_accuracy:  0.9032961046036503 Val_Acc:  1.5480656632173533\n",
      "Epoch number: 2367/10000step_number: 0/29 Accuracy:  0.9177251830410352 Loss:  1.3508491638809905 Val_accuracy:  0.9046581312993734 Val_cost:  1.3508491638809905 Val_accuracy:  0.9046581312993734 Val_Acc:  1.5481321561247121\n",
      "Epoch number: 2368/10000step_number: 0/29 Accuracy:  0.9177592371871275 Loss:  1.3508662424094287 Val_accuracy:  0.9046581312993734 Val_cost:  1.3508662424094287 Val_accuracy:  0.9046581312993734 Val_Acc:  1.5481997051635028\n",
      "Epoch number: 2369/10000step_number: 0/29 Accuracy:  0.9176230206027584 Loss:  1.3508789013464462 Val_accuracy:  0.9046581312993734 Val_cost:  1.3508789013464462 Val_accuracy:  0.9046581312993734 Val_Acc:  1.5482694983141538\n",
      "Epoch number: 2370/10000step_number: 0/29 Accuracy:  0.9176230206027584 Loss:  1.3508880122482452 Val_accuracy:  0.9046581312993734 Val_cost:  1.3508880122482452 Val_accuracy:  0.9046581312993734 Val_Acc:  1.5483424121174842\n",
      "Epoch number: 2371/10000step_number: 0/29 Accuracy:  0.9175549123105738 Loss:  1.3508942424522135 Val_accuracy:  0.9046581312993734 Val_cost:  1.3508942424522135 Val_accuracy:  0.9046581312993734 Val_Acc:  1.5484190589709697\n",
      "Epoch number: 2372/10000step_number: 0/29 Accuracy:  0.9173505874340201 Loss:  1.3508980903507837 Val_accuracy:  0.9046581312993734 Val_cost:  1.3508980903507837 Val_accuracy:  0.9046581312993734 Val_Acc:  1.5484998300057997\n",
      "Epoch number: 2373/10000step_number: 0/29 Accuracy:  0.9173505874340201 Loss:  1.3508999508094612 Val_accuracy:  0.9045219286298012 Val_cost:  1.3508999508094612 Val_accuracy:  0.9045219286298012 Val_Acc:  1.5485849658261341\n",
      "Epoch number: 2374/10000step_number: 0/29 Accuracy:  0.9171462625574663 Loss:  1.3509001708207056 Val_accuracy:  0.9042495232906564 Val_cost:  1.3509001708207056 Val_accuracy:  0.9042495232906564 Val_Acc:  1.5486746154259223\n",
      "Epoch number: 2375/10000step_number: 0/29 Accuracy:  0.9171803167035587 Loss:  1.3508991003305293 Val_accuracy:  0.9042495232906564 Val_cost:  1.3508991003305293 Val_accuracy:  0.9042495232906564 Val_Acc:  1.5487688882293233\n",
      "Epoch number: 2376/10000step_number: 0/29 Accuracy:  0.9172824791418355 Loss:  1.3508971307704045 Val_accuracy:  0.9039771179515118 Val_cost:  1.3508971307704045 Val_accuracy:  0.9039771179515118 Val_Acc:  1.548867891053859\n",
      "Epoch number: 2377/10000step_number: 0/29 Accuracy:  0.917452749872297 Loss:  1.3508947192938277 Val_accuracy:  0.9038409152819395 Val_cost:  1.3508947192938277 Val_accuracy:  0.9038409152819395 Val_Acc:  1.548971754043531\n",
      "Epoch number: 2378/10000step_number: 0/29 Accuracy:  0.917452749872297 Loss:  1.3508923996971802 Val_accuracy:  0.9038409152819395 Val_cost:  1.3508923996971802 Val_accuracy:  0.9038409152819395 Val_Acc:  1.549080650809461\n",
      "Epoch number: 2379/10000step_number: 0/29 Accuracy:  0.9175549123105738 Loss:  1.350890782786282 Val_accuracy:  0.9038409152819395 Val_cost:  1.350890782786282 Val_accuracy:  0.9038409152819395 Val_Acc:  1.549194822210681\n",
      "Epoch number: 2380/10000step_number: 0/29 Accuracy:  0.9176230206027584 Loss:  1.3508905493727363 Val_accuracy:  0.9042495232906564 Val_cost:  1.3508905493727363 Val_accuracy:  0.9042495232906564 Val_Acc:  1.5493146133136524\n",
      "Epoch number: 2381/10000step_number: 0/29 Accuracy:  0.9177251830410352 Loss:  1.3508924382181704 Val_accuracy:  0.9042495232906564 Val_cost:  1.3508924382181704 Val_accuracy:  0.9042495232906564 Val_Acc:  1.549440527121026\n",
      "Epoch number: 2382/10000step_number: 0/29 Accuracy:  0.9178613996254044 Loss:  1.3508972297169417 Val_accuracy:  0.9042495232906564 Val_cost:  1.3508972297169417 Val_accuracy:  0.9042495232906564 Val_Acc:  1.5495732840472924\n",
      "Epoch number: 2383/10000step_number: 0/29 Accuracy:  0.9182700493785119 Loss:  1.3509057256489565 Val_accuracy:  0.9049305366385181 Val_cost:  1.3509057256489565 Val_accuracy:  0.9049305366385181 Val_Acc:  1.549713858087724\n",
      "Epoch number: 2384/10000step_number: 0/29 Accuracy:  0.9184403201089733 Loss:  1.3509187275700283 Val_accuracy:  0.9047943339689458 Val_cost:  1.3509187275700283 Val_accuracy:  0.9047943339689458 Val_Acc:  1.5498634540544296\n",
      "Epoch number: 2385/10000step_number: 0/29 Accuracy:  0.9186786991316193 Loss:  1.3509370213532363 Val_accuracy:  0.9049305366385181 Val_cost:  1.3509370213532363 Val_accuracy:  0.9049305366385181 Val_Acc:  1.5500234116662057\n",
      "Epoch number: 2386/10000step_number: 0/29 Accuracy:  0.9187127532777115 Loss:  1.350961380041486 Val_accuracy:  0.9046581312993734 Val_cost:  1.350961380041486 Val_accuracy:  0.9046581312993734 Val_Acc:  1.550195071982682\n",
      "Epoch number: 2387/10000step_number: 0/29 Accuracy:  0.9188489698620808 Loss:  1.35099259724781 Val_accuracy:  0.9043857259602288 Val_cost:  1.35099259724781 Val_accuracy:  0.9043857259602288 Val_Acc:  1.5503796948130744\n",
      "Epoch number: 2388/10000step_number: 0/29 Accuracy:  0.9181338327941427 Loss:  1.3510315563244484 Val_accuracy:  0.9038409152819395 Val_cost:  1.3510315563244484 Val_accuracy:  0.9038409152819395 Val_Acc:  1.5505785311401787\n",
      "Epoch number: 2389/10000step_number: 0/29 Accuracy:  0.9182019410863272 Loss:  1.3510793256468743 Val_accuracy:  0.9034323072732225 Val_cost:  1.3510793256468743 Val_accuracy:  0.9034323072732225 Val_Acc:  1.550793094082643\n",
      "Epoch number: 2390/10000step_number: 0/29 Accuracy:  0.9180997786480504 Loss:  1.3511372500083563 Val_accuracy:  0.9032961046036503 Val_cost:  1.3511372500083563 Val_accuracy:  0.9032961046036503 Val_Acc:  1.5510255365099463\n",
      "Epoch number: 2391/10000step_number: 0/29 Accuracy:  0.9183381576706964 Loss:  1.351206996558227 Val_accuracy:  0.9037047126123672 Val_cost:  1.351206996558227 Val_accuracy:  0.9037047126123672 Val_Acc:  1.5512789316255466\n",
      "Epoch number: 2392/10000step_number: 0/29 Accuracy:  0.9182359952324195 Loss:  1.351290532824107 Val_accuracy:  0.9037047126123672 Val_cost:  1.351290532824107 Val_accuracy:  0.9037047126123672 Val_Acc:  1.5515573140742756\n",
      "Epoch number: 2393/10000step_number: 0/29 Accuracy:  0.9182019410863272 Loss:  1.351390056686132 Val_accuracy:  0.9038409152819395 Val_cost:  1.351390056686132 Val_accuracy:  0.9038409152819395 Val_Acc:  1.551865549255531\n",
      "Epoch number: 2394/10000step_number: 0/29 Accuracy:  0.918167886940235 Loss:  1.3515079166523472 Val_accuracy:  0.9037047126123672 Val_cost:  1.3515079166523472 Val_accuracy:  0.9037047126123672 Val_Acc:  1.5522092175060203\n",
      "Epoch number: 2395/10000step_number: 0/29 Accuracy:  0.9199046483909415 Loss:  1.3516465357575913 Val_accuracy:  0.9046581312993734 Val_cost:  1.3516465357575913 Val_accuracy:  0.9046581312993734 Val_Acc:  1.5525946163952025\n",
      "Epoch number: 2396/10000step_number: 0/29 Accuracy:  0.9210965435041716 Loss:  1.3518083228412265 Val_accuracy:  0.9053391446472351 Val_cost:  1.3518083228412265 Val_accuracy:  0.9053391446472351 Val_Acc:  1.553028860138746\n",
      "Epoch number: 2397/10000step_number: 0/29 Accuracy:  0.9210284352119871 Loss:  1.3519955474835816 Val_accuracy:  0.9053391446472351 Val_cost:  1.3519955474835816 Val_accuracy:  0.9053391446472351 Val_Acc:  1.553520022566413\n",
      "Epoch number: 2398/10000step_number: 0/29 Accuracy:  0.9211646517963562 Loss:  1.3522101508958784 Val_accuracy:  0.9050667393080905 Val_cost:  1.3522101508958784 Val_accuracy:  0.9050667393080905 Val_Acc:  1.5540772853484195\n",
      "Epoch number: 2399/10000step_number: 0/29 Accuracy:  0.9210965435041716 Loss:  1.352453448198552 Val_accuracy:  0.9050667393080905 Val_cost:  1.352453448198552 Val_accuracy:  0.9050667393080905 Val_Acc:  1.5547110509168633\n",
      "Epoch number: 2400/10000step_number: 0/29 Accuracy:  0.9204495147284182 Loss:  1.352725654231474 Val_accuracy:  0.9049305366385181 Val_cost:  1.352725654231474 Val_accuracy:  0.9049305366385181 Val_Acc:  1.5554329549916925\n",
      "Epoch number: 2401/10000step_number: 0/29 Accuracy:  0.9204495147284182 Loss:  1.3530251444722299 Val_accuracy:  0.9052029419776627 Val_cost:  1.3530251444722299 Val_accuracy:  0.9052029419776627 Val_Acc:  1.5562556778485233\n",
      "Epoch number: 2402/10000step_number: 0/29 Accuracy:  0.9203473522901413 Loss:  1.3533473468274122 Val_accuracy:  0.9049305366385181 Val_cost:  1.3533473468274122 Val_accuracy:  0.9049305366385181 Val_Acc:  1.5571924029523083\n",
      "Epoch number: 2403/10000step_number: 0/29 Accuracy:  0.9210284352119871 Loss:  1.3536831493942822 Val_accuracy:  0.9046581312993734 Val_cost:  1.3536831493942822 Val_accuracy:  0.9046581312993734 Val_Acc:  1.558255687528734\n",
      "Epoch number: 2404/10000step_number: 0/29 Accuracy:  0.921130597650264 Loss:  1.354016702072317 Val_accuracy:  0.9046581312993734 Val_cost:  1.354016702072317 Val_accuracy:  0.9046581312993734 Val_Acc:  1.5594553531675182\n",
      "Epoch number: 2405/10000step_number: 0/29 Accuracy:  0.9214030308190022 Loss:  1.3543224629308817 Val_accuracy:  0.9049305366385181 Val_cost:  1.3543224629308817 Val_accuracy:  0.9049305366385181 Val_Acc:  1.5607947074056652\n",
      "Epoch number: 2406/10000step_number: 0/29 Accuracy:  0.9207560020432488 Loss:  1.3545612143304369 Val_accuracy:  0.9043857259602288 Val_cost:  1.3545612143304369 Val_accuracy:  0.9043857259602288 Val_Acc:  1.562263880328456\n",
      "Epoch number: 2407/10000step_number: 0/29 Accuracy:  0.9206878937510642 Loss:  1.3546745785622976 Val_accuracy:  0.9042495232906564 Val_cost:  1.3546745785622976 Val_accuracy:  0.9042495232906564 Val_Acc:  1.56382844536261\n",
      "Epoch number: 2408/10000step_number: 0/29 Accuracy:  0.9210965435041716 Loss:  1.3545792807728654 Val_accuracy:  0.9041133206210842 Val_cost:  1.3545792807728654 Val_accuracy:  0.9041133206210842 Val_Acc:  1.5654128626698534\n",
      "Epoch number: 2409/10000step_number: 0/29 Accuracy:  0.9207560020432488 Loss:  1.354171390429609 Val_accuracy:  0.9043857259602288 Val_cost:  1.354171390429609 Val_accuracy:  0.9043857259602288 Val_Acc:  1.5668867527318049\n",
      "Epoch number: 2410/10000step_number: 0/29 Accuracy:  0.9206197854588796 Loss:  1.353344557401938 Val_accuracy:  0.9045219286298012 Val_cost:  1.353344557401938 Val_accuracy:  0.9045219286298012 Val_Acc:  1.5680604030032554\n",
      "Epoch number: 2411/10000step_number: 0/29 Accuracy:  0.9204835688745104 Loss:  1.3519939716556983 Val_accuracy:  0.9042495232906564 Val_cost:  1.3519939716556983 Val_accuracy:  0.9042495232906564 Val_Acc:  1.5686676160944881\n",
      "Epoch number: 2412/10000step_number: 0/29 Accuracy:  0.9202792439979568 Loss:  1.3500446306159748 Val_accuracy:  0.9035685099427949 Val_cost:  1.3500446306159748 Val_accuracy:  0.9035685099427949 Val_Acc:  1.5683577437721303\n",
      "Epoch number: 2413/10000step_number: 0/29 Accuracy:  0.9199387025370339 Loss:  1.347541521488748 Val_accuracy:  0.9034323072732225 Val_cost:  1.347541521488748 Val_accuracy:  0.9034323072732225 Val_Acc:  1.5667342181796151\n",
      "Epoch number: 2414/10000step_number: 0/29 Accuracy:  0.9201430274135876 Loss:  1.344683245596744 Val_accuracy:  0.9037047126123672 Val_cost:  1.344683245596744 Val_accuracy:  0.9037047126123672 Val_Acc:  1.5633320101102057\n",
      "Epoch number: 2415/10000step_number: 0/29 Accuracy:  0.9208581644815256 Loss:  1.3417791878936967 Val_accuracy:  0.9042495232906564 Val_cost:  1.3417791878936967 Val_accuracy:  0.9042495232906564 Val_Acc:  1.5576573135851328\n",
      "Epoch number: 2416/10000step_number: 0/29 Accuracy:  0.921845734718202 Loss:  1.33986966546738 Val_accuracy:  0.9046581312993734 Val_cost:  1.33986966546738 Val_accuracy:  0.9046581312993734 Val_Acc:  1.5505778430577202\n",
      "Epoch number: 2417/10000step_number: 0/29 Accuracy:  0.9215051932572791 Loss:  1.3405931306862373 Val_accuracy:  0.9032961046036503 Val_cost:  1.3405931306862373 Val_accuracy:  0.9032961046036503 Val_Acc:  1.54582946152043\n",
      "Epoch number: 2418/10000step_number: 0/29 Accuracy:  0.9205176230206028 Loss:  1.3428073392871056 Val_accuracy:  0.9027512939253609 Val_cost:  1.3428073392871056 Val_accuracy:  0.9027512939253609 Val_Acc:  1.5448157007686598\n",
      "Epoch number: 2419/10000step_number: 0/29 Accuracy:  0.919121403030819 Loss:  1.3447052698621569 Val_accuracy:  0.9037047126123672 Val_cost:  1.3447052698621569 Val_accuracy:  0.9037047126123672 Val_Acc:  1.5450465262824982\n",
      "Epoch number: 2420/10000step_number: 0/29 Accuracy:  0.917452749872297 Loss:  1.3458377264438506 Val_accuracy:  0.9034323072732225 Val_cost:  1.3458377264438506 Val_accuracy:  0.9034323072732225 Val_Acc:  1.5455137215721066\n",
      "Epoch number: 2421/10000step_number: 0/29 Accuracy:  0.9161927464668823 Loss:  1.3463755483783817 Val_accuracy:  0.9022064832470716 Val_cost:  1.3463755483783817 Val_accuracy:  0.9022064832470716 Val_Acc:  1.546126201353278\n",
      "Epoch number: 2422/10000step_number: 0/29 Accuracy:  0.9163289630512514 Loss:  1.346565289503345 Val_accuracy:  0.902342685916644 Val_cost:  1.346565289503345 Val_accuracy:  0.902342685916644 Val_Acc:  1.5467118788464813\n",
      "Epoch number: 2423/10000step_number: 0/29 Accuracy:  0.9161586923207901 Loss:  1.346580705953369 Val_accuracy:  0.9020702805774993 Val_cost:  1.346580705953369 Val_accuracy:  0.9020702805774993 Val_Acc:  1.5472114925368436\n",
      "Epoch number: 2424/10000step_number: 0/29 Accuracy:  0.9161246381746978 Loss:  1.3465555319107954 Val_accuracy:  0.902342685916644 Val_cost:  1.3465555319107954 Val_accuracy:  0.902342685916644 Val_Acc:  1.5476806804573617\n",
      "Epoch number: 2425/10000step_number: 0/29 Accuracy:  0.9163970713434361 Loss:  1.3465136652585694 Val_accuracy:  0.9027512939253609 Val_cost:  1.3465136652585694 Val_accuracy:  0.9027512939253609 Val_Acc:  1.5481220651706646\n",
      "Epoch number: 2426/10000step_number: 0/29 Accuracy:  0.9166013962199898 Loss:  1.3464655541588673 Val_accuracy:  0.9028874965949333 Val_cost:  1.3464655541588673 Val_accuracy:  0.9028874965949333 Val_Acc:  1.5485420176121707\n",
      "Epoch number: 2427/10000step_number: 0/29 Accuracy:  0.9165673420738975 Loss:  1.346411465349069 Val_accuracy:  0.9026150912557886 Val_cost:  1.346411465349069 Val_accuracy:  0.9026150912557886 Val_Acc:  1.548941545337315\n",
      "Epoch number: 2428/10000step_number: 0/29 Accuracy:  0.9166354503660821 Loss:  1.346353254828866 Val_accuracy:  0.9022064832470716 Val_cost:  1.346353254828866 Val_accuracy:  0.9022064832470716 Val_Acc:  1.5493216571717805\n",
      "Epoch number: 2429/10000step_number: 0/29 Accuracy:  0.9165673420738975 Loss:  1.3462915305673682 Val_accuracy:  0.9024788885862163 Val_cost:  1.3462915305673682 Val_accuracy:  0.9024788885862163 Val_Acc:  1.5496837689264964\n",
      "Epoch number: 2430/10000step_number: 0/29 Accuracy:  0.9165332879278052 Loss:  1.34622772910822 Val_accuracy:  0.902342685916644 Val_cost:  1.34622772910822 Val_accuracy:  0.902342685916644 Val_Acc:  1.5500294219536987\n",
      "Epoch number: 2431/10000step_number: 0/29 Accuracy:  0.9164992337817129 Loss:  1.3461632667750814 Val_accuracy:  0.9022064832470716 Val_cost:  1.3461632667750814 Val_accuracy:  0.9022064832470716 Val_Acc:  1.5503594585467642\n",
      "Epoch number: 2432/10000step_number: 0/29 Accuracy:  0.9164651796356207 Loss:  1.3460994530827997 Val_accuracy:  0.901934077907927 Val_cost:  1.3460994530827997 Val_accuracy:  0.901934077907927 Val_Acc:  1.5506740395428067\n",
      "Epoch number: 2433/10000step_number: 0/29 Accuracy:  0.9163970713434361 Loss:  1.3460372630848665 Val_accuracy:  0.9020702805774993 Val_cost:  1.3460372630848665 Val_accuracy:  0.9020702805774993 Val_Acc:  1.5509727726247853\n",
      "Epoch number: 2434/10000step_number: 0/29 Accuracy:  0.9165673420738975 Loss:  1.3459772758215107 Val_accuracy:  0.9020702805774993 Val_cost:  1.3459772758215107 Val_accuracy:  0.9020702805774993 Val_Acc:  1.5512547974877486\n",
      "Epoch number: 2435/10000step_number: 0/29 Accuracy:  0.9164651796356207 Loss:  1.3459196693384792 Val_accuracy:  0.9020702805774993 Val_cost:  1.3459196693384792 Val_accuracy:  0.9020702805774993 Val_Acc:  1.5515189524144823\n",
      "Epoch number: 2436/10000step_number: 0/29 Accuracy:  0.9166013962199898 Loss:  1.3458642901033642 Val_accuracy:  0.9020702805774993 Val_cost:  1.3458642901033642 Val_accuracy:  0.9020702805774993 Val_Acc:  1.5517639007152275\n",
      "Epoch number: 2437/10000step_number: 0/29 Accuracy:  0.9167035586582667 Loss:  1.3458107641881407 Val_accuracy:  0.9022064832470716 Val_cost:  1.3458107641881407 Val_accuracy:  0.9022064832470716 Val_Acc:  1.551988246840727\n",
      "Epoch number: 2438/10000step_number: 0/29 Accuracy:  0.9165673420738975 Loss:  1.3457586182220276 Val_accuracy:  0.9024788885862163 Val_cost:  1.3457586182220276 Val_accuracy:  0.9024788885862163 Val_Acc:  1.5521906538018646\n",
      "Epoch number: 2439/10000step_number: 0/29 Accuracy:  0.916737612804359 Loss:  1.3457073676375835 Val_accuracy:  0.9027512939253609 Val_cost:  1.3457073676375835 Val_accuracy:  0.9027512939253609 Val_Acc:  1.5523699745947839\n",
      "Epoch number: 2440/10000step_number: 0/29 Accuracy:  0.9169419376809127 Loss:  1.3456565589603815 Val_accuracy:  0.9028874965949333 Val_cost:  1.3456565589603815 Val_accuracy:  0.9028874965949333 Val_Acc:  1.5525253931668663\n",
      "Epoch number: 2441/10000step_number: 0/29 Accuracy:  0.9170100459730972 Loss:  1.3456057842113684 Val_accuracy:  0.9031599019340779 Val_cost:  1.3456057842113684 Val_accuracy:  0.9031599019340779 Val_Acc:  1.5526565588955874\n",
      "Epoch number: 2442/10000step_number: 0/29 Accuracy:  0.9170781542652818 Loss:  1.3455546957012714 Val_accuracy:  0.9031599019340779 Val_cost:  1.3455546957012714 Val_accuracy:  0.9031599019340779 Val_Acc:  1.552763688070882\n",
      "Epoch number: 2443/10000step_number: 0/29 Accuracy:  0.917214370849651 Loss:  1.345503034959676 Val_accuracy:  0.9032961046036503 Val_cost:  1.345503034959676 Val_accuracy:  0.9032961046036503 Val_Acc:  1.5528476070548611\n",
      "Epoch number: 2444/10000step_number: 0/29 Accuracy:  0.9171462625574663 Loss:  1.3454506702301892 Val_accuracy:  0.9030236992645055 Val_cost:  1.3454506702301892 Val_accuracy:  0.9030236992645055 Val_Acc:  1.5529097233607592\n",
      "Epoch number: 2445/10000step_number: 0/29 Accuracy:  0.9170781542652818 Loss:  1.3453976300611898 Val_accuracy:  0.9030236992645055 Val_cost:  1.3453976300611898 Val_accuracy:  0.9030236992645055 Val_Acc:  1.5529519307530015\n",
      "Epoch number: 2446/10000step_number: 0/29 Accuracy:  0.9171462625574663 Loss:  1.3453441249715186 Val_accuracy:  0.9030236992645055 Val_cost:  1.3453441249715186 Val_accuracy:  0.9030236992645055 Val_Acc:  1.552976474088993\n",
      "Epoch number: 2447/10000step_number: 0/29 Accuracy:  0.9171803167035587 Loss:  1.345290553977993 Val_accuracy:  0.9030236992645055 Val_cost:  1.345290553977993 Val_accuracy:  0.9030236992645055 Val_Acc:  1.5529858071277827\n",
      "Epoch number: 2448/10000step_number: 0/29 Accuracy:  0.917214370849651 Loss:  1.345237493701344 Val_accuracy:  0.9027512939253609 Val_cost:  1.345237493701344 Val_accuracy:  0.9027512939253609 Val_Acc:  1.552982467632897\n",
      "Epoch number: 2449/10000step_number: 0/29 Accuracy:  0.9174186957262047 Loss:  1.3451856687091712 Val_accuracy:  0.9027512939253609 Val_cost:  1.3451856687091712 Val_accuracy:  0.9027512939253609 Val_Acc:  1.5529689776000366\n",
      "Epoch number: 2450/10000step_number: 0/29 Accuracy:  0.9179976162097735 Loss:  1.3451359048073919 Val_accuracy:  0.9032961046036503 Val_cost:  1.3451359048073919 Val_accuracy:  0.9032961046036503 Val_Acc:  1.5529477641456364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Burak\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py:59: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Burak\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py:59: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 2451/10000step_number: 0/29 Accuracy:  0.9182359952324195 Loss:  1.3450890699737774 Val_accuracy:  0.9039771179515118 Val_cost:  1.3450890699737774 Val_accuracy:  0.9039771179515118 Val_Acc:  1.552921092552804\n",
      "Epoch number: 2452/10000step_number: 0/29 Accuracy:  0.9180997786480504 Loss:  1.345046009167702 Val_accuracy:  0.9039771179515118 Val_cost:  1.345046009167702 Val_accuracy:  0.9039771179515118 Val_Acc:  1.5528910051936522\n",
      "Epoch number: 2453/10000step_number: 0/29 Accuracy:  0.9180997786480504 Loss:  1.3450074801183953 Val_accuracy:  0.9037047126123672 Val_cost:  1.3450074801183953 Val_accuracy:  0.9037047126123672 Val_Acc:  1.5528592651629205\n",
      "Epoch number: 2454/10000step_number: 0/29 Accuracy:  0.9180316703558659 Loss:  1.344974097900086 Val_accuracy:  0.9039771179515118 Val_cost:  1.344974097900086 Val_accuracy:  0.9039771179515118 Val_Acc:  1.5528273090420368\n",
      "Epoch number: 2455/10000step_number: 0/29 Accuracy:  0.9180657245019581 Loss:  1.344946296128211 Val_accuracy:  0.9042495232906564 Val_cost:  1.344946296128211 Val_accuracy:  0.9042495232906564 Val_Acc:  1.5527962171122431\n",
      "Epoch number: 2456/10000step_number: 0/29 Accuracy:  0.918167886940235 Loss:  1.3449243111987734 Val_accuracy:  0.9043857259602288 Val_cost:  1.3449243111987734 Val_accuracy:  0.9043857259602288 Val_Acc:  1.5527667096873572\n",
      "Epoch number: 2457/10000step_number: 0/29 Accuracy:  0.9182359952324195 Loss:  1.3449081925918562 Val_accuracy:  0.9043857259602288 Val_cost:  1.3449081925918562 Val_accuracy:  0.9043857259602288 Val_Acc:  1.5527391742017196\n",
      "Epoch number: 2458/10000step_number: 0/29 Accuracy:  0.9182700493785119 Loss:  1.3448978370096893 Val_accuracy:  0.9041133206210842 Val_cost:  1.3448978370096893 Val_accuracy:  0.9041133206210842 Val_Acc:  1.552713720432323\n",
      "Epoch number: 2459/10000step_number: 0/29 Accuracy:  0.9184743742550655 Loss:  1.3448930385874425 Val_accuracy:  0.9042495232906564 Val_cost:  1.3448930385874425 Val_accuracy:  0.9042495232906564 Val_Acc:  1.55269025410983\n",
      "Epoch number: 2460/10000step_number: 0/29 Accuracy:  0.9184743742550655 Loss:  1.3448935441497192 Val_accuracy:  0.9041133206210842 Val_cost:  1.3448935441497192 Val_accuracy:  0.9041133206210842 Val_Acc:  1.5526685554979134\n",
      "Epoch number: 2461/10000step_number: 0/29 Accuracy:  0.9184743742550655 Loss:  1.344899103076162 Val_accuracy:  0.9041133206210842 Val_cost:  1.344899103076162 Val_accuracy:  0.9041133206210842 Val_Acc:  1.5526483508031348\n",
      "Epoch number: 2462/10000step_number: 0/29 Accuracy:  0.918406265962881 Loss:  1.344909505058115 Val_accuracy:  0.9041133206210842 Val_cost:  1.344909505058115 Val_accuracy:  0.9041133206210842 Val_Acc:  1.5526293689334205\n",
      "Epoch number: 2463/10000step_number: 0/29 Accuracy:  0.9185765366933424 Loss:  1.3449246035848583 Val_accuracy:  0.9043857259602288 Val_cost:  1.3449246035848583 Val_accuracy:  0.9043857259602288 Val_Acc:  1.552611381433597\n",
      "Epoch number: 2464/10000step_number: 0/29 Accuracy:  0.9185424825472501 Loss:  1.3449443263604501 Val_accuracy:  0.9046581312993734 Val_cost:  1.3449443263604501 Val_accuracy:  0.9046581312993734 Val_Acc:  1.5525942272100586\n",
      "Epoch number: 2465/10000step_number: 0/29 Accuracy:  0.9186105908394347 Loss:  1.344968675289155 Val_accuracy:  0.9050667393080905 Val_cost:  1.344968675289155 Val_accuracy:  0.9050667393080905 Val_Acc:  1.5525778253613784\n",
      "Epoch number: 2466/10000step_number: 0/29 Accuracy:  0.917452749872297 Loss:  1.3449977185411122 Val_accuracy:  0.9041133206210842 Val_cost:  1.3449977185411122 Val_accuracy:  0.9041133206210842 Val_Acc:  1.552562179531198\n",
      "Epoch number: 2467/10000step_number: 0/29 Accuracy:  0.9175549123105738 Loss:  1.3450315762760525 Val_accuracy:  0.9045219286298012 Val_cost:  1.3450315762760525 Val_accuracy:  0.9045219286298012 Val_Acc:  1.5525473765617452\n",
      "Epoch number: 2468/10000step_number: 0/29 Accuracy:  0.9178273454793121 Loss:  1.3450704005281242 Val_accuracy:  0.9045219286298012 Val_cost:  1.3450704005281242 Val_accuracy:  0.9045219286298012 Val_Acc:  1.5525335814314372\n",
      "Epoch number: 2469/10000step_number: 0/29 Accuracy:  0.9178273454793121 Loss:  1.3451143489809159 Val_accuracy:  0.9042495232906564 Val_cost:  1.3451143489809159 Val_accuracy:  0.9042495232906564 Val_Acc:  1.5525210298389251\n",
      "Epoch number: 2470/10000step_number: 0/29 Accuracy:  0.9178954537714967 Loss:  1.3451635521168785 Val_accuracy:  0.9041133206210842 Val_cost:  1.3451635521168785 Val_accuracy:  0.9041133206210842 Val_Acc:  1.5525100193792887\n",
      "Epoch number: 2471/10000step_number: 0/29 Accuracy:  0.9179635620636812 Loss:  1.345218073517256 Val_accuracy:  0.9041133206210842 Val_cost:  1.345218073517256 Val_accuracy:  0.9041133206210842 Val_Acc:  1.5525009000495777\n",
      "Epoch number: 2472/10000step_number: 0/29 Accuracy:  0.9180657245019581 Loss:  1.345277863666018 Val_accuracy:  0.9041133206210842 Val_cost:  1.345277863666018 Val_accuracy:  0.9041133206210842 Val_Acc:  1.5524940646851955\n",
      "Epoch number: 2473/10000step_number: 0/29 Accuracy:  0.9182019410863272 Loss:  1.3453427080301823 Val_accuracy:  0.9042495232906564 Val_cost:  1.3453427080301823 Val_accuracy:  0.9042495232906564 Val_Acc:  1.552489939923316\n",
      "Epoch number: 2474/10000step_number: 0/29 Accuracy:  0.9182359952324195 Loss:  1.3454121702076263 Val_accuracy:  0.9042495232906564 Val_cost:  1.3454121702076263 Val_accuracy:  0.9042495232906564 Val_Acc:  1.5524889786173668\n",
      "Epoch number: 2475/10000step_number: 0/29 Accuracy:  0.9181338327941427 Loss:  1.345485531489052 Val_accuracy:  0.9042495232906564 Val_cost:  1.345485531489052 Val_accuracy:  0.9042495232906564 Val_Acc:  1.552491656535139\n",
      "Epoch number: 2476/10000step_number: 0/29 Accuracy:  0.9183722118167887 Loss:  1.3455617330625695 Val_accuracy:  0.9045219286298012 Val_cost:  1.3455617330625695 Val_accuracy:  0.9045219286298012 Val_Acc:  1.552498481449021\n",
      "Epoch number: 2477/10000step_number: 0/29 Accuracy:  0.9184403201089733 Loss:  1.3456393442786112 Val_accuracy:  0.9042495232906564 Val_cost:  1.3456393442786112 Val_accuracy:  0.9042495232906564 Val_Acc:  1.552510033732963\n",
      "Epoch number: 2478/10000step_number: 0/29 Accuracy:  0.9186105908394347 Loss:  1.3457166167742434 Val_accuracy:  0.9045219286298012 Val_cost:  1.3457166167742434 Val_accuracy:  0.9045219286298012 Val_Acc:  1.5525270705372318\n",
      "Epoch number: 2479/10000step_number: 0/29 Accuracy:  0.9185424825472501 Loss:  1.3457917165506479 Val_accuracy:  0.9045219286298012 Val_cost:  1.3457917165506479 Val_accuracy:  0.9045219286298012 Val_Acc:  1.5525507130668956\n",
      "Epoch number: 2480/10000step_number: 0/29 Accuracy:  0.9186786991316193 Loss:  1.345863148445958 Val_accuracy:  0.9046581312993734 Val_cost:  1.345863148445958 Val_accuracy:  0.9046581312993734 Val_Acc:  1.5525826315636797\n",
      "Epoch number: 2481/10000step_number: 0/29 Accuracy:  0.9187808615698961 Loss:  1.3459300839301862 Val_accuracy:  0.9047943339689458 Val_cost:  1.3459300839301862 Val_accuracy:  0.9047943339689458 Val_Acc:  1.5526249328300492\n",
      "Epoch number: 2482/10000step_number: 0/29 Accuracy:  0.9189170781542653 Loss:  1.3459920742253095 Val_accuracy:  0.9045219286298012 Val_cost:  1.3459920742253095 Val_accuracy:  0.9045219286298012 Val_Acc:  1.552679456201793\n",
      "Epoch number: 2483/10000step_number: 0/29 Accuracy:  0.9190532947386344 Loss:  1.3460482128420517 Val_accuracy:  0.9046581312993734 Val_cost:  1.3460482128420517 Val_accuracy:  0.9046581312993734 Val_Acc:  1.5527468305039853\n",
      "Epoch number: 2484/10000step_number: 0/29 Accuracy:  0.9190192405925421 Loss:  1.346096719459436 Val_accuracy:  0.9047943339689458 Val_cost:  1.346096719459436 Val_accuracy:  0.9047943339689458 Val_Acc:  1.5528262149225542\n",
      "Epoch number: 2485/10000step_number: 0/29 Accuracy:  0.9189170781542653 Loss:  1.3461354585395657 Val_accuracy:  0.9047943339689458 Val_cost:  1.3461354585395657 Val_accuracy:  0.9047943339689458 Val_Acc:  1.5529158916748584\n",
      "Epoch number: 2486/10000step_number: 0/29 Accuracy:  0.9189511323003575 Loss:  1.3461627984976117 Val_accuracy:  0.9049305366385181 Val_cost:  1.3461627984976117 Val_accuracy:  0.9049305366385181 Val_Acc:  1.5530139565014536\n",
      "Epoch number: 2487/10000step_number: 0/29 Accuracy:  0.919121403030819 Loss:  1.3461782159099742 Val_accuracy:  0.9053391446472351 Val_cost:  1.3461782159099742 Val_accuracy:  0.9053391446472351 Val_Acc:  1.5531187023961086\n",
      "Epoch number: 2488/10000step_number: 0/29 Accuracy:  0.9193257279073728 Loss:  1.3461825258867917 Val_accuracy:  0.9052029419776627 Val_cost:  1.3461825258867917 Val_accuracy:  0.9052029419776627 Val_Acc:  1.553228827445847\n",
      "Epoch number: 2489/10000step_number: 0/29 Accuracy:  0.9193257279073728 Loss:  1.3461777979535503 Val_accuracy:  0.9052029419776627 Val_cost:  1.3461777979535503 Val_accuracy:  0.9052029419776627 Val_Acc:  1.5533435821497963\n",
      "Epoch number: 2490/10000step_number: 0/29 Accuracy:  0.9192916737612804 Loss:  1.3461670222860904 Val_accuracy:  0.9050667393080905 Val_cost:  1.3461670222860904 Val_accuracy:  0.9050667393080905 Val_Acc:  1.5534628199538305\n",
      "Epoch number: 2491/10000step_number: 0/29 Accuracy:  0.9192916737612804 Loss:  1.3461536061672033 Val_accuracy:  0.9053391446472351 Val_cost:  1.3461536061672033 Val_accuracy:  0.9053391446472351 Val_Acc:  1.5535868768384313\n",
      "Epoch number: 2492/10000step_number: 0/29 Accuracy:  0.9194278903456495 Loss:  1.3461408484000525 Val_accuracy:  0.9054753473168075 Val_cost:  1.3461408484000525 Val_accuracy:  0.9054753473168075 Val_Acc:  1.5537162837481637\n",
      "Epoch number: 2493/10000step_number: 0/29 Accuracy:  0.9194619444917419 Loss:  1.3461315717190792 Val_accuracy:  0.9054753473168075 Val_cost:  1.3461315717190792 Val_accuracy:  0.9054753473168075 Val_Acc:  1.5538514377528336\n",
      "Epoch number: 2494/10000step_number: 0/29 Accuracy:  0.9194619444917419 Loss:  1.3461280049278557 Val_accuracy:  0.9056115499863797 Val_cost:  1.3461280049278557 Val_accuracy:  0.9056115499863797 Val_Acc:  1.553992401717544\n",
      "Epoch number: 2495/10000step_number: 0/29 Accuracy:  0.9187127532777115 Loss:  1.3461318496461694 Val_accuracy:  0.9050667393080905 Val_cost:  1.3461318496461694 Val_accuracy:  0.9050667393080905 Val_Acc:  1.5541388995809287\n",
      "Epoch number: 2496/10000step_number: 0/29 Accuracy:  0.9185084284011579 Loss:  1.3461443836934446 Val_accuracy:  0.9052029419776627 Val_cost:  1.3461443836934446 Val_accuracy:  0.9052029419776627 Val_Acc:  1.554290420338297\n",
      "Epoch number: 2497/10000step_number: 0/29 Accuracy:  0.9174186957262047 Loss:  1.3461665045413373 Val_accuracy:  0.9038409152819395 Val_cost:  1.3461665045413373 Val_accuracy:  0.9038409152819395 Val_Acc:  1.5544462960281757\n",
      "Epoch number: 2498/10000step_number: 0/29 Accuracy:  0.917214370849651 Loss:  1.3461987220661729 Val_accuracy:  0.9037047126123672 Val_cost:  1.3461987220661729 Val_accuracy:  0.9037047126123672 Val_Acc:  1.5546057015079813\n",
      "Epoch number: 2499/10000step_number: 0/29 Accuracy:  0.9171462625574663 Loss:  1.3462411638295007 Val_accuracy:  0.9032961046036503 Val_cost:  1.3462411638295007 Val_accuracy:  0.9032961046036503 Val_Acc:  1.5547676227530087\n",
      "Epoch number: 2500/10000step_number: 0/29 Accuracy:  0.9171462625574663 Loss:  1.346293633327864 Val_accuracy:  0.9034323072732225 Val_cost:  1.346293633327864 Val_accuracy:  0.9034323072732225 Val_Acc:  1.5549308629663285\n",
      "Epoch number: 2501/10000step_number: 0/29 Accuracy:  0.9171803167035587 Loss:  1.3463557097211376 Val_accuracy:  0.9032961046036503 Val_cost:  1.3463557097211376 Val_accuracy:  0.9032961046036503 Val_Acc:  1.555094113141253\n",
      "Epoch number: 2502/10000step_number: 0/29 Accuracy:  0.9170781542652818 Loss:  1.346426844483257 Val_accuracy:  0.9034323072732225 Val_cost:  1.346426844483257 Val_accuracy:  0.9034323072732225 Val_Acc:  1.5552560642564544\n",
      "Epoch number: 2503/10000step_number: 0/29 Accuracy:  0.916975991827005 Loss:  1.346506397255112 Val_accuracy:  0.9035685099427949 Val_cost:  1.346506397255112 Val_accuracy:  0.9035685099427949 Val_Acc:  1.5554155103432423\n",
      "Epoch number: 2504/10000step_number: 0/29 Accuracy:  0.9168738293887281 Loss:  1.3465935441614605 Val_accuracy:  0.9037047126123672 Val_cost:  1.3465935441614605 Val_accuracy:  0.9037047126123672 Val_Acc:  1.5555713786960437\n",
      "Epoch number: 2505/10000step_number: 0/29 Accuracy:  0.9168057210965435 Loss:  1.3466870215525342 Val_accuracy:  0.9035685099427949 Val_cost:  1.3466870215525342 Val_accuracy:  0.9035685099427949 Val_Acc:  1.5557226371261639\n",
      "Epoch number: 2506/10000step_number: 0/29 Accuracy:  0.9168738293887281 Loss:  1.346784785456162 Val_accuracy:  0.9034323072732225 Val_cost:  1.346784785456162 Val_accuracy:  0.9034323072732225 Val_Acc:  1.5558681080515167\n",
      "Epoch number: 2507/10000step_number: 0/29 Accuracy:  0.916975991827005 Loss:  1.346883794211156 Val_accuracy:  0.9032961046036503 Val_cost:  1.346883794211156 Val_accuracy:  0.9032961046036503 Val_Acc:  1.5560063304469796\n",
      "Epoch number: 2508/10000step_number: 0/29 Accuracy:  0.9167716669504512 Loss:  1.346980109933722 Val_accuracy:  0.9034323072732225 Val_cost:  1.346980109933722 Val_accuracy:  0.9034323072732225 Val_Acc:  1.5561356094272647\n",
      "Epoch number: 2509/10000step_number: 0/29 Accuracy:  0.9166354503660821 Loss:  1.3470693422740092 Val_accuracy:  0.9034323072732225 Val_cost:  1.3470693422740092 Val_accuracy:  0.9034323072732225 Val_Acc:  1.5562542257586334\n",
      "Epoch number: 2510/10000step_number: 0/29 Accuracy:  0.9165673420738975 Loss:  1.3471471948209697 Val_accuracy:  0.9034323072732225 Val_cost:  1.3471471948209697 Val_accuracy:  0.9034323072732225 Val_Acc:  1.5563606048059633\n",
      "Epoch number: 2511/10000step_number: 0/29 Accuracy:  0.9166354503660821 Loss:  1.3472097493095172 Val_accuracy:  0.9032961046036503 Val_cost:  1.3472097493095172 Val_accuracy:  0.9032961046036503 Val_Acc:  1.5564532732981393\n",
      "Epoch number: 2512/10000step_number: 0/29 Accuracy:  0.9166695045121743 Loss:  1.347253426562218 Val_accuracy:  0.9032961046036503 Val_cost:  1.347253426562218 Val_accuracy:  0.9032961046036503 Val_Acc:  1.5565306939501466\n",
      "Epoch number: 2513/10000step_number: 0/29 Accuracy:  0.9168057210965435 Loss:  1.3472751819056066 Val_accuracy:  0.9032961046036503 Val_cost:  1.3472751819056066 Val_accuracy:  0.9032961046036503 Val_Acc:  1.556591400283556\n",
      "Epoch number: 2514/10000step_number: 0/29 Accuracy:  0.916737612804359 Loss:  1.3472738013081158 Val_accuracy:  0.9032961046036503 Val_cost:  1.3472738013081158 Val_accuracy:  0.9032961046036503 Val_Acc:  1.5566349384729774\n",
      "Epoch number: 2515/10000step_number: 0/29 Accuracy:  0.9163630171973438 Loss:  1.3472521779868412 Val_accuracy:  0.9030236992645055 Val_cost:  1.3472521779868412 Val_accuracy:  0.9030236992645055 Val_Acc:  1.5566633566261994\n",
      "Epoch number: 2516/10000step_number: 0/29 Accuracy:  0.9163970713434361 Loss:  1.3472190781068123 Val_accuracy:  0.9028874965949333 Val_cost:  1.3472190781068123 Val_accuracy:  0.9028874965949333 Val_Acc:  1.5566818996917955\n",
      "Epoch number: 2517/10000step_number: 0/29 Accuracy:  0.9162949089051592 Loss:  1.3471903964291463 Val_accuracy:  0.9024788885862163 Val_cost:  1.3471903964291463 Val_accuracy:  0.9024788885862163 Val_Acc:  1.556699219318606\n",
      "Epoch number: 2518/10000step_number: 0/29 Accuracy:  0.9162949089051592 Loss:  1.347185711609648 Val_accuracy:  0.9024788885862163 Val_cost:  1.347185711609648 Val_accuracy:  0.9024788885862163 Val_Acc:  1.5567266209898416\n",
      "Epoch number: 2519/10000step_number: 0/29 Accuracy:  0.9170441001191895 Loss:  1.3472135901866746 Val_accuracy:  0.9030236992645055 Val_cost:  1.3472135901866746 Val_accuracy:  0.9030236992645055 Val_Acc:  1.556771608764757\n",
      "Epoch number: 2520/10000step_number: 0/29 Accuracy:  0.9171122084113741 Loss:  1.3472651778717737 Val_accuracy:  0.9031599019340779 Val_cost:  1.3472651778717737 Val_accuracy:  0.9031599019340779 Val_Acc:  1.5568338999788707\n",
      "Epoch number: 2521/10000step_number: 0/29 Accuracy:  0.9170100459730972 Loss:  1.3473316969484972 Val_accuracy:  0.9030236992645055 Val_cost:  1.3473316969484972 Val_accuracy:  0.9030236992645055 Val_Acc:  1.5569133140305838\n",
      "Epoch number: 2522/10000step_number: 0/29 Accuracy:  0.9170441001191895 Loss:  1.3474183044060688 Val_accuracy:  0.9031599019340779 Val_cost:  1.3474183044060688 Val_accuracy:  0.9031599019340779 Val_Acc:  1.5570135605927269\n",
      "Epoch number: 2523/10000step_number: 0/29 Accuracy:  0.9170441001191895 Loss:  1.3475330561397503 Val_accuracy:  0.9031599019340779 Val_cost:  1.3475330561397503 Val_accuracy:  0.9031599019340779 Val_Acc:  1.557135632354258\n",
      "Epoch number: 2524/10000step_number: 0/29 Accuracy:  0.9172824791418355 Loss:  1.3476791684794072 Val_accuracy:  0.9031599019340779 Val_cost:  1.3476791684794072 Val_accuracy:  0.9031599019340779 Val_Acc:  1.5572787704037336\n",
      "Epoch number: 2525/10000step_number: 0/29 Accuracy:  0.9173505874340201 Loss:  1.3478640635566634 Val_accuracy:  0.9028874965949333 Val_cost:  1.3478640635566634 Val_accuracy:  0.9028874965949333 Val_Acc:  1.557445204000038\n",
      "Epoch number: 2526/10000step_number: 0/29 Accuracy:  0.9172824791418355 Loss:  1.3481027030071855 Val_accuracy:  0.9031599019340779 Val_cost:  1.3481027030071855 Val_accuracy:  0.9031599019340779 Val_Acc:  1.5576381346301356\n",
      "Epoch number: 2527/10000step_number: 0/29 Accuracy:  0.9166013962199898 Loss:  1.3484149388893103 Val_accuracy:  0.9024788885862163 Val_cost:  1.3484149388893103 Val_accuracy:  0.9024788885862163 Val_Acc:  1.5578635531749927\n",
      "Epoch number: 2528/10000step_number: 0/29 Accuracy:  0.9165673420738975 Loss:  1.34888556837594 Val_accuracy:  0.9022064832470716 Val_cost:  1.34888556837594 Val_accuracy:  0.9022064832470716 Val_Acc:  1.5581825804716471\n",
      "Epoch number: 2529/10000step_number: 0/29 Accuracy:  0.9164651796356207 Loss:  1.350329312345706 Val_accuracy:  0.9024788885862163 Val_cost:  1.350329312345706 Val_accuracy:  0.9024788885862163 Val_Acc:  1.5590314113164698\n",
      "Epoch number: 2530/10000step_number: 0/29 Accuracy:  0.9164992337817129 Loss:  1.3517108144008219 Val_accuracy:  0.9020702805774993 Val_cost:  1.3517108144008219 Val_accuracy:  0.9020702805774993 Val_Acc:  1.5605542067069285\n",
      "Epoch number: 2531/10000step_number: 0/29 Accuracy:  0.9164992337817129 Loss:  1.351263232148075 Val_accuracy:  0.9024788885862163 Val_cost:  1.351263232148075 Val_accuracy:  0.9024788885862163 Val_Acc:  1.5642669213006368\n",
      "Epoch number: 2532/10000step_number: 0/29 Accuracy:  0.9174186957262047 Loss:  1.3435246154464844 Val_accuracy:  0.9028874965949333 Val_cost:  1.3435246154464844 Val_accuracy:  0.9028874965949333 Val_Acc:  1.552719472058048\n",
      "Epoch number: 2533/10000step_number: 0/29 Accuracy:  0.9168397752426358 Loss:  1.346097692243244 Val_accuracy:  0.9030236992645055 Val_cost:  1.346097692243244 Val_accuracy:  0.9030236992645055 Val_Acc:  1.5591553277990062\n",
      "Epoch number: 2534/10000step_number: 0/29 Accuracy:  0.9180997786480504 Loss:  1.346296775511624 Val_accuracy:  0.9034323072732225 Val_cost:  1.346296775511624 Val_accuracy:  0.9034323072732225 Val_Acc:  1.5547345030410817\n",
      "Epoch number: 2535/10000step_number: 0/29 Accuracy:  0.9178613996254044 Loss:  1.3446143416782503 Val_accuracy:  0.9043857259602288 Val_cost:  1.3446143416782503 Val_accuracy:  0.9043857259602288 Val_Acc:  1.5554117519583335\n",
      "Epoch number: 2536/10000step_number: 0/29 Accuracy:  0.9171462625574663 Loss:  1.3455490081981933 Val_accuracy:  0.9030236992645055 Val_cost:  1.3455490081981933 Val_accuracy:  0.9030236992645055 Val_Acc:  1.5563385361746958\n",
      "Epoch number: 2537/10000step_number: 0/29 Accuracy:  0.917214370849651 Loss:  1.3468961960708425 Val_accuracy:  0.9035685099427949 Val_cost:  1.3468961960708425 Val_accuracy:  0.9035685099427949 Val_Acc:  1.5576737542623145\n",
      "Epoch number: 2538/10000step_number: 0/29 Accuracy:  0.9180657245019581 Loss:  1.3467043040666449 Val_accuracy:  0.9041133206210842 Val_cost:  1.3467043040666449 Val_accuracy:  0.9041133206210842 Val_Acc:  1.557648079281611\n",
      "Epoch number: 2539/10000step_number: 0/29 Accuracy:  0.9168057210965435 Loss:  1.3467225903666291 Val_accuracy:  0.9031599019340779 Val_cost:  1.3467225903666291 Val_accuracy:  0.9031599019340779 Val_Acc:  1.5577780007279822\n",
      "Epoch number: 2540/10000step_number: 0/29 Accuracy:  0.9166695045121743 Loss:  1.346808374932314 Val_accuracy:  0.9034323072732225 Val_cost:  1.346808374932314 Val_accuracy:  0.9034323072732225 Val_Acc:  1.5579566904204716\n",
      "Epoch number: 2541/10000step_number: 0/29 Accuracy:  0.9166354503660821 Loss:  1.346948941236487 Val_accuracy:  0.9034323072732225 Val_cost:  1.346948941236487 Val_accuracy:  0.9034323072732225 Val_Acc:  1.558225942916854\n",
      "Epoch number: 2542/10000step_number: 0/29 Accuracy:  0.9165673420738975 Loss:  1.347013570358804 Val_accuracy:  0.9032961046036503 Val_cost:  1.347013570358804 Val_accuracy:  0.9032961046036503 Val_Acc:  1.5584735699809773\n",
      "Epoch number: 2543/10000step_number: 0/29 Accuracy:  0.9165332879278052 Loss:  1.3470629217169316 Val_accuracy:  0.9034323072732225 Val_cost:  1.3470629217169316 Val_accuracy:  0.9034323072732225 Val_Acc:  1.5587144924409577\n",
      "Epoch number: 2544/10000step_number: 0/29 Accuracy:  0.9166695045121743 Loss:  1.3470870272730049 Val_accuracy:  0.9032961046036503 Val_cost:  1.3470870272730049 Val_accuracy:  0.9032961046036503 Val_Acc:  1.5589056327151116\n",
      "Epoch number: 2545/10000step_number: 0/29 Accuracy:  0.9164992337817129 Loss:  1.3471091797395065 Val_accuracy:  0.9032961046036503 Val_cost:  1.3471091797395065 Val_accuracy:  0.9032961046036503 Val_Acc:  1.559116529923228\n",
      "Epoch number: 2546/10000step_number: 0/29 Accuracy:  0.9164651796356207 Loss:  1.3471279310746784 Val_accuracy:  0.9028874965949333 Val_cost:  1.3471279310746784 Val_accuracy:  0.9028874965949333 Val_Acc:  1.5593046755266684\n",
      "Epoch number: 2547/10000step_number: 0/29 Accuracy:  0.9165332879278052 Loss:  1.3471391835639839 Val_accuracy:  0.9031599019340779 Val_cost:  1.3471391835639839 Val_accuracy:  0.9031599019340779 Val_Acc:  1.5594970212067467\n",
      "Epoch number: 2548/10000step_number: 0/29 Accuracy:  0.9164992337817129 Loss:  1.3471364615967658 Val_accuracy:  0.9030236992645055 Val_cost:  1.3471364615967658 Val_accuracy:  0.9030236992645055 Val_Acc:  1.5596687906208533\n",
      "Epoch number: 2549/10000step_number: 0/29 Accuracy:  0.9164651796356207 Loss:  1.3471301244582665 Val_accuracy:  0.9030236992645055 Val_cost:  1.3471301244582665 Val_accuracy:  0.9030236992645055 Val_Acc:  1.5598517987562233\n",
      "Epoch number: 2550/10000step_number: 0/29 Accuracy:  0.9164651796356207 Loss:  1.3471123139924956 Val_accuracy:  0.9030236992645055 Val_cost:  1.3471123139924956 Val_accuracy:  0.9030236992645055 Val_Acc:  1.56002043556982\n",
      "Epoch number: 2551/10000step_number: 0/29 Accuracy:  0.9164311254895283 Loss:  1.3470923342573071 Val_accuracy:  0.9031599019340779 Val_cost:  1.3470923342573071 Val_accuracy:  0.9031599019340779 Val_Acc:  1.5601990572653022\n",
      "Epoch number: 2552/10000step_number: 0/29 Accuracy:  0.9164992337817129 Loss:  1.3470633538986052 Val_accuracy:  0.9030236992645055 Val_cost:  1.3470633538986052 Val_accuracy:  0.9030236992645055 Val_Acc:  1.5603629841870124\n",
      "Epoch number: 2553/10000step_number: 0/29 Accuracy:  0.9164992337817129 Loss:  1.3470353319499135 Val_accuracy:  0.9030236992645055 Val_cost:  1.3470353319499135 Val_accuracy:  0.9030236992645055 Val_Acc:  1.5605365892416188\n",
      "Epoch number: 2554/10000step_number: 0/29 Accuracy:  0.9166013962199898 Loss:  1.3470009073547502 Val_accuracy:  0.9031599019340779 Val_cost:  1.3470009073547502 Val_accuracy:  0.9031599019340779 Val_Acc:  1.5606963068210717\n",
      "Epoch number: 2555/10000step_number: 0/29 Accuracy:  0.9166013962199898 Loss:  1.346967195373849 Val_accuracy:  0.9031599019340779 Val_cost:  1.346967195373849 Val_accuracy:  0.9031599019340779 Val_Acc:  1.5608670969073815\n",
      "Epoch number: 2556/10000step_number: 0/29 Accuracy:  0.9166354503660821 Loss:  1.3469218886352063 Val_accuracy:  0.9031599019340779 Val_cost:  1.3469218886352063 Val_accuracy:  0.9031599019340779 Val_Acc:  1.5610220473154728\n",
      "Epoch number: 2557/10000step_number: 0/29 Accuracy:  0.9166695045121743 Loss:  1.3468716781386707 Val_accuracy:  0.9031599019340779 Val_cost:  1.3468716781386707 Val_accuracy:  0.9031599019340779 Val_Acc:  1.5611841999378497\n",
      "Epoch number: 2558/10000step_number: 0/29 Accuracy:  0.9167716669504512 Loss:  1.3468032305173783 Val_accuracy:  0.9031599019340779 Val_cost:  1.3468032305173783 Val_accuracy:  0.9031599019340779 Val_Acc:  1.5613252326104772\n",
      "Epoch number: 2559/10000step_number: 0/29 Accuracy:  0.9168738293887281 Loss:  1.346723671004591 Val_accuracy:  0.9031599019340779 Val_cost:  1.346723671004591 Val_accuracy:  0.9031599019340779 Val_Acc:  1.561473136476055\n",
      "Epoch number: 2560/10000step_number: 0/29 Accuracy:  0.916975991827005 Loss:  1.3466212581216 Val_accuracy:  0.9032961046036503 Val_cost:  1.3466212581216 Val_accuracy:  0.9032961046036503 Val_Acc:  1.5616016628426266\n",
      "Epoch number: 2561/10000step_number: 0/29 Accuracy:  0.9169419376809127 Loss:  1.3465115491916098 Val_accuracy:  0.9032961046036503 Val_cost:  1.3465115491916098 Val_accuracy:  0.9032961046036503 Val_Acc:  1.5617423059708193\n",
      "Epoch number: 2562/10000step_number: 0/29 Accuracy:  0.916975991827005 Loss:  1.3463853382595004 Val_accuracy:  0.9035685099427949 Val_cost:  1.3463853382595004 Val_accuracy:  0.9035685099427949 Val_Acc:  1.5618650337675009\n",
      "Epoch number: 2563/10000step_number: 0/29 Accuracy:  0.9170441001191895 Loss:  1.3462605565466825 Val_accuracy:  0.9034323072732225 Val_cost:  1.3462605565466825 Val_accuracy:  0.9034323072732225 Val_Acc:  1.5620010546669036\n",
      "Epoch number: 2564/10000step_number: 0/29 Accuracy:  0.9170781542652818 Loss:  1.346121435772651 Val_accuracy:  0.9032961046036503 Val_cost:  1.346121435772651 Val_accuracy:  0.9032961046036503 Val_Acc:  1.562117007549649\n",
      "Epoch number: 2565/10000step_number: 0/29 Accuracy:  0.9170781542652818 Loss:  1.3459881387145352 Val_accuracy:  0.9030236992645055 Val_cost:  1.3459881387145352 Val_accuracy:  0.9030236992645055 Val_Acc:  1.5622477408618751\n",
      "Epoch number: 2566/10000step_number: 0/29 Accuracy:  0.9171122084113741 Loss:  1.345838380160826 Val_accuracy:  0.9027512939253609 Val_cost:  1.345838380160826 Val_accuracy:  0.9027512939253609 Val_Acc:  1.5623575265444518\n",
      "Epoch number: 2567/10000step_number: 0/29 Accuracy:  0.9171803167035587 Loss:  1.3457004467632994 Val_accuracy:  0.9026150912557886 Val_cost:  1.3457004467632994 Val_accuracy:  0.9026150912557886 Val_Acc:  1.562485742774564\n",
      "Epoch number: 2568/10000step_number: 0/29 Accuracy:  0.9174186957262047 Loss:  1.3455429530553646 Val_accuracy:  0.9027512939253609 Val_cost:  1.3455429530553646 Val_accuracy:  0.9027512939253609 Val_Acc:  1.562591761401738\n",
      "Epoch number: 2569/10000step_number: 0/29 Accuracy:  0.9174868040183892 Loss:  1.345408576475535 Val_accuracy:  0.9026150912557886 Val_cost:  1.345408576475535 Val_accuracy:  0.9026150912557886 Val_Acc:  1.5627214804684884\n",
      "Epoch number: 2570/10000step_number: 0/29 Accuracy:  0.9175208581644815 Loss:  1.3452505646978286 Val_accuracy:  0.9026150912557886 Val_cost:  1.3452505646978286 Val_accuracy:  0.9026150912557886 Val_Acc:  1.562826875132239\n",
      "Epoch number: 2571/10000step_number: 0/29 Accuracy:  0.9178613996254044 Loss:  1.3451369204783308 Val_accuracy:  0.9028874965949333 Val_cost:  1.3451369204783308 Val_accuracy:  0.9028874965949333 Val_Acc:  1.5629641915376074\n",
      "Epoch number: 2572/10000step_number: 0/29 Accuracy:  0.9179976162097735 Loss:  1.3449915197606384 Val_accuracy:  0.9031599019340779 Val_cost:  1.3449915197606384 Val_accuracy:  0.9031599019340779 Val_Acc:  1.5630721418168736\n",
      "Epoch number: 2573/10000step_number: 0/29 Accuracy:  0.9181338327941427 Loss:  1.3449253522315447 Val_accuracy:  0.9031599019340779 Val_cost:  1.3449253522315447 Val_accuracy:  0.9031599019340779 Val_Acc:  1.5632257967585617\n",
      "Epoch number: 2574/10000step_number: 0/29 Accuracy:  0.9177592371871275 Loss:  1.3448026369689658 Val_accuracy:  0.9032961046036503 Val_cost:  1.3448026369689658 Val_accuracy:  0.9032961046036503 Val_Acc:  1.5633387702707384\n",
      "Epoch number: 2575/10000step_number: 0/29 Accuracy:  0.918167886940235 Loss:  1.3448140638681017 Val_accuracy:  0.9032961046036503 Val_cost:  1.3448140638681017 Val_accuracy:  0.9032961046036503 Val_Acc:  1.5635241528997883\n",
      "Epoch number: 2576/10000step_number: 0/29 Accuracy:  0.9192576196151881 Loss:  1.34470543783962 Val_accuracy:  0.9042495232906564 Val_cost:  1.34470543783962 Val_accuracy:  0.9042495232906564 Val_Acc:  1.5636500672709612\n",
      "Epoch number: 2577/10000step_number: 0/29 Accuracy:  0.9191895113230035 Loss:  1.3448367366500817 Val_accuracy:  0.9039771179515118 Val_cost:  1.3448367366500817 Val_accuracy:  0.9039771179515118 Val_Acc:  1.563896445663573\n",
      "Epoch number: 2578/10000step_number: 0/29 Accuracy:  0.9197684318065724 Loss:  1.3447092486998695 Val_accuracy:  0.9045219286298012 Val_cost:  1.3447092486998695 Val_accuracy:  0.9045219286298012 Val_Acc:  1.564071170863188\n",
      "Epoch number: 2579/10000step_number: 0/29 Accuracy:  0.920074919121403 Loss:  1.345059148466522 Val_accuracy:  0.9043857259602288 Val_cost:  1.345059148466522 Val_accuracy:  0.9043857259602288 Val_Acc:  1.564429622553991\n",
      "Epoch number: 2580/10000step_number: 0/29 Accuracy:  0.9197003235143879 Loss:  1.34483346510179 Val_accuracy:  0.9039771179515118 Val_cost:  1.34483346510179 Val_accuracy:  0.9039771179515118 Val_Acc:  1.5647838443071458\n",
      "Epoch number: 2581/10000step_number: 0/29 Accuracy:  0.9200068108292184 Loss:  1.345638139540317 Val_accuracy:  0.9035685099427949 Val_cost:  1.345638139540317 Val_accuracy:  0.9035685099427949 Val_Acc:  1.5653936844677943\n",
      "Epoch number: 2582/10000step_number: 0/29 Accuracy:  0.9194959986378342 Loss:  1.3448305984350368 Val_accuracy:  0.9027512939253609 Val_cost:  1.3448305984350368 Val_accuracy:  0.9027512939253609 Val_Acc:  1.5662262325302934\n",
      "Epoch number: 2583/10000step_number: 0/29 Accuracy:  0.9200068108292184 Loss:  1.3461471152981608 Val_accuracy:  0.9030236992645055 Val_cost:  1.3461471152981608 Val_accuracy:  0.9030236992645055 Val_Acc:  1.5671400449708892\n",
      "Epoch number: 2584/10000step_number: 0/29 Accuracy:  0.9190192405925421 Loss:  1.3411806787003058 Val_accuracy:  0.9024788885862163 Val_cost:  1.3411806787003058 Val_accuracy:  0.9024788885862163 Val_Acc:  1.5685133279029184\n",
      "Epoch number: 2585/10000step_number: 0/29 Accuracy:  0.9189851864464499 Loss:  1.3444019458206558 Val_accuracy:  0.902342685916644 Val_cost:  1.3444019458206558 Val_accuracy:  0.902342685916644 Val_Acc:  1.5679007533520968\n",
      "Epoch number: 2586/10000step_number: 0/29 Accuracy:  0.9199727566831262 Loss:  1.3422432088262344 Val_accuracy:  0.9031599019340779 Val_cost:  1.3422432088262344 Val_accuracy:  0.9031599019340779 Val_Acc:  1.570251106468867\n",
      "Epoch number: 2587/10000step_number: 0/29 Accuracy:  0.9206878937510642 Loss:  1.3478044018887778 Val_accuracy:  0.9041133206210842 Val_cost:  1.3478044018887778 Val_accuracy:  0.9041133206210842 Val_Acc:  1.5849473709325217\n",
      "Epoch number: 2588/10000step_number: 0/29 Accuracy:  0.9248084454282309 Loss:  1.361193951645791 Val_accuracy:  0.9090166167256878 Val_cost:  1.361193951645791 Val_accuracy:  0.9090166167256878 Val_Acc:  1.5697621047133699\n",
      "Epoch number: 2589/10000step_number: 0/29 Accuracy:  0.9232079005618934 Loss:  1.4131579833563608 Val_accuracy:  0.9072459820212476 Val_cost:  1.4131579833563608 Val_accuracy:  0.9072459820212476 Val_Acc:  1.6113972821373448\n",
      "Epoch number: 2590/10000step_number: 0/29 Accuracy:  0.928145751745275 Loss:  1.3872673239746005 Val_accuracy:  0.9140561154998638 Val_cost:  1.3872673239746005 Val_accuracy:  0.9140561154998638 Val_Acc:  1.5840872709102514\n",
      "Epoch number: 2591/10000step_number: 0/29 Accuracy:  0.9340711731653328 Loss:  1.3250922009605262 Val_accuracy:  0.9146009261781531 Val_cost:  1.3250922009605262 Val_accuracy:  0.9146009261781531 Val_Acc:  1.536374125541372\n",
      "Epoch number: 2592/10000step_number: 0/29 Accuracy:  0.9313808956240422 Loss:  1.3264938856169306 Val_accuracy:  0.91500953418687 Val_cost:  1.3264938856169306 Val_accuracy:  0.91500953418687 Val_Acc:  1.5433293878088354\n",
      "Epoch number: 2593/10000step_number: 0/29 Accuracy:  0.9322322492763494 Loss:  1.3314220129902323 Val_accuracy:  0.9151457368564424 Val_cost:  1.3314220129902323 Val_accuracy:  0.9151457368564424 Val_Acc:  1.5493369614233066\n",
      "Epoch number: 2594/10000step_number: 0/29 Accuracy:  0.9317895453771496 Loss:  1.3313916899060223 Val_accuracy:  0.9144647235085808 Val_cost:  1.3313916899060223 Val_accuracy:  0.9144647235085808 Val_Acc:  1.5518758687929268\n",
      "Epoch number: 2595/10000step_number: 0/29 Accuracy:  0.9308360292865656 Loss:  1.3313463819090652 Val_accuracy:  0.9135113048215745 Val_cost:  1.3313463819090652 Val_accuracy:  0.9135113048215745 Val_Acc:  1.5535981081352843\n",
      "Epoch number: 2596/10000step_number: 0/29 Accuracy:  0.9300187297803507 Loss:  1.3314918995352045 Val_accuracy:  0.9126940888041406 Val_cost:  1.3314918995352045 Val_accuracy:  0.9126940888041406 Val_Acc:  1.5547757830842006\n",
      "Epoch number: 2597/10000step_number: 0/29 Accuracy:  0.9293035927124127 Loss:  1.331694640163837 Val_accuracy:  0.9126940888041406 Val_cost:  1.331694640163837 Val_accuracy:  0.9126940888041406 Val_Acc:  1.555565876512986\n",
      "Epoch number: 2598/10000step_number: 0/29 Accuracy:  0.9284522390601055 Loss:  1.3319701655311798 Val_accuracy:  0.9121492781258512 Val_cost:  1.3319701655311798 Val_accuracy:  0.9121492781258512 Val_Acc:  1.5563193821474393\n",
      "Epoch number: 2599/10000step_number: 0/29 Accuracy:  0.9280435893069982 Loss:  1.332223145693874 Val_accuracy:  0.9118768727867066 Val_cost:  1.332223145693874 Val_accuracy:  0.9118768727867066 Val_Acc:  1.5569859727850173\n",
      "Epoch number: 2600/10000step_number: 0/29 Accuracy:  0.9275668312617061 Loss:  1.3324319719511404 Val_accuracy:  0.9113320621084173 Val_cost:  1.3324319719511404 Val_accuracy:  0.9113320621084173 Val_Acc:  1.5575634400937441\n",
      "Epoch number: 2601/10000step_number: 0/29 Accuracy:  0.9276008854077984 Loss:  1.3326068321487536 Val_accuracy:  0.9109234540997003 Val_cost:  1.3326068321487536 Val_accuracy:  0.9109234540997003 Val_Acc:  1.5580578470188031\n",
      "Epoch number: 2602/10000step_number: 0/29 Accuracy:  0.9273965605312446 Loss:  1.332752721856497 Val_accuracy:  0.9106510487605557 Val_cost:  1.332752721856497 Val_accuracy:  0.9106510487605557 Val_Acc:  1.5584713259790202\n",
      "Epoch number: 2603/10000step_number: 0/29 Accuracy:  0.9273625063851524 Loss:  1.332875518983208 Val_accuracy:  0.9106510487605557 Val_cost:  1.332875518983208 Val_accuracy:  0.9106510487605557 Val_Acc:  1.5588165579264432\n",
      "Epoch number: 2604/10000step_number: 0/29 Accuracy:  0.927430614677337 Loss:  1.3329803532671691 Val_accuracy:  0.9106510487605557 Val_cost:  1.3329803532671691 Val_accuracy:  0.9106510487605557 Val_Acc:  1.5591099046038623\n",
      "Epoch number: 2605/10000step_number: 0/29 Accuracy:  0.927430614677337 Loss:  1.3330706282666833 Val_accuracy:  0.9107872514301281 Val_cost:  1.3330706282666833 Val_accuracy:  0.9107872514301281 Val_Acc:  1.5593638109798427\n",
      "Epoch number: 2606/10000step_number: 0/29 Accuracy:  0.9274646688234293 Loss:  1.3331481217850565 Val_accuracy:  0.9106510487605557 Val_cost:  1.3331481217850565 Val_accuracy:  0.9106510487605557 Val_Acc:  1.5595859618489165\n",
      "Epoch number: 2607/10000step_number: 0/29 Accuracy:  0.9274987229695215 Loss:  1.333214213564257 Val_accuracy:  0.9103786434214111 Val_cost:  1.333214213564257 Val_accuracy:  0.9103786434214111 Val_Acc:  1.5597815878103085\n",
      "Epoch number: 2608/10000step_number: 0/29 Accuracy:  0.9275327771156138 Loss:  1.3332702569359294 Val_accuracy:  0.9102424407518387 Val_cost:  1.3332702569359294 Val_accuracy:  0.9102424407518387 Val_Acc:  1.5599547839075125\n",
      "Epoch number: 2609/10000step_number: 0/29 Accuracy:  0.9263749361484761 Loss:  1.3333173869844217 Val_accuracy:  0.9091528193952602 Val_cost:  1.3333173869844217 Val_accuracy:  0.9091528193952602 Val_Acc:  1.5601088687198221\n",
      "Epoch number: 2610/10000step_number: 0/29 Accuracy:  0.9261365571258301 Loss:  1.3333564654245378 Val_accuracy:  0.9091528193952602 Val_cost:  1.3333564654245378 Val_accuracy:  0.9091528193952602 Val_Acc:  1.5602464639130658\n",
      "Epoch number: 2611/10000step_number: 0/29 Accuracy:  0.9258641239570917 Loss:  1.3333881492526833 Val_accuracy:  0.9091528193952602 Val_cost:  1.3333881492526833 Val_accuracy:  0.9091528193952602 Val_Acc:  1.560369522233424\n",
      "Epoch number: 2612/10000step_number: 0/29 Accuracy:  0.9258981781031841 Loss:  1.3334130067094239 Val_accuracy:  0.9092890220648324 Val_cost:  1.3334130067094239 Val_accuracy:  0.9092890220648324 Val_Acc:  1.5604793520754385\n",
      "Epoch number: 2613/10000step_number: 0/29 Accuracy:  0.9259322322492763 Loss:  1.3334315857520374 Val_accuracy:  0.9091528193952602 Val_cost:  1.3334315857520374 Val_accuracy:  0.9091528193952602 Val_Acc:  1.560576653602036\n",
      "Epoch number: 2614/10000step_number: 0/29 Accuracy:  0.9258981781031841 Loss:  1.333444382841241 Val_accuracy:  0.9090166167256878 Val_cost:  1.333444382841241 Val_accuracy:  0.9090166167256878 Val_Acc:  1.5606616294392974\n",
      "Epoch number: 2615/10000step_number: 0/29 Accuracy:  0.9261025029797377 Loss:  1.3334517588244472 Val_accuracy:  0.9090166167256878 Val_cost:  1.3334517588244472 Val_accuracy:  0.9090166167256878 Val_Acc:  1.5607342015835244\n",
      "Epoch number: 2616/10000step_number: 0/29 Accuracy:  0.926238719564107 Loss:  1.3334539034143362 Val_accuracy:  0.9090166167256878 Val_cost:  1.3334539034143362 Val_accuracy:  0.9090166167256878 Val_Acc:  1.5607942788800317\n",
      "Epoch number: 2617/10000step_number: 0/29 Accuracy:  0.9261365571258301 Loss:  1.3334508911686134 Val_accuracy:  0.9087442113865432 Val_cost:  1.3334508911686134 Val_accuracy:  0.9087442113865432 Val_Acc:  1.5608419676701215\n",
      "Epoch number: 2618/10000step_number: 0/29 Accuracy:  0.9259322322492763 Loss:  1.3334427746044182 Val_accuracy:  0.9087442113865432 Val_cost:  1.3334427746044182 Val_accuracy:  0.9087442113865432 Val_Acc:  1.5608776537341948\n",
      "Epoch number: 2619/10000step_number: 0/29 Accuracy:  0.9259322322492763 Loss:  1.3334296520639726 Val_accuracy:  0.9084718060473985 Val_cost:  1.3334296520639726 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5609019786553961\n",
      "Epoch number: 2620/10000step_number: 0/29 Accuracy:  0.9258300698109995 Loss:  1.3334117068557907 Val_accuracy:  0.9086080087169709 Val_cost:  1.3334117068557907 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5609157933719837\n",
      "Epoch number: 2621/10000step_number: 0/29 Accuracy:  0.9261025029797377 Loss:  1.3333892520629755 Val_accuracy:  0.9086080087169709 Val_cost:  1.3333892520629755 Val_accuracy:  0.9086080087169709 Val_Acc:  1.56092016388929\n",
      "Epoch number: 2622/10000step_number: 0/29 Accuracy:  0.9261365571258301 Loss:  1.3333628116487908 Val_accuracy:  0.9086080087169709 Val_cost:  1.3333628116487908 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5609164621999996\n",
      "Epoch number: 2623/10000step_number: 0/29 Accuracy:  0.926000340541461 Loss:  1.333333235124151 Val_accuracy:  0.9086080087169709 Val_cost:  1.333333235124151 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5609065125245618\n",
      "Epoch number: 2624/10000step_number: 0/29 Accuracy:  0.9259662863953686 Loss:  1.333301773176206 Val_accuracy:  0.9086080087169709 Val_cost:  1.333301773176206 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5608926532518705\n",
      "Epoch number: 2625/10000step_number: 0/29 Accuracy:  0.9258981781031841 Loss:  1.3332699562511245 Val_accuracy:  0.9087442113865432 Val_cost:  1.3332699562511245 Val_accuracy:  0.9087442113865432 Val_Acc:  1.560877464456144\n",
      "Epoch number: 2626/10000step_number: 0/29 Accuracy:  0.926000340541461 Loss:  1.33323916744171 Val_accuracy:  0.9083356033778262 Val_cost:  1.33323916744171 Val_accuracy:  0.9083356033778262 Val_Acc:  1.5608630588104706\n",
      "Epoch number: 2627/10000step_number: 0/29 Accuracy:  0.9261706112719224 Loss:  1.3332101254345103 Val_accuracy:  0.9088804140561155 Val_cost:  1.3332101254345103 Val_accuracy:  0.9088804140561155 Val_Acc:  1.560850382216369\n",
      "Epoch number: 2628/10000step_number: 0/29 Accuracy:  0.9260343946875532 Loss:  1.333182738983361 Val_accuracy:  0.9088804140561155 Val_cost:  1.333182738983361 Val_accuracy:  0.9088804140561155 Val_Acc:  1.5608392034416876\n",
      "Epoch number: 2629/10000step_number: 0/29 Accuracy:  0.9257960156649072 Loss:  1.3331564438187022 Val_accuracy:  0.9087442113865432 Val_cost:  1.3331564438187022 Val_accuracy:  0.9087442113865432 Val_Acc:  1.5608287284576228\n",
      "Epoch number: 2630/10000step_number: 0/29 Accuracy:  0.9243657415290312 Loss:  1.333130643638734 Val_accuracy:  0.9083356033778262 Val_cost:  1.333130643638734 Val_accuracy:  0.9083356033778262 Val_Acc:  1.56081814455112\n",
      "Epoch number: 2631/10000step_number: 0/29 Accuracy:  0.9242976332368465 Loss:  1.3331049393921937 Val_accuracy:  0.9083356033778262 Val_cost:  1.3331049393921937 Val_accuracy:  0.9083356033778262 Val_Acc:  1.560806756622643\n",
      "Epoch number: 2632/10000step_number: 0/29 Accuracy:  0.9241273625063852 Loss:  1.3330791569934377 Val_accuracy:  0.9081994007082539 Val_cost:  1.3330791569934377 Val_accuracy:  0.9081994007082539 Val_Acc:  1.5607938629105635\n",
      "Epoch number: 2633/10000step_number: 0/29 Accuracy:  0.9238889834837392 Loss:  1.3330533188110798 Val_accuracy:  0.9083356033778262 Val_cost:  1.3330533188110798 Val_accuracy:  0.9083356033778262 Val_Acc:  1.560778610525674\n",
      "Epoch number: 2634/10000step_number: 0/29 Accuracy:  0.92375276689937 Loss:  1.3330276375413674 Val_accuracy:  0.9083356033778262 Val_cost:  1.3330276375413674 Val_accuracy:  0.9083356033778262 Val_Acc:  1.56075999279727\n",
      "Epoch number: 2635/10000step_number: 0/29 Accuracy:  0.92375276689937 Loss:  1.3330025030855162 Val_accuracy:  0.9080631980386815 Val_cost:  1.3330025030855162 Val_accuracy:  0.9080631980386815 Val_Acc:  1.560737039479035\n",
      "Epoch number: 2636/10000step_number: 0/29 Accuracy:  0.9239230376298314 Loss:  1.3329784019047706 Val_accuracy:  0.9083356033778262 Val_cost:  1.3329784019047706 Val_accuracy:  0.9083356033778262 Val_Acc:  1.5607091256640675\n",
      "Epoch number: 2637/10000step_number: 0/29 Accuracy:  0.9236506044610931 Loss:  1.33295577807324 Val_accuracy:  0.9077907926995369 Val_cost:  1.33295577807324 Val_accuracy:  0.9077907926995369 Val_Acc:  1.5606762275622736\n",
      "Epoch number: 2638/10000step_number: 0/29 Accuracy:  0.9236846586071854 Loss:  1.3329349317640113 Val_accuracy:  0.9077907926995369 Val_cost:  1.3329349317640113 Val_accuracy:  0.9077907926995369 Val_Acc:  1.560638969885797\n",
      "Epoch number: 2639/10000step_number: 0/29 Accuracy:  0.9236846586071854 Loss:  1.3329160265912672 Val_accuracy:  0.9076545900299646 Val_cost:  1.3329160265912672 Val_accuracy:  0.9076545900299646 Val_Acc:  1.5605984506122184\n",
      "Epoch number: 2640/10000step_number: 0/29 Accuracy:  0.9235484420228163 Loss:  1.3328991643705228 Val_accuracy:  0.9075183873603923 Val_cost:  1.3328991643705228 Val_accuracy:  0.9075183873603923 Val_Acc:  1.5605559620482037\n",
      "Epoch number: 2641/10000step_number: 0/29 Accuracy:  0.9234462795845394 Loss:  1.3328844437995682 Val_accuracy:  0.9077907926995369 Val_cost:  1.3328844437995682 Val_accuracy:  0.9077907926995369 Val_Acc:  1.560512743606256\n",
      "Epoch number: 2642/10000step_number: 0/29 Accuracy:  0.923514387876724 Loss:  1.3328719768521942 Val_accuracy:  0.9077907926995369 Val_cost:  1.3328719768521942 Val_accuracy:  0.9077907926995369 Val_Acc:  1.5604698350064121\n",
      "Epoch number: 2643/10000step_number: 0/29 Accuracy:  0.9233100630001703 Loss:  1.3328618847633247 Val_accuracy:  0.9081994007082539 Val_cost:  1.3328618847633247 Val_accuracy:  0.9081994007082539 Val_Acc:  1.5604280297896957\n",
      "Epoch number: 2644/10000step_number: 0/29 Accuracy:  0.9233441171462625 Loss:  1.3328542941419388 Val_accuracy:  0.9081994007082539 Val_cost:  1.3328542941419388 Val_accuracy:  0.9081994007082539 Val_Acc:  1.560387895649163\n",
      "Epoch number: 2645/10000step_number: 0/29 Accuracy:  0.9233441171462625 Loss:  1.3328493376597867 Val_accuracy:  0.9080631980386815 Val_cost:  1.3328493376597867 Val_accuracy:  0.9080631980386815 Val_Acc:  1.5603498271593528\n",
      "Epoch number: 2646/10000step_number: 0/29 Accuracy:  0.9233781712923549 Loss:  1.3328471550136491 Val_accuracy:  0.9080631980386815 Val_cost:  1.3328471550136491 Val_accuracy:  0.9080631980386815 Val_Acc:  1.5603141082086842\n",
      "Epoch number: 2647/10000step_number: 0/29 Accuracy:  0.9234803337306317 Loss:  1.3328478886377502 Val_accuracy:  0.9081994007082539 Val_cost:  1.3328478886377502 Val_accuracy:  0.9081994007082539 Val_Acc:  1.5602809716882877\n",
      "Epoch number: 2648/10000step_number: 0/29 Accuracy:  0.923514387876724 Loss:  1.3328516712671332 Val_accuracy:  0.9086080087169709 Val_cost:  1.3328516712671332 Val_accuracy:  0.9086080087169709 Val_Acc:  1.560250647703636\n",
      "Epoch number: 2649/10000step_number: 0/29 Accuracy:  0.9237187127532777 Loss:  1.3328586064801216 Val_accuracy:  0.9084718060473985 Val_cost:  1.3328586064801216 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5602233914188806\n",
      "Epoch number: 2650/10000step_number: 0/29 Accuracy:  0.9237187127532777 Loss:  1.3328687470383638 Val_accuracy:  0.9083356033778262 Val_cost:  1.3328687470383638 Val_accuracy:  0.9083356033778262 Val_Acc:  1.5601994822325587\n",
      "Epoch number: 2651/10000step_number: 0/29 Accuracy:  0.9236846586071854 Loss:  1.3328820777720272 Val_accuracy:  0.9083356033778262 Val_cost:  1.3328820777720272 Val_accuracy:  0.9083356033778262 Val_Acc:  1.5601791932538673\n",
      "Epoch number: 2652/10000step_number: 0/29 Accuracy:  0.9231738464158011 Loss:  1.332898509098931 Val_accuracy:  0.9079269953691093 Val_cost:  1.332898509098931 Val_accuracy:  0.9079269953691093 Val_Acc:  1.5601627431663265\n",
      "Epoch number: 2653/10000step_number: 0/29 Accuracy:  0.9231057381236165 Loss:  1.3329178841021991 Val_accuracy:  0.9079269953691093 Val_cost:  1.3329178841021991 Val_accuracy:  0.9079269953691093 Val_Acc:  1.5601502529055884\n",
      "Epoch number: 2654/10000step_number: 0/29 Accuracy:  0.9231738464158011 Loss:  1.332939997499142 Val_accuracy:  0.9079269953691093 Val_cost:  1.332939997499142 Val_accuracy:  0.9079269953691093 Val_Acc:  1.5601417267838085\n",
      "Epoch number: 2655/10000step_number: 0/29 Accuracy:  0.9231397922697089 Loss:  1.3329646206949528 Val_accuracy:  0.9080631980386815 Val_cost:  1.3329646206949528 Val_accuracy:  0.9080631980386815 Val_Acc:  1.560137062998383\n",
      "Epoch number: 2656/10000step_number: 0/29 Accuracy:  0.9230716839775243 Loss:  1.33299152537175 Val_accuracy:  0.9080631980386815 Val_cost:  1.33299152537175 Val_accuracy:  0.9080631980386815 Val_Acc:  1.5601360835163607\n",
      "Epoch number: 2657/10000step_number: 0/29 Accuracy:  0.9230716839775243 Loss:  1.333020499553113 Val_accuracy:  0.9081994007082539 Val_cost:  1.333020499553113 Val_accuracy:  0.9081994007082539 Val_Acc:  1.5601385680243054\n",
      "Epoch number: 2658/10000step_number: 0/29 Accuracy:  0.9218116805721096 Loss:  1.3330513538673399 Val_accuracy:  0.906564968673386 Val_cost:  1.3330513538673399 Val_accuracy:  0.906564968673386 Val_Acc:  1.560144281561024\n",
      "Epoch number: 2659/10000step_number: 0/29 Accuracy:  0.9218116805721096 Loss:  1.3330839197016953 Val_accuracy:  0.9062925633342414 Val_cost:  1.3330839197016953 Val_accuracy:  0.9062925633342414 Val_Acc:  1.5601529925636661\n",
      "Epoch number: 2660/10000step_number: 0/29 Accuracy:  0.9218797888642942 Loss:  1.3331180432380147 Val_accuracy:  0.9062925633342414 Val_cost:  1.3331180432380147 Val_accuracy:  0.9062925633342414 Val_Acc:  1.5601644831237917\n",
      "Epoch number: 2661/10000step_number: 0/29 Accuracy:  0.9219478971564788 Loss:  1.3331535793917915 Val_accuracy:  0.9064287660038137 Val_cost:  1.3331535793917915 Val_accuracy:  0.9064287660038137 Val_Acc:  1.5601785542727835\n",
      "Epoch number: 2662/10000step_number: 0/29 Accuracy:  0.922084113740848 Loss:  1.333190388102752 Val_accuracy:  0.9064287660038137 Val_cost:  1.333190388102752 Val_accuracy:  0.9064287660038137 Val_Acc:  1.5601950286951134\n",
      "Epoch number: 2663/10000step_number: 0/29 Accuracy:  0.9220160054486634 Loss:  1.333228333469162 Val_accuracy:  0.9062925633342414 Val_cost:  1.333228333469162 Val_accuracy:  0.9062925633342414 Val_Acc:  1.560213751858909\n",
      "Epoch number: 2664/10000step_number: 0/29 Accuracy:  0.9217776264260173 Loss:  1.3332672848807883 Val_accuracy:  0.9064287660038137 Val_cost:  1.3332672848807883 Val_accuracy:  0.9064287660038137 Val_Acc:  1.560234591794356\n",
      "Epoch number: 2665/10000step_number: 0/29 Accuracy:  0.9217095181338328 Loss:  1.3333071189078969 Val_accuracy:  0.906564968673386 Val_cost:  1.3333071189078969 Val_accuracy:  0.906564968673386 Val_Acc:  1.5602574373853864\n",
      "Epoch number: 2666/10000step_number: 0/29 Accuracy:  0.9217095181338328 Loss:  1.3333477209435423 Val_accuracy:  0.906564968673386 Val_cost:  1.3333477209435423 Val_accuracy:  0.906564968673386 Val_Acc:  1.560282195170699\n",
      "Epoch number: 2667/10000step_number: 0/29 Accuracy:  0.9219138430103865 Loss:  1.3333889859442014 Val_accuracy:  0.9068373740125306 Val_cost:  1.3333889859442014 Val_accuracy:  0.9068373740125306 Val_Acc:  1.560308784992705\n",
      "Epoch number: 2668/10000step_number: 0/29 Accuracy:  0.9219478971564788 Loss:  1.333430817675992 Val_accuracy:  0.906973576682103 Val_cost:  1.333430817675992 Val_accuracy:  0.906973576682103 Val_Acc:  1.5603371351341262\n",
      "Epoch number: 2669/10000step_number: 0/29 Accuracy:  0.9218797888642942 Loss:  1.3334731254922454 Val_accuracy:  0.9068373740125306 Val_cost:  1.3334731254922454 Val_accuracy:  0.9068373740125306 Val_Acc:  1.5603671777357695\n",
      "Epoch number: 2670/10000step_number: 0/29 Accuracy:  0.9219819513025711 Loss:  1.3335158168376784 Val_accuracy:  0.9067011713429584 Val_cost:  1.3335158168376784 Val_accuracy:  0.9067011713429584 Val_Acc:  1.5603988452565358\n",
      "Epoch number: 2671/10000step_number: 0/29 Accuracy:  0.9219819513025711 Loss:  1.333558782535637 Val_accuracy:  0.9068373740125306 Val_cost:  1.333558782535637 Val_accuracy:  0.9068373740125306 Val_Acc:  1.560432068803159\n",
      "Epoch number: 2672/10000step_number: 0/29 Accuracy:  0.9219138430103865 Loss:  1.333601871133336 Val_accuracy:  0.9062925633342414 Val_cost:  1.333601871133336 Val_accuracy:  0.9062925633342414 Val_Acc:  1.5604667790929732\n",
      "Epoch number: 2673/10000step_number: 0/29 Accuracy:  0.9222203303252171 Loss:  1.3336448504703926 Val_accuracy:  0.9064287660038137 Val_cost:  1.3336448504703926 Val_accuracy:  0.9064287660038137 Val_Acc:  1.560502910942705\n",
      "Epoch number: 2674/10000step_number: 0/29 Accuracy:  0.9224246552017709 Loss:  1.3336873649757677 Val_accuracy:  0.9062925633342414 Val_cost:  1.3336873649757677 Val_accuracy:  0.9062925633342414 Val_Acc:  1.560540412244907\n",
      "Epoch number: 2675/10000step_number: 0/29 Accuracy:  0.92256087178614 Loss:  1.3337289244630761 Val_accuracy:  0.9064287660038137 Val_cost:  1.3337289244630761 Val_accuracy:  0.9064287660038137 Val_Acc:  1.560579258582109\n",
      "Epoch number: 2676/10000step_number: 0/29 Accuracy:  0.9227311425166014 Loss:  1.333768999818023 Val_accuracy:  0.906156360664669 Val_cost:  1.333768999818023 Val_accuracy:  0.906156360664669 Val_Acc:  1.5606194746166357\n",
      "Epoch number: 2677/10000step_number: 0/29 Accuracy:  0.9216414098416482 Loss:  1.333807293160978 Val_accuracy:  0.9046581312993734 Val_cost:  1.333807293160978 Val_accuracy:  0.9046581312993734 Val_Acc:  1.5606611601710356\n",
      "Epoch number: 2678/10000step_number: 0/29 Accuracy:  0.9215733015494636 Loss:  1.3338440830693625 Val_accuracy:  0.9047943339689458 Val_cost:  1.3338440830693625 Val_accuracy:  0.9047943339689458 Val_Acc:  1.5607045060220797\n",
      "Epoch number: 2679/10000step_number: 0/29 Accuracy:  0.9215051932572791 Loss:  1.33388029482195 Val_accuracy:  0.9045219286298012 Val_cost:  1.33388029482195 Val_accuracy:  0.9045219286298012 Val_Acc:  1.5607497634681262\n",
      "Epoch number: 2680/10000step_number: 0/29 Accuracy:  0.9214711391111868 Loss:  1.3339170747992235 Val_accuracy:  0.9045219286298012 Val_cost:  1.3339170747992235 Val_accuracy:  0.9045219286298012 Val_Acc:  1.5607971400224578\n",
      "Epoch number: 2681/10000step_number: 0/29 Accuracy:  0.9214370849650945 Loss:  1.3339552254107225 Val_accuracy:  0.9046581312993734 Val_cost:  1.3339552254107225 Val_accuracy:  0.9046581312993734 Val_Acc:  1.560846664264474\n",
      "Epoch number: 2682/10000step_number: 0/29 Accuracy:  0.9213008683807253 Loss:  1.3339949887926315 Val_accuracy:  0.9046581312993734 Val_cost:  1.3339949887926315 Val_accuracy:  0.9046581312993734 Val_Acc:  1.5608981135640667\n",
      "Epoch number: 2683/10000step_number: 0/29 Accuracy:  0.9214030308190022 Loss:  1.3340361724182825 Val_accuracy:  0.9047943339689458 Val_cost:  1.3340361724182825 Val_accuracy:  0.9047943339689458 Val_Acc:  1.5609510357949559\n",
      "Epoch number: 2684/10000step_number: 0/29 Accuracy:  0.9215733015494636 Loss:  1.334078369257807 Val_accuracy:  0.9047943339689458 Val_cost:  1.334078369257807 Val_accuracy:  0.9047943339689458 Val_Acc:  1.5610048368179215\n",
      "Epoch number: 2685/10000step_number: 0/29 Accuracy:  0.9216414098416482 Loss:  1.334121147698338 Val_accuracy:  0.9052029419776627 Val_cost:  1.334121147698338 Val_accuracy:  0.9052029419776627 Val_Acc:  1.5610589197916658\n",
      "Epoch number: 2686/10000step_number: 0/29 Accuracy:  0.9217095181338328 Loss:  1.3341641691529 Val_accuracy:  0.9052029419776627 Val_cost:  1.3341641691529 Val_accuracy:  0.9052029419776627 Val_Acc:  1.561112830840054\n",
      "Epoch number: 2687/10000step_number: 0/29 Accuracy:  0.9217435722799251 Loss:  1.3342072187758118 Val_accuracy:  0.9052029419776627 Val_cost:  1.3342072187758118 Val_accuracy:  0.9052029419776627 Val_Acc:  1.5611663271539244\n",
      "Epoch number: 2688/10000step_number: 0/29 Accuracy:  0.9218116805721096 Loss:  1.3342501809885219 Val_accuracy:  0.9052029419776627 Val_cost:  1.3342501809885219 Val_accuracy:  0.9052029419776627 Val_Acc:  1.5612193433975725\n",
      "Epoch number: 2689/10000step_number: 0/29 Accuracy:  0.9218116805721096 Loss:  1.3342930040080192 Val_accuracy:  0.9054753473168075 Val_cost:  1.3342930040080192 Val_accuracy:  0.9054753473168075 Val_Acc:  1.5612719113070563\n",
      "Epoch number: 2690/10000step_number: 0/29 Accuracy:  0.9213008683807253 Loss:  1.3343356723237147 Val_accuracy:  0.9050667393080905 Val_cost:  1.3343356723237147 Val_accuracy:  0.9050667393080905 Val_Acc:  1.561324093234486\n",
      "Epoch number: 2691/10000step_number: 0/29 Accuracy:  0.9213008683807253 Loss:  1.334378188877707 Val_accuracy:  0.9049305366385181 Val_cost:  1.334378188877707 Val_accuracy:  0.9049305366385181 Val_Acc:  1.5613759516861503\n",
      "Epoch number: 2692/10000step_number: 0/29 Accuracy:  0.9213349225268176 Loss:  1.3344205651178567 Val_accuracy:  0.9049305366385181 Val_cost:  1.3344205651178567 Val_accuracy:  0.9049305366385181 Val_Acc:  1.561427546498289\n",
      "Epoch number: 2693/10000step_number: 0/29 Accuracy:  0.9213349225268176 Loss:  1.3344628162083936 Val_accuracy:  0.9052029419776627 Val_cost:  1.3344628162083936 Val_accuracy:  0.9052029419776627 Val_Acc:  1.5614789436734864\n",
      "Epoch number: 2694/10000step_number: 0/29 Accuracy:  0.9214370849650945 Loss:  1.3345049586518642 Val_accuracy:  0.9053391446472351 Val_cost:  1.3345049586518642 Val_accuracy:  0.9053391446472351 Val_Acc:  1.5615302248239131\n",
      "Epoch number: 2695/10000step_number: 0/29 Accuracy:  0.9214030308190022 Loss:  1.33454700870807 Val_accuracy:  0.9053391446472351 Val_cost:  1.33454700870807 Val_accuracy:  0.9053391446472351 Val_Acc:  1.561581492890375\n",
      "Epoch number: 2696/10000step_number: 0/29 Accuracy:  0.9213349225268176 Loss:  1.334588981202902 Val_accuracy:  0.9053391446472351 Val_cost:  1.334588981202902 Val_accuracy:  0.9053391446472351 Val_Acc:  1.5616328737660417\n",
      "Epoch number: 2697/10000step_number: 0/29 Accuracy:  0.9215733015494636 Loss:  1.3346308888243368 Val_accuracy:  0.9053391446472351 Val_cost:  1.3346308888243368 Val_accuracy:  0.9053391446472351 Val_Acc:  1.561684514924261\n",
      "Epoch number: 2698/10000step_number: 0/29 Accuracy:  0.9215051932572791 Loss:  1.3346727419607585 Val_accuracy:  0.9056115499863797 Val_cost:  1.3346727419607585 Val_accuracy:  0.9056115499863797 Val_Acc:  1.5617365821955256\n",
      "Epoch number: 2699/10000step_number: 0/29 Accuracy:  0.9214711391111868 Loss:  1.3347145489707515 Val_accuracy:  0.9057477526559521 Val_cost:  1.3347145489707515 Val_accuracy:  0.9057477526559521 Val_Acc:  1.561789255381235\n",
      "Epoch number: 2700/10000step_number: 0/29 Accuracy:  0.9214370849650945 Loss:  1.334756316690622 Val_accuracy:  0.9057477526559521 Val_cost:  1.334756316690622 Val_accuracy:  0.9057477526559521 Val_Acc:  1.5618427232017498\n",
      "Epoch number: 2701/10000step_number: 0/29 Accuracy:  0.9212668142346331 Loss:  1.3347980509892583 Val_accuracy:  0.9058839553255243 Val_cost:  1.3347980509892583 Val_accuracy:  0.9058839553255243 Val_Acc:  1.5618971777858834\n",
      "Epoch number: 2702/10000step_number: 0/29 Accuracy:  0.9213008683807253 Loss:  1.334839757215923 Val_accuracy:  0.9060201579950967 Val_cost:  1.334839757215923 Val_accuracy:  0.9060201579950967 Val_Acc:  1.561952808968336\n",
      "Epoch number: 2703/10000step_number: 0/29 Accuracy:  0.9213349225268176 Loss:  1.3348814404234985 Val_accuracy:  0.9058839553255243 Val_cost:  1.3348814404234985 Val_accuracy:  0.9058839553255243 Val_Acc:  1.5620097986944415\n",
      "Epoch number: 2704/10000step_number: 0/29 Accuracy:  0.9212327600885408 Loss:  1.3349231052838946 Val_accuracy:  0.9058839553255243 Val_cost:  1.3349231052838946 Val_accuracy:  0.9058839553255243 Val_Acc:  1.5620683157229815\n",
      "Epoch number: 2705/10000step_number: 0/29 Accuracy:  0.9211646517963562 Loss:  1.3349647556504478 Val_accuracy:  0.906156360664669 Val_cost:  1.3349647556504478 Val_accuracy:  0.906156360664669 Val_Acc:  1.5621285108967524\n",
      "Epoch number: 2706/10000step_number: 0/29 Accuracy:  0.9210965435041716 Loss:  1.3350063937670757 Val_accuracy:  0.9060201579950967 Val_cost:  1.3350063937670757 Val_accuracy:  0.9060201579950967 Val_Acc:  1.5621905131337637\n",
      "Epoch number: 2707/10000step_number: 0/29 Accuracy:  0.9210624893580793 Loss:  1.3350480191710346 Val_accuracy:  0.9060201579950967 Val_cost:  1.3350480191710346 Val_accuracy:  0.9060201579950967 Val_Acc:  1.5622544262192737\n",
      "Epoch number: 2708/10000step_number: 0/29 Accuracy:  0.9210965435041716 Loss:  1.3350896273764652 Val_accuracy:  0.9060201579950967 Val_cost:  1.3350896273764652 Val_accuracy:  0.9060201579950967 Val_Acc:  1.562320326454804\n",
      "Epoch number: 2709/10000step_number: 0/29 Accuracy:  0.9209943810658948 Loss:  1.335131208451831 Val_accuracy:  0.9058839553255243 Val_cost:  1.335131208451831 Val_accuracy:  0.9058839553255243 Val_Acc:  1.5623882611773858\n",
      "Epoch number: 2710/10000step_number: 0/29 Accuracy:  0.9210965435041716 Loss:  1.3351727456135354 Val_accuracy:  0.9062925633342414 Val_cost:  1.3351727456135354 Val_accuracy:  0.9062925633342414 Val_Acc:  1.5624582481592129\n",
      "Epoch number: 2711/10000step_number: 0/29 Accuracy:  0.9210624893580793 Loss:  1.3352142139525294 Val_accuracy:  0.906156360664669 Val_cost:  1.3352142139525294 Val_accuracy:  0.906156360664669 Val_Acc:  1.5625302758528403\n",
      "Epoch number: 2712/10000step_number: 0/29 Accuracy:  0.9211646517963562 Loss:  1.3352555793952405 Val_accuracy:  0.9060201579950967 Val_cost:  1.3352555793952405 Val_accuracy:  0.9060201579950967 Val_Acc:  1.5626043044877926\n",
      "Epoch number: 2713/10000step_number: 0/29 Accuracy:  0.9209262727737102 Loss:  1.3352967979786676 Val_accuracy:  0.9058839553255243 Val_cost:  1.3352967979786676 Val_accuracy:  0.9058839553255243 Val_Acc:  1.562680267960337\n",
      "Epoch number: 2714/10000step_number: 0/29 Accuracy:  0.9209943810658948 Loss:  1.3353378154945768 Val_accuracy:  0.9057477526559521 Val_cost:  1.3353378154945768 Val_accuracy:  0.9057477526559521 Val_Acc:  1.5627580764311597\n",
      "Epoch number: 2715/10000step_number: 0/29 Accuracy:  0.9209603269198025 Loss:  1.3353785675310652 Val_accuracy:  0.9057477526559521 Val_cost:  1.3353785675310652 Val_accuracy:  0.9057477526559521 Val_Acc:  1.5628376195561984\n",
      "Epoch number: 2716/10000step_number: 0/29 Accuracy:  0.9210624893580793 Loss:  1.3354189799123024 Val_accuracy:  0.9057477526559521 Val_cost:  1.3354189799123024 Val_accuracy:  0.9057477526559521 Val_Acc:  1.5629187701840253\n",
      "Epoch number: 2717/10000step_number: 0/29 Accuracy:  0.9210965435041716 Loss:  1.335458969510852 Val_accuracy:  0.9056115499863797 Val_cost:  1.335458969510852 Val_accuracy:  0.9056115499863797 Val_Acc:  1.56300138838351\n",
      "Epoch number: 2718/10000step_number: 0/29 Accuracy:  0.9211646517963562 Loss:  1.3354984453835523 Val_accuracy:  0.9053391446472351 Val_cost:  1.3354984453835523 Val_accuracy:  0.9053391446472351 Val_Acc:  1.5630853256340909\n",
      "Epoch number: 2719/10000step_number: 0/29 Accuracy:  0.9210624893580793 Loss:  1.3355373101635293 Val_accuracy:  0.9056115499863797 Val_cost:  1.3355373101635293 Val_accuracy:  0.9056115499863797 Val_Acc:  1.5631704290113868\n",
      "Epoch number: 2720/10000step_number: 0/29 Accuracy:  0.9209943810658948 Loss:  1.3355754616291131 Val_accuracy:  0.9056115499863797 Val_cost:  1.3355754616291131 Val_accuracy:  0.9056115499863797 Val_Acc:  1.5632565452342106\n",
      "Epoch number: 2721/10000step_number: 0/29 Accuracy:  0.9208922186276179 Loss:  1.335612794365703 Val_accuracy:  0.9053391446472351 Val_cost:  1.335612794365703 Val_accuracy:  0.9053391446472351 Val_Acc:  1.5633435243908549\n",
      "Epoch number: 2722/10000step_number: 0/29 Accuracy:  0.9208581644815256 Loss:  1.3356492014386385 Val_accuracy:  0.9056115499863797 Val_cost:  1.3356492014386385 Val_accuracy:  0.9056115499863797 Val_Acc:  1.5634312233074956\n",
      "Epoch number: 2723/10000step_number: 0/29 Accuracy:  0.9206197854588796 Loss:  1.3356845760026341 Val_accuracy:  0.9056115499863797 Val_cost:  1.3356845760026341 Val_accuracy:  0.9056115499863797 Val_Acc:  1.5635195084046682\n",
      "Epoch number: 2724/10000step_number: 0/29 Accuracy:  0.9205857313127873 Loss:  1.3357188127847444 Val_accuracy:  0.9057477526559521 Val_cost:  1.3357188127847444 Val_accuracy:  0.9057477526559521 Val_Acc:  1.5636082580118436\n",
      "Epoch number: 2725/10000step_number: 0/29 Accuracy:  0.9205176230206028 Loss:  1.335751809391433 Val_accuracy:  0.9057477526559521 Val_cost:  1.335751809391433 Val_accuracy:  0.9057477526559521 Val_Acc:  1.5636973641190028\n",
      "Epoch number: 2726/10000step_number: 0/29 Accuracy:  0.9204154605823259 Loss:  1.3357834674047016 Val_accuracy:  0.9057477526559521 Val_cost:  1.3357834674047016 Val_accuracy:  0.9057477526559521 Val_Acc:  1.5637867335335327\n",
      "Epoch number: 2727/10000step_number: 0/29 Accuracy:  0.9203814064362336 Loss:  1.3358136932463809 Val_accuracy:  0.9056115499863797 Val_cost:  1.3358136932463809 Val_accuracy:  0.9056115499863797 Val_Acc:  1.5638762884528339\n",
      "Epoch number: 2728/10000step_number: 0/29 Accuracy:  0.9203473522901413 Loss:  1.3358423988027792 Val_accuracy:  0.9053391446472351 Val_cost:  1.3358423988027792 Val_accuracy:  0.9053391446472351 Val_Acc:  1.563965966505785\n",
      "Epoch number: 2729/10000step_number: 0/29 Accuracy:  0.9204495147284182 Loss:  1.3358695018137021 Val_accuracy:  0.9053391446472351 Val_cost:  1.3358695018137021 Val_accuracy:  0.9053391446472351 Val_Acc:  1.564055720315201\n",
      "Epoch number: 2730/10000step_number: 0/29 Accuracy:  0.9204495147284182 Loss:  1.3358949260400805 Val_accuracy:  0.9053391446472351 Val_cost:  1.3358949260400805 Val_accuracy:  0.9053391446472351 Val_Acc:  1.5641455166207707\n",
      "Epoch number: 2731/10000step_number: 0/29 Accuracy:  0.9204835688745104 Loss:  1.3359186012330675 Val_accuracy:  0.9056115499863797 Val_cost:  1.3359186012330675 Val_accuracy:  0.9056115499863797 Val_Acc:  1.5642353350613776\n",
      "Epoch number: 2732/10000step_number: 0/29 Accuracy:  0.9206197854588796 Loss:  1.3359404629343474 Val_accuracy:  0.9056115499863797 Val_cost:  1.3359404629343474 Val_accuracy:  0.9056115499863797 Val_Acc:  1.5643251666957374\n",
      "Epoch number: 2733/10000step_number: 0/29 Accuracy:  0.9206538396049719 Loss:  1.335960452142529 Val_accuracy:  0.9056115499863797 Val_cost:  1.335960452142529 Val_accuracy:  0.9056115499863797 Val_Acc:  1.5644150123484206\n",
      "Epoch number: 2734/10000step_number: 0/29 Accuracy:  0.9207219478971564 Loss:  1.335978514883678 Val_accuracy:  0.9056115499863797 Val_cost:  1.335978514883678 Val_accuracy:  0.9056115499863797 Val_Acc:  1.5645048808513973\n",
      "Epoch number: 2735/10000step_number: 0/29 Accuracy:  0.9207219478971564 Loss:  1.3359946017252204 Val_accuracy:  0.9057477526559521 Val_cost:  1.3359946017252204 Val_accuracy:  0.9057477526559521 Val_Acc:  1.5645947872790493\n",
      "Epoch number: 2736/10000step_number: 0/29 Accuracy:  0.9207560020432488 Loss:  1.3360086672715692 Val_accuracy:  0.9056115499863797 Val_cost:  1.3360086672715692 Val_accuracy:  0.9056115499863797 Val_Acc:  1.5646847512184985\n",
      "Epoch number: 2737/10000step_number: 0/29 Accuracy:  0.9207560020432488 Loss:  1.3360206696768646 Val_accuracy:  0.9054753473168075 Val_cost:  1.3360206696768646 Val_accuracy:  0.9054753473168075 Val_Acc:  1.5647747951543451\n",
      "Epoch number: 2738/10000step_number: 0/29 Accuracy:  0.9208581644815256 Loss:  1.3360305702054216 Val_accuracy:  0.9054753473168075 Val_cost:  1.3360305702054216 Val_accuracy:  0.9054753473168075 Val_Acc:  1.564864943015858\n",
      "Epoch number: 2739/10000step_number: 0/29 Accuracy:  0.9208922186276179 Loss:  1.3360383328641379 Val_accuracy:  0.9054753473168075 Val_cost:  1.3360383328641379 Val_accuracy:  0.9054753473168075 Val_Acc:  1.564955218890138\n",
      "Epoch number: 2740/10000step_number: 0/29 Accuracy:  0.9208581644815256 Loss:  1.336043924123751 Val_accuracy:  0.9052029419776627 Val_cost:  1.336043924123751 Val_accuracy:  0.9052029419776627 Val_Acc:  1.565045645967256\n",
      "Epoch number: 2741/10000step_number: 0/29 Accuracy:  0.9209262727737102 Loss:  1.3360473127380412 Val_accuracy:  0.9052029419776627 Val_cost:  1.3360473127380412 Val_accuracy:  0.9052029419776627 Val_Acc:  1.5651362456925821\n",
      "Epoch number: 2742/10000step_number: 0/29 Accuracy:  0.9209262727737102 Loss:  1.3360484696625872 Val_accuracy:  0.9053391446472351 Val_cost:  1.3360484696625872 Val_accuracy:  0.9053391446472351 Val_Acc:  1.5652270371503978\n",
      "Epoch number: 2743/10000step_number: 0/29 Accuracy:  0.9209943810658948 Loss:  1.336047368067982 Val_accuracy:  0.9053391446472351 Val_cost:  1.336047368067982 Val_accuracy:  0.9053391446472351 Val_Acc:  1.5653180366789539\n",
      "Epoch number: 2744/10000step_number: 0/29 Accuracy:  0.9209262727737102 Loss:  1.336043983437107 Val_accuracy:  0.9052029419776627 Val_cost:  1.336043983437107 Val_accuracy:  0.9052029419776627 Val_Acc:  1.565409257673885\n",
      "Epoch number: 2745/10000step_number: 0/29 Accuracy:  0.9209603269198025 Loss:  1.3360382937323558 Val_accuracy:  0.9052029419776627 Val_cost:  1.3360382937323558 Val_accuracy:  0.9052029419776627 Val_Acc:  1.5655007106032566\n",
      "Epoch number: 2746/10000step_number: 0/29 Accuracy:  0.9209603269198025 Loss:  1.3360302796166073 Val_accuracy:  0.9050667393080905 Val_cost:  1.3360302796166073 Val_accuracy:  0.9050667393080905 Val_Acc:  1.5655924031696284\n",
      "Epoch number: 2747/10000step_number: 0/29 Accuracy:  0.9209603269198025 Loss:  1.3360199247111013 Val_accuracy:  0.9050667393080905 Val_cost:  1.3360199247111013 Val_accuracy:  0.9050667393080905 Val_Acc:  1.5656843406207837\n",
      "Epoch number: 2748/10000step_number: 0/29 Accuracy:  0.9209943810658948 Loss:  1.3360072158737595 Val_accuracy:  0.9050667393080905 Val_cost:  1.3360072158737595 Val_accuracy:  0.9050667393080905 Val_Acc:  1.5657765261284629\n",
      "Epoch number: 2749/10000step_number: 0/29 Accuracy:  0.9209603269198025 Loss:  1.335992143482318 Val_accuracy:  0.9050667393080905 Val_cost:  1.335992143482318 Val_accuracy:  0.9050667393080905 Val_Acc:  1.5658689612394217\n",
      "Epoch number: 2750/10000step_number: 0/29 Accuracy:  0.9209603269198025 Loss:  1.3359747017073365 Val_accuracy:  0.9047943339689458 Val_cost:  1.3359747017073365 Val_accuracy:  0.9047943339689458 Val_Acc:  1.5659616462855146\n",
      "Epoch number: 2751/10000step_number: 0/29 Accuracy:  0.921130597650264 Loss:  1.3359548887601709 Val_accuracy:  0.9047943339689458 Val_cost:  1.3359548887601709 Val_accuracy:  0.9047943339689458 Val_Acc:  1.566054580768329\n",
      "Epoch number: 2752/10000step_number: 0/29 Accuracy:  0.921130597650264 Loss:  1.335932707099927 Val_accuracy:  0.9052029419776627 Val_cost:  1.335932707099927 Val_accuracy:  0.9052029419776627 Val_Acc:  1.5661477635801744\n",
      "Epoch number: 2753/10000step_number: 0/29 Accuracy:  0.921130597650264 Loss:  1.3359081635812453 Val_accuracy:  0.9052029419776627 Val_cost:  1.3359081635812453 Val_accuracy:  0.9052029419776627 Val_Acc:  1.566241193075563\n",
      "Epoch number: 2754/10000step_number: 0/29 Accuracy:  0.921130597650264 Loss:  1.3358812695218794 Val_accuracy:  0.9052029419776627 Val_cost:  1.3358812695218794 Val_accuracy:  0.9052029419776627 Val_Acc:  1.5663348669170962\n",
      "Epoch number: 2755/10000step_number: 0/29 Accuracy:  0.9210284352119871 Loss:  1.3358520406663947 Val_accuracy:  0.9052029419776627 Val_cost:  1.3358520406663947 Val_accuracy:  0.9052029419776627 Val_Acc:  1.5664287816663147\n",
      "Epoch number: 2756/10000step_number: 0/29 Accuracy:  0.9210624893580793 Loss:  1.3358204970214702 Val_accuracy:  0.9053391446472351 Val_cost:  1.3358204970214702 Val_accuracy:  0.9053391446472351 Val_Acc:  1.5665229321808147\n",
      "Epoch number: 2757/10000step_number: 0/29 Accuracy:  0.92136897667291 Loss:  1.3357866625411752 Val_accuracy:  0.9054753473168075 Val_cost:  1.3357866625411752 Val_accuracy:  0.9054753473168075 Val_Acc:  1.5666173107576022\n",
      "Epoch number: 2758/10000step_number: 0/29 Accuracy:  0.92136897667291 Loss:  1.3357505646490107 Val_accuracy:  0.9054753473168075 Val_cost:  1.3357505646490107 Val_accuracy:  0.9054753473168075 Val_Acc:  1.5667119062181174\n",
      "Epoch number: 2759/10000step_number: 0/29 Accuracy:  0.92136897667291 Loss:  1.3357122335987939 Val_accuracy:  0.9058839553255243 Val_cost:  1.3357122335987939 Val_accuracy:  0.9058839553255243 Val_Acc:  1.5668067029409674\n",
      "Epoch number: 2760/10000step_number: 0/29 Accuracy:  0.92136897667291 Loss:  1.3356717016980935 Val_accuracy:  0.9058839553255243 Val_cost:  1.3356717016980935 Val_accuracy:  0.9058839553255243 Val_Acc:  1.5669016800226276\n",
      "Epoch number: 2761/10000step_number: 0/29 Accuracy:  0.9214370849650945 Loss:  1.335629002443472 Val_accuracy:  0.906156360664669 Val_cost:  1.335629002443472 Val_accuracy:  0.906156360664669 Val_Acc:  1.5669968107071452\n",
      "Epoch number: 2762/10000step_number: 0/29 Accuracy:  0.9214370849650945 Loss:  1.3355841696414434 Val_accuracy:  0.906156360664669 Val_cost:  1.3355841696414434 Val_accuracy:  0.906156360664669 Val_Acc:  1.56709206218187\n",
      "Epoch number: 2763/10000step_number: 0/29 Accuracy:  0.9215733015494636 Loss:  1.3355372366063654 Val_accuracy:  0.9062925633342414 Val_cost:  1.3355372366063654 Val_accuracy:  0.9062925633342414 Val_Acc:  1.5671873958403484\n",
      "Epoch number: 2764/10000step_number: 0/29 Accuracy:  0.9217435722799251 Loss:  1.3354882355302369 Val_accuracy:  0.9062925633342414 Val_cost:  1.3354882355302369 Val_accuracy:  0.9062925633342414 Val_Acc:  1.567282768015503\n",
      "Epoch number: 2765/10000step_number: 0/29 Accuracy:  0.921845734718202 Loss:  1.3354371971058092 Val_accuracy:  0.9062925633342414 Val_cost:  1.3354371971058092 Val_accuracy:  0.9062925633342414 Val_Acc:  1.5673781312001094\n",
      "Epoch number: 2766/10000step_number: 0/29 Accuracy:  0.9218797888642942 Loss:  1.3353841504537298 Val_accuracy:  0.9062925633342414 Val_cost:  1.3353841504537298 Val_accuracy:  0.9062925633342414 Val_Acc:  1.5674734355996118\n",
      "Epoch number: 2767/10000step_number: 0/29 Accuracy:  0.9218116805721096 Loss:  1.3353291233623255 Val_accuracy:  0.9064287660038137 Val_cost:  1.3353291233623255 Val_accuracy:  0.9064287660038137 Val_Acc:  1.567568630951264\n",
      "Epoch number: 2768/10000step_number: 0/29 Accuracy:  0.9218116805721096 Loss:  1.335272142803937 Val_accuracy:  0.9062925633342414 Val_cost:  1.335272142803937 Val_accuracy:  0.9062925633342414 Val_Acc:  1.5676636683749576\n",
      "Epoch number: 2769/10000step_number: 0/29 Accuracy:  0.9219819513025711 Loss:  1.3352132356548547 Val_accuracy:  0.9064287660038137 Val_cost:  1.3352132356548547 Val_accuracy:  0.9064287660038137 Val_Acc:  1.56775850221345\n",
      "Epoch number: 2770/10000step_number: 0/29 Accuracy:  0.9221181678869402 Loss:  1.3351524295246044 Val_accuracy:  0.9067011713429584 Val_cost:  1.3351524295246044 Val_accuracy:  0.9067011713429584 Val_Acc:  1.5678530915977718\n",
      "Epoch number: 2771/10000step_number: 0/29 Accuracy:  0.9221181678869402 Loss:  1.3350897535979136 Val_accuracy:  0.9067011713429584 Val_cost:  1.3350897535979136 Val_accuracy:  0.9067011713429584 Val_Acc:  1.5679474017901793\n",
      "Epoch number: 2772/10000step_number: 0/29 Accuracy:  0.9222203303252171 Loss:  1.3350252394069857 Val_accuracy:  0.9067011713429584 Val_cost:  1.3350252394069857 Val_accuracy:  0.9067011713429584 Val_Acc:  1.5680414051554794\n",
      "Epoch number: 2773/10000step_number: 0/29 Accuracy:  0.9222203303252171 Loss:  1.3349589214766884 Val_accuracy:  0.9067011713429584 Val_cost:  1.3349589214766884 Val_accuracy:  0.9067011713429584 Val_Acc:  1.5681350817869248\n",
      "Epoch number: 2774/10000step_number: 0/29 Accuracy:  0.9222543844713094 Loss:  1.3348908378134003 Val_accuracy:  0.9068373740125306 Val_cost:  1.3348908378134003 Val_accuracy:  0.9068373740125306 Val_Acc:  1.5682284198109315\n",
      "Epoch number: 2775/10000step_number: 0/29 Accuracy:  0.9222543844713094 Loss:  1.3348210302329944 Val_accuracy:  0.9068373740125306 Val_cost:  1.3348210302329944 Val_accuracy:  0.9068373740125306 Val_Acc:  1.568321415349173\n",
      "Epoch number: 2776/10000step_number: 0/29 Accuracy:  0.9222543844713094 Loss:  1.334749544540786 Val_accuracy:  0.9068373740125306 Val_cost:  1.334749544540786 Val_accuracy:  0.9068373740125306 Val_Acc:  1.5684140721878035\n",
      "Epoch number: 2777/10000step_number: 0/29 Accuracy:  0.9223565469095862 Loss:  1.3346764305853196 Val_accuracy:  0.9068373740125306 Val_cost:  1.3346764305853196 Val_accuracy:  0.9068373740125306 Val_Acc:  1.5685064010476268\n",
      "Epoch number: 2778/10000step_number: 0/29 Accuracy:  0.9223906010556785 Loss:  1.334601742210226 Val_accuracy:  0.906973576682103 Val_cost:  1.334601742210226 Val_accuracy:  0.906973576682103 Val_Acc:  1.5685984184451678\n",
      "Epoch number: 2779/10000step_number: 0/29 Accuracy:  0.9223565469095862 Loss:  1.3345255371274198 Val_accuracy:  0.9071097793516752 Val_cost:  1.3345255371274198 Val_accuracy:  0.9071097793516752 Val_Acc:  1.5686901449348094\n",
      "Epoch number: 2780/10000step_number: 0/29 Accuracy:  0.9224246552017709 Loss:  1.3344478767351136 Val_accuracy:  0.906973576682103 Val_cost:  1.3344478767351136 Val_accuracy:  0.906973576682103 Val_Acc:  1.5687816024989227\n",
      "Epoch number: 2781/10000step_number: 0/29 Accuracy:  0.9224246552017709 Loss:  1.3343688259110211 Val_accuracy:  0.906973576682103 Val_cost:  1.3343688259110211 Val_accuracy:  0.906973576682103 Val_Acc:  1.5688728107530492\n",
      "Epoch number: 2782/10000step_number: 0/29 Accuracy:  0.9225268176400476 Loss:  1.3342884528310923 Val_accuracy:  0.9071097793516752 Val_cost:  1.3342884528310923 Val_accuracy:  0.9071097793516752 Val_Acc:  1.5689637815418116\n",
      "Epoch number: 2783/10000step_number: 0/29 Accuracy:  0.9225268176400476 Loss:  1.3342068289045328 Val_accuracy:  0.9071097793516752 Val_cost:  1.3342068289045328 Val_accuracy:  0.9071097793516752 Val_Acc:  1.5690545114825774\n",
      "Epoch number: 2784/10000step_number: 0/29 Accuracy:  0.92256087178614 Loss:  1.3341240289829235 Val_accuracy:  0.9071097793516752 Val_cost:  1.3341240289829235 Val_accuracy:  0.9071097793516752 Val_Acc:  1.5691449720928656\n",
      "Epoch number: 2785/10000step_number: 0/29 Accuracy:  0.9224927634939554 Loss:  1.3340401320950552 Val_accuracy:  0.9071097793516752 Val_cost:  1.3340401320950552 Val_accuracy:  0.9071097793516752 Val_Acc:  1.5692350974670601\n",
      "Epoch number: 2786/10000step_number: 0/29 Accuracy:  0.9224587093478631 Loss:  1.3339552230619096 Val_accuracy:  0.9071097793516752 Val_cost:  1.3339552230619096 Val_accuracy:  0.9071097793516752 Val_Acc:  1.5693247702711193\n",
      "Epoch number: 2787/10000step_number: 0/29 Accuracy:  0.9224246552017709 Loss:  1.3338693954055898 Val_accuracy:  0.9071097793516752 Val_cost:  1.3338693954055898 Val_accuracy:  0.9071097793516752 Val_Acc:  1.569413808132139\n",
      "Epoch number: 2788/10000step_number: 0/29 Accuracy:  0.9224587093478631 Loss:  1.3337827558781203 Val_accuracy:  0.9071097793516752 Val_cost:  1.3337827558781203 Val_accuracy:  0.9071097793516752 Val_Acc:  1.5695019545308933\n",
      "Epoch number: 2789/10000step_number: 0/29 Accuracy:  0.922799250808786 Loss:  1.333695430555662 Val_accuracy:  0.9075183873603923 Val_cost:  1.333695430555662 Val_accuracy:  0.9075183873603923 Val_Acc:  1.5695888803072515\n",
      "Epoch number: 2790/10000step_number: 0/29 Accuracy:  0.9231738464158011 Loss:  1.3336075716509166 Val_accuracy:  0.9075183873603923 Val_cost:  1.3336075716509166 Val_accuracy:  0.9075183873603923 Val_Acc:  1.569674202873809\n",
      "Epoch number: 2791/10000step_number: 0/29 Accuracy:  0.923276008854078 Loss:  1.333519363025518 Val_accuracy:  0.90738218469082 Val_cost:  1.333519363025518 Val_accuracy:  0.90738218469082 Val_Acc:  1.569757527631047\n",
      "Epoch number: 2792/10000step_number: 0/29 Accuracy:  0.9234462795845394 Loss:  1.3334310211060014 Val_accuracy:  0.9076545900299646 Val_cost:  1.3334310211060014 Val_accuracy:  0.9076545900299646 Val_Acc:  1.569838508748345\n",
      "Epoch number: 2793/10000step_number: 0/29 Accuracy:  0.9234122254384471 Loss:  1.3333427869449208 Val_accuracy:  0.9077907926995369 Val_cost:  1.3333427869449208 Val_accuracy:  0.9077907926995369 Val_Acc:  1.5699169154537596\n",
      "Epoch number: 2794/10000step_number: 0/29 Accuracy:  0.9234122254384471 Loss:  1.3332549050608584 Val_accuracy:  0.9079269953691093 Val_cost:  1.3332549050608584 Val_accuracy:  0.9079269953691093 Val_Acc:  1.5699926819916374\n",
      "Epoch number: 2795/10000step_number: 0/29 Accuracy:  0.9234462795845394 Loss:  1.3331675866902861 Val_accuracy:  0.9079269953691093 Val_cost:  1.3331675866902861 Val_accuracy:  0.9079269953691093 Val_Acc:  1.570065922127752\n",
      "Epoch number: 2796/10000step_number: 0/29 Accuracy:  0.923514387876724 Loss:  1.3330809614936034 Val_accuracy:  0.9079269953691093 Val_cost:  1.3330809614936034 Val_accuracy:  0.9079269953691093 Val_Acc:  1.5701369038765745\n",
      "Epoch number: 2797/10000step_number: 0/29 Accuracy:  0.9236165503150009 Loss:  1.332995032830777 Val_accuracy:  0.9077907926995369 Val_cost:  1.332995032830777 Val_accuracy:  0.9077907926995369 Val_Acc:  1.5702059976561413\n",
      "Epoch number: 2798/10000step_number: 0/29 Accuracy:  0.9237187127532777 Loss:  1.3329096600981127 Val_accuracy:  0.9077907926995369 Val_cost:  1.3329096600981127 Val_accuracy:  0.9077907926995369 Val_Acc:  1.5702736176090093\n",
      "Epoch number: 2799/10000step_number: 0/29 Accuracy:  0.9236846586071854 Loss:  1.3328245853867442 Val_accuracy:  0.9077907926995369 Val_cost:  1.3328245853867442 Val_accuracy:  0.9077907926995369 Val_Acc:  1.5703401674626574\n",
      "Epoch number: 2800/10000step_number: 0/29 Accuracy:  0.9236846586071854 Loss:  1.332739499425078 Val_accuracy:  0.9077907926995369 Val_cost:  1.332739499425078 Val_accuracy:  0.9077907926995369 Val_Acc:  1.570405990561307\n",
      "Epoch number: 2801/10000step_number: 0/29 Accuracy:  0.9236846586071854 Loss:  1.332654119366361 Val_accuracy:  0.9079269953691093 Val_cost:  1.332654119366361 Val_accuracy:  0.9079269953691093 Val_Acc:  1.5704713241471056\n",
      "Epoch number: 2802/10000step_number: 0/29 Accuracy:  0.9237187127532777 Loss:  1.3325682459622867 Val_accuracy:  0.9080631980386815 Val_cost:  1.3325682459622867 Val_accuracy:  0.9080631980386815 Val_Acc:  1.570536270974216\n",
      "Epoch number: 2803/10000step_number: 0/29 Accuracy:  0.92375276689937 Loss:  1.3324817818259922 Val_accuracy:  0.9081994007082539 Val_cost:  1.3324817818259922 Val_accuracy:  0.9081994007082539 Val_Acc:  1.5706008097258002\n",
      "Epoch number: 2804/10000step_number: 0/29 Accuracy:  0.9237868210454623 Loss:  1.3323947136073875 Val_accuracy:  0.9084718060473985 Val_cost:  1.3323947136073875 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5706648539435855\n",
      "Epoch number: 2805/10000step_number: 0/29 Accuracy:  0.92375276689937 Loss:  1.3323070770268886 Val_accuracy:  0.9084718060473985 Val_cost:  1.3323070770268886 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5707283408602464\n",
      "Epoch number: 2806/10000step_number: 0/29 Accuracy:  0.9236846586071854 Loss:  1.3322189288291342 Val_accuracy:  0.9086080087169709 Val_cost:  1.3322189288291342 Val_accuracy:  0.9086080087169709 Val_Acc:  1.570791307275095\n",
      "Epoch number: 2807/10000step_number: 0/29 Accuracy:  0.9236846586071854 Loss:  1.3321303461915055 Val_accuracy:  0.9084718060473985 Val_cost:  1.3321303461915055 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5708539084275945\n",
      "Epoch number: 2808/10000step_number: 0/29 Accuracy:  0.9236506044610931 Loss:  1.332041463385499 Val_accuracy:  0.9083356033778262 Val_cost:  1.332041463385499 Val_accuracy:  0.9083356033778262 Val_Acc:  1.5709163632303638\n",
      "Epoch number: 2809/10000step_number: 0/29 Accuracy:  0.9237187127532777 Loss:  1.3319525386087152 Val_accuracy:  0.9083356033778262 Val_cost:  1.3319525386087152 Val_accuracy:  0.9083356033778262 Val_Acc:  1.5709788503082238\n",
      "Epoch number: 2810/10000step_number: 0/29 Accuracy:  0.92375276689937 Loss:  1.3318640089501723 Val_accuracy:  0.9083356033778262 Val_cost:  1.3318640089501723 Val_accuracy:  0.9083356033778262 Val_Acc:  1.5710414098107301\n",
      "Epoch number: 2811/10000step_number: 0/29 Accuracy:  0.92375276689937 Loss:  1.3317764585810405 Val_accuracy:  0.9084718060473985 Val_cost:  1.3317764585810405 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5711039032273955\n",
      "Epoch number: 2812/10000step_number: 0/29 Accuracy:  0.9239230376298314 Loss:  1.3316904460415873 Val_accuracy:  0.9084718060473985 Val_cost:  1.3316904460415873 Val_accuracy:  0.9084718060473985 Val_Acc:  1.571166047424572\n",
      "Epoch number: 2813/10000step_number: 0/29 Accuracy:  0.9239570917759237 Loss:  1.331606283682771 Val_accuracy:  0.9086080087169709 Val_cost:  1.331606283682771 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5712274905269037\n",
      "Epoch number: 2814/10000step_number: 0/29 Accuracy:  0.923991145922016 Loss:  1.3315239597341901 Val_accuracy:  0.9087442113865432 Val_cost:  1.3315239597341901 Val_accuracy:  0.9087442113865432 Val_Acc:  1.571287890113067\n",
      "Epoch number: 2815/10000step_number: 0/29 Accuracy:  0.923991145922016 Loss:  1.3314432682052193 Val_accuracy:  0.9087442113865432 Val_cost:  1.3314432682052193 Val_accuracy:  0.9087442113865432 Val_Acc:  1.5713469805085978\n",
      "Epoch number: 2816/10000step_number: 0/29 Accuracy:  0.9240592542142005 Loss:  1.3313639392176921 Val_accuracy:  0.9087442113865432 Val_cost:  1.3313639392176921 Val_accuracy:  0.9087442113865432 Val_Acc:  1.5714046410620315\n",
      "Epoch number: 2817/10000step_number: 0/29 Accuracy:  0.9240933083602929 Loss:  1.331285681109679 Val_accuracy:  0.9087442113865432 Val_cost:  1.331285681109679 Val_accuracy:  0.9087442113865432 Val_Acc:  1.571460956790658\n",
      "Epoch number: 2818/10000step_number: 0/29 Accuracy:  0.9240933083602929 Loss:  1.3312081888959173 Val_accuracy:  0.9087442113865432 Val_cost:  1.3312081888959173 Val_accuracy:  0.9087442113865432 Val_Acc:  1.5715162641591667\n",
      "Epoch number: 2819/10000step_number: 0/29 Accuracy:  0.9240592542142005 Loss:  1.33113128075841 Val_accuracy:  0.9087442113865432 Val_cost:  1.33113128075841 Val_accuracy:  0.9087442113865432 Val_Acc:  1.5715710857735026\n",
      "Epoch number: 2820/10000step_number: 0/29 Accuracy:  0.9240252000681083 Loss:  1.3310549082067016 Val_accuracy:  0.9087442113865432 Val_cost:  1.3310549082067016 Val_accuracy:  0.9087442113865432 Val_Acc:  1.5716259479694037\n",
      "Epoch number: 2821/10000step_number: 0/29 Accuracy:  0.9240592542142005 Loss:  1.3309791741941777 Val_accuracy:  0.9086080087169709 Val_cost:  1.3309791741941777 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5716811076651644\n",
      "Epoch number: 2822/10000step_number: 0/29 Accuracy:  0.9240933083602929 Loss:  1.3309040701312242 Val_accuracy:  0.9086080087169709 Val_cost:  1.3309040701312242 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5717364867589503\n",
      "Epoch number: 2823/10000step_number: 0/29 Accuracy:  0.9240933083602929 Loss:  1.3308296559298973 Val_accuracy:  0.9086080087169709 Val_cost:  1.3308296559298973 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5717917210049253\n",
      "Epoch number: 2824/10000step_number: 0/29 Accuracy:  0.9241273625063852 Loss:  1.3307557805027161 Val_accuracy:  0.9086080087169709 Val_cost:  1.3307557805027161 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5718465437408649\n",
      "Epoch number: 2825/10000step_number: 0/29 Accuracy:  0.9241614166524774 Loss:  1.3306827739341571 Val_accuracy:  0.9086080087169709 Val_cost:  1.3306827739341571 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5719008106802852\n",
      "Epoch number: 2826/10000step_number: 0/29 Accuracy:  0.9241614166524774 Loss:  1.3306105276068425 Val_accuracy:  0.9086080087169709 Val_cost:  1.3306105276068425 Val_accuracy:  0.9086080087169709 Val_Acc:  1.571954872651387\n",
      "Epoch number: 2827/10000step_number: 0/29 Accuracy:  0.9240933083602929 Loss:  1.3305398722161799 Val_accuracy:  0.9084718060473985 Val_cost:  1.3305398722161799 Val_accuracy:  0.9084718060473985 Val_Acc:  1.57200892396412\n",
      "Epoch number: 2828/10000step_number: 0/29 Accuracy:  0.9240933083602929 Loss:  1.3304699698991405 Val_accuracy:  0.9084718060473985 Val_cost:  1.3304699698991405 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5720637080544717\n",
      "Epoch number: 2829/10000step_number: 0/29 Accuracy:  0.9241273625063852 Loss:  1.3304021676192843 Val_accuracy:  0.9084718060473985 Val_cost:  1.3304021676192843 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5721189634305077\n",
      "Epoch number: 2830/10000step_number: 0/29 Accuracy:  0.9242635790907543 Loss:  1.3303337225672753 Val_accuracy:  0.9086080087169709 Val_cost:  1.3303337225672753 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5721757618739844\n",
      "Epoch number: 2831/10000step_number: 0/29 Accuracy:  0.9242635790907543 Loss:  1.3302682241374064 Val_accuracy:  0.9086080087169709 Val_cost:  1.3302682241374064 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5722325835029856\n",
      "Epoch number: 2832/10000step_number: 0/29 Accuracy:  0.9242635790907543 Loss:  1.3301991749597366 Val_accuracy:  0.9086080087169709 Val_cost:  1.3301991749597366 Val_accuracy:  0.9086080087169709 Val_Acc:  1.572291743977724\n",
      "Epoch number: 2833/10000step_number: 0/29 Accuracy:  0.9242635790907543 Loss:  1.3301367415991467 Val_accuracy:  0.9084718060473985 Val_cost:  1.3301367415991467 Val_accuracy:  0.9084718060473985 Val_Acc:  1.57234881760509\n",
      "Epoch number: 2834/10000step_number: 0/29 Accuracy:  0.9242976332368465 Loss:  1.3300646216874292 Val_accuracy:  0.9084718060473985 Val_cost:  1.3300646216874292 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5724100234820506\n",
      "Epoch number: 2835/10000step_number: 0/29 Accuracy:  0.9243657415290312 Loss:  1.3300093937875013 Val_accuracy:  0.9084718060473985 Val_cost:  1.3300093937875013 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5724642595605829\n",
      "Epoch number: 2836/10000step_number: 0/29 Accuracy:  0.9243657415290312 Loss:  1.329928643895324 Val_accuracy:  0.9084718060473985 Val_cost:  1.329928643895324 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5725288540136224\n",
      "Epoch number: 2837/10000step_number: 0/29 Accuracy:  0.9244338498212157 Loss:  1.3298903971401363 Val_accuracy:  0.9084718060473985 Val_cost:  1.3298903971401363 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5725767823429213\n",
      "Epoch number: 2838/10000step_number: 0/29 Accuracy:  0.9243997956751234 Loss:  1.3297864304403 Val_accuracy:  0.9084718060473985 Val_cost:  1.3297864304403 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5726523077069634\n",
      "Epoch number: 2839/10000step_number: 0/29 Accuracy:  0.9245019581134003 Loss:  1.3297813459132641 Val_accuracy:  0.9083356033778262 Val_cost:  1.3297813459132641 Val_accuracy:  0.9083356033778262 Val_Acc:  1.5726946254884615\n",
      "Epoch number: 2840/10000step_number: 0/29 Accuracy:  0.9245360122594926 Loss:  1.3296328867494343 Val_accuracy:  0.9083356033778262 Val_cost:  1.3296328867494343 Val_accuracy:  0.9083356033778262 Val_Acc:  1.5727875024085654\n",
      "Epoch number: 2841/10000step_number: 0/29 Accuracy:  0.9246381746977694 Loss:  1.329650124184559 Val_accuracy:  0.9084718060473985 Val_cost:  1.329650124184559 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5728652851879672\n",
      "Epoch number: 2842/10000step_number: 0/29 Accuracy:  0.924706282989954 Loss:  1.329538344150516 Val_accuracy:  0.9084718060473985 Val_cost:  1.329538344150516 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5728742098167745\n",
      "Epoch number: 2843/10000step_number: 0/29 Accuracy:  0.9247403371360463 Loss:  1.3295502740874003 Val_accuracy:  0.9084718060473985 Val_cost:  1.3295502740874003 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5729562838475213\n",
      "Epoch number: 2844/10000step_number: 0/29 Accuracy:  0.9247403371360463 Loss:  1.3293881496567055 Val_accuracy:  0.9084718060473985 Val_cost:  1.3293881496567055 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5729673163336872\n",
      "Epoch number: 2845/10000step_number: 0/29 Accuracy:  0.9247743912821386 Loss:  1.329393032324825 Val_accuracy:  0.9086080087169709 Val_cost:  1.329393032324825 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5731433527493126\n",
      "Epoch number: 2846/10000step_number: 0/29 Accuracy:  0.9247743912821386 Loss:  1.329308017108515 Val_accuracy:  0.9086080087169709 Val_cost:  1.329308017108515 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5730505996083435\n",
      "Epoch number: 2847/10000step_number: 0/29 Accuracy:  0.9247743912821386 Loss:  1.3292785918795271 Val_accuracy:  0.9084718060473985 Val_cost:  1.3292785918795271 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5731943283495717\n",
      "Epoch number: 2848/10000step_number: 0/29 Accuracy:  0.9248765537204154 Loss:  1.329161501811815 Val_accuracy:  0.9084718060473985 Val_cost:  1.329161501811815 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5731822525483963\n",
      "Epoch number: 2849/10000step_number: 0/29 Accuracy:  0.9247743912821386 Loss:  1.329151009126913 Val_accuracy:  0.9083356033778262 Val_cost:  1.329151009126913 Val_accuracy:  0.9083356033778262 Val_Acc:  1.5734071769537172\n",
      "Epoch number: 2850/10000step_number: 0/29 Accuracy:  0.9248765537204154 Loss:  1.3291116064150879 Val_accuracy:  0.9081994007082539 Val_cost:  1.3291116064150879 Val_accuracy:  0.9081994007082539 Val_Acc:  1.5732919780787447\n",
      "Epoch number: 2851/10000step_number: 0/29 Accuracy:  0.9248765537204154 Loss:  1.3290577171195466 Val_accuracy:  0.9081994007082539 Val_cost:  1.3290577171195466 Val_accuracy:  0.9081994007082539 Val_Acc:  1.5734567143347\n",
      "Epoch number: 2852/10000step_number: 0/29 Accuracy:  0.9247403371360463 Loss:  1.3289472907202102 Val_accuracy:  0.9084718060473985 Val_cost:  1.3289472907202102 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5735132110716832\n",
      "Epoch number: 2853/10000step_number: 0/29 Accuracy:  0.9247743912821386 Loss:  1.32893861372012 Val_accuracy:  0.9081994007082539 Val_cost:  1.32893861372012 Val_accuracy:  0.9081994007082539 Val_Acc:  1.573755729335135\n",
      "Epoch number: 2854/10000step_number: 0/29 Accuracy:  0.9248084454282309 Loss:  1.3288827495620048 Val_accuracy:  0.9083356033778262 Val_cost:  1.3288827495620048 Val_accuracy:  0.9083356033778262 Val_Acc:  1.5736651805429527\n",
      "Epoch number: 2855/10000step_number: 0/29 Accuracy:  0.9248765537204154 Loss:  1.3288375283409979 Val_accuracy:  0.9080631980386815 Val_cost:  1.3288375283409979 Val_accuracy:  0.9080631980386815 Val_Acc:  1.5737938850593303\n",
      "Epoch number: 2856/10000step_number: 0/29 Accuracy:  0.9247743912821386 Loss:  1.3286920374458173 Val_accuracy:  0.9084718060473985 Val_cost:  1.3286920374458173 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5737992393864286\n",
      "Epoch number: 2857/10000step_number: 0/29 Accuracy:  0.924706282989954 Loss:  1.3286928077495308 Val_accuracy:  0.9084718060473985 Val_cost:  1.3286928077495308 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5740218626695648\n",
      "Epoch number: 2858/10000step_number: 0/29 Accuracy:  0.9248424995743232 Loss:  1.3286546686293719 Val_accuracy:  0.9086080087169709 Val_cost:  1.3286546686293719 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5738848165252028\n",
      "Epoch number: 2859/10000step_number: 0/29 Accuracy:  0.924706282989954 Loss:  1.3285961318612676 Val_accuracy:  0.9086080087169709 Val_cost:  1.3285961318612676 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5740395488775125\n",
      "Epoch number: 2860/10000step_number: 0/29 Accuracy:  0.9248765537204154 Loss:  1.3284780809278747 Val_accuracy:  0.9086080087169709 Val_cost:  1.3284780809278747 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5740939481188723\n",
      "Epoch number: 2861/10000step_number: 0/29 Accuracy:  0.9246722288438617 Loss:  1.3284823238820482 Val_accuracy:  0.9087442113865432 Val_cost:  1.3284823238820482 Val_accuracy:  0.9087442113865432 Val_Acc:  1.5743964963699502\n",
      "Epoch number: 2862/10000step_number: 0/29 Accuracy:  0.9249106078665077 Loss:  1.3284180009456859 Val_accuracy:  0.9086080087169709 Val_cost:  1.3284180009456859 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5743438739979079\n",
      "Epoch number: 2863/10000step_number: 0/29 Accuracy:  0.9249446620126001 Loss:  1.3284365524514177 Val_accuracy:  0.9086080087169709 Val_cost:  1.3284365524514177 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5746567386681725\n",
      "Epoch number: 2864/10000step_number: 0/29 Accuracy:  0.9247743912821386 Loss:  1.3283560853359513 Val_accuracy:  0.9087442113865432 Val_cost:  1.3283560853359513 Val_accuracy:  0.9087442113865432 Val_Acc:  1.574851740056172\n",
      "Epoch number: 2865/10000step_number: 0/29 Accuracy:  0.9248765537204154 Loss:  1.3282196337373104 Val_accuracy:  0.9083356033778262 Val_cost:  1.3282196337373104 Val_accuracy:  0.9083356033778262 Val_Acc:  1.5750582530534927\n",
      "Epoch number: 2866/10000step_number: 0/29 Accuracy:  0.9250127703047846 Loss:  1.3280766724169148 Val_accuracy:  0.9086080087169709 Val_cost:  1.3280766724169148 Val_accuracy:  0.9086080087169709 Val_Acc:  1.5749859550625398\n",
      "Epoch number: 2867/10000step_number: 0/29 Accuracy:  0.9247743912821386 Loss:  1.3280653456866605 Val_accuracy:  0.9083356033778262 Val_cost:  1.3280653456866605 Val_accuracy:  0.9083356033778262 Val_Acc:  1.5748989262835837\n",
      "Epoch number: 2868/10000step_number: 0/29 Accuracy:  0.9249106078665077 Loss:  1.3279307196603887 Val_accuracy:  0.9084718060473985 Val_cost:  1.3279307196603887 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5747984905337657\n",
      "Epoch number: 2869/10000step_number: 0/29 Accuracy:  0.9249446620126001 Loss:  1.3280243804122798 Val_accuracy:  0.9084718060473985 Val_cost:  1.3280243804122798 Val_accuracy:  0.9084718060473985 Val_Acc:  1.5751345654894373\n",
      "Epoch number: 2870/10000step_number: 0/29 Accuracy:  0.9249106078665077 Loss:  1.327804309085328 Val_accuracy:  0.9079269953691093 Val_cost:  1.327804309085328 Val_accuracy:  0.9079269953691093 Val_Acc:  1.5749670407710932\n",
      "Epoch number: 2871/10000step_number: 0/29 Accuracy:  0.9250468244508769 Loss:  1.3276679292709619 Val_accuracy:  0.9080631980386815 Val_cost:  1.3276679292709619 Val_accuracy:  0.9080631980386815 Val_Acc:  1.575389065941941\n",
      "Epoch number: 2872/10000step_number: 0/29 Accuracy:  0.9248765537204154 Loss:  1.3274462693148044 Val_accuracy:  0.9081994007082539 Val_cost:  1.3274462693148044 Val_accuracy:  0.9081994007082539 Val_Acc:  1.5758827412532141\n",
      "Epoch number: 2873/10000step_number: 0/29 Accuracy:  0.9246041205516772 Loss:  1.3279700289769094 Val_accuracy:  0.9081994007082539 Val_cost:  1.3279700289769094 Val_accuracy:  0.9081994007082539 Val_Acc:  1.577364994276429\n",
      "Epoch number: 2874/10000step_number: 0/29 Accuracy:  0.9249106078665077 Loss:  1.3260864634546032 Val_accuracy:  0.9081994007082539 Val_cost:  1.3260864634546032 Val_accuracy:  0.9081994007082539 Val_Acc:  1.5730902790202708\n",
      "Epoch number: 2875/10000step_number: 0/29 Accuracy:  0.9264089902945684 Loss:  1.329467411810875 Val_accuracy:  0.9090166167256878 Val_cost:  1.329467411810875 Val_accuracy:  0.9090166167256878 Val_Acc:  1.5763281640473572\n",
      "Epoch number: 2876/10000step_number: 0/29 Accuracy:  0.9275327771156138 Loss:  1.3362899212383128 Val_accuracy:  0.911604467447562 Val_cost:  1.3362899212383128 Val_accuracy:  0.911604467447562 Val_Acc:  1.5883180590425297\n",
      "Epoch number: 2877/10000step_number: 0/29 Accuracy:  0.9281116975991827 Loss:  1.3293361513957997 Val_accuracy:  0.9114682647779897 Val_cost:  1.3293361513957997 Val_accuracy:  0.9114682647779897 Val_Acc:  1.5811875707772212\n",
      "Epoch number: 2878/10000step_number: 0/29 Accuracy:  0.928384130767921 Loss:  1.3755435675600958 Val_accuracy:  0.9080631980386815 Val_cost:  1.3755435675600958 Val_accuracy:  0.9080631980386815 Val_Acc:  1.6421947553703171\n",
      "Epoch number: 2879/10000step_number: 0/29 Accuracy:  0.9188489698620808 Loss:  1.36070536599088 Val_accuracy:  0.9002996458730591 Val_cost:  1.36070536599088 Val_accuracy:  0.9002996458730591 Val_Acc:  1.6558895340756767\n",
      "Epoch number: 2880/10000step_number: 0/29 Accuracy:  0.9283500766218287 Loss:  1.3533724765772732 Val_accuracy:  0.9125578861345682 Val_cost:  1.3533724765772732 Val_accuracy:  0.9125578861345682 Val_Acc:  1.6038802230780898\n",
      "Epoch number: 2881/10000step_number: 0/29 Accuracy:  0.9430614677336966 Loss:  1.321024997338984 Val_accuracy:  0.9265867611005175 Val_cost:  1.321024997338984 Val_accuracy:  0.9265867611005175 Val_Acc:  1.5558974842128452\n",
      "Epoch number: 2882/10000step_number: 0/29 Accuracy:  0.9359782053465009 Loss:  1.3200455806059819 Val_accuracy:  0.9192318169436121 Val_cost:  1.3200455806059819 Val_accuracy:  0.9192318169436121 Val_Acc:  1.5561402305794716\n",
      "Epoch number: 2883/10000step_number: 0/29 Accuracy:  0.9401328111697599 Loss:  1.3131267181534199 Val_accuracy:  0.9230454916916372 Val_cost:  1.3131267181534199 Val_accuracy:  0.9230454916916372 Val_Acc:  1.552726569600386\n",
      "Epoch number: 2884/10000step_number: 0/29 Accuracy:  0.9394857823940065 Loss:  1.3178858874769634 Val_accuracy:  0.9201852356306184 Val_cost:  1.3178858874769634 Val_accuracy:  0.9201852356306184 Val_Acc:  1.5521649264751476\n",
      "Epoch number: 2885/10000step_number: 0/29 Accuracy:  0.9391111867869913 Loss:  1.3199613019446816 Val_accuracy:  0.920457640969763 Val_cost:  1.3199613019446816 Val_accuracy:  0.920457640969763 Val_Acc:  1.5581356557595674\n",
      "Epoch number: 2886/10000step_number: 0/29 Accuracy:  0.9384301038651456 Loss:  1.3198876562144723 Val_accuracy:  0.92086624897848 Val_cost:  1.3198876562144723 Val_accuracy:  0.92086624897848 Val_Acc:  1.5596835988798834\n",
      "Epoch number: 2887/10000step_number: 0/29 Accuracy:  0.938123616550315 Loss:  1.320757583929616 Val_accuracy:  0.9210024516480523 Val_cost:  1.320757583929616 Val_accuracy:  0.9210024516480523 Val_Acc:  1.561247474429883\n",
      "Epoch number: 2888/10000step_number: 0/29 Accuracy:  0.9381917248424996 Loss:  1.3213818232166428 Val_accuracy:  0.92086624897848 Val_cost:  1.3213818232166428 Val_accuracy:  0.92086624897848 Val_Acc:  1.5624050720979585\n",
      "Epoch number: 2889/10000step_number: 0/29 Accuracy:  0.9381917248424996 Loss:  1.321925412011581 Val_accuracy:  0.9203214383001906 Val_cost:  1.321925412011581 Val_accuracy:  0.9203214383001906 Val_Acc:  1.563517262778247\n",
      "Epoch number: 2890/10000step_number: 0/29 Accuracy:  0.9385322663034225 Loss:  1.3223857421362637 Val_accuracy:  0.920457640969763 Val_cost:  1.3223857421362637 Val_accuracy:  0.920457640969763 Val_Acc:  1.5644863634334316\n",
      "Epoch number: 2891/10000step_number: 0/29 Accuracy:  0.9380214541120382 Loss:  1.3227682500743532 Val_accuracy:  0.9196404249523291 Val_cost:  1.3227682500743532 Val_accuracy:  0.9196404249523291 Val_Acc:  1.5653076412379554\n",
      "Epoch number: 2892/10000step_number: 0/29 Accuracy:  0.9378171292354844 Loss:  1.323090750152813 Val_accuracy:  0.9192318169436121 Val_cost:  1.323090750152813 Val_accuracy:  0.9192318169436121 Val_Acc:  1.5660166383697036\n",
      "Epoch number: 2893/10000step_number: 0/29 Accuracy:  0.9377490209432998 Loss:  1.323359069402788 Val_accuracy:  0.9185508035957505 Val_cost:  1.323359069402788 Val_accuracy:  0.9185508035957505 Val_Acc:  1.5666251596777996\n",
      "Epoch number: 2894/10000step_number: 0/29 Accuracy:  0.9377149667972076 Loss:  1.3235781343969757 Val_accuracy:  0.9180059929174612 Val_cost:  1.3235781343969757 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5671443345693308\n",
      "Epoch number: 2895/10000step_number: 0/29 Accuracy:  0.9378511833815767 Loss:  1.323752512183949 Val_accuracy:  0.9180059929174612 Val_cost:  1.323752512183949 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5675802747291927\n",
      "Epoch number: 2896/10000step_number: 0/29 Accuracy:  0.9374765877745616 Loss:  1.3238876793360006 Val_accuracy:  0.9180059929174612 Val_cost:  1.3238876793360006 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5679400329580575\n",
      "Epoch number: 2897/10000step_number: 0/29 Accuracy:  0.9374084794823769 Loss:  1.3239890027296035 Val_accuracy:  0.9180059929174612 Val_cost:  1.3239890027296035 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5682313734423097\n",
      "Epoch number: 2898/10000step_number: 0/29 Accuracy:  0.9373063170441002 Loss:  1.3240610738295204 Val_accuracy:  0.9184146009261781 Val_cost:  1.3240610738295204 Val_accuracy:  0.9184146009261781 Val_Acc:  1.5684624245129715\n",
      "Epoch number: 2899/10000step_number: 0/29 Accuracy:  0.9374084794823769 Loss:  1.3241071453888735 Val_accuracy:  0.9184146009261781 Val_cost:  1.3241071453888735 Val_accuracy:  0.9184146009261781 Val_Acc:  1.5686414748857207\n",
      "Epoch number: 2900/10000step_number: 0/29 Accuracy:  0.9370679380214542 Loss:  1.3241297104692165 Val_accuracy:  0.9182783982566058 Val_cost:  1.3241297104692165 Val_accuracy:  0.9182783982566058 Val_Acc:  1.5687758002907024\n",
      "Epoch number: 2901/10000step_number: 0/29 Accuracy:  0.9372041546058233 Loss:  1.324132111308307 Val_accuracy:  0.9184146009261781 Val_cost:  1.324132111308307 Val_accuracy:  0.9184146009261781 Val_Acc:  1.5688719964386626\n",
      "Epoch number: 2902/10000step_number: 0/29 Accuracy:  0.9369998297292695 Loss:  1.3241184712789025 Val_accuracy:  0.9180059929174612 Val_cost:  1.3241184712789025 Val_accuracy:  0.9180059929174612 Val_Acc:  1.568936720209409\n",
      "Epoch number: 2903/10000step_number: 0/29 Accuracy:  0.9369657755831773 Loss:  1.3240925789050197 Val_accuracy:  0.9178697902478888 Val_cost:  1.3240925789050197 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5689762977555701\n",
      "Epoch number: 2904/10000step_number: 0/29 Accuracy:  0.9369657755831773 Loss:  1.3240573590182179 Val_accuracy:  0.9178697902478888 Val_cost:  1.3240573590182179 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5689964156632934\n",
      "Epoch number: 2905/10000step_number: 0/29 Accuracy:  0.9367614507066235 Loss:  1.3240147194517287 Val_accuracy:  0.9174611822391718 Val_cost:  1.3240147194517287 Val_accuracy:  0.9174611822391718 Val_Acc:  1.569001703145877\n",
      "Epoch number: 2906/10000step_number: 0/29 Accuracy:  0.9366933424144389 Loss:  1.3239657520950683 Val_accuracy:  0.9173249795695996 Val_cost:  1.3239657520950683 Val_accuracy:  0.9173249795695996 Val_Acc:  1.5689955262746162\n",
      "Epoch number: 2907/10000step_number: 0/29 Accuracy:  0.9366933424144389 Loss:  1.3239113303017918 Val_accuracy:  0.9175973849087442 Val_cost:  1.3239113303017918 Val_accuracy:  0.9175973849087442 Val_Acc:  1.5689804545217483\n",
      "Epoch number: 2908/10000step_number: 0/29 Accuracy:  0.9366252341222544 Loss:  1.3238525603760034 Val_accuracy:  0.9177335875783166 Val_cost:  1.3238525603760034 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5689589051164923\n",
      "Epoch number: 2909/10000step_number: 0/29 Accuracy:  0.9365571258300698 Loss:  1.3237907572575769 Val_accuracy:  0.9177335875783166 Val_cost:  1.3237907572575769 Val_accuracy:  0.9177335875783166 Val_Acc:  1.568933156457058\n",
      "Epoch number: 2910/10000step_number: 0/29 Accuracy:  0.9363187468074238 Loss:  1.3237272912816516 Val_accuracy:  0.9180059929174612 Val_cost:  1.3237272912816516 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5689049848185632\n",
      "Epoch number: 2911/10000step_number: 0/29 Accuracy:  0.9362846926613315 Loss:  1.323663344503238 Val_accuracy:  0.9178697902478888 Val_cost:  1.323663344503238 Val_accuracy:  0.9178697902478888 Val_Acc:  1.568875535639568\n",
      "Epoch number: 2912/10000step_number: 0/29 Accuracy:  0.9361484760769624 Loss:  1.323599364531044 Val_accuracy:  0.9175973849087442 Val_cost:  1.323599364531044 Val_accuracy:  0.9175973849087442 Val_Acc:  1.568845477704209\n",
      "Epoch number: 2913/10000step_number: 0/29 Accuracy:  0.9360122594925933 Loss:  1.323534537570403 Val_accuracy:  0.9175973849087442 Val_cost:  1.323534537570403 Val_accuracy:  0.9175973849087442 Val_Acc:  1.5688150803568974\n",
      "Epoch number: 2914/10000step_number: 0/29 Accuracy:  0.9359441512004086 Loss:  1.32346751452276 Val_accuracy:  0.9174611822391718 Val_cost:  1.32346751452276 Val_accuracy:  0.9174611822391718 Val_Acc:  1.5687841887464282\n",
      "Epoch number: 2915/10000step_number: 0/29 Accuracy:  0.9359100970543164 Loss:  1.3233980848534774 Val_accuracy:  0.9173249795695996 Val_cost:  1.3233980848534774 Val_accuracy:  0.9173249795695996 Val_Acc:  1.5687522714774114\n",
      "Epoch number: 2916/10000step_number: 0/29 Accuracy:  0.9358419887621318 Loss:  1.323327315407704 Val_accuracy:  0.9173249795695996 Val_cost:  1.323327315407704 Val_accuracy:  0.9173249795695996 Val_Acc:  1.5687186187197228\n",
      "Epoch number: 2917/10000step_number: 0/29 Accuracy:  0.9358760429082241 Loss:  1.3232563778093456 Val_accuracy:  0.9174611822391718 Val_cost:  1.3232563778093456 Val_accuracy:  0.9174611822391718 Val_Acc:  1.5686825835456448\n",
      "Epoch number: 2918/10000step_number: 0/29 Accuracy:  0.9357057721777626 Loss:  1.3231859736070115 Val_accuracy:  0.9171887769000272 Val_cost:  1.3231859736070115 Val_accuracy:  0.9171887769000272 Val_Acc:  1.568643694550149\n",
      "Epoch number: 2919/10000step_number: 0/29 Accuracy:  0.9356717180316704 Loss:  1.3231165231086233 Val_accuracy:  0.9173249795695996 Val_cost:  1.3231165231086233 Val_accuracy:  0.9173249795695996 Val_Acc:  1.5686017104341277\n",
      "Epoch number: 2920/10000step_number: 0/29 Accuracy:  0.9355695555933935 Loss:  1.3230484539932694 Val_accuracy:  0.9174611822391718 Val_cost:  1.3230484539932694 Val_accuracy:  0.9174611822391718 Val_Acc:  1.5685566833297278\n",
      "Epoch number: 2921/10000step_number: 0/29 Accuracy:  0.9353992848629321 Loss:  1.322982279041512 Val_accuracy:  0.9175973849087442 Val_cost:  1.322982279041512 Val_accuracy:  0.9175973849087442 Val_Acc:  1.5685089611996945\n",
      "Epoch number: 2922/10000step_number: 0/29 Accuracy:  0.9353652307168397 Loss:  1.3229185025431567 Val_accuracy:  0.9174611822391718 Val_cost:  1.3229185025431567 Val_accuracy:  0.9174611822391718 Val_Acc:  1.568459099382939\n",
      "Epoch number: 2923/10000step_number: 0/29 Accuracy:  0.9355014473012089 Loss:  1.3228574916260918 Val_accuracy:  0.9174611822391718 Val_cost:  1.3228574916260918 Val_accuracy:  0.9174611822391718 Val_Acc:  1.5684077110222325\n",
      "Epoch number: 2924/10000step_number: 0/29 Accuracy:  0.9339690107270561 Loss:  1.3227994155792144 Val_accuracy:  0.9165077635521657 Val_cost:  1.3227994155792144 Val_accuracy:  0.9165077635521657 Val_Acc:  1.5683553345057266\n",
      "Epoch number: 2925/10000step_number: 0/29 Accuracy:  0.9338668482887792 Loss:  1.322744286865957 Val_accuracy:  0.9165077635521657 Val_cost:  1.322744286865957 Val_accuracy:  0.9165077635521657 Val_Acc:  1.5683023979217112\n",
      "Epoch number: 2926/10000step_number: 0/29 Accuracy:  0.9337646858505023 Loss:  1.32269206152529 Val_accuracy:  0.9163715608825933 Val_cost:  1.32269206152529 Val_accuracy:  0.9163715608825933 Val_Acc:  1.5682492674865045\n",
      "Epoch number: 2927/10000step_number: 0/29 Accuracy:  0.9338668482887792 Loss:  1.3226427300556285 Val_accuracy:  0.9163715608825933 Val_cost:  1.3226427300556285 Val_accuracy:  0.9163715608825933 Val_Acc:  1.568196306435421\n",
      "Epoch number: 2928/10000step_number: 0/29 Accuracy:  0.9339009024348714 Loss:  1.3225963618263474 Val_accuracy:  0.9162353582130209 Val_cost:  1.3225963618263474 Val_accuracy:  0.9162353582130209 Val_Acc:  1.568143898691136\n",
      "Epoch number: 2929/10000step_number: 0/29 Accuracy:  0.9337306317044101 Loss:  1.3225531043340646 Val_accuracy:  0.9162353582130209 Val_cost:  1.3225531043340646 Val_accuracy:  0.9162353582130209 Val_Acc:  1.5680924346090659\n",
      "Epoch number: 2930/10000step_number: 0/29 Accuracy:  0.9336625234122254 Loss:  1.3225131565936763 Val_accuracy:  0.9160991555434487 Val_cost:  1.3225131565936763 Val_accuracy:  0.9160991555434487 Val_Acc:  1.5680422762245485\n",
      "Epoch number: 2931/10000step_number: 0/29 Accuracy:  0.9335603609739486 Loss:  1.3224767364911536 Val_accuracy:  0.9160991555434487 Val_cost:  1.3224767364911536 Val_accuracy:  0.9160991555434487 Val_Acc:  1.5679937288048724\n",
      "Epoch number: 2932/10000step_number: 0/29 Accuracy:  0.9333560360973948 Loss:  1.3224440537190139 Val_accuracy:  0.9160991555434487 Val_cost:  1.3224440537190139 Val_accuracy:  0.9160991555434487 Val_Acc:  1.5679470360004122\n",
      "Epoch number: 2933/10000step_number: 0/29 Accuracy:  0.9326068448833645 Loss:  1.3224152915761078 Val_accuracy:  0.915418142195587 Val_cost:  1.3224152915761078 Val_accuracy:  0.915418142195587 Val_Acc:  1.5679024024739472\n",
      "Epoch number: 2934/10000step_number: 0/29 Accuracy:  0.9326068448833645 Loss:  1.3223905968551115 Val_accuracy:  0.915826750204304 Val_cost:  1.3223905968551115 Val_accuracy:  0.915826750204304 Val_Acc:  1.567860036423218\n",
      "Epoch number: 2935/10000step_number: 0/29 Accuracy:  0.9326068448833645 Loss:  1.3223700758956476 Val_accuracy:  0.9160991555434487 Val_cost:  1.3223700758956476 Val_accuracy:  0.9160991555434487 Val_Acc:  1.5678201936590925\n",
      "Epoch number: 2936/10000step_number: 0/29 Accuracy:  0.9326749531755492 Loss:  1.3223537944064052 Val_accuracy:  0.9159629528738763 Val_cost:  1.3223537944064052 Val_accuracy:  0.9159629528738763 Val_Acc:  1.5677832055141205\n",
      "Epoch number: 2937/10000step_number: 0/29 Accuracy:  0.9326408990294568 Loss:  1.3223417786411533 Val_accuracy:  0.9160991555434487 Val_cost:  1.3223417786411533 Val_accuracy:  0.9160991555434487 Val_Acc:  1.567749475419734\n",
      "Epoch number: 2938/10000step_number: 0/29 Accuracy:  0.9324706282989954 Loss:  1.3223340162292843 Val_accuracy:  0.915826750204304 Val_cost:  1.3223340162292843 Val_accuracy:  0.915826750204304 Val_Acc:  1.567719444276799\n",
      "Epoch number: 2939/10000step_number: 0/29 Accuracy:  0.9325046824450877 Loss:  1.3223304560734659 Val_accuracy:  0.915826750204304 Val_cost:  1.3223304560734659 Val_accuracy:  0.915826750204304 Val_Acc:  1.5676935369124874\n",
      "Epoch number: 2940/10000step_number: 0/29 Accuracy:  0.9324365741529032 Loss:  1.3223310079218638 Val_accuracy:  0.9156905475347317 Val_cost:  1.3223310079218638 Val_accuracy:  0.9156905475347317 Val_Acc:  1.5676721089855723\n",
      "Epoch number: 2941/10000step_number: 0/29 Accuracy:  0.93253873659118 Loss:  1.3223355432590642 Val_accuracy:  0.9159629528738763 Val_cost:  1.3223355432590642 Val_accuracy:  0.9159629528738763 Val_Acc:  1.5676554108417007\n",
      "Epoch number: 2942/10000step_number: 0/29 Accuracy:  0.93253873659118 Loss:  1.322343899387625 Val_accuracy:  0.9159629528738763 Val_cost:  1.322343899387625 Val_accuracy:  0.9159629528738763 Val_Acc:  1.5676435745398072\n",
      "Epoch number: 2943/10000step_number: 0/29 Accuracy:  0.93253873659118 Loss:  1.3223558874512187 Val_accuracy:  0.9162353582130209 Val_cost:  1.3223558874512187 Val_accuracy:  0.9162353582130209 Val_Acc:  1.56763662133542\n",
      "Epoch number: 2944/10000step_number: 0/29 Accuracy:  0.93253873659118 Loss:  1.3223713031515827 Val_accuracy:  0.9160991555434487 Val_cost:  1.3223713031515827 Val_accuracy:  0.9160991555434487 Val_Acc:  1.5676344804116342\n",
      "Epoch number: 2945/10000step_number: 0/29 Accuracy:  0.9327090073216414 Loss:  1.322389937351265 Val_accuracy:  0.915826750204304 Val_cost:  1.322389937351265 Val_accuracy:  0.915826750204304 Val_Acc:  1.5676370092142229\n",
      "Epoch number: 2946/10000step_number: 0/29 Accuracy:  0.9329473863442874 Loss:  1.3224115836855004 Val_accuracy:  0.915826750204304 Val_cost:  1.3224115836855004 Val_accuracy:  0.915826750204304 Val_Acc:  1.5676440131940725\n",
      "Epoch number: 2947/10000step_number: 0/29 Accuracy:  0.933015494636472 Loss:  1.3224360415297913 Val_accuracy:  0.9160991555434487 Val_cost:  1.3224360415297913 Val_accuracy:  0.9160991555434487 Val_Acc:  1.5676552661249321\n",
      "Epoch number: 2948/10000step_number: 0/29 Accuracy:  0.9330495487825643 Loss:  1.3224631134878644 Val_accuracy:  0.9162353582130209 Val_cost:  1.3224631134878644 Val_accuracy:  0.9162353582130209 Val_Acc:  1.5676705309720151\n",
      "Epoch number: 2949/10000step_number: 0/29 Accuracy:  0.932777115613826 Loss:  1.3224925949931268 Val_accuracy:  0.9160991555434487 Val_cost:  1.3224925949931268 Val_accuracy:  0.9160991555434487 Val_Acc:  1.5676895731397238\n",
      "Epoch number: 2950/10000step_number: 0/29 Accuracy:  0.9329133321981952 Loss:  1.3225242503765982 Val_accuracy:  0.915826750204304 Val_cost:  1.3225242503765982 Val_accuracy:  0.915826750204304 Val_Acc:  1.5677121588396274\n",
      "Epoch number: 2951/10000step_number: 0/29 Accuracy:  0.9324706282989954 Loss:  1.3225577705245042 Val_accuracy:  0.9159629528738763 Val_cost:  1.3225577705245042 Val_accuracy:  0.9159629528738763 Val_Acc:  1.5677380417363604\n",
      "Epoch number: 2952/10000step_number: 0/29 Accuracy:  0.9324025200068108 Loss:  1.3225927199316208 Val_accuracy:  0.9159629528738763 Val_cost:  1.3225927199316208 Val_accuracy:  0.9159629528738763 Val_Acc:  1.5677669483527013\n",
      "Epoch number: 2953/10000step_number: 0/29 Accuracy:  0.9324025200068108 Loss:  1.3226285042921295 Val_accuracy:  0.9160991555434487 Val_cost:  1.3226285042921295 Val_accuracy:  0.9160991555434487 Val_Acc:  1.5677985687850946\n",
      "Epoch number: 2954/10000step_number: 0/29 Accuracy:  0.9324706282989954 Loss:  1.3226643986863547 Val_accuracy:  0.9160991555434487 Val_cost:  1.3226643986863547 Val_accuracy:  0.9160991555434487 Val_Acc:  1.5678325482147382\n",
      "Epoch number: 2955/10000step_number: 0/29 Accuracy:  0.9323344117146263 Loss:  1.3226996388237346 Val_accuracy:  0.9155543448651594 Val_cost:  1.3226996388237346 Val_accuracy:  0.9155543448651594 Val_Acc:  1.5678684653037833\n",
      "Epoch number: 2956/10000step_number: 0/29 Accuracy:  0.9322663034224417 Loss:  1.3227335144734416 Val_accuracy:  0.9155543448651594 Val_cost:  1.3227335144734416 Val_accuracy:  0.9155543448651594 Val_Acc:  1.5679057801899134\n",
      "Epoch number: 2957/10000step_number: 0/29 Accuracy:  0.9324025200068108 Loss:  1.3227653856120591 Val_accuracy:  0.915826750204304 Val_cost:  1.3227653856120591 Val_accuracy:  0.915826750204304 Val_Acc:  1.5679437286907987\n",
      "Epoch number: 2958/10000step_number: 0/29 Accuracy:  0.9324365741529032 Loss:  1.3227945795992198 Val_accuracy:  0.915826750204304 Val_cost:  1.3227945795992198 Val_accuracy:  0.915826750204304 Val_Acc:  1.5679811133542032\n",
      "Epoch number: 2959/10000step_number: 0/29 Accuracy:  0.9323684658607185 Loss:  1.3228201490370848 Val_accuracy:  0.9159629528738763 Val_cost:  1.3228201490370848 Val_accuracy:  0.9159629528738763 Val_Acc:  1.5680158677542522\n",
      "Epoch number: 2960/10000step_number: 0/29 Accuracy:  0.9323684658607185 Loss:  1.3228404238531888 Val_accuracy:  0.9162353582130209 Val_cost:  1.3228404238531888 Val_accuracy:  0.9162353582130209 Val_Acc:  1.568044114959493\n",
      "Epoch number: 2961/10000step_number: 0/29 Accuracy:  0.932300357568534 Loss:  1.322852272119368 Val_accuracy:  0.9160991555434487 Val_cost:  1.322852272119368 Val_accuracy:  0.9160991555434487 Val_Acc:  1.5680583023021006\n",
      "Epoch number: 2962/10000step_number: 0/29 Accuracy:  0.9324365741529032 Loss:  1.3228508676462063 Val_accuracy:  0.9162353582130209 Val_cost:  1.3228508676462063 Val_accuracy:  0.9162353582130209 Val_Acc:  1.5680456140566839\n",
      "Epoch number: 2963/10000step_number: 0/29 Accuracy:  0.93253873659118 Loss:  1.3228363131353913 Val_accuracy:  0.9163715608825933 Val_cost:  1.3228363131353913 Val_accuracy:  0.9163715608825933 Val_Acc:  1.5680017200621061\n",
      "Epoch number: 2964/10000step_number: 0/29 Accuracy:  0.9324706282989954 Loss:  1.3228318770990184 Val_accuracy:  0.9163715608825933 Val_cost:  1.3228318770990184 Val_accuracy:  0.9163715608825933 Val_Acc:  1.5679842750502304\n",
      "Epoch number: 2965/10000step_number: 0/29 Accuracy:  0.9325046824450877 Loss:  1.322850413305976 Val_accuracy:  0.9163715608825933 Val_cost:  1.322850413305976 Val_accuracy:  0.9163715608825933 Val_Acc:  1.5680303337138057\n",
      "Epoch number: 2966/10000step_number: 0/29 Accuracy:  0.93253873659118 Loss:  1.322875855163782 Val_accuracy:  0.9162353582130209 Val_cost:  1.322875855163782 Val_accuracy:  0.9162353582130209 Val_Acc:  1.5680724100684353\n",
      "Epoch number: 2967/10000step_number: 0/29 Accuracy:  0.9324706282989954 Loss:  1.322908075554641 Val_accuracy:  0.9163715608825933 Val_cost:  1.322908075554641 Val_accuracy:  0.9163715608825933 Val_Acc:  1.568111005990788\n",
      "Epoch number: 2968/10000step_number: 0/29 Accuracy:  0.9325046824450877 Loss:  1.3229360652958027 Val_accuracy:  0.9163715608825933 Val_cost:  1.3229360652958027 Val_accuracy:  0.9163715608825933 Val_Acc:  1.5681532145597368\n",
      "Epoch number: 2969/10000step_number: 0/29 Accuracy:  0.9324706282989954 Loss:  1.322954987680101 Val_accuracy:  0.9162353582130209 Val_cost:  1.322954987680101 Val_accuracy:  0.9162353582130209 Val_Acc:  1.5681978191099863\n",
      "Epoch number: 2970/10000step_number: 0/29 Accuracy:  0.9323684658607185 Loss:  1.3229636912648026 Val_accuracy:  0.9162353582130209 Val_cost:  1.3229636912648026 Val_accuracy:  0.9162353582130209 Val_Acc:  1.5682458112615936\n",
      "Epoch number: 2971/10000step_number: 0/29 Accuracy:  0.9323684658607185 Loss:  1.3229637030784858 Val_accuracy:  0.9162353582130209 Val_cost:  1.3229637030784858 Val_accuracy:  0.9162353582130209 Val_Acc:  1.5682975779917494\n",
      "Epoch number: 2972/10000step_number: 0/29 Accuracy:  0.9324365741529032 Loss:  1.3229573555878955 Val_accuracy:  0.9163715608825933 Val_cost:  1.3229573555878955 Val_accuracy:  0.9163715608825933 Val_Acc:  1.5683530220501416\n",
      "Epoch number: 2973/10000step_number: 0/29 Accuracy:  0.9324025200068108 Loss:  1.3229456919449358 Val_accuracy:  0.9162353582130209 Val_cost:  1.3229456919449358 Val_accuracy:  0.9162353582130209 Val_Acc:  1.5684110654842087\n",
      "Epoch number: 2974/10000step_number: 0/29 Accuracy:  0.9324025200068108 Loss:  1.3229287571694521 Val_accuracy:  0.9163715608825933 Val_cost:  1.3229287571694521 Val_accuracy:  0.9163715608825933 Val_Acc:  1.5684696131604354\n",
      "Epoch number: 2975/10000step_number: 0/29 Accuracy:  0.9323344117146263 Loss:  1.3229071427638008 Val_accuracy:  0.9165077635521657 Val_cost:  1.3229071427638008 Val_accuracy:  0.9165077635521657 Val_Acc:  1.568527004636094\n",
      "Epoch number: 2976/10000step_number: 0/29 Accuracy:  0.9323684658607185 Loss:  1.3228820957132101 Val_accuracy:  0.9163715608825933 Val_cost:  1.3228820957132101 Val_accuracy:  0.9163715608825933 Val_Acc:  1.5685830508014988\n",
      "Epoch number: 2977/10000step_number: 0/29 Accuracy:  0.9313808956240422 Loss:  1.3228547646350772 Val_accuracy:  0.9148733315172978 Val_cost:  1.3228547646350772 Val_accuracy:  0.9148733315172978 Val_Acc:  1.568638367311234\n",
      "Epoch number: 2978/10000step_number: 0/29 Accuracy:  0.9313127873318576 Loss:  1.3228260899438602 Val_accuracy:  0.9148733315172978 Val_cost:  1.3228260899438602 Val_accuracy:  0.9148733315172978 Val_Acc:  1.568693540565785\n",
      "Epoch number: 2979/10000step_number: 0/29 Accuracy:  0.9314149497701345 Loss:  1.3227969316474928 Val_accuracy:  0.9147371288477254 Val_cost:  1.3227969316474928 Val_accuracy:  0.9147371288477254 Val_Acc:  1.5687488329768087\n",
      "Epoch number: 2980/10000step_number: 0/29 Accuracy:  0.9314830580623191 Loss:  1.3227681106235545 Val_accuracy:  0.9147371288477254 Val_cost:  1.3227681106235545 Val_accuracy:  0.9147371288477254 Val_Acc:  1.5688042296299662\n",
      "Epoch number: 2981/10000step_number: 0/29 Accuracy:  0.9313808956240422 Loss:  1.3227403327263296 Val_accuracy:  0.9146009261781531 Val_cost:  1.3227403327263296 Val_accuracy:  0.9146009261781531 Val_Acc:  1.56885956882135\n",
      "Epoch number: 2982/10000step_number: 0/29 Accuracy:  0.9313808956240422 Loss:  1.3227140770551113 Val_accuracy:  0.9146009261781531 Val_cost:  1.3227140770551113 Val_accuracy:  0.9146009261781531 Val_Acc:  1.5689146481916127\n",
      "Epoch number: 2983/10000step_number: 0/29 Accuracy:  0.93134684147795 Loss:  1.322689534064009 Val_accuracy:  0.9146009261781531 Val_cost:  1.322689534064009 Val_accuracy:  0.9146009261781531 Val_Acc:  1.5689692840729246\n",
      "Epoch number: 2984/10000step_number: 0/29 Accuracy:  0.9312787331857654 Loss:  1.3226666414872479 Val_accuracy:  0.9144647235085808 Val_cost:  1.3226666414872479 Val_accuracy:  0.9144647235085808 Val_Acc:  1.5690233462912782\n",
      "Epoch number: 2985/10000step_number: 0/29 Accuracy:  0.9311765707474885 Loss:  1.3226452093803955 Val_accuracy:  0.9147371288477254 Val_cost:  1.3226452093803955 Val_accuracy:  0.9147371288477254 Val_Acc:  1.5690767881926262\n",
      "Epoch number: 2986/10000step_number: 0/29 Accuracy:  0.931108462455304 Loss:  1.3226250754916313 Val_accuracy:  0.9152819395260147 Val_cost:  1.3226250754916313 Val_accuracy:  0.9152819395260147 Val_Acc:  1.5691296656721785\n",
      "Epoch number: 2987/10000step_number: 0/29 Accuracy:  0.9311765707474885 Loss:  1.3226062140230261 Val_accuracy:  0.9155543448651594 Val_cost:  1.3226062140230261 Val_accuracy:  0.9155543448651594 Val_Acc:  1.5691821209708021\n",
      "Epoch number: 2988/10000step_number: 0/29 Accuracy:  0.9311765707474885 Loss:  1.3225887526217726 Val_accuracy:  0.9155543448651594 Val_cost:  1.3225887526217726 Val_accuracy:  0.9155543448651594 Val_Acc:  1.5692343265422029\n",
      "Epoch number: 2989/10000step_number: 0/29 Accuracy:  0.9311425166013962 Loss:  1.3225729160269635 Val_accuracy:  0.9155543448651594 Val_cost:  1.3225729160269635 Val_accuracy:  0.9155543448651594 Val_Acc:  1.5692864187403956\n",
      "Epoch number: 2990/10000step_number: 0/29 Accuracy:  0.9311425166013962 Loss:  1.3225589501674826 Val_accuracy:  0.9155543448651594 Val_cost:  1.3225589501674826 Val_accuracy:  0.9155543448651594 Val_Acc:  1.569338456791517\n",
      "Epoch number: 2991/10000step_number: 0/29 Accuracy:  0.9310403541631194 Loss:  1.3225470645885555 Val_accuracy:  0.9155543448651594 Val_cost:  1.3225470645885555 Val_accuracy:  0.9155543448651594 Val_Acc:  1.5693904172644508\n",
      "Epoch number: 2992/10000step_number: 0/29 Accuracy:  0.930870083432658 Loss:  1.3225373997862757 Val_accuracy:  0.915418142195587 Val_cost:  1.3225373997862757 Val_accuracy:  0.915418142195587 Val_Acc:  1.569442212180255\n",
      "Epoch number: 2993/10000step_number: 0/29 Accuracy:  0.9305976502639196 Loss:  1.322530009915291 Val_accuracy:  0.9151457368564424 Val_cost:  1.322530009915291 Val_accuracy:  0.9151457368564424 Val_Acc:  1.5694937150830228\n",
      "Epoch number: 2994/10000step_number: 0/29 Accuracy:  0.9304273795334582 Loss:  1.3225248513941978 Val_accuracy:  0.9152819395260147 Val_cost:  1.3225248513941978 Val_accuracy:  0.9152819395260147 Val_Acc:  1.5695447859786258\n",
      "Epoch number: 2995/10000step_number: 0/29 Accuracy:  0.9304273795334582 Loss:  1.3225217753505103 Val_accuracy:  0.9151457368564424 Val_cost:  1.3225217753505103 Val_accuracy:  0.9151457368564424 Val_Acc:  1.5695952934349862\n",
      "Epoch number: 2996/10000step_number: 0/29 Accuracy:  0.9300868380725353 Loss:  1.3225205295699003 Val_accuracy:  0.9148733315172978 Val_cost:  1.3225205295699003 Val_accuracy:  0.9148733315172978 Val_Acc:  1.5696451371424633\n",
      "Epoch number: 2997/10000step_number: 0/29 Accuracy:  0.9300868380725353 Loss:  1.32252077807854 Val_accuracy:  0.9147371288477254 Val_cost:  1.32252077807854 Val_accuracy:  0.9147371288477254 Val_Acc:  1.5696942744033051\n",
      "Epoch number: 2998/10000step_number: 0/29 Accuracy:  0.9301890005108122 Loss:  1.3225221380649346 Val_accuracy:  0.9146009261781531 Val_cost:  1.3225221380649346 Val_accuracy:  0.9146009261781531 Val_Acc:  1.5697427488101061\n",
      "Epoch number: 2999/10000step_number: 0/29 Accuracy:  0.9301890005108122 Loss:  1.3225242130306751 Val_accuracy:  0.9144647235085808 Val_cost:  1.3225242130306751 Val_accuracy:  0.9144647235085808 Val_Acc:  1.569790705295766\n",
      "Epoch number: 3000/10000step_number: 0/29 Accuracy:  0.9298825131959816 Loss:  1.3225265812580351 Val_accuracy:  0.9141923181694361 Val_cost:  1.3225265812580351 Val_accuracy:  0.9141923181694361 Val_Acc:  1.5698383662495896\n",
      "Epoch number: 3001/10000step_number: 0/29 Accuracy:  0.9295760258811511 Loss:  1.3225287094722789 Val_accuracy:  0.9135113048215745 Val_cost:  1.3225287094722789 Val_accuracy:  0.9135113048215745 Val_Acc:  1.5698859629517787\n",
      "Epoch number: 3002/10000step_number: 0/29 Accuracy:  0.929678188319428 Loss:  1.3225298434056292 Val_accuracy:  0.9137837101607191 Val_cost:  1.3225298434056292 Val_accuracy:  0.9137837101607191 Val_Acc:  1.5699336642772572\n",
      "Epoch number: 3003/10000step_number: 0/29 Accuracy:  0.9295760258811511 Loss:  1.3225291097216771 Val_accuracy:  0.9136475074911469 Val_cost:  1.3225291097216771 Val_accuracy:  0.9136475074911469 Val_Acc:  1.5699816019848007\n",
      "Epoch number: 3004/10000step_number: 0/29 Accuracy:  0.9295419717350587 Loss:  1.3225260580847285 Val_accuracy:  0.9136475074911469 Val_cost:  1.3225260580847285 Val_accuracy:  0.9136475074911469 Val_Acc:  1.570030087375385\n",
      "Epoch number: 3005/10000step_number: 0/29 Accuracy:  0.9295760258811511 Loss:  1.3225211759361424 Val_accuracy:  0.9136475074911469 Val_cost:  1.3225211759361424 Val_accuracy:  0.9136475074911469 Val_Acc:  1.5700798035193764\n",
      "Epoch number: 3006/10000step_number: 0/29 Accuracy:  0.9295419717350587 Loss:  1.322515628584058 Val_accuracy:  0.9135113048215745 Val_cost:  1.322515628584058 Val_accuracy:  0.9135113048215745 Val_Acc:  1.570131593837884\n",
      "Epoch number: 3007/10000step_number: 0/29 Accuracy:  0.9295760258811511 Loss:  1.3225105974938147 Val_accuracy:  0.9135113048215745 Val_cost:  1.3225105974938147 Val_accuracy:  0.9135113048215745 Val_Acc:  1.5701861072804926\n",
      "Epoch number: 3008/10000step_number: 0/29 Accuracy:  0.9295079175889664 Loss:  1.3225069596828767 Val_accuracy:  0.9133751021520021 Val_cost:  1.3225069596828767 Val_accuracy:  0.9133751021520021 Val_Acc:  1.5702437131098135\n",
      "Epoch number: 3009/10000step_number: 0/29 Accuracy:  0.9294398092967819 Loss:  1.3225052924950338 Val_accuracy:  0.9133751021520021 Val_cost:  1.3225052924950338 Val_accuracy:  0.9133751021520021 Val_Acc:  1.5703045740739572\n",
      "Epoch number: 3010/10000step_number: 0/29 Accuracy:  0.9294398092967819 Loss:  1.3225059435557296 Val_accuracy:  0.9132388994824299 Val_cost:  1.3225059435557296 Val_accuracy:  0.9132388994824299 Val_Acc:  1.570368711854688\n",
      "Epoch number: 3011/10000step_number: 0/29 Accuracy:  0.9294738634428742 Loss:  1.3225090982631862 Val_accuracy:  0.9132388994824299 Val_cost:  1.3225090982631862 Val_accuracy:  0.9132388994824299 Val_Acc:  1.5704360587418977\n",
      "Epoch number: 3012/10000step_number: 0/29 Accuracy:  0.9294398092967819 Loss:  1.3225148434237148 Val_accuracy:  0.9135113048215745 Val_cost:  1.3225148434237148 Val_accuracy:  0.9135113048215745 Val_Acc:  1.5705065003412073\n",
      "Epoch number: 3013/10000step_number: 0/29 Accuracy:  0.9293717010045973 Loss:  1.3225232143453831 Val_accuracy:  0.9135113048215745 Val_cost:  1.3225232143453831 Val_accuracy:  0.9135113048215745 Val_Acc:  1.5705799028710203\n",
      "Epoch number: 3014/10000step_number: 0/29 Accuracy:  0.9295079175889664 Loss:  1.3225342172769194 Val_accuracy:  0.9133751021520021 Val_cost:  1.3225342172769194 Val_accuracy:  0.9133751021520021 Val_Acc:  1.5706561267464576\n",
      "Epoch number: 3015/10000step_number: 0/29 Accuracy:  0.9295760258811511 Loss:  1.3225478316558423 Val_accuracy:  0.9135113048215745 Val_cost:  1.3225478316558423 Val_accuracy:  0.9135113048215745 Val_Acc:  1.5707350297380784\n",
      "Epoch number: 3016/10000step_number: 0/29 Accuracy:  0.9297462966116125 Loss:  1.322563999765253 Val_accuracy:  0.9136475074911469 Val_cost:  1.322563999765253 Val_accuracy:  0.9136475074911469 Val_Acc:  1.5708164638366093\n",
      "Epoch number: 3017/10000step_number: 0/29 Accuracy:  0.9296100800272433 Loss:  1.3225826081507066 Val_accuracy:  0.9136475074911469 Val_cost:  1.3225826081507066 Val_accuracy:  0.9136475074911469 Val_Acc:  1.5709002690119778\n",
      "Epoch number: 3018/10000step_number: 0/29 Accuracy:  0.9296441341733356 Loss:  1.3226034615471913 Val_accuracy:  0.9139199128302915 Val_cost:  1.3226034615471913 Val_accuracy:  0.9139199128302915 Val_Acc:  1.570986265884504\n",
      "Epoch number: 3019/10000step_number: 0/29 Accuracy:  0.9296100800272433 Loss:  1.3226262489660363 Val_accuracy:  0.9140561154998638 Val_cost:  1.3226262489660363 Val_accuracy:  0.9140561154998638 Val_Acc:  1.571074249799588\n",
      "Epoch number: 3020/10000step_number: 0/29 Accuracy:  0.9295419717350587 Loss:  1.3226505052557131 Val_accuracy:  0.9140561154998638 Val_cost:  1.3226505052557131 Val_accuracy:  0.9140561154998638 Val_Acc:  1.571163990005185\n",
      "Epoch number: 3021/10000step_number: 0/29 Accuracy:  0.9294738634428742 Loss:  1.3226755801998478 Val_accuracy:  0.9139199128302915 Val_cost:  1.3226755801998478 Val_accuracy:  0.9139199128302915 Val_Acc:  1.5712552395601045\n",
      "Epoch number: 3022/10000step_number: 0/29 Accuracy:  0.9294057551506896 Loss:  1.3227006377280255 Val_accuracy:  0.9139199128302915 Val_cost:  1.3227006377280255 Val_accuracy:  0.9139199128302915 Val_Acc:  1.571347762203946\n",
      "Epoch number: 3023/10000step_number: 0/29 Accuracy:  0.9293717010045973 Loss:  1.3227247113056424 Val_accuracy:  0.9139199128302915 Val_cost:  1.3227247113056424 Val_accuracy:  0.9139199128302915 Val_Acc:  1.5714413763312314\n",
      "Epoch number: 3024/10000step_number: 0/29 Accuracy:  0.9292695385663204 Loss:  1.3227468268835352 Val_accuracy:  0.9139199128302915 Val_cost:  1.3227468268835352 Val_accuracy:  0.9139199128302915 Val_Acc:  1.571536003928835\n",
      "Epoch number: 3025/10000step_number: 0/29 Accuracy:  0.9293035927124127 Loss:  1.3227661693424657 Val_accuracy:  0.9139199128302915 Val_cost:  1.3227661693424657 Val_accuracy:  0.9139199128302915 Val_Acc:  1.571631698333303\n",
      "Epoch number: 3026/10000step_number: 0/29 Accuracy:  0.9293035927124127 Loss:  1.32278223056522 Val_accuracy:  0.9141923181694361 Val_cost:  1.32278223056522 Val_accuracy:  0.9141923181694361 Val_Acc:  1.5717286254002063\n",
      "Epoch number: 3027/10000step_number: 0/29 Accuracy:  0.9293035927124127 Loss:  1.3227948709059747 Val_accuracy:  0.9141923181694361 Val_cost:  1.3227948709059747 Val_accuracy:  0.9141923181694361 Val_Acc:  1.5718269969251646\n",
      "Epoch number: 3028/10000step_number: 0/29 Accuracy:  0.9293376468585051 Loss:  1.3228042675885991 Val_accuracy:  0.9140561154998638 Val_cost:  1.3228042675885991 Val_accuracy:  0.9140561154998638 Val_Acc:  1.5719269893933183\n",
      "Epoch number: 3029/10000step_number: 0/29 Accuracy:  0.9293376468585051 Loss:  1.322810785865899 Val_accuracy:  0.9140561154998638 Val_cost:  1.322810785865899 Val_accuracy:  0.9140561154998638 Val_Acc:  1.5720286910146077\n",
      "Epoch number: 3030/10000step_number: 0/29 Accuracy:  0.9293035927124127 Loss:  1.3228148412593836 Val_accuracy:  0.9140561154998638 Val_cost:  1.3228148412593836 Val_accuracy:  0.9140561154998638 Val_Acc:  1.5721320952585982\n",
      "Epoch number: 3031/10000step_number: 0/29 Accuracy:  0.9292014302741359 Loss:  1.3228168025015465 Val_accuracy:  0.9140561154998638 Val_cost:  1.3228168025015465 Val_accuracy:  0.9140561154998638 Val_Acc:  1.5722371224503053\n",
      "Epoch number: 3032/10000step_number: 0/29 Accuracy:  0.9292014302741359 Loss:  1.3228169404715286 Val_accuracy:  0.9139199128302915 Val_cost:  1.3228169404715286 Val_accuracy:  0.9139199128302915 Val_Acc:  1.5723436332477427\n",
      "Epoch number: 3033/10000step_number: 0/29 Accuracy:  0.9292014302741359 Loss:  1.3228153997168508 Val_accuracy:  0.9137837101607191 Val_cost:  1.3228153997168508 Val_accuracy:  0.9137837101607191 Val_Acc:  1.5724514090378532\n",
      "Epoch number: 3034/10000step_number: 0/29 Accuracy:  0.9292354844202282 Loss:  1.3228121761064 Val_accuracy:  0.9137837101607191 Val_cost:  1.3228121761064 Val_accuracy:  0.9137837101607191 Val_Acc:  1.5725601071168136\n",
      "Epoch number: 3035/10000step_number: 0/29 Accuracy:  0.9292014302741359 Loss:  1.3228071139258282 Val_accuracy:  0.9137837101607191 Val_cost:  1.3228071139258282 Val_accuracy:  0.9137837101607191 Val_Acc:  1.5726692366152817\n",
      "Epoch number: 3036/10000step_number: 0/29 Accuracy:  0.9292014302741359 Loss:  1.3227999547505276 Val_accuracy:  0.9137837101607191 Val_cost:  1.3227999547505276 Val_accuracy:  0.9137837101607191 Val_Acc:  1.5727782085305828\n",
      "Epoch number: 3037/10000step_number: 0/29 Accuracy:  0.9292354844202282 Loss:  1.3227904511927533 Val_accuracy:  0.9136475074911469 Val_cost:  1.3227904511927533 Val_accuracy:  0.9136475074911469 Val_Acc:  1.57288646534014\n",
      "Epoch number: 3038/10000step_number: 0/29 Accuracy:  0.9292695385663204 Loss:  1.3227785057080035 Val_accuracy:  0.9136475074911469 Val_cost:  1.3227785057080035 Val_accuracy:  0.9136475074911469 Val_Acc:  1.5729936188145925\n",
      "Epoch number: 3039/10000step_number: 0/29 Accuracy:  0.9293376468585051 Loss:  1.3227642471483743 Val_accuracy:  0.9136475074911469 Val_cost:  1.3227642471483743 Val_accuracy:  0.9136475074911469 Val_Acc:  1.5730994838261392\n",
      "Epoch number: 3040/10000step_number: 0/29 Accuracy:  0.9292014302741359 Loss:  1.3227479647319338 Val_accuracy:  0.9136475074911469 Val_cost:  1.3227479647319338 Val_accuracy:  0.9136475074911469 Val_Acc:  1.5732039391191424\n",
      "Epoch number: 3041/10000step_number: 0/29 Accuracy:  0.9292354844202282 Loss:  1.3227299060060846 Val_accuracy:  0.9136475074911469 Val_cost:  1.3227299060060846 Val_accuracy:  0.9136475074911469 Val_Acc:  1.5733066868149272\n",
      "Epoch number: 3042/10000step_number: 0/29 Accuracy:  0.929678188319428 Loss:  1.3227100707760775 Val_accuracy:  0.9137837101607191 Val_cost:  1.3227100707760775 Val_accuracy:  0.9137837101607191 Val_Acc:  1.5734071290934337\n",
      "Epoch number: 3043/10000step_number: 0/29 Accuracy:  0.9296441341733356 Loss:  1.3226881726231048 Val_accuracy:  0.9137837101607191 Val_cost:  1.3226881726231048 Val_accuracy:  0.9137837101607191 Val_Acc:  1.5735045238532686\n",
      "Epoch number: 3044/10000step_number: 0/29 Accuracy:  0.9296441341733356 Loss:  1.3226638098679155 Val_accuracy:  0.9137837101607191 Val_cost:  1.3226638098679155 Val_accuracy:  0.9137837101607191 Val_Acc:  1.5735983111043303\n",
      "Epoch number: 3045/10000step_number: 0/29 Accuracy:  0.9296441341733356 Loss:  1.3226367074976553 Val_accuracy:  0.9136475074911469 Val_cost:  1.3226367074976553 Val_accuracy:  0.9136475074911469 Val_Acc:  1.5736883405983326\n",
      "Epoch number: 3046/10000step_number: 0/29 Accuracy:  0.9297122424655202 Loss:  1.322606852177691 Val_accuracy:  0.9135113048215745 Val_cost:  1.322606852177691 Val_accuracy:  0.9135113048215745 Val_Acc:  1.5737748490156567\n",
      "Epoch number: 3047/10000step_number: 0/29 Accuracy:  0.929678188319428 Loss:  1.322574446836231 Val_accuracy:  0.9135113048215745 Val_cost:  1.322574446836231 Val_accuracy:  0.9135113048215745 Val_Acc:  1.5738582368900078\n",
      "Epoch number: 3048/10000step_number: 0/29 Accuracy:  0.9296441341733356 Loss:  1.3225397345285512 Val_accuracy:  0.9135113048215745 Val_cost:  1.3225397345285512 Val_accuracy:  0.9135113048215745 Val_Acc:  1.5739388043917661\n",
      "Epoch number: 3049/10000step_number: 0/29 Accuracy:  0.9298825131959816 Loss:  1.3225028105706884 Val_accuracy:  0.9136475074911469 Val_cost:  1.3225028105706884 Val_accuracy:  0.9136475074911469 Val_Acc:  1.5740166046033075\n",
      "Epoch number: 3050/10000step_number: 0/29 Accuracy:  0.929916567342074 Loss:  1.3224635351042662 Val_accuracy:  0.9137837101607191 Val_cost:  1.3224635351042662 Val_accuracy:  0.9137837101607191 Val_Acc:  1.5740914803915316\n",
      "Epoch number: 3051/10000step_number: 0/29 Accuracy:  0.9299846756342585 Loss:  1.3224215814903781 Val_accuracy:  0.9137837101607191 Val_cost:  1.3224215814903781 Val_accuracy:  0.9137837101607191 Val_Acc:  1.5741632234385912\n",
      "Epoch number: 3052/10000step_number: 0/29 Accuracy:  0.929916567342074 Loss:  1.3223765694213052 Val_accuracy:  0.9137837101607191 Val_cost:  1.3223765694213052 Val_accuracy:  0.9137837101607191 Val_Acc:  1.574231730834668\n",
      "Epoch number: 3053/10000step_number: 0/29 Accuracy:  0.929916567342074 Loss:  1.3223282007727548 Val_accuracy:  0.9135113048215745 Val_cost:  1.3223282007727548 Val_accuracy:  0.9135113048215745 Val_Acc:  1.5742970733429054\n",
      "Epoch number: 3054/10000step_number: 0/29 Accuracy:  0.9300187297803507 Loss:  1.3222763402718567 Val_accuracy:  0.9137837101607191 Val_cost:  1.3222763402718567 Val_accuracy:  0.9137837101607191 Val_Acc:  1.5743594652727468\n",
      "Epoch number: 3055/10000step_number: 0/29 Accuracy:  0.9300868380725353 Loss:  1.3222210199709532 Val_accuracy:  0.9137837101607191 Val_cost:  1.3222210199709532 Val_accuracy:  0.9137837101607191 Val_Acc:  1.574419168956573\n",
      "Epoch number: 3056/10000step_number: 0/29 Accuracy:  0.9300868380725353 Loss:  1.3221623731836298 Val_accuracy:  0.9137837101607191 Val_cost:  1.3221623731836298 Val_accuracy:  0.9137837101607191 Val_Acc:  1.5744763733586786\n",
      "Epoch number: 3057/10000step_number: 0/29 Accuracy:  0.9300868380725353 Loss:  1.322100522478558 Val_accuracy:  0.9137837101607191 Val_cost:  1.322100522478558 Val_accuracy:  0.9137837101607191 Val_Acc:  1.5745310861766912\n",
      "Epoch number: 3058/10000step_number: 0/29 Accuracy:  0.9300527839264431 Loss:  1.3220354618718033 Val_accuracy:  0.9136475074911469 Val_cost:  1.3220354618718033 Val_accuracy:  0.9136475074911469 Val_Acc:  1.5745830848146851\n",
      "Epoch number: 3059/10000step_number: 0/29 Accuracy:  0.9300527839264431 Loss:  1.3219669784950738 Val_accuracy:  0.9133751021520021 Val_cost:  1.3219669784950738 Val_accuracy:  0.9133751021520021 Val_Acc:  1.5746319601346108\n",
      "Epoch number: 3060/10000step_number: 0/29 Accuracy:  0.9300187297803507 Loss:  1.3218946434007017 Val_accuracy:  0.9135113048215745 Val_cost:  1.3218946434007017 Val_accuracy:  0.9135113048215745 Val_Acc:  1.574677237127942\n",
      "Epoch number: 3061/10000step_number: 0/29 Accuracy:  0.9299846756342585 Loss:  1.3218178711876076 Val_accuracy:  0.9135113048215745 Val_cost:  1.3218178711876076 Val_accuracy:  0.9135113048215745 Val_Acc:  1.5747185086250641\n",
      "Epoch number: 3062/10000step_number: 0/29 Accuracy:  0.9300187297803507 Loss:  1.3217360251410024 Val_accuracy:  0.9136475074911469 Val_cost:  1.3217360251410024 Val_accuracy:  0.9136475074911469 Val_Acc:  1.5747555213496558\n",
      "Epoch number: 3063/10000step_number: 0/29 Accuracy:  0.9299506214881662 Loss:  1.3216485381383145 Val_accuracy:  0.9135113048215745 Val_cost:  1.3216485381383145 Val_accuracy:  0.9135113048215745 Val_Acc:  1.574788200306417\n",
      "Epoch number: 3064/10000step_number: 0/29 Accuracy:  0.9298825131959816 Loss:  1.3215550206550186 Val_accuracy:  0.9135113048215745 Val_cost:  1.3215550206550186 Val_accuracy:  0.9135113048215745 Val_Acc:  1.5748166319865455\n",
      "Epoch number: 3065/10000step_number: 0/29 Accuracy:  0.9298825131959816 Loss:  1.3214553265129345 Val_accuracy:  0.9137837101607191 Val_cost:  1.3214553265129345 Val_accuracy:  0.9137837101607191 Val_Acc:  1.5748410195174127\n",
      "Epoch number: 3066/10000step_number: 0/29 Accuracy:  0.9298144049037971 Loss:  1.3213495457844078 Val_accuracy:  0.9137837101607191 Val_cost:  1.3213495457844078 Val_accuracy:  0.9137837101607191 Val_Acc:  1.574861589066721\n",
      "Epoch number: 3067/10000step_number: 0/29 Accuracy:  0.9298484590498893 Loss:  1.321237904406168 Val_accuracy:  0.9137837101607191 Val_cost:  1.321237904406168 Val_accuracy:  0.9137837101607191 Val_Acc:  1.5748784248178254\n",
      "Epoch number: 3068/10000step_number: 0/29 Accuracy:  0.9298144049037971 Loss:  1.3211205841528937 Val_accuracy:  0.9135113048215745 Val_cost:  1.3211205841528937 Val_accuracy:  0.9135113048215745 Val_Acc:  1.5748912822778873\n",
      "Epoch number: 3069/10000step_number: 0/29 Accuracy:  0.9298825131959816 Loss:  1.3209975194429822 Val_accuracy:  0.9135113048215745 Val_cost:  1.3209975194429822 Val_accuracy:  0.9135113048215745 Val_Acc:  1.5748995171216549\n",
      "Epoch number: 3070/10000step_number: 0/29 Accuracy:  0.9298825131959816 Loss:  1.32086823417989 Val_accuracy:  0.9135113048215745 Val_cost:  1.32086823417989 Val_accuracy:  0.9135113048215745 Val_Acc:  1.5749022197636269\n",
      "Epoch number: 3071/10000step_number: 0/29 Accuracy:  0.9310744083092116 Loss:  1.3207317475333167 Val_accuracy:  0.9146009261781531 Val_cost:  1.3207317475333167 Val_accuracy:  0.9146009261781531 Val_Acc:  1.5748984669499495\n",
      "Epoch number: 3072/10000step_number: 0/29 Accuracy:  0.9310403541631194 Loss:  1.3205865635275345 Val_accuracy:  0.9146009261781531 Val_cost:  1.3205865635275345 Val_accuracy:  0.9146009261781531 Val_Acc:  1.574887502075854\n",
      "Epoch number: 3073/10000step_number: 0/29 Accuracy:  0.9309722458709347 Loss:  1.3204307829980553 Val_accuracy:  0.9144647235085808 Val_cost:  1.3204307829980553 Val_accuracy:  0.9144647235085808 Val_Acc:  1.5748687477380032\n",
      "Epoch number: 3074/10000step_number: 0/29 Accuracy:  0.9309041375787502 Loss:  1.3202623718064497 Val_accuracy:  0.9141923181694361 Val_cost:  1.3202623718064497 Val_accuracy:  0.9141923181694361 Val_Acc:  1.5748417005055244\n",
      "Epoch number: 3075/10000step_number: 0/29 Accuracy:  0.9309041375787502 Loss:  1.3200795648355752 Val_accuracy:  0.9141923181694361 Val_cost:  1.3200795648355752 Val_accuracy:  0.9141923181694361 Val_Acc:  1.5748058344608957\n",
      "Epoch number: 3076/10000step_number: 0/29 Accuracy:  0.9309381917248425 Loss:  1.3198813391696578 Val_accuracy:  0.9143285208390084 Val_cost:  1.3198813391696578 Val_accuracy:  0.9143285208390084 Val_Acc:  1.5747606960246872\n",
      "Epoch number: 3077/10000step_number: 0/29 Accuracy:  0.9309381917248425 Loss:  1.3196678661641914 Val_accuracy:  0.9141923181694361 Val_cost:  1.3196678661641914 Val_accuracy:  0.9141923181694361 Val_Acc:  1.5747064584242183\n",
      "Epoch number: 3078/10000step_number: 0/29 Accuracy:  0.9311765707474885 Loss:  1.3194407617017039 Val_accuracy:  0.9140561154998638 Val_cost:  1.3194407617017039 Val_accuracy:  0.9140561154998638 Val_Acc:  1.5746449550631905\n",
      "Epoch number: 3079/10000step_number: 0/29 Accuracy:  0.9312106248935808 Loss:  1.319202726356803 Val_accuracy:  0.9143285208390084 Val_cost:  1.319202726356803 Val_accuracy:  0.9143285208390084 Val_Acc:  1.5745798803111108\n",
      "Epoch number: 3080/10000step_number: 0/29 Accuracy:  0.93134684147795 Loss:  1.3189561934270386 Val_accuracy:  0.9144647235085808 Val_cost:  1.3189561934270386 Val_accuracy:  0.9144647235085808 Val_Acc:  1.5745139393515655\n",
      "Epoch number: 3081/10000step_number: 0/29 Accuracy:  0.9312446790396731 Loss:  1.318701821803485 Val_accuracy:  0.9146009261781531 Val_cost:  1.318701821803485 Val_accuracy:  0.9146009261781531 Val_Acc:  1.5744448461103997\n",
      "Epoch number: 3082/10000step_number: 0/29 Accuracy:  0.9326068448833645 Loss:  1.3184385787012327 Val_accuracy:  0.9151457368564424 Val_cost:  1.3184385787012327 Val_accuracy:  0.9151457368564424 Val_Acc:  1.5743661159160154\n",
      "Epoch number: 3083/10000step_number: 0/29 Accuracy:  0.9326068448833645 Loss:  1.3181646510510963 Val_accuracy:  0.9152819395260147 Val_cost:  1.3181646510510963 Val_accuracy:  0.9152819395260147 Val_Acc:  1.5742717660639967\n",
      "Epoch number: 3084/10000step_number: 0/29 Accuracy:  0.9329133321981952 Loss:  1.3178773920442988 Val_accuracy:  0.915418142195587 Val_cost:  1.3178773920442988 Val_accuracy:  0.915418142195587 Val_Acc:  1.574159048261705\n",
      "Epoch number: 3085/10000step_number: 0/29 Accuracy:  0.9332879278052103 Loss:  1.3175737545981183 Val_accuracy:  0.9160991555434487 Val_cost:  1.3175737545981183 Val_accuracy:  0.9160991555434487 Val_Acc:  1.5740287074939607\n",
      "Epoch number: 3086/10000step_number: 0/29 Accuracy:  0.9332879278052103 Loss:  1.3172524837882247 Val_accuracy:  0.9160991555434487 Val_cost:  1.3172524837882247 Val_accuracy:  0.9160991555434487 Val_Acc:  1.5738844887614454\n",
      "Epoch number: 3087/10000step_number: 0/29 Accuracy:  0.9338668482887792 Loss:  1.316915871718084 Val_accuracy:  0.9162353582130209 Val_cost:  1.316915871718084 Val_accuracy:  0.9162353582130209 Val_Acc:  1.5737318741210913\n",
      "Epoch number: 3088/10000step_number: 0/29 Accuracy:  0.9339349565809637 Loss:  1.3165685578024942 Val_accuracy:  0.9165077635521657 Val_cost:  1.3165685578024942 Val_accuracy:  0.9165077635521657 Val_Acc:  1.5735760129924279\n",
      "Epoch number: 3089/10000step_number: 0/29 Accuracy:  0.9338668482887792 Loss:  1.3162146521042644 Val_accuracy:  0.9162353582130209 Val_cost:  1.3162146521042644 Val_accuracy:  0.9162353582130209 Val_Acc:  1.573420929299603\n",
      "Epoch number: 3090/10000step_number: 0/29 Accuracy:  0.9341052273114252 Loss:  1.315855995549799 Val_accuracy:  0.9163715608825933 Val_cost:  1.315855995549799 Val_accuracy:  0.9163715608825933 Val_Acc:  1.5732708899077457\n",
      "Epoch number: 3091/10000step_number: 0/29 Accuracy:  0.9342754980418866 Loss:  1.315491676659514 Val_accuracy:  0.9167801688913103 Val_cost:  1.315491676659514 Val_accuracy:  0.9167801688913103 Val_Acc:  1.5731320824300161\n",
      "Epoch number: 3092/10000step_number: 0/29 Accuracy:  0.9341052273114252 Loss:  1.3151195512388336 Val_accuracy:  0.9167801688913103 Val_cost:  1.3151195512388336 Val_accuracy:  0.9167801688913103 Val_Acc:  1.5730142208615994\n",
      "Epoch number: 3093/10000step_number: 0/29 Accuracy:  0.9343095521879788 Loss:  1.3147440254738945 Val_accuracy:  0.9166439662217379 Val_cost:  1.3147440254738945 Val_accuracy:  0.9166439662217379 Val_Acc:  1.5729316639139739\n",
      "Epoch number: 3094/10000step_number: 0/29 Accuracy:  0.9343436063340712 Loss:  1.3143962869066763 Val_accuracy:  0.9163715608825933 Val_cost:  1.3143962869066763 Val_accuracy:  0.9163715608825933 Val_Acc:  1.572886434905591\n",
      "Epoch number: 3095/10000step_number: 0/29 Accuracy:  0.9342754980418866 Loss:  1.3141196106292208 Val_accuracy:  0.9163715608825933 Val_cost:  1.3141196106292208 Val_accuracy:  0.9163715608825933 Val_Acc:  1.5726218095857452\n",
      "Epoch number: 3096/10000step_number: 0/29 Accuracy:  0.9348884726715477 Loss:  1.31414892076931 Val_accuracy:  0.9173249795695996 Val_cost:  1.31414892076931 Val_accuracy:  0.9173249795695996 Val_Acc:  1.5728040699259362\n",
      "Epoch number: 3097/10000step_number: 0/29 Accuracy:  0.9347522560871786 Loss:  1.3140706301963045 Val_accuracy:  0.9166439662217379 Val_cost:  1.3140706301963045 Val_accuracy:  0.9166439662217379 Val_Acc:  1.5723934243930153\n",
      "Epoch number: 3098/10000step_number: 0/29 Accuracy:  0.9356717180316704 Loss:  1.3170297469377357 Val_accuracy:  0.9177335875783166 Val_cost:  1.3170297469377357 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5764732273309792\n",
      "Epoch number: 3099/10000step_number: 0/29 Accuracy:  0.9374425336284693 Loss:  1.3191506199803402 Val_accuracy:  0.9182783982566058 Val_cost:  1.3191506199803402 Val_accuracy:  0.9182783982566058 Val_Acc:  1.5777234021710704\n",
      "Epoch number: 3100/10000step_number: 0/29 Accuracy:  0.9372722628980078 Loss:  1.3383557624176978 Val_accuracy:  0.9185508035957505 Val_cost:  1.3383557624176978 Val_accuracy:  0.9185508035957505 Val_Acc:  1.5858920993941743\n",
      "Epoch number: 3101/10000step_number: 0/29 Accuracy:  0.9408820023837903 Loss:  1.4011313369912304 Val_accuracy:  0.920457640969763 Val_cost:  1.4011313369912304 Val_accuracy:  0.920457640969763 Val_Acc:  nan\n",
      "Epoch number: 3102/10000step_number: 0/29 Accuracy:  0.9273965605312446 Loss:  1.337482658302753 Val_accuracy:  0.9071097793516752 Val_cost:  1.337482658302753 Val_accuracy:  0.9071097793516752 Val_Acc:  1.6184000502402083\n",
      "Epoch number: 3103/10000step_number: 0/29 Accuracy:  0.9447641750383109 Loss:  1.338962260207703 Val_accuracy:  0.9245437210569327 Val_cost:  1.338962260207703 Val_accuracy:  0.9245437210569327 Val_Acc:  nan\n",
      "Epoch number: 3104/10000step_number: 0/29 Accuracy:  0.9480333730631705 Loss:  1.3010443429207261 Val_accuracy:  0.9267229637700899 Val_cost:  1.3010443429207261 Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 3105/10000step_number: 0/29 Accuracy:  0.950008513536523 Loss:  1.3096432573664807 Val_accuracy:  0.9268591664396623 Val_cost:  1.3096432573664807 Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3106/10000step_number: 0/29 Accuracy:  0.9474885067256938 Loss:  1.3046571169160492 Val_accuracy:  0.9242713157177881 Val_cost:  1.3046571169160492 Val_accuracy:  0.9242713157177881 Val_Acc:  1.56894507432161\n",
      "Epoch number: 3107/10000step_number: 0/29 Accuracy:  0.9415971394517283 Loss:  1.304094967182649 Val_accuracy:  0.920049032961046 Val_cost:  1.304094967182649 Val_accuracy:  0.920049032961046 Val_Acc:  1.5700649531465847\n",
      "Epoch number: 3108/10000step_number: 0/29 Accuracy:  0.9410182189681594 Loss:  1.3032678039213346 Val_accuracy:  0.9203214383001906 Val_cost:  1.3032678039213346 Val_accuracy:  0.9203214383001906 Val_Acc:  1.5688219100906449\n",
      "Epoch number: 3109/10000step_number: 0/29 Accuracy:  0.9411544355525285 Loss:  1.3031431673378606 Val_accuracy:  0.9205938436393354 Val_cost:  1.3031431673378606 Val_accuracy:  0.9205938436393354 Val_Acc:  1.5690282028855613\n",
      "Epoch number: 3110/10000step_number: 0/29 Accuracy:  0.9408479482376979 Loss:  1.3033419645433684 Val_accuracy:  0.92086624897848 Val_cost:  1.3033419645433684 Val_accuracy:  0.92086624897848 Val_Acc:  1.5691947822962837\n",
      "Epoch number: 3111/10000step_number: 0/29 Accuracy:  0.9406776775072365 Loss:  1.3036251993723749 Val_accuracy:  0.9210024516480523 Val_cost:  1.3036251993723749 Val_accuracy:  0.9210024516480523 Val_Acc:  1.5695846608720203\n",
      "Epoch number: 3112/10000step_number: 0/29 Accuracy:  0.9403030819002214 Loss:  1.3039171205883262 Val_accuracy:  0.9210024516480523 Val_cost:  1.3039171205883262 Val_accuracy:  0.9210024516480523 Val_Acc:  1.570046762951025\n",
      "Epoch number: 3113/10000step_number: 0/29 Accuracy:  0.9400647028775754 Loss:  1.304215020069739 Val_accuracy:  0.9211386543176246 Val_cost:  1.304215020069739 Val_accuracy:  0.9211386543176246 Val_Acc:  1.5705420543649207\n",
      "Epoch number: 3114/10000step_number: 0/29 Accuracy:  0.9396901072705602 Loss:  1.304497926159314 Val_accuracy:  0.9212748569871969 Val_cost:  1.304497926159314 Val_accuracy:  0.9212748569871969 Val_Acc:  1.571049312593132\n",
      "Epoch number: 3115/10000step_number: 0/29 Accuracy:  0.9395879448322834 Loss:  1.3047604476522314 Val_accuracy:  0.9212748569871969 Val_cost:  1.3047604476522314 Val_accuracy:  0.9212748569871969 Val_Acc:  1.571541411258313\n",
      "Epoch number: 3116/10000step_number: 0/29 Accuracy:  0.9394857823940065 Loss:  1.3050002688747873 Val_accuracy:  0.9218196676654863 Val_cost:  1.3050002688747873 Val_accuracy:  0.9218196676654863 Val_Acc:  1.5720118148733395\n",
      "Epoch number: 3117/10000step_number: 0/29 Accuracy:  0.9396219989783756 Loss:  1.3052166214753607 Val_accuracy:  0.9218196676654863 Val_cost:  1.3052166214753607 Val_accuracy:  0.9218196676654863 Val_Acc:  1.5724530586218608\n",
      "Epoch number: 3118/10000step_number: 0/29 Accuracy:  0.9393836199557296 Loss:  1.3054099060942927 Val_accuracy:  0.9216834649959139 Val_cost:  1.3054099060942927 Val_accuracy:  0.9216834649959139 Val_Acc:  1.572862979978316\n",
      "Epoch number: 3119/10000step_number: 0/29 Accuracy:  0.9392814575174527 Loss:  1.3055805660824362 Val_accuracy:  0.9215472623263415 Val_cost:  1.3055805660824362 Val_accuracy:  0.9215472623263415 Val_Acc:  1.5732401884155907\n",
      "Epoch number: 3120/10000step_number: 0/29 Accuracy:  0.9392814575174527 Loss:  1.3057293803765193 Val_accuracy:  0.9215472623263415 Val_cost:  1.3057293803765193 Val_accuracy:  0.9215472623263415 Val_Acc:  1.573583970364169\n",
      "Epoch number: 3121/10000step_number: 0/29 Accuracy:  0.9392814575174527 Loss:  1.305857571158265 Val_accuracy:  0.9211386543176246 Val_cost:  1.305857571158265 Val_accuracy:  0.9211386543176246 Val_Acc:  1.5738925947141182\n",
      "Epoch number: 3122/10000step_number: 0/29 Accuracy:  0.9391792950791759 Loss:  1.305966467442958 Val_accuracy:  0.9210024516480523 Val_cost:  1.305966467442958 Val_accuracy:  0.9210024516480523 Val_Acc:  1.5741638507069458\n",
      "Epoch number: 3123/10000step_number: 0/29 Accuracy:  0.9389749702026222 Loss:  1.3060567061542625 Val_accuracy:  0.9210024516480523 Val_cost:  1.3060567061542625 Val_accuracy:  0.9210024516480523 Val_Acc:  1.57439690801996\n",
      "Epoch number: 3124/10000step_number: 0/29 Accuracy:  0.9388046994721607 Loss:  1.3061286024154735 Val_accuracy:  0.9210024516480523 Val_cost:  1.3061286024154735 Val_accuracy:  0.9210024516480523 Val_Acc:  1.5745936808794747\n",
      "Epoch number: 3125/10000step_number: 0/29 Accuracy:  0.9385663204495147 Loss:  1.3061830934979928 Val_accuracy:  0.92086624897848 Val_cost:  1.3061830934979928 Val_accuracy:  0.92086624897848 Val_Acc:  1.5747585429479292\n",
      "Epoch number: 3126/10000step_number: 0/29 Accuracy:  0.9384982121573302 Loss:  1.3062219454878397 Val_accuracy:  0.9205938436393354 Val_cost:  1.3062219454878397 Val_accuracy:  0.9205938436393354 Val_Acc:  1.5748970510410911\n",
      "Epoch number: 3127/10000step_number: 0/29 Accuracy:  0.9383279414268687 Loss:  1.3062472720514453 Val_accuracy:  0.9201852356306184 Val_cost:  1.3062472720514453 Val_accuracy:  0.9201852356306184 Val_Acc:  1.5750146674142602\n",
      "Epoch number: 3128/10000step_number: 0/29 Accuracy:  0.9378511833815767 Loss:  1.3062610172547315 Val_accuracy:  0.9196404249523291 Val_cost:  1.3062610172547315 Val_accuracy:  0.9196404249523291 Val_Acc:  1.575116072282867\n",
      "Epoch number: 3129/10000step_number: 0/29 Accuracy:  0.9378171292354844 Loss:  1.3062647558796598 Val_accuracy:  0.9192318169436121 Val_cost:  1.3062647558796598 Val_accuracy:  0.9192318169436121 Val_Acc:  1.5752050784997904\n",
      "Epoch number: 3130/10000step_number: 0/29 Accuracy:  0.9377149667972076 Loss:  1.3062597883347002 Val_accuracy:  0.9190956142740397 Val_cost:  1.3062597883347002 Val_accuracy:  0.9190956142740397 Val_Acc:  1.5752847343976162\n",
      "Epoch number: 3131/10000step_number: 0/29 Accuracy:  0.9376468585050229 Loss:  1.3062473782142576 Val_accuracy:  0.9190956142740397 Val_cost:  1.3062473782142576 Val_accuracy:  0.9190956142740397 Val_Acc:  1.57535722535772\n",
      "Epoch number: 3132/10000step_number: 0/29 Accuracy:  0.9377149667972076 Loss:  1.3062287738133735 Val_accuracy:  0.9192318169436121 Val_cost:  1.3062287738133735 Val_accuracy:  0.9192318169436121 Val_Acc:  1.5754237898445278\n",
      "Epoch number: 3133/10000step_number: 0/29 Accuracy:  0.9377490209432998 Loss:  1.3062050071056295 Val_accuracy:  0.9192318169436121 Val_cost:  1.3062050071056295 Val_accuracy:  0.9192318169436121 Val_Acc:  1.5754850131037015\n",
      "Epoch number: 3134/10000step_number: 0/29 Accuracy:  0.9377149667972076 Loss:  1.3061769413066904 Val_accuracy:  0.9192318169436121 Val_cost:  1.3061769413066904 Val_accuracy:  0.9192318169436121 Val_Acc:  1.5755411795360543\n",
      "Epoch number: 3135/10000step_number: 0/29 Accuracy:  0.9375787502128384 Loss:  1.306145420170104 Val_accuracy:  0.9195042222827567 Val_cost:  1.306145420170104 Val_accuracy:  0.9195042222827567 Val_Acc:  1.5755923474612596\n",
      "Epoch number: 3136/10000step_number: 0/29 Accuracy:  0.9375787502128384 Loss:  1.306111263358492 Val_accuracy:  0.9193680196131844 Val_cost:  1.306111263358492 Val_accuracy:  0.9193680196131844 Val_Acc:  1.5756383304588317\n",
      "Epoch number: 3137/10000step_number: 0/29 Accuracy:  0.9375787502128384 Loss:  1.3060751932776966 Val_accuracy:  0.9190956142740397 Val_cost:  1.3060751932776966 Val_accuracy:  0.9190956142740397 Val_Acc:  1.5756788509346158\n",
      "Epoch number: 3138/10000step_number: 0/29 Accuracy:  0.9373744253362847 Loss:  1.3060377299372872 Val_accuracy:  0.9190956142740397 Val_cost:  1.3060377299372872 Val_accuracy:  0.9190956142740397 Val_Acc:  1.575713897741323\n",
      "Epoch number: 3139/10000step_number: 0/29 Accuracy:  0.9373744253362847 Loss:  1.3059990852100265 Val_accuracy:  0.9190956142740397 Val_cost:  1.3059990852100265 Val_accuracy:  0.9190956142740397 Val_Acc:  1.575744098451298\n",
      "Epoch number: 3140/10000step_number: 0/29 Accuracy:  0.9375106419206538 Loss:  1.3059591572642246 Val_accuracy:  0.9190956142740397 Val_cost:  1.3059591572642246 Val_accuracy:  0.9190956142740397 Val_Acc:  1.5757708063021743\n",
      "Epoch number: 3141/10000step_number: 0/29 Accuracy:  0.9375106419206538 Loss:  1.305917693704766 Val_accuracy:  0.9192318169436121 Val_cost:  1.305917693704766 Val_accuracy:  0.9192318169436121 Val_Acc:  1.5757957628435826\n",
      "Epoch number: 3142/10000step_number: 0/29 Accuracy:  0.9373744253362847 Loss:  1.3058745488479873 Val_accuracy:  0.9192318169436121 Val_cost:  1.3058745488479873 Val_accuracy:  0.9192318169436121 Val_Acc:  1.5758205689135072\n",
      "Epoch number: 3143/10000step_number: 0/29 Accuracy:  0.9375106419206538 Loss:  1.3058298581521222 Val_accuracy:  0.9195042222827567 Val_cost:  1.3058298581521222 Val_accuracy:  0.9195042222827567 Val_Acc:  1.575846346761898\n",
      "Epoch number: 3144/10000step_number: 0/29 Accuracy:  0.9373744253362847 Loss:  1.3057840282755833 Val_accuracy:  0.9193680196131844 Val_cost:  1.3057840282755833 Val_accuracy:  0.9193680196131844 Val_Acc:  1.575873729936012\n",
      "Epoch number: 3145/10000step_number: 0/29 Accuracy:  0.9373063170441002 Loss:  1.3057376037510127 Val_accuracy:  0.9193680196131844 Val_cost:  1.3057376037510127 Val_accuracy:  0.9193680196131844 Val_Acc:  1.575903031668193\n",
      "Epoch number: 3146/10000step_number: 0/29 Accuracy:  0.9373403711901924 Loss:  1.3056911331106331 Val_accuracy:  0.9193680196131844 Val_cost:  1.3056911331106331 Val_accuracy:  0.9193680196131844 Val_Acc:  1.575934408300734\n",
      "Epoch number: 3147/10000step_number: 0/29 Accuracy:  0.9373063170441002 Loss:  1.3056450980019492 Val_accuracy:  0.9196404249523291 Val_cost:  1.3056450980019492 Val_accuracy:  0.9196404249523291 Val_Acc:  1.5759679491260457\n",
      "Epoch number: 3148/10000step_number: 0/29 Accuracy:  0.9374084794823769 Loss:  1.3055998979230687 Val_accuracy:  0.9195042222827567 Val_cost:  1.3055998979230687 Val_accuracy:  0.9195042222827567 Val_Acc:  1.5760037079758775\n",
      "Epoch number: 3149/10000step_number: 0/29 Accuracy:  0.9373063170441002 Loss:  1.3055558604470763 Val_accuracy:  0.9197766276219014 Val_cost:  1.3055558604470763 Val_accuracy:  0.9197766276219014 Val_Acc:  1.5760417069067012\n",
      "Epoch number: 3150/10000step_number: 0/29 Accuracy:  0.9373403711901924 Loss:  1.3055132558044467 Val_accuracy:  0.9195042222827567 Val_cost:  1.3055132558044467 Val_accuracy:  0.9195042222827567 Val_Acc:  1.5760819315160877\n",
      "Epoch number: 3151/10000step_number: 0/29 Accuracy:  0.9372382087519155 Loss:  1.3054723080874993 Val_accuracy:  0.9197766276219014 Val_cost:  1.3054723080874993 Val_accuracy:  0.9197766276219014 Val_Acc:  1.5761243264965872\n",
      "Epoch number: 3152/10000step_number: 0/29 Accuracy:  0.9371701004597309 Loss:  1.305433203043171 Val_accuracy:  0.9199128302914737 Val_cost:  1.305433203043171 Val_accuracy:  0.9199128302914737 Val_Acc:  1.5761687935707527\n",
      "Epoch number: 3153/10000step_number: 0/29 Accuracy:  0.9368636131449004 Loss:  1.3053960948819843 Val_accuracy:  0.9190956142740397 Val_cost:  1.3053960948819843 Val_accuracy:  0.9190956142740397 Val_Acc:  1.5762151923679453\n",
      "Epoch number: 3154/10000step_number: 0/29 Accuracy:  0.9368636131449004 Loss:  1.305361114178618 Val_accuracy:  0.9195042222827567 Val_cost:  1.305361114178618 Val_accuracy:  0.9195042222827567 Val_Acc:  1.576263343677347\n",
      "Epoch number: 3155/10000step_number: 0/29 Accuracy:  0.9369317214370849 Loss:  1.30532837747963 Val_accuracy:  0.9196404249523291 Val_cost:  1.30532837747963 Val_accuracy:  0.9196404249523291 Val_Acc:  1.5763130343153076\n",
      "Epoch number: 3156/10000step_number: 0/29 Accuracy:  0.9369657755831773 Loss:  1.3052979976590755 Val_accuracy:  0.9197766276219014 Val_cost:  1.3052979976590755 Val_accuracy:  0.9197766276219014 Val_Acc:  1.576364022739462\n",
      "Epoch number: 3157/10000step_number: 0/29 Accuracy:  0.9370679380214542 Loss:  1.3052700929998127 Val_accuracy:  0.9197766276219014 Val_cost:  1.3052700929998127 Val_accuracy:  0.9197766276219014 Val_Acc:  1.5764160446768734\n",
      "Epoch number: 3158/10000step_number: 0/29 Accuracy:  0.9370338838753618 Loss:  1.3052447927793287 Val_accuracy:  0.9197766276219014 Val_cost:  1.3052447927793287 Val_accuracy:  0.9197766276219014 Val_Acc:  1.5764688185738656\n",
      "Epoch number: 3159/10000step_number: 0/29 Accuracy:  0.9369998297292695 Loss:  1.3052222378140232 Val_accuracy:  0.9199128302914737 Val_cost:  1.3052222378140232 Val_accuracy:  0.9199128302914737 Val_Acc:  1.5765220495306917\n",
      "Epoch number: 3160/10000step_number: 0/29 Accuracy:  0.9369998297292695 Loss:  1.305202575630113 Val_accuracy:  0.9197766276219014 Val_cost:  1.305202575630113 Val_accuracy:  0.9197766276219014 Val_Acc:  1.5765754327332948\n",
      "Epoch number: 3161/10000step_number: 0/29 Accuracy:  0.9370338838753618 Loss:  1.305185951169674 Val_accuracy:  0.9197766276219014 Val_cost:  1.305185951169674 Val_accuracy:  0.9197766276219014 Val_Acc:  1.5766286562580718\n",
      "Epoch number: 3162/10000step_number: 0/29 Accuracy:  0.9371019921675464 Loss:  1.3051724947728438 Val_accuracy:  0.9196404249523291 Val_cost:  1.3051724947728438 Val_accuracy:  0.9196404249523291 Val_Acc:  1.5766814038276837\n",
      "Epoch number: 3163/10000step_number: 0/29 Accuracy:  0.9371019921675464 Loss:  1.305162309426312 Val_accuracy:  0.9196404249523291 Val_cost:  1.305162309426312 Val_accuracy:  0.9196404249523291 Val_Acc:  1.576733358449471\n",
      "Epoch number: 3164/10000step_number: 0/29 Accuracy:  0.9371019921675464 Loss:  1.3051554590240635 Val_accuracy:  0.9193680196131844 Val_cost:  1.3051554590240635 Val_accuracy:  0.9193680196131844 Val_Acc:  1.5767842073215106\n",
      "Epoch number: 3165/10000step_number: 0/29 Accuracy:  0.9373063170441002 Loss:  1.3051519588818528 Val_accuracy:  0.9195042222827567 Val_cost:  1.3051519588818528 Val_accuracy:  0.9195042222827567 Val_Acc:  1.57683364764639\n",
      "Epoch number: 3166/10000step_number: 0/29 Accuracy:  0.9374765877745616 Loss:  1.3051517692141539 Val_accuracy:  0.9197766276219014 Val_cost:  1.3051517692141539 Val_accuracy:  0.9197766276219014 Val_Acc:  1.5768813932772703\n",
      "Epoch number: 3167/10000step_number: 0/29 Accuracy:  0.9374425336284693 Loss:  1.305154791864705 Val_accuracy:  0.9196404249523291 Val_cost:  1.305154791864705 Val_accuracy:  0.9196404249523291 Val_Acc:  1.5769271811483192\n",
      "Epoch number: 3168/10000step_number: 0/29 Accuracy:  0.9374084794823769 Loss:  1.30516087031405 Val_accuracy:  0.9197766276219014 Val_cost:  1.30516087031405 Val_accuracy:  0.9197766276219014 Val_Acc:  1.5769707767740149\n",
      "Epoch number: 3169/10000step_number: 0/29 Accuracy:  0.9374765877745616 Loss:  1.3051697928222512 Val_accuracy:  0.9197766276219014 Val_cost:  1.3051697928222512 Val_accuracy:  0.9197766276219014 Val_Acc:  1.5770119782515157\n",
      "Epoch number: 3170/10000step_number: 0/29 Accuracy:  0.9375787502128384 Loss:  1.3051812984266102 Val_accuracy:  0.9197766276219014 Val_cost:  1.3051812984266102 Val_accuracy:  0.9197766276219014 Val_Acc:  1.577050619079911\n",
      "Epoch number: 3171/10000step_number: 0/29 Accuracy:  0.9376468585050229 Loss:  1.305195085356586 Val_accuracy:  0.9197766276219014 Val_cost:  1.305195085356586 Val_accuracy:  0.9197766276219014 Val_Acc:  1.5770865700145804\n",
      "Epoch number: 3172/10000step_number: 0/29 Accuracy:  0.9375787502128384 Loss:  1.3052108212610751 Val_accuracy:  0.9196404249523291 Val_cost:  1.3052108212610751 Val_accuracy:  0.9196404249523291 Val_Acc:  1.577119739682277\n",
      "Epoch number: 3173/10000step_number: 0/29 Accuracy:  0.9365230716839775 Loss:  1.3052281545111664 Val_accuracy:  0.9181421955870335 Val_cost:  1.3052281545111664 Val_accuracy:  0.9181421955870335 Val_Acc:  1.5771500747281328\n",
      "Epoch number: 3174/10000step_number: 0/29 Accuracy:  0.9366592882683467 Loss:  1.3052467257821758 Val_accuracy:  0.9185508035957505 Val_cost:  1.3052467257821758 Val_accuracy:  0.9185508035957505 Val_Acc:  1.5771775589655377\n",
      "Epoch number: 3175/10000step_number: 0/29 Accuracy:  0.9366592882683467 Loss:  1.3052661791446116 Val_accuracy:  0.9182783982566058 Val_cost:  1.3052661791446116 Val_accuracy:  0.9182783982566058 Val_Acc:  1.577202211492926\n",
      "Epoch number: 3176/10000step_number: 0/29 Accuracy:  0.9365571258300698 Loss:  1.3052861719975544 Val_accuracy:  0.9181421955870335 Val_cost:  1.3052861719975544 Val_accuracy:  0.9181421955870335 Val_Acc:  1.5772240840206009\n",
      "Epoch number: 3177/10000step_number: 0/29 Accuracy:  0.9356376638855781 Loss:  1.3053063833429228 Val_accuracy:  0.9177335875783166 Val_cost:  1.3053063833429228 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5772432576534279\n",
      "Epoch number: 3178/10000step_number: 0/29 Accuracy:  0.9356036097394858 Loss:  1.3053265201005328 Val_accuracy:  0.9178697902478888 Val_cost:  1.3053265201005328 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5772598390798365\n",
      "Epoch number: 3179/10000step_number: 0/29 Accuracy:  0.9354673931551166 Loss:  1.3053463213719567 Val_accuracy:  0.9178697902478888 Val_cost:  1.3053463213719567 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5772739569385954\n",
      "Epoch number: 3180/10000step_number: 0/29 Accuracy:  0.9354673931551166 Loss:  1.305365560747129 Val_accuracy:  0.9178697902478888 Val_cost:  1.305365560747129 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5772857578985713\n",
      "Epoch number: 3181/10000step_number: 0/29 Accuracy:  0.9355014473012089 Loss:  1.3053840468902482 Val_accuracy:  0.9180059929174612 Val_cost:  1.3053840468902482 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5772954034464584\n",
      "Epoch number: 3182/10000step_number: 0/29 Accuracy:  0.9354673931551166 Loss:  1.3054016227311631 Val_accuracy:  0.9180059929174612 Val_cost:  1.3054016227311631 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5773030669495849\n",
      "Epoch number: 3183/10000step_number: 0/29 Accuracy:  0.9358419887621318 Loss:  1.3054181636264077 Val_accuracy:  0.9180059929174612 Val_cost:  1.3054181636264077 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5773089310215178\n",
      "Epoch number: 3184/10000step_number: 0/29 Accuracy:  0.9358419887621318 Loss:  1.305433574849766 Val_accuracy:  0.9181421955870335 Val_cost:  1.305433574849766 Val_accuracy:  0.9181421955870335 Val_Acc:  1.5773131859307385\n",
      "Epoch number: 3185/10000step_number: 0/29 Accuracy:  0.9359782053465009 Loss:  1.3054477887391331 Val_accuracy:  0.9180059929174612 Val_cost:  1.3054477887391331 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5773160278498952\n",
      "Epoch number: 3186/10000step_number: 0/29 Accuracy:  0.9360803677847778 Loss:  1.3054607617783387 Val_accuracy:  0.9177335875783166 Val_cost:  1.3054607617783387 Val_accuracy:  0.9177335875783166 Val_Acc:  1.577317657751783\n",
      "Epoch number: 3187/10000step_number: 0/29 Accuracy:  0.9360463136386855 Loss:  1.3054724718408912 Val_accuracy:  0.9177335875783166 Val_cost:  1.3054724718408912 Val_accuracy:  0.9177335875783166 Val_Acc:  1.577318280458754\n",
      "Epoch number: 3188/10000step_number: 0/29 Accuracy:  0.9360463136386855 Loss:  1.3054829157738004 Val_accuracy:  0.9177335875783166 Val_cost:  1.3054829157738004 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5773181031864594\n",
      "Epoch number: 3189/10000step_number: 0/29 Accuracy:  0.9360463136386855 Loss:  1.3054921074510188 Val_accuracy:  0.9177335875783166 Val_cost:  1.3054921074510188 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5773173341446365\n",
      "Epoch number: 3190/10000step_number: 0/29 Accuracy:  0.9360803677847778 Loss:  1.3055000763565596 Val_accuracy:  0.9177335875783166 Val_cost:  1.3055000763565596 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5773161792718688\n",
      "Epoch number: 3191/10000step_number: 0/29 Accuracy:  0.9360803677847778 Loss:  1.3055068666070355 Val_accuracy:  0.9175973849087442 Val_cost:  1.3055068666070355 Val_accuracy:  0.9175973849087442 Val_Acc:  1.5773148377324782\n",
      "Epoch number: 3192/10000step_number: 0/29 Accuracy:  0.9361144219308701 Loss:  1.305512535964552 Val_accuracy:  0.9175973849087442 Val_cost:  1.305512535964552 Val_accuracy:  0.9175973849087442 Val_Acc:  1.5773134946528873\n",
      "Epoch number: 3193/10000step_number: 0/29 Accuracy:  0.9361484760769624 Loss:  1.3055171536304215 Val_accuracy:  0.9177335875783166 Val_cost:  1.3055171536304215 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5773123106262015\n",
      "Epoch number: 3194/10000step_number: 0/29 Accuracy:  0.9358760429082241 Loss:  1.3055207943749907 Val_accuracy:  0.9175973849087442 Val_cost:  1.3055207943749907 Val_accuracy:  0.9175973849087442 Val_Acc:  1.5773114095896115\n",
      "Epoch number: 3195/10000step_number: 0/29 Accuracy:  0.9359782053465009 Loss:  1.3055235255185276 Val_accuracy:  0.9175973849087442 Val_cost:  1.3055235255185276 Val_accuracy:  0.9175973849087442 Val_Acc:  1.5773108666858442\n",
      "Epoch number: 3196/10000step_number: 0/29 Accuracy:  0.9359100970543164 Loss:  1.3055253847273638 Val_accuracy:  0.9178697902478888 Val_cost:  1.3055253847273638 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5773107014697387\n",
      "Epoch number: 3197/10000step_number: 0/29 Accuracy:  0.9358079346160395 Loss:  1.305526353620664 Val_accuracy:  0.9178697902478888 Val_cost:  1.305526353620664 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5773108798792606\n",
      "Epoch number: 3198/10000step_number: 0/29 Accuracy:  0.9357738804699473 Loss:  1.3055263431199573 Val_accuracy:  0.9180059929174612 Val_cost:  1.3055263431199573 Val_accuracy:  0.9180059929174612 Val_Acc:  1.577311326748844\n",
      "Epoch number: 3199/10000step_number: 0/29 Accuracy:  0.9356717180316704 Loss:  1.3055252091054776 Val_accuracy:  0.9175973849087442 Val_cost:  1.3055252091054776 Val_accuracy:  0.9175973849087442 Val_Acc:  1.5773119453106952\n",
      "Epoch number: 3200/10000step_number: 0/29 Accuracy:  0.9357398263238549 Loss:  1.30552279921631 Val_accuracy:  0.9174611822391718 Val_cost:  1.30552279921631 Val_accuracy:  0.9174611822391718 Val_Acc:  1.577312639042691\n",
      "Epoch number: 3201/10000step_number: 0/29 Accuracy:  0.9358760429082241 Loss:  1.3055190056768702 Val_accuracy:  0.9174611822391718 Val_cost:  1.3055190056768702 Val_accuracy:  0.9174611822391718 Val_Acc:  1.577313331707499\n",
      "Epoch number: 3202/10000step_number: 0/29 Accuracy:  0.9359100970543164 Loss:  1.305513794124056 Val_accuracy:  0.9178697902478888 Val_cost:  1.305513794124056 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5773139830478573\n",
      "Epoch number: 3203/10000step_number: 0/29 Accuracy:  0.9357738804699473 Loss:  1.3055071993456313 Val_accuracy:  0.9178697902478888 Val_cost:  1.3055071993456313 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5773145958050534\n",
      "Epoch number: 3204/10000step_number: 0/29 Accuracy:  0.9358760429082241 Loss:  1.3054993004208522 Val_accuracy:  0.9180059929174612 Val_cost:  1.3054993004208522 Val_accuracy:  0.9180059929174612 Val_Acc:  1.577315215352246\n",
      "Epoch number: 3205/10000step_number: 0/29 Accuracy:  0.9358419887621318 Loss:  1.3054901925893094 Val_accuracy:  0.9181421955870335 Val_cost:  1.3054901925893094 Val_accuracy:  0.9181421955870335 Val_Acc:  1.5773159234831613\n",
      "Epoch number: 3206/10000step_number: 0/29 Accuracy:  0.9358760429082241 Loss:  1.3054799661773735 Val_accuracy:  0.9181421955870335 Val_cost:  1.3054799661773735 Val_accuracy:  0.9181421955870335 Val_Acc:  1.5773168311231027\n",
      "Epoch number: 3207/10000step_number: 0/29 Accuracy:  0.9360122594925933 Loss:  1.3054686947997594 Val_accuracy:  0.9184146009261781 Val_cost:  1.3054686947997594 Val_accuracy:  0.9184146009261781 Val_Acc:  1.5773180710066945\n",
      "Epoch number: 3208/10000step_number: 0/29 Accuracy:  0.9360463136386855 Loss:  1.3054564307657324 Val_accuracy:  0.9182783982566058 Val_cost:  1.3054564307657324 Val_accuracy:  0.9182783982566058 Val_Acc:  1.5773197909968806\n",
      "Epoch number: 3209/10000step_number: 0/29 Accuracy:  0.9360803677847778 Loss:  1.3054432046764173 Val_accuracy:  0.9181421955870335 Val_cost:  1.3054432046764173 Val_accuracy:  0.9181421955870335 Val_Acc:  1.5773221470898466\n",
      "Epoch number: 3210/10000step_number: 0/29 Accuracy:  0.9361144219308701 Loss:  1.3054290269373474 Val_accuracy:  0.9182783982566058 Val_cost:  1.3054290269373474 Val_accuracy:  0.9182783982566058 Val_Acc:  1.5773252946529188\n",
      "Epoch number: 3211/10000step_number: 0/29 Accuracy:  0.9361484760769624 Loss:  1.3054138893551264 Val_accuracy:  0.9181421955870335 Val_cost:  1.3054138893551264 Val_accuracy:  0.9181421955870335 Val_Acc:  1.5773293773809263\n",
      "Epoch number: 3212/10000step_number: 0/29 Accuracy:  0.9361825302230546 Loss:  1.3053977662818734 Val_accuracy:  0.9181421955870335 Val_cost:  1.3053977662818734 Val_accuracy:  0.9181421955870335 Val_Acc:  1.5773345111163757\n",
      "Epoch number: 3213/10000step_number: 0/29 Accuracy:  0.9361484760769624 Loss:  1.305380612999276 Val_accuracy:  0.9181421955870335 Val_cost:  1.305380612999276 Val_accuracy:  0.9181421955870335 Val_Acc:  1.5773407660811312\n",
      "Epoch number: 3214/10000step_number: 0/29 Accuracy:  0.9362165843691469 Loss:  1.3053623642141716 Val_accuracy:  0.9181421955870335 Val_cost:  1.3053623642141716 Val_accuracy:  0.9181421955870335 Val_Acc:  1.5773481416232535\n",
      "Epoch number: 3215/10000step_number: 0/29 Accuracy:  0.9362506385152393 Loss:  1.3053429229688895 Val_accuracy:  0.9181421955870335 Val_cost:  1.3053429229688895 Val_accuracy:  0.9181421955870335 Val_Acc:  1.5773565594469154\n",
      "Epoch number: 3216/10000step_number: 0/29 Accuracy:  0.9362506385152393 Loss:  1.3053221658222163 Val_accuracy:  0.9181421955870335 Val_cost:  1.3053221658222163 Val_accuracy:  0.9181421955870335 Val_Acc:  1.577365843323144\n",
      "Epoch number: 3217/10000step_number: 0/29 Accuracy:  0.9362506385152393 Loss:  1.3052999036803945 Val_accuracy:  0.9180059929174612 Val_cost:  1.3052999036803945 Val_accuracy:  0.9180059929174612 Val_Acc:  1.577375819001378\n",
      "Epoch number: 3218/10000step_number: 0/29 Accuracy:  0.9362165843691469 Loss:  1.3052759825240656 Val_accuracy:  0.9180059929174612 Val_cost:  1.3052759825240656 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5773862431903434\n",
      "Epoch number: 3219/10000step_number: 0/29 Accuracy:  0.9361825302230546 Loss:  1.3052500571589776 Val_accuracy:  0.9181421955870335 Val_cost:  1.3052500571589776 Val_accuracy:  0.9181421955870335 Val_Acc:  1.5773973169580757\n",
      "Epoch number: 3220/10000step_number: 0/29 Accuracy:  0.9362506385152393 Loss:  1.3052223390430122 Val_accuracy:  0.9180059929174612 Val_cost:  1.3052223390430122 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5774086651235053\n",
      "Epoch number: 3221/10000step_number: 0/29 Accuracy:  0.9362506385152393 Loss:  1.3051916934509522 Val_accuracy:  0.9180059929174612 Val_cost:  1.3051916934509522 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5774221530404173\n",
      "Epoch number: 3222/10000step_number: 0/29 Accuracy:  0.9363187468074238 Loss:  1.3051611059699895 Val_accuracy:  0.9178697902478888 Val_cost:  1.3051611059699895 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5774339174092964\n",
      "Epoch number: 3223/10000step_number: 0/29 Accuracy:  0.9363187468074238 Loss:  1.3051224548909863 Val_accuracy:  0.9178697902478888 Val_cost:  1.3051224548909863 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5774548434755626\n",
      "Epoch number: 3224/10000step_number: 0/29 Accuracy:  0.9362165843691469 Loss:  1.305100123572654 Val_accuracy:  0.9178697902478888 Val_cost:  1.305100123572654 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5774527526209583\n",
      "Epoch number: 3225/10000step_number: 0/29 Accuracy:  0.9363187468074238 Loss:  1.3050334619823762 Val_accuracy:  0.9178697902478888 Val_cost:  1.3050334619823762 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5774824618620764\n",
      "Epoch number: 3226/10000step_number: 0/29 Accuracy:  0.9363187468074238 Loss:  1.3050337794319813 Val_accuracy:  0.9180059929174612 Val_cost:  1.3050337794319813 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5774960586348405\n",
      "Epoch number: 3227/10000step_number: 0/29 Accuracy:  0.9363528009535161 Loss:  1.304951261069451 Val_accuracy:  0.9184146009261781 Val_cost:  1.304951261069451 Val_accuracy:  0.9184146009261781 Val_Acc:  1.577495878461238\n",
      "Epoch number: 3228/10000step_number: 0/29 Accuracy:  0.9361825302230546 Loss:  1.3049612870283678 Val_accuracy:  0.9181421955870335 Val_cost:  1.3049612870283678 Val_accuracy:  0.9181421955870335 Val_Acc:  1.5775038894674223\n",
      "Epoch number: 3229/10000step_number: 0/29 Accuracy:  0.9362506385152393 Loss:  1.3048727160583746 Val_accuracy:  0.9182783982566058 Val_cost:  1.3048727160583746 Val_accuracy:  0.9182783982566058 Val_Acc:  1.5774835095730153\n",
      "Epoch number: 3230/10000step_number: 0/29 Accuracy:  0.9361825302230546 Loss:  1.304868310589625 Val_accuracy:  0.9180059929174612 Val_cost:  1.304868310589625 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5775381546234084\n",
      "Epoch number: 3231/10000step_number: 0/29 Accuracy:  0.9362506385152393 Loss:  1.3048538301190098 Val_accuracy:  0.9182783982566058 Val_cost:  1.3048538301190098 Val_accuracy:  0.9182783982566058 Val_Acc:  1.577447026424485\n",
      "Epoch number: 3232/10000step_number: 0/29 Accuracy:  0.9361825302230546 Loss:  1.3047623034536697 Val_accuracy:  0.9181421955870335 Val_cost:  1.3047623034536697 Val_accuracy:  0.9181421955870335 Val_Acc:  1.5774105301324737\n",
      "Epoch number: 3233/10000step_number: 0/29 Accuracy:  0.9361484760769624 Loss:  1.3047540843724152 Val_accuracy:  0.9180059929174612 Val_cost:  1.3047540843724152 Val_accuracy:  0.9180059929174612 Val_Acc:  1.577417889544491\n",
      "Epoch number: 3234/10000step_number: 0/29 Accuracy:  0.9360803677847778 Loss:  1.3046652093396356 Val_accuracy:  0.9181421955870335 Val_cost:  1.3046652093396356 Val_accuracy:  0.9181421955870335 Val_Acc:  1.5773964143287345\n",
      "Epoch number: 3235/10000step_number: 0/29 Accuracy:  0.9361144219308701 Loss:  1.304623776762936 Val_accuracy:  0.9178697902478888 Val_cost:  1.304623776762936 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5774186082317927\n",
      "Epoch number: 3236/10000step_number: 0/29 Accuracy:  0.9361144219308701 Loss:  1.3045678080197383 Val_accuracy:  0.9180059929174612 Val_cost:  1.3045678080197383 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5774080491736162\n",
      "Epoch number: 3237/10000step_number: 0/29 Accuracy:  0.9361484760769624 Loss:  1.30451234271038 Val_accuracy:  0.9178697902478888 Val_cost:  1.30451234271038 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5774089346992404\n",
      "Epoch number: 3238/10000step_number: 0/29 Accuracy:  0.9363187468074238 Loss:  1.3044590939689664 Val_accuracy:  0.9182783982566058 Val_cost:  1.3044590939689664 Val_accuracy:  0.9182783982566058 Val_Acc:  1.5774142399386015\n",
      "Epoch number: 3239/10000step_number: 0/29 Accuracy:  0.9362846926613315 Loss:  1.3044026711091696 Val_accuracy:  0.9181421955870335 Val_cost:  1.3044026711091696 Val_accuracy:  0.9181421955870335 Val_Acc:  1.5774179645839437\n",
      "Epoch number: 3240/10000step_number: 0/29 Accuracy:  0.9362846926613315 Loss:  1.3043422715693183 Val_accuracy:  0.9181421955870335 Val_cost:  1.3043422715693183 Val_accuracy:  0.9181421955870335 Val_Acc:  1.5774240621444566\n",
      "Epoch number: 3241/10000step_number: 0/29 Accuracy:  0.9363187468074238 Loss:  1.3042804763591476 Val_accuracy:  0.9180059929174612 Val_cost:  1.3042804763591476 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5774318744286988\n",
      "Epoch number: 3242/10000step_number: 0/29 Accuracy:  0.9363528009535161 Loss:  1.3042153494673125 Val_accuracy:  0.9180059929174612 Val_cost:  1.3042153494673125 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5774391714061378\n",
      "Epoch number: 3243/10000step_number: 0/29 Accuracy:  0.9363528009535161 Loss:  1.30414825444435 Val_accuracy:  0.9178697902478888 Val_cost:  1.30414825444435 Val_accuracy:  0.9178697902478888 Val_Acc:  1.577448533492051\n",
      "Epoch number: 3244/10000step_number: 0/29 Accuracy:  0.9363528009535161 Loss:  1.304080536712752 Val_accuracy:  0.9178697902478888 Val_cost:  1.304080536712752 Val_accuracy:  0.9178697902478888 Val_Acc:  1.577458823196516\n",
      "Epoch number: 3245/10000step_number: 0/29 Accuracy:  0.9363187468074238 Loss:  1.304012600497946 Val_accuracy:  0.9178697902478888 Val_cost:  1.304012600497946 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5774705896838115\n",
      "Epoch number: 3246/10000step_number: 0/29 Accuracy:  0.9362846926613315 Loss:  1.3039455871162655 Val_accuracy:  0.9178697902478888 Val_cost:  1.3039455871162655 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5774844140644138\n",
      "Epoch number: 3247/10000step_number: 0/29 Accuracy:  0.9363187468074238 Loss:  1.3038803672560777 Val_accuracy:  0.9180059929174612 Val_cost:  1.3038803672560777 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5775005149216432\n",
      "Epoch number: 3248/10000step_number: 0/29 Accuracy:  0.9363868550996084 Loss:  1.3038173951160537 Val_accuracy:  0.9180059929174612 Val_cost:  1.3038173951160537 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5775191843735086\n",
      "Epoch number: 3249/10000step_number: 0/29 Accuracy:  0.9364209092457007 Loss:  1.3037570741786921 Val_accuracy:  0.9180059929174612 Val_cost:  1.3037570741786921 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5775406638382632\n",
      "Epoch number: 3250/10000step_number: 0/29 Accuracy:  0.9363528009535161 Loss:  1.3036995941122032 Val_accuracy:  0.9180059929174612 Val_cost:  1.3036995941122032 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5775650038493603\n",
      "Epoch number: 3251/10000step_number: 0/29 Accuracy:  0.9363528009535161 Loss:  1.3036449578579459 Val_accuracy:  0.9178697902478888 Val_cost:  1.3036449578579459 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5775922078079339\n",
      "Epoch number: 3252/10000step_number: 0/29 Accuracy:  0.9364549633917929 Loss:  1.3035930985401067 Val_accuracy:  0.9177335875783166 Val_cost:  1.3035930985401067 Val_accuracy:  0.9177335875783166 Val_Acc:  1.577622187029587\n",
      "Epoch number: 3253/10000step_number: 0/29 Accuracy:  0.9364890175378853 Loss:  1.3035438865912075 Val_accuracy:  0.9177335875783166 Val_cost:  1.3035438865912075 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5776547763028543\n",
      "Epoch number: 3254/10000step_number: 0/29 Accuracy:  0.9364890175378853 Loss:  1.3034971525426735 Val_accuracy:  0.9177335875783166 Val_cost:  1.3034971525426735 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5776897537929093\n",
      "Epoch number: 3255/10000step_number: 0/29 Accuracy:  0.9364890175378853 Loss:  1.3034527185040012 Val_accuracy:  0.9177335875783166 Val_cost:  1.3034527185040012 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5777268423019142\n",
      "Epoch number: 3256/10000step_number: 0/29 Accuracy:  0.9366592882683467 Loss:  1.3034104110783655 Val_accuracy:  0.9175973849087442 Val_cost:  1.3034104110783655 Val_accuracy:  0.9175973849087442 Val_Acc:  1.5777657046262605\n",
      "Epoch number: 3257/10000step_number: 0/29 Accuracy:  0.9366933424144389 Loss:  1.3033700760774032 Val_accuracy:  0.9175973849087442 Val_cost:  1.3033700760774032 Val_accuracy:  0.9175973849087442 Val_Acc:  1.5778059469340897\n",
      "Epoch number: 3258/10000step_number: 0/29 Accuracy:  0.9366933424144389 Loss:  1.3033316129400918 Val_accuracy:  0.9177335875783166 Val_cost:  1.3033316129400918 Val_accuracy:  0.9177335875783166 Val_Acc:  1.577847164512658\n",
      "Epoch number: 3259/10000step_number: 0/29 Accuracy:  0.9366933424144389 Loss:  1.3032950383625002 Val_accuracy:  0.9175973849087442 Val_cost:  1.3032950383625002 Val_accuracy:  0.9175973849087442 Val_Acc:  1.5778890839377329\n",
      "Epoch number: 3260/10000step_number: 0/29 Accuracy:  0.9367273965605313 Loss:  1.3032605142772393 Val_accuracy:  0.9175973849087442 Val_cost:  1.3032605142772393 Val_accuracy:  0.9175973849087442 Val_Acc:  1.5779317520224847\n",
      "Epoch number: 3261/10000step_number: 0/29 Accuracy:  0.9367614507066235 Loss:  1.3032280700936107 Val_accuracy:  0.9175973849087442 Val_cost:  1.3032280700936107 Val_accuracy:  0.9175973849087442 Val_Acc:  1.5779754077264272\n",
      "Epoch number: 3262/10000step_number: 0/29 Accuracy:  0.9367955048527158 Loss:  1.3031969616431125 Val_accuracy:  0.9175973849087442 Val_cost:  1.3031969616431125 Val_accuracy:  0.9175973849087442 Val_Acc:  1.5780199949923328\n",
      "Epoch number: 3263/10000step_number: 0/29 Accuracy:  0.9368636131449004 Loss:  1.303165674737602 Val_accuracy:  0.9174611822391718 Val_cost:  1.303165674737602 Val_accuracy:  0.9174611822391718 Val_Acc:  1.5780652761370613\n",
      "Epoch number: 3264/10000step_number: 0/29 Accuracy:  0.9368636131449004 Loss:  1.3031330977806495 Val_accuracy:  0.9174611822391718 Val_cost:  1.3031330977806495 Val_accuracy:  0.9174611822391718 Val_Acc:  1.5781114241640375\n",
      "Epoch number: 3265/10000step_number: 0/29 Accuracy:  0.9368636131449004 Loss:  1.303099076776644 Val_accuracy:  0.9174611822391718 Val_cost:  1.303099076776644 Val_accuracy:  0.9174611822391718 Val_Acc:  1.5781593678671733\n",
      "Epoch number: 3266/10000step_number: 0/29 Accuracy:  0.9368976672909927 Loss:  1.3030627227250344 Val_accuracy:  0.9174611822391718 Val_cost:  1.3030627227250344 Val_accuracy:  0.9174611822391718 Val_Acc:  1.5782084020434126\n",
      "Epoch number: 3267/10000step_number: 0/29 Accuracy:  0.9368976672909927 Loss:  1.3030219468537758 Val_accuracy:  0.9174611822391718 Val_cost:  1.3030219468537758 Val_accuracy:  0.9174611822391718 Val_Acc:  1.5782545542158692\n",
      "Epoch number: 3268/10000step_number: 0/29 Accuracy:  0.9368636131449004 Loss:  1.3029769893329868 Val_accuracy:  0.9174611822391718 Val_cost:  1.3029769893329868 Val_accuracy:  0.9174611822391718 Val_Acc:  1.5782977002285574\n",
      "Epoch number: 3269/10000step_number: 0/29 Accuracy:  0.9368636131449004 Loss:  1.3029302369914448 Val_accuracy:  0.9175973849087442 Val_cost:  1.3029302369914448 Val_accuracy:  0.9175973849087442 Val_Acc:  1.578338253524402\n",
      "Epoch number: 3270/10000step_number: 0/29 Accuracy:  0.9370338838753618 Loss:  1.3028830203098154 Val_accuracy:  0.9174611822391718 Val_cost:  1.3028830203098154 Val_accuracy:  0.9174611822391718 Val_Acc:  1.5783773279398494\n",
      "Epoch number: 3271/10000step_number: 0/29 Accuracy:  0.9371019921675464 Loss:  1.3028369096767938 Val_accuracy:  0.9174611822391718 Val_cost:  1.3028369096767938 Val_accuracy:  0.9174611822391718 Val_Acc:  1.5784160488375116\n",
      "Epoch number: 3272/10000step_number: 0/29 Accuracy:  0.9371701004597309 Loss:  1.3027920173646477 Val_accuracy:  0.9175973849087442 Val_cost:  1.3027920173646477 Val_accuracy:  0.9175973849087442 Val_Acc:  1.5784548603768938\n",
      "Epoch number: 3273/10000step_number: 0/29 Accuracy:  0.9373403711901924 Loss:  1.302747357389421 Val_accuracy:  0.9177335875783166 Val_cost:  1.302747357389421 Val_accuracy:  0.9177335875783166 Val_Acc:  1.578494715750678\n",
      "Epoch number: 3274/10000step_number: 0/29 Accuracy:  0.9373403711901924 Loss:  1.3027023306460068 Val_accuracy:  0.9177335875783166 Val_cost:  1.3027023306460068 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5785369392315187\n",
      "Epoch number: 3275/10000step_number: 0/29 Accuracy:  0.9373403711901924 Loss:  1.302656918984563 Val_accuracy:  0.9177335875783166 Val_cost:  1.302656918984563 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5785827590042747\n",
      "Epoch number: 3276/10000step_number: 0/29 Accuracy:  0.9373063170441002 Loss:  1.3026116837831725 Val_accuracy:  0.9177335875783166 Val_cost:  1.3026116837831725 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5786328681998516\n",
      "Epoch number: 3277/10000step_number: 0/29 Accuracy:  0.9374425336284693 Loss:  1.3025674711172015 Val_accuracy:  0.9177335875783166 Val_cost:  1.3025674711172015 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5786870939219\n",
      "Epoch number: 3278/10000step_number: 0/29 Accuracy:  0.9374084794823769 Loss:  1.3025252608090196 Val_accuracy:  0.9177335875783166 Val_cost:  1.3025252608090196 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5787445272832619\n",
      "Epoch number: 3279/10000step_number: 0/29 Accuracy:  0.9374084794823769 Loss:  1.3024859567148732 Val_accuracy:  0.9177335875783166 Val_cost:  1.3024859567148732 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5788038050952522\n",
      "Epoch number: 3280/10000step_number: 0/29 Accuracy:  0.9374084794823769 Loss:  1.302450097031026 Val_accuracy:  0.9177335875783166 Val_cost:  1.302450097031026 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5788637299199895\n",
      "Epoch number: 3281/10000step_number: 0/29 Accuracy:  0.9374425336284693 Loss:  1.302417419550472 Val_accuracy:  0.9177335875783166 Val_cost:  1.302417419550472 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5789239216681077\n",
      "Epoch number: 3282/10000step_number: 0/29 Accuracy:  0.9375446960667462 Loss:  1.3023862686008087 Val_accuracy:  0.9178697902478888 Val_cost:  1.3023862686008087 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5789853076784357\n",
      "Epoch number: 3283/10000step_number: 0/29 Accuracy:  0.9375787502128384 Loss:  1.3023532184145676 Val_accuracy:  0.9178697902478888 Val_cost:  1.3023532184145676 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5790501010082585\n",
      "Epoch number: 3284/10000step_number: 0/29 Accuracy:  0.9376128043589307 Loss:  1.302313465425407 Val_accuracy:  0.9175973849087442 Val_cost:  1.302313465425407 Val_accuracy:  0.9175973849087442 Val_Acc:  1.579121222042944\n",
      "Epoch number: 3285/10000step_number: 0/29 Accuracy:  0.9375106419206538 Loss:  1.3022625433647035 Val_accuracy:  0.9175973849087442 Val_cost:  1.3022625433647035 Val_accuracy:  0.9175973849087442 Val_Acc:  1.5792016011060792\n",
      "Epoch number: 3286/10000step_number: 0/29 Accuracy:  0.9375106419206538 Loss:  1.3021990541460413 Val_accuracy:  0.9177335875783166 Val_cost:  1.3021990541460413 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5792935435661204\n",
      "Epoch number: 3287/10000step_number: 0/29 Accuracy:  0.9374084794823769 Loss:  1.3021269736276777 Val_accuracy:  0.9180059929174612 Val_cost:  1.3021269736276777 Val_accuracy:  0.9180059929174612 Val_Acc:  1.579397843521634\n",
      "Epoch number: 3288/10000step_number: 0/29 Accuracy:  0.9373403711901924 Loss:  1.3020558731667944 Val_accuracy:  0.9180059929174612 Val_cost:  1.3020558731667944 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5795118303377038\n",
      "Epoch number: 3289/10000step_number: 0/29 Accuracy:  0.9374084794823769 Loss:  1.3019997188153285 Val_accuracy:  0.9177335875783166 Val_cost:  1.3019997188153285 Val_accuracy:  0.9177335875783166 Val_Acc:  1.5796236056281105\n",
      "Epoch number: 3290/10000step_number: 0/29 Accuracy:  0.9374084794823769 Loss:  1.3019787823585744 Val_accuracy:  0.9180059929174612 Val_cost:  1.3019787823585744 Val_accuracy:  0.9180059929174612 Val_Acc:  1.5797047803894022\n",
      "Epoch number: 3291/10000step_number: 0/29 Accuracy:  0.9375106419206538 Loss:  1.3020288733047876 Val_accuracy:  0.9182783982566058 Val_cost:  1.3020288733047876 Val_accuracy:  0.9182783982566058 Val_Acc:  1.579730344820037\n",
      "Epoch number: 3292/10000step_number: 0/29 Accuracy:  0.9378171292354844 Loss:  1.3022016518314705 Val_accuracy:  0.9182783982566058 Val_cost:  1.3022016518314705 Val_accuracy:  0.9182783982566058 Val_Acc:  1.5797323736509554\n",
      "Epoch number: 3293/10000step_number: 0/29 Accuracy:  0.9379192916737613 Loss:  1.3025071364754854 Val_accuracy:  0.9189594116044675 Val_cost:  1.3025071364754854 Val_accuracy:  0.9189594116044675 Val_Acc:  1.5797862249580596\n",
      "Epoch number: 3294/10000step_number: 0/29 Accuracy:  0.9382257789885918 Loss:  1.3028090398429626 Val_accuracy:  0.920049032961046 Val_cost:  1.3028090398429626 Val_accuracy:  0.920049032961046 Val_Acc:  1.579917805497273\n",
      "Epoch number: 3295/10000step_number: 0/29 Accuracy:  0.938600374595607 Loss:  1.3029031918944922 Val_accuracy:  0.9203214383001906 Val_cost:  1.3029031918944922 Val_accuracy:  0.9203214383001906 Val_Acc:  1.5802496691935615\n",
      "Epoch number: 3296/10000step_number: 0/29 Accuracy:  0.9392133492252682 Loss:  1.302394209208759 Val_accuracy:  0.92086624897848 Val_cost:  1.302394209208759 Val_accuracy:  0.92086624897848 Val_Acc:  1.5803468186881577\n",
      "Epoch number: 3297/10000step_number: 0/29 Accuracy:  0.9379533458198536 Loss:  1.3010901799443824 Val_accuracy:  0.9195042222827567 Val_cost:  1.3010901799443824 Val_accuracy:  0.9195042222827567 Val_Acc:  1.5791847830222296\n",
      "Epoch number: 3298/10000step_number: 0/29 Accuracy:  0.9377490209432998 Loss:  1.3043413128322467 Val_accuracy:  0.9178697902478888 Val_cost:  1.3043413128322467 Val_accuracy:  0.9178697902478888 Val_Acc:  1.5795674568452889\n",
      "Epoch number: 3299/10000step_number: 0/29 Accuracy:  0.9347182019410863 Loss:  1.3061175950357427 Val_accuracy:  0.9147371288477254 Val_cost:  1.3061175950357427 Val_accuracy:  0.9147371288477254 Val_Acc:  1.5988529192004723\n",
      "Epoch number: 3300/10000step_number: 0/29 Accuracy:  0.9457517452749872 Loss:  1.3396700409272113 Val_accuracy:  0.9246799237265051 Val_cost:  1.3396700409272113 Val_accuracy:  0.9246799237265051 Val_Acc:  1.608102257406531\n",
      "Epoch number: 3301/10000step_number: 0/29 Accuracy:  0.9438787672399115 Loss:  1.3571502415736094 Val_accuracy:  0.9234540997003541 Val_cost:  1.3571502415736094 Val_accuracy:  0.9234540997003541 Val_Acc:  nan\n",
      "Epoch number: 3302/10000step_number: 0/29 Accuracy:  0.9460582325898178 Loss:  1.3201244421976448 Val_accuracy:  0.9248161263960774 Val_cost:  1.3201244421976448 Val_accuracy:  0.9248161263960774 Val_Acc:  nan\n",
      "Epoch number: 3303/10000step_number: 0/29 Accuracy:  0.949054997445939 Loss:  1.3012498661326402 Val_accuracy:  0.9261781530918006 Val_cost:  1.3012498661326402 Val_accuracy:  0.9261781530918006 Val_Acc:  1.5707041204942693\n",
      "Epoch number: 3304/10000step_number: 0/29 Accuracy:  0.9492593223224928 Loss:  1.300131978398867 Val_accuracy:  0.9271315717788069 Val_cost:  1.300131978398867 Val_accuracy:  0.9271315717788069 Val_Acc:  1.5736721763719737\n",
      "Epoch number: 3305/10000step_number: 0/29 Accuracy:  0.9491912140303082 Loss:  1.3001959540336445 Val_accuracy:  0.9260419504222283 Val_cost:  1.3001959540336445 Val_accuracy:  0.9260419504222283 Val_Acc:  1.5726559898436079\n",
      "Epoch number: 3306/10000step_number: 0/29 Accuracy:  0.9489528350076621 Loss:  1.301416953235973 Val_accuracy:  0.9260419504222283 Val_cost:  1.301416953235973 Val_accuracy:  0.9260419504222283 Val_Acc:  1.5743557697571953\n",
      "Epoch number: 3307/10000step_number: 0/29 Accuracy:  0.9484420228162779 Loss:  1.3025605567499348 Val_accuracy:  0.9256333424135113 Val_cost:  1.3025605567499348 Val_accuracy:  0.9256333424135113 Val_Acc:  1.5757442710561866\n",
      "Epoch number: 3308/10000step_number: 0/29 Accuracy:  0.9484760769623701 Loss:  1.302814699327657 Val_accuracy:  0.9256333424135113 Val_cost:  1.302814699327657 Val_accuracy:  0.9256333424135113 Val_Acc:  1.5768939018799781\n",
      "Epoch number: 3309/10000step_number: 0/29 Accuracy:  0.9481695896475396 Loss:  1.3028947835302074 Val_accuracy:  0.925905747752656 Val_cost:  1.3028947835302074 Val_accuracy:  0.925905747752656 Val_Acc:  1.5775148755250659\n",
      "Epoch number: 3310/10000step_number: 0/29 Accuracy:  0.9428571428571428 Loss:  1.3029125820083483 Val_accuracy:  0.9215472623263415 Val_cost:  1.3029125820083483 Val_accuracy:  0.9215472623263415 Val_Acc:  1.5781510017895968\n",
      "Epoch number: 3311/10000step_number: 0/29 Accuracy:  0.9428230887110506 Loss:  1.302906337894962 Val_accuracy:  0.9214110596567693 Val_cost:  1.302906337894962 Val_accuracy:  0.9214110596567693 Val_Acc:  1.5786056839710645\n",
      "Epoch number: 3312/10000step_number: 0/29 Accuracy:  0.9426187638344968 Loss:  1.3029002701264103 Val_accuracy:  0.9212748569871969 Val_cost:  1.3029002701264103 Val_accuracy:  0.9212748569871969 Val_Acc:  1.5790219552615996\n",
      "Epoch number: 3313/10000step_number: 0/29 Accuracy:  0.9424825472501277 Loss:  1.3028572513915189 Val_accuracy:  0.92086624897848 Val_cost:  1.3028572513915189 Val_accuracy:  0.92086624897848 Val_Acc:  1.579341423433994\n",
      "Epoch number: 3314/10000step_number: 0/29 Accuracy:  0.9423122765196663 Loss:  1.3027785783301051 Val_accuracy:  0.9207300463089076 Val_cost:  1.3027785783301051 Val_accuracy:  0.9207300463089076 Val_Acc:  1.5795944138162745\n",
      "Epoch number: 3315/10000step_number: 0/29 Accuracy:  0.9419036267665588 Loss:  1.3026627275500877 Val_accuracy:  0.9205938436393354 Val_cost:  1.3026627275500877 Val_accuracy:  0.9205938436393354 Val_Acc:  1.5797793568824718\n",
      "Epoch number: 3316/10000step_number: 0/29 Accuracy:  0.9418355184743743 Loss:  1.3025195651940613 Val_accuracy:  0.9207300463089076 Val_cost:  1.3025195651940613 Val_accuracy:  0.9207300463089076 Val_Acc:  1.5799178696253289\n",
      "Epoch number: 3317/10000step_number: 0/29 Accuracy:  0.9418014643282819 Loss:  1.3023563672819474 Val_accuracy:  0.92086624897848 Val_cost:  1.3023563672819474 Val_accuracy:  0.92086624897848 Val_Acc:  1.5800219044211996\n",
      "Epoch number: 3318/10000step_number: 0/29 Accuracy:  0.9418355184743743 Loss:  1.3021793620211306 Val_accuracy:  0.9212748569871969 Val_cost:  1.3021793620211306 Val_accuracy:  0.9212748569871969 Val_Acc:  1.58010341863875\n",
      "Epoch number: 3319/10000step_number: 0/29 Accuracy:  0.9418014643282819 Loss:  1.301992583302394 Val_accuracy:  0.9214110596567693 Val_cost:  1.301992583302394 Val_accuracy:  0.9214110596567693 Val_Acc:  1.5801700119352013\n",
      "Epoch number: 3320/10000step_number: 0/29 Accuracy:  0.9418355184743743 Loss:  1.30179883284545 Val_accuracy:  0.9211386543176246 Val_cost:  1.30179883284545 Val_accuracy:  0.9211386543176246 Val_Acc:  1.580227065182865\n",
      "Epoch number: 3321/10000step_number: 0/29 Accuracy:  0.9416311935978205 Loss:  1.3016001537608215 Val_accuracy:  0.9211386543176246 Val_cost:  1.3016001537608215 Val_accuracy:  0.9211386543176246 Val_Acc:  1.5802779343814055\n",
      "Epoch number: 3322/10000step_number: 0/29 Accuracy:  0.9417333560360974 Loss:  1.301398210283291 Val_accuracy:  0.9214110596567693 Val_cost:  1.301398210283291 Val_accuracy:  0.9214110596567693 Val_Acc:  1.5803246260025143\n",
      "Epoch number: 3323/10000step_number: 0/29 Accuracy:  0.9416993018900051 Loss:  1.3011944612921227 Val_accuracy:  0.9214110596567693 Val_cost:  1.3011944612921227 Val_accuracy:  0.9214110596567693 Val_Acc:  1.5803681704754657\n",
      "Epoch number: 3324/10000step_number: 0/29 Accuracy:  0.9409501106759748 Loss:  1.3009902220828011 Val_accuracy:  0.9214110596567693 Val_cost:  1.3009902220828011 Val_accuracy:  0.9214110596567693 Val_Acc:  1.5804090031178175\n",
      "Epoch number: 3325/10000step_number: 0/29 Accuracy:  0.9411544355525285 Loss:  1.3007866833172383 Val_accuracy:  0.9215472623263415 Val_cost:  1.3007866833172383 Val_accuracy:  0.9215472623263415 Val_Acc:  1.5804472483362455\n",
      "Epoch number: 3326/10000step_number: 0/29 Accuracy:  0.9411203814064363 Loss:  1.3005849135713778 Val_accuracy:  0.9216834649959139 Val_cost:  1.3005849135713778 Val_accuracy:  0.9216834649959139 Val_Acc:  1.5804829481186782\n",
      "Epoch number: 3327/10000step_number: 0/29 Accuracy:  0.9411544355525285 Loss:  1.3003858556283874 Val_accuracy:  0.9218196676654863 Val_cost:  1.3003858556283874 Val_accuracy:  0.9218196676654863 Val_Acc:  1.5805162426403077\n",
      "Epoch number: 3328/10000step_number: 0/29 Accuracy:  0.9410522731142517 Loss:  1.3001903243637931 Val_accuracy:  0.9219558703350585 Val_cost:  1.3001903243637931 Val_accuracy:  0.9219558703350585 Val_Acc:  1.5805474604611724\n",
      "Epoch number: 3329/10000step_number: 0/29 Accuracy:  0.9407798399455134 Loss:  1.2999990157054224 Val_accuracy:  0.9219558703350585 Val_cost:  1.2999990157054224 Val_accuracy:  0.9219558703350585 Val_Acc:  1.5805771667225164\n",
      "Epoch number: 3330/10000step_number: 0/29 Accuracy:  0.940745785799421 Loss:  1.2998125284698019 Val_accuracy:  0.9222282756742032 Val_cost:  1.2998125284698019 Val_accuracy:  0.9222282756742032 Val_Acc:  1.5806061320692724\n",
      "Epoch number: 3331/10000step_number: 0/29 Accuracy:  0.940745785799421 Loss:  1.299631389943358 Val_accuracy:  0.9222282756742032 Val_cost:  1.299631389943358 Val_accuracy:  0.9222282756742032 Val_Acc:  1.5806352057765523\n",
      "Epoch number: 3332/10000step_number: 0/29 Accuracy:  0.9406436233611443 Loss:  1.2994560719882415 Val_accuracy:  0.9225006810133478 Val_cost:  1.2994560719882415 Val_accuracy:  0.9225006810133478 Val_Acc:  1.5806652712558837\n",
      "Epoch number: 3333/10000step_number: 0/29 Accuracy:  0.940745785799421 Loss:  1.2992869906046733 Val_accuracy:  0.9222282756742032 Val_cost:  1.2992869906046733 Val_accuracy:  0.9222282756742032 Val_Acc:  1.5806971198948094\n",
      "Epoch number: 3334/10000step_number: 0/29 Accuracy:  0.9408479482376979 Loss:  1.299124492329163 Val_accuracy:  0.9222282756742032 Val_cost:  1.299124492329163 Val_accuracy:  0.9222282756742032 Val_Acc:  1.5807314189745567\n",
      "Epoch number: 3335/10000step_number: 0/29 Accuracy:  0.9406436233611443 Loss:  1.2989688372524582 Val_accuracy:  0.9222282756742032 Val_cost:  1.2989688372524582 Val_accuracy:  0.9222282756742032 Val_Acc:  1.5807686510282482\n",
      "Epoch number: 3336/10000step_number: 0/29 Accuracy:  0.9407798399455134 Loss:  1.2988201878139944 Val_accuracy:  0.9223644783437756 Val_cost:  1.2988201878139944 Val_accuracy:  0.9223644783437756 Val_Acc:  1.5808091471087433\n",
      "Epoch number: 3337/10000step_number: 0/29 Accuracy:  0.9408820023837903 Loss:  1.2986786077455674 Val_accuracy:  0.9222282756742032 Val_cost:  1.2986786077455674 Val_accuracy:  0.9222282756742032 Val_Acc:  1.5808530776417187\n",
      "Epoch number: 3338/10000step_number: 0/29 Accuracy:  0.940745785799421 Loss:  1.2985440707596319 Val_accuracy:  0.9222282756742032 Val_cost:  1.2985440707596319 Val_accuracy:  0.9222282756742032 Val_Acc:  1.5809004731680087\n",
      "Epoch number: 3339/10000step_number: 0/29 Accuracy:  0.9406095692150519 Loss:  1.298416475929169 Val_accuracy:  0.9223644783437756 Val_cost:  1.298416475929169 Val_accuracy:  0.9223644783437756 Val_Acc:  1.5809512617321093\n",
      "Epoch number: 3340/10000step_number: 0/29 Accuracy:  0.9406095692150519 Loss:  1.2982956661556475 Val_accuracy:  0.9225006810133478 Val_cost:  1.2982956661556475 Val_accuracy:  0.9225006810133478 Val_Acc:  1.581005273426866\n",
      "Epoch number: 3341/10000step_number: 0/29 Accuracy:  0.9406095692150519 Loss:  1.2981814467730692 Val_accuracy:  0.9225006810133478 Val_cost:  1.2981814467730692 Val_accuracy:  0.9225006810133478 Val_Acc:  1.5810622837367647\n",
      "Epoch number: 3342/10000step_number: 0/29 Accuracy:  0.9400647028775754 Loss:  1.298073602369613 Val_accuracy:  0.9216834649959139 Val_cost:  1.298073602369613 Val_accuracy:  0.9216834649959139 Val_Acc:  1.5811220279506897\n",
      "Epoch number: 3343/10000step_number: 0/29 Accuracy:  0.940030648731483 Loss:  1.2979719108547811 Val_accuracy:  0.9215472623263415 Val_cost:  1.2979719108547811 Val_accuracy:  0.9215472623263415 Val_Acc:  1.5811842198972474\n",
      "Epoch number: 3344/10000step_number: 0/29 Accuracy:  0.9399284862932062 Loss:  1.2978761544778872 Val_accuracy:  0.9216834649959139 Val_cost:  1.2978761544778872 Val_accuracy:  0.9216834649959139 Val_Acc:  1.5812485552941646\n",
      "Epoch number: 3345/10000step_number: 0/29 Accuracy:  0.940030648731483 Loss:  1.2977861278972196 Val_accuracy:  0.9216834649959139 Val_cost:  1.2977861278972196 Val_accuracy:  0.9216834649959139 Val_Acc:  1.5813147552169082\n",
      "Epoch number: 3346/10000step_number: 0/29 Accuracy:  0.9403030819002214 Loss:  1.2977016435701756 Val_accuracy:  0.9218196676654863 Val_cost:  1.2977016435701756 Val_accuracy:  0.9218196676654863 Val_Acc:  1.581382533173288\n",
      "Epoch number: 3347/10000step_number: 0/29 Accuracy:  0.9404052443384983 Loss:  1.2976225347714136 Val_accuracy:  0.9218196676654863 Val_cost:  1.2976225347714136 Val_accuracy:  0.9218196676654863 Val_Acc:  1.5814516495434883\n",
      "Epoch number: 3348/10000step_number: 0/29 Accuracy:  0.9402349736080368 Loss:  1.2975486565300791 Val_accuracy:  0.9215472623263415 Val_cost:  1.2975486565300791 Val_accuracy:  0.9215472623263415 Val_Acc:  nan\n",
      "Epoch number: 3349/10000step_number: 0/29 Accuracy:  0.940269027754129 Loss:  1.2974798847630213 Val_accuracy:  0.9212748569871969 Val_cost:  1.2974798847630213 Val_accuracy:  0.9212748569871969 Val_Acc:  nan\n",
      "Epoch number: 3350/10000step_number: 0/29 Accuracy:  0.9403030819002214 Loss:  1.2974161138882865 Val_accuracy:  0.9214110596567693 Val_cost:  1.2974161138882865 Val_accuracy:  0.9214110596567693 Val_Acc:  nan\n",
      "Epoch number: 3351/10000step_number: 0/29 Accuracy:  0.9404052443384983 Loss:  1.297357253224256 Val_accuracy:  0.9215472623263415 Val_cost:  1.297357253224256 Val_accuracy:  0.9215472623263415 Val_Acc:  nan\n",
      "Epoch number: 3352/10000step_number: 0/29 Accuracy:  0.9403711901924059 Loss:  1.2973032224953258 Val_accuracy:  0.9216834649959139 Val_cost:  1.2973032224953258 Val_accuracy:  0.9216834649959139 Val_Acc:  nan\n",
      "Epoch number: 3353/10000step_number: 0/29 Accuracy:  0.9404052443384983 Loss:  1.2972539467599444 Val_accuracy:  0.9216834649959139 Val_cost:  1.2972539467599444 Val_accuracy:  0.9216834649959139 Val_Acc:  nan\n",
      "Epoch number: 3354/10000step_number: 0/29 Accuracy:  0.9404052443384983 Loss:  1.2972093510481724 Val_accuracy:  0.9218196676654863 Val_cost:  1.2972093510481724 Val_accuracy:  0.9218196676654863 Val_Acc:  nan\n",
      "Epoch number: 3355/10000step_number: 0/29 Accuracy:  0.9404392984845905 Loss:  1.2971693549510583 Val_accuracy:  0.9218196676654863 Val_cost:  1.2971693549510583 Val_accuracy:  0.9218196676654863 Val_Acc:  nan\n",
      "Epoch number: 3356/10000step_number: 0/29 Accuracy:  0.9405755150689596 Loss:  1.2971338673558281 Val_accuracy:  0.9216834649959139 Val_cost:  1.2971338673558281 Val_accuracy:  0.9216834649959139 Val_Acc:  nan\n",
      "Epoch number: 3357/10000step_number: 0/29 Accuracy:  0.9406776775072365 Loss:  1.2971027814804639 Val_accuracy:  0.9218196676654863 Val_cost:  1.2971027814804639 Val_accuracy:  0.9218196676654863 Val_Acc:  nan\n",
      "Epoch number: 3358/10000step_number: 0/29 Accuracy:  0.9405755150689596 Loss:  1.2970759703358554 Val_accuracy:  0.9218196676654863 Val_cost:  1.2970759703358554 Val_accuracy:  0.9218196676654863 Val_Acc:  nan\n",
      "Epoch number: 3359/10000step_number: 0/29 Accuracy:  0.9405755150689596 Loss:  1.2970532827340435 Val_accuracy:  0.9218196676654863 Val_cost:  1.2970532827340435 Val_accuracy:  0.9218196676654863 Val_Acc:  nan\n",
      "Epoch number: 3360/10000step_number: 0/29 Accuracy:  0.9405414609228674 Loss:  1.2970345399619554 Val_accuracy:  0.9216834649959139 Val_cost:  1.2970345399619554 Val_accuracy:  0.9216834649959139 Val_Acc:  nan\n",
      "Epoch number: 3361/10000step_number: 0/29 Accuracy:  0.940507406776775 Loss:  1.297019533241801 Val_accuracy:  0.9218196676654863 Val_cost:  1.297019533241801 Val_accuracy:  0.9218196676654863 Val_Acc:  nan\n",
      "Epoch number: 3362/10000step_number: 0/29 Accuracy:  0.9406095692150519 Loss:  1.2970080220900775 Val_accuracy:  0.9216834649959139 Val_cost:  1.2970080220900775 Val_accuracy:  0.9216834649959139 Val_Acc:  nan\n",
      "Epoch number: 3363/10000step_number: 0/29 Accuracy:  0.9405755150689596 Loss:  1.296999733656444 Val_accuracy:  0.9216834649959139 Val_cost:  1.296999733656444 Val_accuracy:  0.9216834649959139 Val_Acc:  nan\n",
      "Epoch number: 3364/10000step_number: 0/29 Accuracy:  0.9405755150689596 Loss:  1.2969943630658431 Val_accuracy:  0.9218196676654863 Val_cost:  1.2969943630658431 Val_accuracy:  0.9218196676654863 Val_Acc:  nan\n",
      "Epoch number: 3365/10000step_number: 0/29 Accuracy:  0.9407117316533288 Loss:  1.2969915747050185 Val_accuracy:  0.9218196676654863 Val_cost:  1.2969915747050185 Val_accuracy:  0.9218196676654863 Val_Acc:  nan\n",
      "Epoch number: 3366/10000step_number: 0/29 Accuracy:  0.9405414609228674 Loss:  1.2969910043040134 Val_accuracy:  0.9218196676654863 Val_cost:  1.2969910043040134 Val_accuracy:  0.9218196676654863 Val_Acc:  nan\n",
      "Epoch number: 3367/10000step_number: 0/29 Accuracy:  0.9405414609228674 Loss:  1.2969922616007274 Val_accuracy:  0.9219558703350585 Val_cost:  1.2969922616007274 Val_accuracy:  0.9219558703350585 Val_Acc:  nan\n",
      "Epoch number: 3368/10000step_number: 0/29 Accuracy:  0.940745785799421 Loss:  1.2969949334161746 Val_accuracy:  0.9223644783437756 Val_cost:  1.2969949334161746 Val_accuracy:  0.9223644783437756 Val_Acc:  nan\n",
      "Epoch number: 3369/10000step_number: 0/29 Accuracy:  0.940745785799421 Loss:  1.296998587260346 Val_accuracy:  0.9225006810133478 Val_cost:  1.296998587260346 Val_accuracy:  0.9225006810133478 Val_Acc:  nan\n",
      "Epoch number: 3370/10000step_number: 0/29 Accuracy:  0.940745785799421 Loss:  1.2970027764406533 Val_accuracy:  0.9225006810133478 Val_cost:  1.2970027764406533 Val_accuracy:  0.9225006810133478 Val_Acc:  nan\n",
      "Epoch number: 3371/10000step_number: 0/29 Accuracy:  0.9406776775072365 Loss:  1.2970070496367136 Val_accuracy:  0.9225006810133478 Val_cost:  1.2970070496367136 Val_accuracy:  0.9225006810133478 Val_Acc:  nan\n",
      "Epoch number: 3372/10000step_number: 0/29 Accuracy:  0.9406436233611443 Loss:  1.2970109718511107 Val_accuracy:  0.9226368836829202 Val_cost:  1.2970109718511107 Val_accuracy:  0.9226368836829202 Val_Acc:  nan\n",
      "Epoch number: 3373/10000step_number: 0/29 Accuracy:  0.9406436233611443 Loss:  1.2970141694607227 Val_accuracy:  0.9226368836829202 Val_cost:  1.2970141694607227 Val_accuracy:  0.9226368836829202 Val_Acc:  nan\n",
      "Epoch number: 3374/10000step_number: 0/29 Accuracy:  0.9406436233611443 Loss:  1.2970164140226084 Val_accuracy:  0.9226368836829202 Val_cost:  1.2970164140226084 Val_accuracy:  0.9226368836829202 Val_Acc:  nan\n",
      "Epoch number: 3375/10000step_number: 0/29 Accuracy:  0.9406776775072365 Loss:  1.2970177369153297 Val_accuracy:  0.9226368836829202 Val_cost:  1.2970177369153297 Val_accuracy:  0.9226368836829202 Val_Acc:  nan\n",
      "Epoch number: 3376/10000step_number: 0/29 Accuracy:  0.9407798399455134 Loss:  1.2970184935930043 Val_accuracy:  0.9225006810133478 Val_cost:  1.2970184935930043 Val_accuracy:  0.9225006810133478 Val_Acc:  nan\n",
      "Epoch number: 3377/10000step_number: 0/29 Accuracy:  0.9408138940916057 Loss:  1.2970192272211332 Val_accuracy:  0.9226368836829202 Val_cost:  1.2970192272211332 Val_accuracy:  0.9226368836829202 Val_Acc:  nan\n",
      "Epoch number: 3378/10000step_number: 0/29 Accuracy:  0.9407798399455134 Loss:  1.2970203188025375 Val_accuracy:  0.9226368836829202 Val_cost:  1.2970203188025375 Val_accuracy:  0.9226368836829202 Val_Acc:  nan\n",
      "Epoch number: 3379/10000step_number: 0/29 Accuracy:  0.9408820023837903 Loss:  1.2970217319705513 Val_accuracy:  0.9227730863524926 Val_cost:  1.2970217319705513 Val_accuracy:  0.9227730863524926 Val_Acc:  nan\n",
      "Epoch number: 3380/10000step_number: 0/29 Accuracy:  0.9407798399455134 Loss:  1.297023110545842 Val_accuracy:  0.9225006810133478 Val_cost:  1.297023110545842 Val_accuracy:  0.9225006810133478 Val_Acc:  nan\n",
      "Epoch number: 3381/10000step_number: 0/29 Accuracy:  0.9407798399455134 Loss:  1.2970240281464462 Val_accuracy:  0.9226368836829202 Val_cost:  1.2970240281464462 Val_accuracy:  0.9226368836829202 Val_Acc:  nan\n",
      "Epoch number: 3382/10000step_number: 0/29 Accuracy:  0.9408820023837903 Loss:  1.2970241127751738 Val_accuracy:  0.9227730863524926 Val_cost:  1.2970241127751738 Val_accuracy:  0.9227730863524926 Val_Acc:  nan\n",
      "Epoch number: 3383/10000step_number: 0/29 Accuracy:  0.940984164822067 Loss:  1.297023062091846 Val_accuracy:  0.9227730863524926 Val_cost:  1.297023062091846 Val_accuracy:  0.9227730863524926 Val_Acc:  nan\n",
      "Epoch number: 3384/10000step_number: 0/29 Accuracy:  0.9409160565298825 Loss:  1.2970206402892532 Val_accuracy:  0.9226368836829202 Val_cost:  1.2970206402892532 Val_accuracy:  0.9226368836829202 Val_Acc:  nan\n",
      "Epoch number: 3385/10000step_number: 0/29 Accuracy:  0.940984164822067 Loss:  1.297016671934188 Val_accuracy:  0.9225006810133478 Val_cost:  1.297016671934188 Val_accuracy:  0.9225006810133478 Val_Acc:  nan\n",
      "Epoch number: 3386/10000step_number: 0/29 Accuracy:  0.940984164822067 Loss:  1.2970110315396095 Val_accuracy:  0.9225006810133478 Val_cost:  1.2970110315396095 Val_accuracy:  0.9225006810133478 Val_Acc:  nan\n",
      "Epoch number: 3387/10000step_number: 0/29 Accuracy:  0.9410863272603439 Loss:  1.2970036329406731 Val_accuracy:  0.9226368836829202 Val_cost:  1.2970036329406731 Val_accuracy:  0.9226368836829202 Val_Acc:  nan\n",
      "Epoch number: 3388/10000step_number: 0/29 Accuracy:  0.9410522731142517 Loss:  1.2969944212619247 Val_accuracy:  0.9223644783437756 Val_cost:  1.2969944212619247 Val_accuracy:  0.9223644783437756 Val_Acc:  nan\n",
      "Epoch number: 3389/10000step_number: 0/29 Accuracy:  0.9410522731142517 Loss:  1.2969833676191949 Val_accuracy:  0.9225006810133478 Val_cost:  1.2969833676191949 Val_accuracy:  0.9225006810133478 Val_Acc:  nan\n",
      "Epoch number: 3390/10000step_number: 0/29 Accuracy:  0.9407798399455134 Loss:  1.2969704655581715 Val_accuracy:  0.9227730863524926 Val_cost:  1.2969704655581715 Val_accuracy:  0.9227730863524926 Val_Acc:  nan\n",
      "Epoch number: 3391/10000step_number: 0/29 Accuracy:  0.9407798399455134 Loss:  1.2969557284659792 Val_accuracy:  0.9227730863524926 Val_cost:  1.2969557284659792 Val_accuracy:  0.9227730863524926 Val_Acc:  nan\n",
      "Epoch number: 3392/10000step_number: 0/29 Accuracy:  0.9408479482376979 Loss:  1.2969391875287575 Val_accuracy:  0.9227730863524926 Val_cost:  1.2969391875287575 Val_accuracy:  0.9227730863524926 Val_Acc:  nan\n",
      "Epoch number: 3393/10000step_number: 0/29 Accuracy:  0.9408820023837903 Loss:  1.2969208899340519 Val_accuracy:  0.9227730863524926 Val_cost:  1.2969208899340519 Val_accuracy:  0.9227730863524926 Val_Acc:  nan\n",
      "Epoch number: 3394/10000step_number: 0/29 Accuracy:  0.9410182189681594 Loss:  1.2969008970901332 Val_accuracy:  0.9229092890220648 Val_cost:  1.2969008970901332 Val_accuracy:  0.9229092890220648 Val_Acc:  nan\n",
      "Epoch number: 3395/10000step_number: 0/29 Accuracy:  0.9410522731142517 Loss:  1.2968792827226379 Val_accuracy:  0.9229092890220648 Val_cost:  1.2968792827226379 Val_accuracy:  0.9229092890220648 Val_Acc:  nan\n",
      "Epoch number: 3396/10000step_number: 0/29 Accuracy:  0.9399625404392985 Loss:  1.2968561307942272 Val_accuracy:  0.9212748569871969 Val_cost:  1.2968561307942272 Val_accuracy:  0.9212748569871969 Val_Acc:  nan\n",
      "Epoch number: 3397/10000step_number: 0/29 Accuracy:  0.9398603780010216 Loss:  1.296831533259715 Val_accuracy:  0.9214110596567693 Val_cost:  1.296831533259715 Val_accuracy:  0.9214110596567693 Val_Acc:  nan\n",
      "Epoch number: 3398/10000step_number: 0/29 Accuracy:  0.9398603780010216 Loss:  1.2968055877102493 Val_accuracy:  0.9220920730046309 Val_cost:  1.2968055877102493 Val_accuracy:  0.9220920730046309 Val_Acc:  nan\n",
      "Epoch number: 3399/10000step_number: 0/29 Accuracy:  0.9396901072705602 Loss:  1.2967783949746978 Val_accuracy:  0.9220920730046309 Val_cost:  1.2967783949746978 Val_accuracy:  0.9220920730046309 Val_Acc:  nan\n",
      "Epoch number: 3400/10000step_number: 0/29 Accuracy:  0.9395879448322834 Loss:  1.2967500567449886 Val_accuracy:  0.9218196676654863 Val_cost:  1.2967500567449886 Val_accuracy:  0.9218196676654863 Val_Acc:  nan\n",
      "Epoch number: 3401/10000step_number: 0/29 Accuracy:  0.9395879448322834 Loss:  1.2967206732872012 Val_accuracy:  0.9219558703350585 Val_cost:  1.2967206732872012 Val_accuracy:  0.9219558703350585 Val_Acc:  nan\n",
      "Epoch number: 3402/10000step_number: 0/29 Accuracy:  0.9394857823940065 Loss:  1.2966903412988509 Val_accuracy:  0.9218196676654863 Val_cost:  1.2966903412988509 Val_accuracy:  0.9218196676654863 Val_Acc:  nan\n",
      "Epoch number: 3403/10000step_number: 0/29 Accuracy:  0.9394517282479142 Loss:  1.2966591519755906 Val_accuracy:  0.9216834649959139 Val_cost:  1.2966591519755906 Val_accuracy:  0.9216834649959139 Val_Acc:  nan\n",
      "Epoch number: 3404/10000step_number: 0/29 Accuracy:  0.9394176741018219 Loss:  1.2966271893532488 Val_accuracy:  0.9216834649959139 Val_cost:  1.2966271893532488 Val_accuracy:  0.9216834649959139 Val_Acc:  nan\n",
      "Epoch number: 3405/10000step_number: 0/29 Accuracy:  0.9394857823940065 Loss:  1.296594528987313 Val_accuracy:  0.9215472623263415 Val_cost:  1.296594528987313 Val_accuracy:  0.9215472623263415 Val_Acc:  nan\n",
      "Epoch number: 3406/10000step_number: 0/29 Accuracy:  0.9395879448322834 Loss:  1.296561237017478 Val_accuracy:  0.9215472623263415 Val_cost:  1.296561237017478 Val_accuracy:  0.9215472623263415 Val_Acc:  nan\n",
      "Epoch number: 3407/10000step_number: 0/29 Accuracy:  0.9396560531244679 Loss:  1.2965273696386885 Val_accuracy:  0.9214110596567693 Val_cost:  1.2965273696386885 Val_accuracy:  0.9214110596567693 Val_Acc:  nan\n",
      "Epoch number: 3408/10000step_number: 0/29 Accuracy:  0.9395879448322834 Loss:  1.2964929729662014 Val_accuracy:  0.9212748569871969 Val_cost:  1.2964929729662014 Val_accuracy:  0.9212748569871969 Val_Acc:  nan\n",
      "Epoch number: 3409/10000step_number: 0/29 Accuracy:  0.9395879448322834 Loss:  1.2964580832475168 Val_accuracy:  0.9214110596567693 Val_cost:  1.2964580832475168 Val_accuracy:  0.9214110596567693 Val_Acc:  nan\n",
      "Epoch number: 3410/10000step_number: 0/29 Accuracy:  0.939553890686191 Loss:  1.2964227273473845 Val_accuracy:  0.9215472623263415 Val_cost:  1.2964227273473845 Val_accuracy:  0.9215472623263415 Val_Acc:  nan\n",
      "Epoch number: 3411/10000step_number: 0/29 Accuracy:  0.9394857823940065 Loss:  1.296386923421221 Val_accuracy:  0.9215472623263415 Val_cost:  1.296386923421221 Val_accuracy:  0.9215472623263415 Val_Acc:  nan\n",
      "Epoch number: 3412/10000step_number: 0/29 Accuracy:  0.9395198365400987 Loss:  1.2963506817022423 Val_accuracy:  0.9215472623263415 Val_cost:  1.2963506817022423 Val_accuracy:  0.9215472623263415 Val_Acc:  nan\n",
      "Epoch number: 3413/10000step_number: 0/29 Accuracy:  0.9395198365400987 Loss:  1.2963140053593485 Val_accuracy:  0.9216834649959139 Val_cost:  1.2963140053593485 Val_accuracy:  0.9216834649959139 Val_Acc:  nan\n",
      "Epoch number: 3414/10000step_number: 0/29 Accuracy:  0.9394857823940065 Loss:  1.2962768914335188 Val_accuracy:  0.9216834649959139 Val_cost:  1.2962768914335188 Val_accuracy:  0.9216834649959139 Val_Acc:  nan\n",
      "Epoch number: 3415/10000step_number: 0/29 Accuracy:  0.9394517282479142 Loss:  1.296239331923642 Val_accuracy:  0.9216834649959139 Val_cost:  1.296239331923642 Val_accuracy:  0.9216834649959139 Val_Acc:  nan\n",
      "Epoch number: 3416/10000step_number: 0/29 Accuracy:  0.9394517282479142 Loss:  1.2962013151586267 Val_accuracy:  0.9218196676654863 Val_cost:  1.2962013151586267 Val_accuracy:  0.9218196676654863 Val_Acc:  nan\n",
      "Epoch number: 3417/10000step_number: 0/29 Accuracy:  0.9394176741018219 Loss:  1.2961628276471129 Val_accuracy:  0.9215472623263415 Val_cost:  1.2961628276471129 Val_accuracy:  0.9215472623263415 Val_Acc:  nan\n",
      "Epoch number: 3418/10000step_number: 0/29 Accuracy:  0.9394176741018219 Loss:  1.2961238566182531 Val_accuracy:  0.9215472623263415 Val_cost:  1.2961238566182531 Val_accuracy:  0.9215472623263415 Val_Acc:  nan\n",
      "Epoch number: 3419/10000step_number: 0/29 Accuracy:  0.9394517282479142 Loss:  1.296084393426826 Val_accuracy:  0.9216834649959139 Val_cost:  1.296084393426826 Val_accuracy:  0.9216834649959139 Val_Acc:  nan\n",
      "Epoch number: 3420/10000step_number: 0/29 Accuracy:  0.9393495658096374 Loss:  1.2960444378541163 Val_accuracy:  0.9218196676654863 Val_cost:  1.2960444378541163 Val_accuracy:  0.9218196676654863 Val_Acc:  nan\n",
      "Epoch number: 3421/10000step_number: 0/29 Accuracy:  0.9393836199557296 Loss:  1.296004003052192 Val_accuracy:  0.9216834649959139 Val_cost:  1.296004003052192 Val_accuracy:  0.9216834649959139 Val_Acc:  nan\n",
      "Epoch number: 3422/10000step_number: 0/29 Accuracy:  0.9393836199557296 Loss:  1.295963120431527 Val_accuracy:  0.9219558703350585 Val_cost:  1.295963120431527 Val_accuracy:  0.9219558703350585 Val_Acc:  nan\n",
      "Epoch number: 3423/10000step_number: 0/29 Accuracy:  0.9391792950791759 Loss:  1.2959218432193247 Val_accuracy:  0.9215472623263415 Val_cost:  1.2959218432193247 Val_accuracy:  0.9215472623263415 Val_Acc:  nan\n",
      "Epoch number: 3424/10000step_number: 0/29 Accuracy:  0.9391792950791759 Loss:  1.2958802468730082 Val_accuracy:  0.9215472623263415 Val_cost:  1.2958802468730082 Val_accuracy:  0.9215472623263415 Val_Acc:  nan\n",
      "Epoch number: 3425/10000step_number: 0/29 Accuracy:  0.9391452409330836 Loss:  1.2958384243448104 Val_accuracy:  0.9214110596567693 Val_cost:  1.2958384243448104 Val_accuracy:  0.9214110596567693 Val_Acc:  nan\n",
      "Epoch number: 3426/10000step_number: 0/29 Accuracy:  0.939077132640899 Loss:  1.2957964748159045 Val_accuracy:  0.9212748569871969 Val_cost:  1.2957964748159045 Val_accuracy:  0.9212748569871969 Val_Acc:  nan\n",
      "Epoch number: 3427/10000step_number: 0/29 Accuracy:  0.9391792950791759 Loss:  1.295754486322062 Val_accuracy:  0.9212748569871969 Val_cost:  1.295754486322062 Val_accuracy:  0.9212748569871969 Val_Acc:  nan\n",
      "Epoch number: 3428/10000step_number: 0/29 Accuracy:  0.9390090243487145 Loss:  1.295712515497179 Val_accuracy:  0.9212748569871969 Val_cost:  1.295712515497179 Val_accuracy:  0.9212748569871969 Val_Acc:  nan\n",
      "Epoch number: 3429/10000step_number: 0/29 Accuracy:  0.9389749702026222 Loss:  1.2956705703404237 Val_accuracy:  0.9212748569871969 Val_cost:  1.2956705703404237 Val_accuracy:  0.9212748569871969 Val_Acc:  nan\n",
      "Epoch number: 3430/10000step_number: 0/29 Accuracy:  0.9389749702026222 Loss:  1.2956286026230774 Val_accuracy:  0.9212748569871969 Val_cost:  1.2956286026230774 Val_accuracy:  0.9212748569871969 Val_Acc:  nan\n",
      "Epoch number: 3431/10000step_number: 0/29 Accuracy:  0.9389409160565299 Loss:  1.295586514015845 Val_accuracy:  0.9212748569871969 Val_cost:  1.295586514015845 Val_accuracy:  0.9212748569871969 Val_Acc:  nan\n",
      "Epoch number: 3432/10000step_number: 0/29 Accuracy:  0.9390430784948067 Loss:  1.295544174962607 Val_accuracy:  0.9212748569871969 Val_cost:  1.295544174962607 Val_accuracy:  0.9212748569871969 Val_Acc:  nan\n",
      "Epoch number: 3433/10000step_number: 0/29 Accuracy:  0.9389409160565299 Loss:  1.295501450481012 Val_accuracy:  0.9212748569871969 Val_cost:  1.295501450481012 Val_accuracy:  0.9212748569871969 Val_Acc:  nan\n",
      "Epoch number: 3434/10000step_number: 0/29 Accuracy:  0.9390090243487145 Loss:  1.2954582250647086 Val_accuracy:  0.9212748569871969 Val_cost:  1.2954582250647086 Val_accuracy:  0.9212748569871969 Val_Acc:  nan\n",
      "Epoch number: 3435/10000step_number: 0/29 Accuracy:  0.9389409160565299 Loss:  1.2954144201755013 Val_accuracy:  0.9212748569871969 Val_cost:  1.2954144201755013 Val_accuracy:  0.9212748569871969 Val_Acc:  nan\n",
      "Epoch number: 3436/10000step_number: 0/29 Accuracy:  0.9390430784948067 Loss:  1.295370000770055 Val_accuracy:  0.9211386543176246 Val_cost:  1.295370000770055 Val_accuracy:  0.9211386543176246 Val_Acc:  nan\n",
      "Epoch number: 3437/10000step_number: 0/29 Accuracy:  0.9390430784948067 Loss:  1.2953249700364475 Val_accuracy:  0.9211386543176246 Val_cost:  1.2953249700364475 Val_accuracy:  0.9211386543176246 Val_Acc:  nan\n",
      "Epoch number: 3438/10000step_number: 0/29 Accuracy:  0.9389749702026222 Loss:  1.2952793535296352 Val_accuracy:  0.9210024516480523 Val_cost:  1.2952793535296352 Val_accuracy:  0.9210024516480523 Val_Acc:  nan\n",
      "Epoch number: 3439/10000step_number: 0/29 Accuracy:  0.9389409160565299 Loss:  1.2952331764415577 Val_accuracy:  0.9211386543176246 Val_cost:  1.2952331764415577 Val_accuracy:  0.9211386543176246 Val_Acc:  nan\n",
      "Epoch number: 3440/10000step_number: 0/29 Accuracy:  0.9389749702026222 Loss:  1.2951864426939483 Val_accuracy:  0.9211386543176246 Val_cost:  1.2951864426939483 Val_accuracy:  0.9211386543176246 Val_Acc:  nan\n",
      "Epoch number: 3441/10000step_number: 0/29 Accuracy:  0.9391792950791759 Loss:  1.2951391315062097 Val_accuracy:  0.92086624897848 Val_cost:  1.2951391315062097 Val_accuracy:  0.92086624897848 Val_Acc:  nan\n",
      "Epoch number: 3442/10000step_number: 0/29 Accuracy:  0.9391111867869913 Loss:  1.2950912278237856 Val_accuracy:  0.92086624897848 Val_cost:  1.2950912278237856 Val_accuracy:  0.92086624897848 Val_Acc:  nan\n",
      "Epoch number: 3443/10000step_number: 0/29 Accuracy:  0.9391452409330836 Loss:  1.295042782488391 Val_accuracy:  0.92086624897848 Val_cost:  1.295042782488391 Val_accuracy:  0.92086624897848 Val_Acc:  nan\n",
      "Epoch number: 3444/10000step_number: 0/29 Accuracy:  0.9391111867869913 Loss:  1.2949939612703811 Val_accuracy:  0.9207300463089076 Val_cost:  1.2949939612703811 Val_accuracy:  0.9207300463089076 Val_Acc:  nan\n",
      "Epoch number: 3445/10000step_number: 0/29 Accuracy:  0.9391111867869913 Loss:  1.2949450367789366 Val_accuracy:  0.9205938436393354 Val_cost:  1.2949450367789366 Val_accuracy:  0.9205938436393354 Val_Acc:  nan\n",
      "Epoch number: 3446/10000step_number: 0/29 Accuracy:  0.9392814575174527 Loss:  1.294896328380261 Val_accuracy:  0.9210024516480523 Val_cost:  1.294896328380261 Val_accuracy:  0.9210024516480523 Val_Acc:  nan\n",
      "Epoch number: 3447/10000step_number: 0/29 Accuracy:  0.939315511663545 Loss:  1.2948481389188335 Val_accuracy:  0.9211386543176246 Val_cost:  1.2948481389188335 Val_accuracy:  0.9211386543176246 Val_Acc:  nan\n",
      "Epoch number: 3448/10000step_number: 0/29 Accuracy:  0.9393836199557296 Loss:  1.2948007224297016 Val_accuracy:  0.9211386543176246 Val_cost:  1.2948007224297016 Val_accuracy:  0.9211386543176246 Val_Acc:  nan\n",
      "Epoch number: 3449/10000step_number: 0/29 Accuracy:  0.9393836199557296 Loss:  1.294754281759529 Val_accuracy:  0.9210024516480523 Val_cost:  1.294754281759529 Val_accuracy:  0.9210024516480523 Val_Acc:  nan\n",
      "Epoch number: 3450/10000step_number: 0/29 Accuracy:  0.9391452409330836 Loss:  1.2947089810294357 Val_accuracy:  0.9207300463089076 Val_cost:  1.2947089810294357 Val_accuracy:  0.9207300463089076 Val_Acc:  nan\n",
      "Epoch number: 3451/10000step_number: 0/29 Accuracy:  0.9391792950791759 Loss:  1.2946649694750958 Val_accuracy:  0.9207300463089076 Val_cost:  1.2946649694750958 Val_accuracy:  0.9207300463089076 Val_Acc:  nan\n",
      "Epoch number: 3452/10000step_number: 0/29 Accuracy:  0.9391792950791759 Loss:  1.2946224353591025 Val_accuracy:  0.9205938436393354 Val_cost:  1.2946224353591025 Val_accuracy:  0.9205938436393354 Val_Acc:  nan\n",
      "Epoch number: 3453/10000step_number: 0/29 Accuracy:  0.9392133492252682 Loss:  1.2945816733810203 Val_accuracy:  0.920457640969763 Val_cost:  1.2945816733810203 Val_accuracy:  0.920457640969763 Val_Acc:  nan\n",
      "Epoch number: 3454/10000step_number: 0/29 Accuracy:  0.939315511663545 Loss:  1.294543032311934 Val_accuracy:  0.920457640969763 Val_cost:  1.294543032311934 Val_accuracy:  0.920457640969763 Val_Acc:  nan\n",
      "Epoch number: 3455/10000step_number: 0/29 Accuracy:  0.9394517282479142 Loss:  1.2945067213186958 Val_accuracy:  0.920457640969763 Val_cost:  1.2945067213186958 Val_accuracy:  0.920457640969763 Val_Acc:  nan\n",
      "Epoch number: 3456/10000step_number: 0/29 Accuracy:  0.9394517282479142 Loss:  1.2944727620401368 Val_accuracy:  0.9207300463089076 Val_cost:  1.2944727620401368 Val_accuracy:  0.9207300463089076 Val_Acc:  nan\n",
      "Epoch number: 3457/10000step_number: 0/29 Accuracy:  0.9394857823940065 Loss:  1.2944411476924824 Val_accuracy:  0.9207300463089076 Val_cost:  1.2944411476924824 Val_accuracy:  0.9207300463089076 Val_Acc:  nan\n",
      "Epoch number: 3458/10000step_number: 0/29 Accuracy:  0.939553890686191 Loss:  1.294411935855725 Val_accuracy:  0.9207300463089076 Val_cost:  1.294411935855725 Val_accuracy:  0.9207300463089076 Val_Acc:  nan\n",
      "Epoch number: 3459/10000step_number: 0/29 Accuracy:  0.9395879448322834 Loss:  1.2943852313289945 Val_accuracy:  0.9207300463089076 Val_cost:  1.2943852313289945 Val_accuracy:  0.9207300463089076 Val_Acc:  nan\n",
      "Epoch number: 3460/10000step_number: 0/29 Accuracy:  0.939553890686191 Loss:  1.2943611846105487 Val_accuracy:  0.920457640969763 Val_cost:  1.2943611846105487 Val_accuracy:  0.920457640969763 Val_Acc:  nan\n",
      "Epoch number: 3461/10000step_number: 0/29 Accuracy:  0.9396901072705602 Loss:  1.2943400127119673 Val_accuracy:  0.9207300463089076 Val_cost:  1.2943400127119673 Val_accuracy:  0.9207300463089076 Val_Acc:  nan\n",
      "Epoch number: 3462/10000step_number: 0/29 Accuracy:  0.939792269708837 Loss:  1.2943219890454958 Val_accuracy:  0.92086624897848 Val_cost:  1.2943219890454958 Val_accuracy:  0.92086624897848 Val_Acc:  nan\n",
      "Epoch number: 3463/10000step_number: 0/29 Accuracy:  0.9399625404392985 Loss:  1.2943074290127383 Val_accuracy:  0.9207300463089076 Val_cost:  1.2943074290127383 Val_accuracy:  0.9207300463089076 Val_Acc:  nan\n",
      "Epoch number: 3464/10000step_number: 0/29 Accuracy:  0.9399625404392985 Loss:  1.2942967068458648 Val_accuracy:  0.92086624897848 Val_cost:  1.2942967068458648 Val_accuracy:  0.92086624897848 Val_Acc:  nan\n",
      "Epoch number: 3465/10000step_number: 0/29 Accuracy:  0.9400987570236676 Loss:  1.2942902891848662 Val_accuracy:  0.92086624897848 Val_cost:  1.2942902891848662 Val_accuracy:  0.92086624897848 Val_Acc:  nan\n",
      "Epoch number: 3466/10000step_number: 0/29 Accuracy:  0.940269027754129 Loss:  1.2942887418143203 Val_accuracy:  0.9210024516480523 Val_cost:  1.2942887418143203 Val_accuracy:  0.9210024516480523 Val_Acc:  nan\n",
      "Epoch number: 3467/10000step_number: 0/29 Accuracy:  0.9404392984845905 Loss:  1.294292725881719 Val_accuracy:  0.9211386543176246 Val_cost:  1.294292725881719 Val_accuracy:  0.9211386543176246 Val_Acc:  nan\n",
      "Epoch number: 3468/10000step_number: 0/29 Accuracy:  0.940507406776775 Loss:  1.2943030099879393 Val_accuracy:  0.9211386543176246 Val_cost:  1.2943030099879393 Val_accuracy:  0.9211386543176246 Val_Acc:  nan\n",
      "Epoch number: 3469/10000step_number: 0/29 Accuracy:  0.9406095692150519 Loss:  1.294320510284545 Val_accuracy:  0.9211386543176246 Val_cost:  1.294320510284545 Val_accuracy:  0.9211386543176246 Val_Acc:  nan\n",
      "Epoch number: 3470/10000step_number: 0/29 Accuracy:  0.9408138940916057 Loss:  1.2943463294270796 Val_accuracy:  0.9216834649959139 Val_cost:  1.2943463294270796 Val_accuracy:  0.9216834649959139 Val_Acc:  nan\n",
      "Epoch number: 3471/10000step_number: 0/29 Accuracy:  0.9410182189681594 Loss:  1.2943818056579652 Val_accuracy:  0.9216834649959139 Val_cost:  1.2943818056579652 Val_accuracy:  0.9216834649959139 Val_Acc:  nan\n",
      "Epoch number: 3472/10000step_number: 0/29 Accuracy:  0.9410182189681594 Loss:  1.2944285731207927 Val_accuracy:  0.9216834649959139 Val_cost:  1.2944285731207927 Val_accuracy:  0.9216834649959139 Val_Acc:  nan\n",
      "Epoch number: 3473/10000step_number: 0/29 Accuracy:  0.9409501106759748 Loss:  1.2944886527814714 Val_accuracy:  0.9218196676654863 Val_cost:  1.2944886527814714 Val_accuracy:  0.9218196676654863 Val_Acc:  nan\n",
      "Epoch number: 3474/10000step_number: 0/29 Accuracy:  0.9410863272603439 Loss:  1.2945645404578303 Val_accuracy:  0.9220920730046309 Val_cost:  1.2945645404578303 Val_accuracy:  0.9220920730046309 Val_Acc:  nan\n",
      "Epoch number: 3475/10000step_number: 0/29 Accuracy:  0.9412565979908054 Loss:  1.2946593185087136 Val_accuracy:  0.9223644783437756 Val_cost:  1.2946593185087136 Val_accuracy:  0.9223644783437756 Val_Acc:  nan\n",
      "Epoch number: 3476/10000step_number: 0/29 Accuracy:  0.9415290311595437 Loss:  1.2947767799088992 Val_accuracy:  0.9225006810133478 Val_cost:  1.2947767799088992 Val_accuracy:  0.9225006810133478 Val_Acc:  nan\n",
      "Epoch number: 3477/10000step_number: 0/29 Accuracy:  0.9418355184743743 Loss:  1.2949216123794214 Val_accuracy:  0.9226368836829202 Val_cost:  1.2949216123794214 Val_accuracy:  0.9226368836829202 Val_Acc:  nan\n",
      "Epoch number: 3478/10000step_number: 0/29 Accuracy:  0.9419376809126511 Loss:  1.2950995958635267 Val_accuracy:  0.9227730863524926 Val_cost:  1.2950995958635267 Val_accuracy:  0.9227730863524926 Val_Acc:  nan\n",
      "Epoch number: 3479/10000step_number: 0/29 Accuracy:  0.9422101140813894 Loss:  1.2953178861070647 Val_accuracy:  0.9226368836829202 Val_cost:  1.2953178861070647 Val_accuracy:  0.9226368836829202 Val_Acc:  nan\n",
      "Epoch number: 3480/10000step_number: 0/29 Accuracy:  0.9423803848118508 Loss:  1.2955854121835733 Val_accuracy:  0.9229092890220648 Val_cost:  1.2955854121835733 Val_accuracy:  0.9229092890220648 Val_Acc:  nan\n",
      "Epoch number: 3481/10000step_number: 0/29 Accuracy:  0.9426187638344968 Loss:  1.2959137047017755 Val_accuracy:  0.9234540997003541 Val_cost:  1.2959137047017755 Val_accuracy:  0.9234540997003541 Val_Acc:  nan\n",
      "Epoch number: 3482/10000step_number: 0/29 Accuracy:  0.9424825472501277 Loss:  1.296318310173726 Val_accuracy:  0.9233178970307818 Val_cost:  1.296318310173726 Val_accuracy:  0.9233178970307818 Val_Acc:  nan\n",
      "Epoch number: 3483/10000step_number: 0/29 Accuracy:  0.9424484931040354 Loss:  1.2968185314858316 Val_accuracy:  0.9227730863524926 Val_cost:  1.2968185314858316 Val_accuracy:  0.9227730863524926 Val_Acc:  nan\n",
      "Epoch number: 3484/10000step_number: 0/29 Accuracy:  0.9426868721266815 Loss:  1.29742311881558 Val_accuracy:  0.9231816943612094 Val_cost:  1.29742311881558 Val_accuracy:  0.9231816943612094 Val_Acc:  nan\n",
      "Epoch number: 3485/10000step_number: 0/29 Accuracy:  0.9430614677336966 Loss:  1.29809879632115 Val_accuracy:  0.9235903023699265 Val_cost:  1.29809879632115 Val_accuracy:  0.9235903023699265 Val_Acc:  nan\n",
      "Epoch number: 3486/10000step_number: 0/29 Accuracy:  0.9430274135876043 Loss:  1.2988067334329025 Val_accuracy:  0.9239989103786435 Val_cost:  1.2988067334329025 Val_accuracy:  0.9239989103786435 Val_Acc:  nan\n",
      "Epoch number: 3487/10000step_number: 0/29 Accuracy:  0.943470117486804 Loss:  1.2995921869566536 Val_accuracy:  0.9238627077090711 Val_cost:  1.2995921869566536 Val_accuracy:  0.9238627077090711 Val_Acc:  nan\n",
      "Epoch number: 3488/10000step_number: 0/29 Accuracy:  0.9437766048016346 Loss:  1.3003614442289713 Val_accuracy:  0.9235903023699265 Val_cost:  1.3003614442289713 Val_accuracy:  0.9235903023699265 Val_Acc:  nan\n",
      "Epoch number: 3489/10000step_number: 0/29 Accuracy:  0.9442533628469266 Loss:  1.3006524698380026 Val_accuracy:  0.9233178970307818 Val_cost:  1.3006524698380026 Val_accuracy:  0.9233178970307818 Val_Acc:  nan\n",
      "Epoch number: 3490/10000step_number: 0/29 Accuracy:  0.9452409330836029 Loss:  1.2998071055839096 Val_accuracy:  0.9239989103786435 Val_cost:  1.2998071055839096 Val_accuracy:  0.9239989103786435 Val_Acc:  nan\n",
      "Epoch number: 3491/10000step_number: 0/29 Accuracy:  0.9445939043078495 Loss:  1.2984734066812775 Val_accuracy:  0.9246799237265051 Val_cost:  1.2984734066812775 Val_accuracy:  0.9246799237265051 Val_Acc:  nan\n",
      "Epoch number: 3492/10000step_number: 0/29 Accuracy:  0.9443895794312958 Loss:  1.2994562995616388 Val_accuracy:  0.9231816943612094 Val_cost:  1.2994562995616388 Val_accuracy:  0.9231816943612094 Val_Acc:  nan\n",
      "Epoch number: 3493/10000step_number: 0/29 Accuracy:  0.9455474203984335 Loss:  1.2978462640146378 Val_accuracy:  0.9244075183873603 Val_cost:  1.2978462640146378 Val_accuracy:  0.9244075183873603 Val_Acc:  nan\n",
      "Epoch number: 3494/10000step_number: 0/29 Accuracy:  0.945138770645326 Loss:  1.3345832966273738 Val_accuracy:  0.9238627077090711 Val_cost:  1.3345832966273738 Val_accuracy:  0.9238627077090711 Val_Acc:  nan\n",
      "Epoch number: 3495/10000step_number: 0/29 Accuracy:  0.9392133492252682 Loss:  nan Val_accuracy:  0.9180059929174612 Val_cost:  nan Val_accuracy:  0.9180059929174612 Val_Acc:  nan\n",
      "Epoch number: 3496/10000step_number: 0/29 Accuracy:  0.9402349736080368 Loss:  1.3555912833583892 Val_accuracy:  0.9184146009261781 Val_cost:  1.3555912833583892 Val_accuracy:  0.9184146009261781 Val_Acc:  nan\n",
      "Epoch number: 3497/10000step_number: 0/29 Accuracy:  0.9510301379192917 Loss:  nan Val_accuracy:  0.9272677744483792 Val_cost:  nan Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3498/10000step_number: 0/29 Accuracy:  0.9499063510982462 Loss:  1.2950823853893976 Val_accuracy:  0.925497139743939 Val_cost:  1.2950823853893976 Val_accuracy:  0.925497139743939 Val_Acc:  nan\n",
      "Epoch number: 3499/10000step_number: 0/29 Accuracy:  0.9490890515920314 Loss:  1.2901296369425177 Val_accuracy:  0.9274039771179515 Val_cost:  1.2901296369425177 Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 3500/10000step_number: 0/29 Accuracy:  0.9476587774561552 Loss:  1.2885126869216323 Val_accuracy:  0.925905747752656 Val_cost:  1.2885126869216323 Val_accuracy:  0.925905747752656 Val_Acc:  nan\n",
      "Epoch number: 3501/10000step_number: 0/29 Accuracy:  0.9474885067256938 Loss:  1.2886550603421758 Val_accuracy:  0.9257695450830836 Val_cost:  1.2886550603421758 Val_accuracy:  0.9257695450830836 Val_Acc:  nan\n",
      "Epoch number: 3502/10000step_number: 0/29 Accuracy:  0.9471139111186787 Loss:  1.287776676259839 Val_accuracy:  0.925088531735222 Val_cost:  1.287776676259839 Val_accuracy:  0.925088531735222 Val_Acc:  nan\n",
      "Epoch number: 3503/10000step_number: 0/29 Accuracy:  0.9470458028264941 Loss:  1.2875408325502267 Val_accuracy:  0.9252247344047944 Val_cost:  1.2875408325502267 Val_accuracy:  0.9252247344047944 Val_Acc:  nan\n",
      "Epoch number: 3504/10000step_number: 0/29 Accuracy:  0.9470117486804018 Loss:  1.2873202566010946 Val_accuracy:  0.9253609370743666 Val_cost:  1.2873202566010946 Val_accuracy:  0.9253609370743666 Val_Acc:  nan\n",
      "Epoch number: 3505/10000step_number: 0/29 Accuracy:  0.9468755320960327 Loss:  1.287304652683419 Val_accuracy:  0.925497139743939 Val_cost:  1.287304652683419 Val_accuracy:  0.925497139743939 Val_Acc:  nan\n",
      "Epoch number: 3506/10000step_number: 0/29 Accuracy:  0.946671207219479 Loss:  1.2873205382511 Val_accuracy:  0.9248161263960774 Val_cost:  1.2873205382511 Val_accuracy:  0.9248161263960774 Val_Acc:  nan\n",
      "Epoch number: 3507/10000step_number: 0/29 Accuracy:  0.9465690447812021 Loss:  1.2873878949885533 Val_accuracy:  0.9248161263960774 Val_cost:  1.2873878949885533 Val_accuracy:  0.9248161263960774 Val_Acc:  nan\n",
      "Epoch number: 3508/10000step_number: 0/29 Accuracy:  0.9462966116124638 Loss:  1.2874813953577575 Val_accuracy:  0.9248161263960774 Val_cost:  1.2874813953577575 Val_accuracy:  0.9248161263960774 Val_Acc:  nan\n",
      "Epoch number: 3509/10000step_number: 0/29 Accuracy:  0.9460922867359101 Loss:  1.2875909873375946 Val_accuracy:  0.9248161263960774 Val_cost:  1.2875909873375946 Val_accuracy:  0.9248161263960774 Val_Acc:  nan\n",
      "Epoch number: 3510/10000step_number: 0/29 Accuracy:  0.9460922867359101 Loss:  1.2877002219726614 Val_accuracy:  0.9248161263960774 Val_cost:  1.2877002219726614 Val_accuracy:  0.9248161263960774 Val_Acc:  nan\n",
      "Epoch number: 3511/10000step_number: 0/29 Accuracy:  0.9460241784437255 Loss:  1.2878082633624985 Val_accuracy:  0.9252247344047944 Val_cost:  1.2878082633624985 Val_accuracy:  0.9252247344047944 Val_Acc:  nan\n",
      "Epoch number: 3512/10000step_number: 0/29 Accuracy:  0.9459901242976332 Loss:  1.2879161676778594 Val_accuracy:  0.925088531735222 Val_cost:  1.2879161676778594 Val_accuracy:  0.925088531735222 Val_Acc:  nan\n",
      "Epoch number: 3513/10000step_number: 0/29 Accuracy:  0.9459560701515409 Loss:  1.2880183581989846 Val_accuracy:  0.925088531735222 Val_cost:  1.2880183581989846 Val_accuracy:  0.925088531735222 Val_Acc:  nan\n",
      "Epoch number: 3514/10000step_number: 0/29 Accuracy:  0.9459220160054487 Loss:  1.2881097714335685 Val_accuracy:  0.925497139743939 Val_cost:  1.2881097714335685 Val_accuracy:  0.925497139743939 Val_Acc:  nan\n",
      "Epoch number: 3515/10000step_number: 0/29 Accuracy:  0.9454452579601567 Loss:  1.288187331066354 Val_accuracy:  0.9249523290656497 Val_cost:  1.288187331066354 Val_accuracy:  0.9249523290656497 Val_Acc:  nan\n",
      "Epoch number: 3516/10000step_number: 0/29 Accuracy:  0.9454452579601567 Loss:  1.2882491122642594 Val_accuracy:  0.925088531735222 Val_cost:  1.2882491122642594 Val_accuracy:  0.925088531735222 Val_Acc:  nan\n",
      "Epoch number: 3517/10000step_number: 0/29 Accuracy:  0.9455133662523412 Loss:  1.2882942631290137 Val_accuracy:  0.925088531735222 Val_cost:  1.2882942631290137 Val_accuracy:  0.925088531735222 Val_Acc:  nan\n",
      "Epoch number: 3518/10000step_number: 0/29 Accuracy:  0.9455814745445258 Loss:  1.288323037469422 Val_accuracy:  0.925088531735222 Val_cost:  1.288323037469422 Val_accuracy:  0.925088531735222 Val_Acc:  nan\n",
      "Epoch number: 3519/10000step_number: 0/29 Accuracy:  0.945853907713264 Loss:  1.288336426314139 Val_accuracy:  0.9249523290656497 Val_cost:  1.288336426314139 Val_accuracy:  0.9249523290656497 Val_Acc:  nan\n",
      "Epoch number: 3520/10000step_number: 0/29 Accuracy:  0.945853907713264 Loss:  1.2883356479361696 Val_accuracy:  0.9246799237265051 Val_cost:  1.2883356479361696 Val_accuracy:  0.9246799237265051 Val_Acc:  nan\n",
      "Epoch number: 3521/10000step_number: 0/29 Accuracy:  0.9459220160054487 Loss:  1.2883218960748 Val_accuracy:  0.9246799237265051 Val_cost:  1.2883218960748 Val_accuracy:  0.9246799237265051 Val_Acc:  nan\n",
      "Epoch number: 3522/10000step_number: 0/29 Accuracy:  0.9458879618593564 Loss:  1.288296348853071 Val_accuracy:  0.9246799237265051 Val_cost:  1.288296348853071 Val_accuracy:  0.9246799237265051 Val_Acc:  nan\n",
      "Epoch number: 3523/10000step_number: 0/29 Accuracy:  0.9460922867359101 Loss:  1.2882602305890578 Val_accuracy:  0.9246799237265051 Val_cost:  1.2882602305890578 Val_accuracy:  0.9246799237265051 Val_Acc:  nan\n",
      "Epoch number: 3524/10000step_number: 0/29 Accuracy:  0.9462285033202792 Loss:  1.2882148141567886 Val_accuracy:  0.9248161263960774 Val_cost:  1.2882148141567886 Val_accuracy:  0.9248161263960774 Val_Acc:  nan\n",
      "Epoch number: 3525/10000step_number: 0/29 Accuracy:  0.9463306657585561 Loss:  1.2881612921251349 Val_accuracy:  0.9246799237265051 Val_cost:  1.2881612921251349 Val_accuracy:  0.9246799237265051 Val_Acc:  nan\n",
      "Epoch number: 3526/10000step_number: 0/29 Accuracy:  0.9465349906351098 Loss:  1.288100483906594 Val_accuracy:  0.9246799237265051 Val_cost:  1.288100483906594 Val_accuracy:  0.9246799237265051 Val_Acc:  nan\n",
      "Epoch number: 3527/10000step_number: 0/29 Accuracy:  0.9466371530733867 Loss:  1.2880326535288864 Val_accuracy:  0.925497139743939 Val_cost:  1.2880326535288864 Val_accuracy:  0.925497139743939 Val_Acc:  nan\n",
      "Epoch number: 3528/10000step_number: 0/29 Accuracy:  0.9465349906351098 Loss:  1.287957905167512 Val_accuracy:  0.9253609370743666 Val_cost:  1.287957905167512 Val_accuracy:  0.9253609370743666 Val_Acc:  nan\n",
      "Epoch number: 3529/10000step_number: 0/29 Accuracy:  0.9467393155116636 Loss:  1.287876990517354 Val_accuracy:  0.9252247344047944 Val_cost:  1.287876990517354 Val_accuracy:  0.9252247344047944 Val_Acc:  nan\n",
      "Epoch number: 3530/10000step_number: 0/29 Accuracy:  0.9468755320960327 Loss:  1.2877916175296709 Val_accuracy:  0.9253609370743666 Val_cost:  1.2877916175296709 Val_accuracy:  0.9253609370743666 Val_Acc:  nan\n",
      "Epoch number: 3531/10000step_number: 0/29 Accuracy:  0.9468074238038481 Loss:  1.2877038543777777 Val_accuracy:  0.9253609370743666 Val_cost:  1.2877038543777777 Val_accuracy:  0.9253609370743666 Val_Acc:  nan\n",
      "Epoch number: 3532/10000step_number: 0/29 Accuracy:  0.9468414779499404 Loss:  1.2876152710074726 Val_accuracy:  0.9256333424135113 Val_cost:  1.2876152710074726 Val_accuracy:  0.9256333424135113 Val_Acc:  nan\n",
      "Epoch number: 3533/10000step_number: 0/29 Accuracy:  0.9468414779499404 Loss:  1.2875266192325456 Val_accuracy:  0.9256333424135113 Val_cost:  1.2875266192325456 Val_accuracy:  0.9256333424135113 Val_Acc:  nan\n",
      "Epoch number: 3534/10000step_number: 0/29 Accuracy:  0.9468755320960327 Loss:  1.28743809507844 Val_accuracy:  0.9256333424135113 Val_cost:  1.28743809507844 Val_accuracy:  0.9256333424135113 Val_Acc:  nan\n",
      "Epoch number: 3535/10000step_number: 0/29 Accuracy:  0.9469776945343096 Loss:  1.287349749381097 Val_accuracy:  0.925497139743939 Val_cost:  1.287349749381097 Val_accuracy:  0.925497139743939 Val_Acc:  nan\n",
      "Epoch number: 3536/10000step_number: 0/29 Accuracy:  0.9469436403882172 Loss:  1.2872617344350692 Val_accuracy:  0.925497139743939 Val_cost:  1.2872617344350692 Val_accuracy:  0.925497139743939 Val_Acc:  nan\n",
      "Epoch number: 3537/10000step_number: 0/29 Accuracy:  0.9469776945343096 Loss:  1.28717432741215 Val_accuracy:  0.9257695450830836 Val_cost:  1.28717432741215 Val_accuracy:  0.9257695450830836 Val_Acc:  nan\n",
      "Epoch number: 3538/10000step_number: 0/29 Accuracy:  0.9468074238038481 Loss:  1.2870878402324835 Val_accuracy:  0.9260419504222283 Val_cost:  1.2870878402324835 Val_accuracy:  0.9260419504222283 Val_Acc:  nan\n",
      "Epoch number: 3539/10000step_number: 0/29 Accuracy:  0.9468074238038481 Loss:  1.2870025454832639 Val_accuracy:  0.9260419504222283 Val_cost:  1.2870025454832639 Val_accuracy:  0.9260419504222283 Val_Acc:  nan\n",
      "Epoch number: 3540/10000step_number: 0/29 Accuracy:  0.9468074238038481 Loss:  1.2869186593471578 Val_accuracy:  0.9257695450830836 Val_cost:  1.2869186593471578 Val_accuracy:  0.9257695450830836 Val_Acc:  nan\n",
      "Epoch number: 3541/10000step_number: 0/29 Accuracy:  0.9468074238038481 Loss:  1.2868363547759705 Val_accuracy:  0.9257695450830836 Val_cost:  1.2868363547759705 Val_accuracy:  0.9257695450830836 Val_Acc:  nan\n",
      "Epoch number: 3542/10000step_number: 0/29 Accuracy:  0.9468414779499404 Loss:  1.2867557762571409 Val_accuracy:  0.9260419504222283 Val_cost:  1.2867557762571409 Val_accuracy:  0.9260419504222283 Val_Acc:  nan\n",
      "Epoch number: 3543/10000step_number: 0/29 Accuracy:  0.9468755320960327 Loss:  1.286677046373994 Val_accuracy:  0.9261781530918006 Val_cost:  1.286677046373994 Val_accuracy:  0.9261781530918006 Val_Acc:  nan\n",
      "Epoch number: 3544/10000step_number: 0/29 Accuracy:  0.9468755320960327 Loss:  1.2866002643961894 Val_accuracy:  0.9263143557613729 Val_cost:  1.2866002643961894 Val_accuracy:  0.9263143557613729 Val_Acc:  nan\n",
      "Epoch number: 3545/10000step_number: 0/29 Accuracy:  0.946909586242125 Loss:  1.2865255003201403 Val_accuracy:  0.9261781530918006 Val_cost:  1.2865255003201403 Val_accuracy:  0.9261781530918006 Val_Acc:  nan\n",
      "Epoch number: 3546/10000step_number: 0/29 Accuracy:  0.9469436403882172 Loss:  1.2864527882771626 Val_accuracy:  0.9261781530918006 Val_cost:  1.2864527882771626 Val_accuracy:  0.9261781530918006 Val_Acc:  nan\n",
      "Epoch number: 3547/10000step_number: 0/29 Accuracy:  0.9469436403882172 Loss:  1.2863821219522311 Val_accuracy:  0.9261781530918006 Val_cost:  1.2863821219522311 Val_accuracy:  0.9261781530918006 Val_Acc:  nan\n",
      "Epoch number: 3548/10000step_number: 0/29 Accuracy:  0.9470117486804018 Loss:  1.2863134528147624 Val_accuracy:  0.9263143557613729 Val_cost:  1.2863134528147624 Val_accuracy:  0.9263143557613729 Val_Acc:  nan\n",
      "Epoch number: 3549/10000step_number: 0/29 Accuracy:  0.9471139111186787 Loss:  1.286246690686638 Val_accuracy:  0.9263143557613729 Val_cost:  1.286246690686638 Val_accuracy:  0.9263143557613729 Val_Acc:  nan\n",
      "Epoch number: 3550/10000step_number: 0/29 Accuracy:  0.9472160735569556 Loss:  1.2861817057473486 Val_accuracy:  0.9264505584309453 Val_cost:  1.2861817057473486 Val_accuracy:  0.9264505584309453 Val_Acc:  nan\n",
      "Epoch number: 3551/10000step_number: 0/29 Accuracy:  0.9472501277030478 Loss:  1.2861183312490283 Val_accuracy:  0.9265867611005175 Val_cost:  1.2861183312490283 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3552/10000step_number: 0/29 Accuracy:  0.9472160735569556 Loss:  1.286056366653827 Val_accuracy:  0.9265867611005175 Val_cost:  1.286056366653827 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3553/10000step_number: 0/29 Accuracy:  0.9472501277030478 Loss:  1.2859955813576127 Val_accuracy:  0.9265867611005175 Val_cost:  1.2859955813576127 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3554/10000step_number: 0/29 Accuracy:  0.9472841818491401 Loss:  1.2859357194265004 Val_accuracy:  0.9267229637700899 Val_cost:  1.2859357194265004 Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 3555/10000step_number: 0/29 Accuracy:  0.9473182359952325 Loss:  1.2858765057172712 Val_accuracy:  0.9264505584309453 Val_cost:  1.2858765057172712 Val_accuracy:  0.9264505584309453 Val_Acc:  nan\n",
      "Epoch number: 3556/10000step_number: 0/29 Accuracy:  0.9474203984335092 Loss:  1.2858176534078585 Val_accuracy:  0.9264505584309453 Val_cost:  1.2858176534078585 Val_accuracy:  0.9264505584309453 Val_Acc:  nan\n",
      "Epoch number: 3557/10000step_number: 0/29 Accuracy:  0.947386344287417 Loss:  1.2857588725260771 Val_accuracy:  0.9264505584309453 Val_cost:  1.2857588725260771 Val_accuracy:  0.9264505584309453 Val_Acc:  nan\n",
      "Epoch number: 3558/10000step_number: 0/29 Accuracy:  0.947386344287417 Loss:  1.2856998787537968 Val_accuracy:  0.9264505584309453 Val_cost:  1.2856998787537968 Val_accuracy:  0.9264505584309453 Val_Acc:  nan\n",
      "Epoch number: 3559/10000step_number: 0/29 Accuracy:  0.9476587774561552 Loss:  1.285640401681532 Val_accuracy:  0.9265867611005175 Val_cost:  1.285640401681532 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3560/10000step_number: 0/29 Accuracy:  0.947624723310063 Loss:  1.285580191752819 Val_accuracy:  0.9268591664396623 Val_cost:  1.285580191752819 Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3561/10000step_number: 0/29 Accuracy:  0.9477268857483399 Loss:  1.2855190253588913 Val_accuracy:  0.9269953691092345 Val_cost:  1.2855190253588913 Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3562/10000step_number: 0/29 Accuracy:  0.9478290481866167 Loss:  1.2854567079853747 Val_accuracy:  0.9269953691092345 Val_cost:  1.2854567079853747 Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3563/10000step_number: 0/29 Accuracy:  0.9478971564788012 Loss:  1.285393075916771 Val_accuracy:  0.9269953691092345 Val_cost:  1.285393075916771 Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3564/10000step_number: 0/29 Accuracy:  0.9479652647709859 Loss:  1.2853279974295122 Val_accuracy:  0.9271315717788069 Val_cost:  1.2853279974295122 Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3565/10000step_number: 0/29 Accuracy:  0.9479652647709859 Loss:  1.285261374235789 Val_accuracy:  0.9271315717788069 Val_cost:  1.285261374235789 Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3566/10000step_number: 0/29 Accuracy:  0.9479652647709859 Loss:  1.2851931431619763 Val_accuracy:  0.9272677744483792 Val_cost:  1.2851931431619763 Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3567/10000step_number: 0/29 Accuracy:  0.9480674272092627 Loss:  1.2851232772059624 Val_accuracy:  0.9272677744483792 Val_cost:  1.2851232772059624 Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3568/10000step_number: 0/29 Accuracy:  0.9479993189170781 Loss:  1.285051784896273 Val_accuracy:  0.9274039771179515 Val_cost:  1.285051784896273 Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 3569/10000step_number: 0/29 Accuracy:  0.9480333730631705 Loss:  1.2849787074548666 Val_accuracy:  0.9276763824570962 Val_cost:  1.2849787074548666 Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3570/10000step_number: 0/29 Accuracy:  0.948101481355355 Loss:  1.2849041141717839 Val_accuracy:  0.9276763824570962 Val_cost:  1.2849041141717839 Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3571/10000step_number: 0/29 Accuracy:  0.9482036437936319 Loss:  1.2848280969672383 Val_accuracy:  0.9276763824570962 Val_cost:  1.2848280969672383 Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3572/10000step_number: 0/29 Accuracy:  0.9481695896475396 Loss:  1.2847507650585035 Val_accuracy:  0.9274039771179515 Val_cost:  1.2847507650585035 Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 3573/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  1.28467224018463 Val_accuracy:  0.9275401797875238 Val_cost:  1.28467224018463 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3574/10000step_number: 0/29 Accuracy:  0.9484420228162779 Loss:  1.2845926523785038 Val_accuracy:  0.9276763824570962 Val_cost:  1.2845926523785038 Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3575/10000step_number: 0/29 Accuracy:  0.9484760769623701 Loss:  1.2845121360595397 Val_accuracy:  0.9278125851266685 Val_cost:  1.2845121360595397 Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3576/10000step_number: 0/29 Accuracy:  0.9483058062319087 Loss:  1.2844308262490274 Val_accuracy:  0.9278125851266685 Val_cost:  1.2844308262490274 Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3577/10000step_number: 0/29 Accuracy:  0.9484079686701856 Loss:  1.2843488548468864 Val_accuracy:  0.9276763824570962 Val_cost:  1.2843488548468864 Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3578/10000step_number: 0/29 Accuracy:  0.9483058062319087 Loss:  1.2842663470155753 Val_accuracy:  0.9276763824570962 Val_cost:  1.2842663470155753 Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3579/10000step_number: 0/29 Accuracy:  0.9482036437936319 Loss:  1.2841834177143705 Val_accuracy:  0.9275401797875238 Val_cost:  1.2841834177143705 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3580/10000step_number: 0/29 Accuracy:  0.9483058062319087 Loss:  1.284100168290984 Val_accuracy:  0.9275401797875238 Val_cost:  1.284100168290984 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3581/10000step_number: 0/29 Accuracy:  0.948339860378001 Loss:  1.284016682773569 Val_accuracy:  0.9275401797875238 Val_cost:  1.284016682773569 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3582/10000step_number: 0/29 Accuracy:  0.9484079686701856 Loss:  1.2839330231281902 Val_accuracy:  0.9275401797875238 Val_cost:  1.2839330231281902 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3583/10000step_number: 0/29 Accuracy:  0.9483739145240933 Loss:  1.283849222267539 Val_accuracy:  0.9274039771179515 Val_cost:  1.283849222267539 Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 3584/10000step_number: 0/29 Accuracy:  0.9484079686701856 Loss:  1.2837652730511744 Val_accuracy:  0.9274039771179515 Val_cost:  1.2837652730511744 Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 3585/10000step_number: 0/29 Accuracy:  0.9483058062319087 Loss:  1.2836811110618616 Val_accuracy:  0.9274039771179515 Val_cost:  1.2836811110618616 Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 3586/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  1.2835965891169485 Val_accuracy:  0.9272677744483792 Val_cost:  1.2835965891169485 Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3587/10000step_number: 0/29 Accuracy:  0.9481695896475396 Loss:  1.283511443728463 Val_accuracy:  0.9272677744483792 Val_cost:  1.283511443728463 Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3588/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  1.2834252610083707 Val_accuracy:  0.9278125851266685 Val_cost:  1.2834252610083707 Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3589/10000step_number: 0/29 Accuracy:  0.9481355355014472 Loss:  1.2833374654751848 Val_accuracy:  0.9275401797875238 Val_cost:  1.2833374654751848 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3590/10000step_number: 0/29 Accuracy:  0.9479993189170781 Loss:  1.2832473782029292 Val_accuracy:  0.9275401797875238 Val_cost:  1.2832473782029292 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3591/10000step_number: 0/29 Accuracy:  0.9479312106248936 Loss:  1.2831543998881916 Val_accuracy:  0.9275401797875238 Val_cost:  1.2831543998881916 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3592/10000step_number: 0/29 Accuracy:  0.9477949940405245 Loss:  1.283058323618163 Val_accuracy:  0.9275401797875238 Val_cost:  1.283058323618163 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3593/10000step_number: 0/29 Accuracy:  0.9475225608717861 Loss:  1.2829596484773456 Val_accuracy:  0.9278125851266685 Val_cost:  1.2829596484773456 Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3594/10000step_number: 0/29 Accuracy:  0.9473522901413247 Loss:  1.282859647348363 Val_accuracy:  0.9279487877962408 Val_cost:  1.282859647348363 Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3595/10000step_number: 0/29 Accuracy:  0.9472841818491401 Loss:  1.2827600302037312 Val_accuracy:  0.9280849904658132 Val_cost:  1.2827600302037312 Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 3596/10000step_number: 0/29 Accuracy:  0.947147965264771 Loss:  1.2826623443413259 Val_accuracy:  0.9280849904658132 Val_cost:  1.2826623443413259 Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 3597/10000step_number: 0/29 Accuracy:  0.9471139111186787 Loss:  1.2825674494266766 Val_accuracy:  0.9280849904658132 Val_cost:  1.2825674494266766 Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 3598/10000step_number: 0/29 Accuracy:  0.946909586242125 Loss:  1.2824752479017512 Val_accuracy:  0.9279487877962408 Val_cost:  1.2824752479017512 Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3599/10000step_number: 0/29 Accuracy:  0.9467052613655712 Loss:  1.2823845575903088 Val_accuracy:  0.9278125851266685 Val_cost:  1.2823845575903088 Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3600/10000step_number: 0/29 Accuracy:  0.9465690447812021 Loss:  1.2822930574396658 Val_accuracy:  0.9276763824570962 Val_cost:  1.2822930574396658 Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3601/10000step_number: 0/29 Accuracy:  0.9465009364890176 Loss:  1.2821984451574022 Val_accuracy:  0.9274039771179515 Val_cost:  1.2821984451574022 Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 3602/10000step_number: 0/29 Accuracy:  0.9463647199046484 Loss:  1.28210426197982 Val_accuracy:  0.9272677744483792 Val_cost:  1.28210426197982 Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3603/10000step_number: 0/29 Accuracy:  0.9463647199046484 Loss:  1.2820214197371913 Val_accuracy:  0.9275401797875238 Val_cost:  1.2820214197371913 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3604/10000step_number: 0/29 Accuracy:  0.9462285033202792 Loss:  1.281949145738885 Val_accuracy:  0.9275401797875238 Val_cost:  1.281949145738885 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3605/10000step_number: 0/29 Accuracy:  0.9460922867359101 Loss:  1.2818764600191253 Val_accuracy:  0.9275401797875238 Val_cost:  1.2818764600191253 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3606/10000step_number: 0/29 Accuracy:  0.9460582325898178 Loss:  1.2817996313196274 Val_accuracy:  0.9275401797875238 Val_cost:  1.2817996313196274 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3607/10000step_number: 0/29 Accuracy:  0.9460241784437255 Loss:  1.2817204388271075 Val_accuracy:  0.9276763824570962 Val_cost:  1.2817204388271075 Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3608/10000step_number: 0/29 Accuracy:  0.9459220160054487 Loss:  1.2816417949422994 Val_accuracy:  0.9278125851266685 Val_cost:  1.2816417949422994 Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3609/10000step_number: 0/29 Accuracy:  0.9458879618593564 Loss:  1.2815599255485532 Val_accuracy:  0.9276763824570962 Val_cost:  1.2815599255485532 Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3610/10000step_number: 0/29 Accuracy:  0.9458879618593564 Loss:  1.2814785622589862 Val_accuracy:  0.9276763824570962 Val_cost:  1.2814785622589862 Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3611/10000step_number: 0/29 Accuracy:  0.9458879618593564 Loss:  1.2813927715552063 Val_accuracy:  0.9278125851266685 Val_cost:  1.2813927715552063 Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3612/10000step_number: 0/29 Accuracy:  0.9459560701515409 Loss:  1.2813106386559243 Val_accuracy:  0.9276763824570962 Val_cost:  1.2813106386559243 Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3613/10000step_number: 0/29 Accuracy:  0.9460241784437255 Loss:  1.281220286591655 Val_accuracy:  0.9275401797875238 Val_cost:  1.281220286591655 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3614/10000step_number: 0/29 Accuracy:  0.9459220160054487 Loss:  1.2811397312028252 Val_accuracy:  0.9274039771179515 Val_cost:  1.2811397312028252 Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 3615/10000step_number: 0/29 Accuracy:  0.9458879618593564 Loss:  1.2810424559762457 Val_accuracy:  0.9274039771179515 Val_cost:  1.2810424559762457 Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 3616/10000step_number: 0/29 Accuracy:  0.9461263408820024 Loss:  1.2809683206964548 Val_accuracy:  0.9272677744483792 Val_cost:  1.2809683206964548 Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3617/10000step_number: 0/29 Accuracy:  0.9461263408820024 Loss:  1.2808594715572454 Val_accuracy:  0.9271315717788069 Val_cost:  1.2808594715572454 Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3618/10000step_number: 0/29 Accuracy:  0.9461603950280947 Loss:  1.2807993744466242 Val_accuracy:  0.9269953691092345 Val_cost:  1.2807993744466242 Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3619/10000step_number: 0/29 Accuracy:  0.9461263408820024 Loss:  1.2806707337244456 Val_accuracy:  0.9269953691092345 Val_cost:  1.2806707337244456 Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3620/10000step_number: 0/29 Accuracy:  0.9461944491741869 Loss:  1.2806342716208614 Val_accuracy:  0.9269953691092345 Val_cost:  1.2806342716208614 Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3621/10000step_number: 0/29 Accuracy:  0.9461603950280947 Loss:  1.2804767178752934 Val_accuracy:  0.9267229637700899 Val_cost:  1.2804767178752934 Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 3622/10000step_number: 0/29 Accuracy:  0.9460582325898178 Loss:  1.280471552410963 Val_accuracy:  0.9268591664396623 Val_cost:  1.280471552410963 Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3623/10000step_number: 0/29 Accuracy:  0.9461944491741869 Loss:  1.2802823645465315 Val_accuracy:  0.9269953691092345 Val_cost:  1.2802823645465315 Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3624/10000step_number: 0/29 Accuracy:  0.9460241784437255 Loss:  1.2803053626899255 Val_accuracy:  0.9268591664396623 Val_cost:  1.2803053626899255 Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3625/10000step_number: 0/29 Accuracy:  0.9460582325898178 Loss:  1.2800970321865894 Val_accuracy:  0.9265867611005175 Val_cost:  1.2800970321865894 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3626/10000step_number: 0/29 Accuracy:  0.9459901242976332 Loss:  1.2801277051150994 Val_accuracy:  0.9265867611005175 Val_cost:  1.2801277051150994 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3627/10000step_number: 0/29 Accuracy:  0.9459560701515409 Loss:  1.2799280551932382 Val_accuracy:  0.9265867611005175 Val_cost:  1.2799280551932382 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3628/10000step_number: 0/29 Accuracy:  0.9460241784437255 Loss:  1.2799369276231747 Val_accuracy:  0.9267229637700899 Val_cost:  1.2799369276231747 Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 3629/10000step_number: 0/29 Accuracy:  0.9459901242976332 Loss:  1.2797721340243133 Val_accuracy:  0.9267229637700899 Val_cost:  1.2797721340243133 Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 3630/10000step_number: 0/29 Accuracy:  0.9460241784437255 Loss:  1.2797425477313813 Val_accuracy:  0.9267229637700899 Val_cost:  1.2797425477313813 Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 3631/10000step_number: 0/29 Accuracy:  0.9460582325898178 Loss:  1.2796174692540043 Val_accuracy:  0.9267229637700899 Val_cost:  1.2796174692540043 Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 3632/10000step_number: 0/29 Accuracy:  0.9460922867359101 Loss:  1.2795558726405247 Val_accuracy:  0.9267229637700899 Val_cost:  1.2795558726405247 Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 3633/10000step_number: 0/29 Accuracy:  0.9460582325898178 Loss:  1.2794569964349007 Val_accuracy:  0.9265867611005175 Val_cost:  1.2794569964349007 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3634/10000step_number: 0/29 Accuracy:  0.9460582325898178 Loss:  1.279379159726947 Val_accuracy:  0.9265867611005175 Val_cost:  1.279379159726947 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3635/10000step_number: 0/29 Accuracy:  0.9460241784437255 Loss:  1.2792923052831606 Val_accuracy:  0.9265867611005175 Val_cost:  1.2792923052831606 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3636/10000step_number: 0/29 Accuracy:  0.9460582325898178 Loss:  1.2792095878286982 Val_accuracy:  0.9265867611005175 Val_cost:  1.2792095878286982 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3637/10000step_number: 0/29 Accuracy:  0.9460922867359101 Loss:  1.2791271361604686 Val_accuracy:  0.9265867611005175 Val_cost:  1.2791271361604686 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3638/10000step_number: 0/29 Accuracy:  0.9461263408820024 Loss:  1.2790453432092386 Val_accuracy:  0.9265867611005175 Val_cost:  1.2790453432092386 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3639/10000step_number: 0/29 Accuracy:  0.9460582325898178 Loss:  1.2789651482457371 Val_accuracy:  0.9264505584309453 Val_cost:  1.2789651482457371 Val_accuracy:  0.9264505584309453 Val_Acc:  nan\n",
      "Epoch number: 3640/10000step_number: 0/29 Accuracy:  0.9460922867359101 Loss:  1.2788861167051637 Val_accuracy:  0.9264505584309453 Val_cost:  1.2788861167051637 Val_accuracy:  0.9264505584309453 Val_Acc:  nan\n",
      "Epoch number: 3641/10000step_number: 0/29 Accuracy:  0.9461603950280947 Loss:  1.278808261128304 Val_accuracy:  0.9267229637700899 Val_cost:  1.278808261128304 Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 3642/10000step_number: 0/29 Accuracy:  0.9461944491741869 Loss:  1.2787318953738358 Val_accuracy:  0.9265867611005175 Val_cost:  1.2787318953738358 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3643/10000step_number: 0/29 Accuracy:  0.9462625574663716 Loss:  1.2786560992592508 Val_accuracy:  0.9265867611005175 Val_cost:  1.2786560992592508 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3644/10000step_number: 0/29 Accuracy:  0.9463306657585561 Loss:  1.2785813453058736 Val_accuracy:  0.9265867611005175 Val_cost:  1.2785813453058736 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3645/10000step_number: 0/29 Accuracy:  0.9463306657585561 Loss:  1.278506939522062 Val_accuracy:  0.9265867611005175 Val_cost:  1.278506939522062 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3646/10000step_number: 0/29 Accuracy:  0.9462285033202792 Loss:  1.2784332360281092 Val_accuracy:  0.9265867611005175 Val_cost:  1.2784332360281092 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3647/10000step_number: 0/29 Accuracy:  0.9463306657585561 Loss:  1.2783600436649043 Val_accuracy:  0.9265867611005175 Val_cost:  1.2783600436649043 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3648/10000step_number: 0/29 Accuracy:  0.9463647199046484 Loss:  1.2782875989685583 Val_accuracy:  0.9264505584309453 Val_cost:  1.2782875989685583 Val_accuracy:  0.9264505584309453 Val_Acc:  nan\n",
      "Epoch number: 3649/10000step_number: 0/29 Accuracy:  0.9463987740507407 Loss:  1.2782160713079476 Val_accuracy:  0.9263143557613729 Val_cost:  1.2782160713079476 Val_accuracy:  0.9263143557613729 Val_Acc:  nan\n",
      "Epoch number: 3650/10000step_number: 0/29 Accuracy:  0.9464328281968329 Loss:  1.2781457339566087 Val_accuracy:  0.9263143557613729 Val_cost:  1.2781457339566087 Val_accuracy:  0.9263143557613729 Val_Acc:  nan\n",
      "Epoch number: 3651/10000step_number: 0/29 Accuracy:  0.9462285033202792 Loss:  1.2780768606489188 Val_accuracy:  0.9263143557613729 Val_cost:  1.2780768606489188 Val_accuracy:  0.9263143557613729 Val_Acc:  nan\n",
      "Epoch number: 3652/10000step_number: 0/29 Accuracy:  0.9462625574663716 Loss:  1.2780096813216646 Val_accuracy:  0.9261781530918006 Val_cost:  1.2780096813216646 Val_accuracy:  0.9261781530918006 Val_Acc:  nan\n",
      "Epoch number: 3653/10000step_number: 0/29 Accuracy:  0.9463306657585561 Loss:  1.2779443419624872 Val_accuracy:  0.9261781530918006 Val_cost:  1.2779443419624872 Val_accuracy:  0.9261781530918006 Val_Acc:  nan\n",
      "Epoch number: 3654/10000step_number: 0/29 Accuracy:  0.9463987740507407 Loss:  1.2778809558027437 Val_accuracy:  0.9263143557613729 Val_cost:  1.2778809558027437 Val_accuracy:  0.9263143557613729 Val_Acc:  nan\n",
      "Epoch number: 3655/10000step_number: 0/29 Accuracy:  0.9463987740507407 Loss:  1.2778195389470652 Val_accuracy:  0.9261781530918006 Val_cost:  1.2778195389470652 Val_accuracy:  0.9261781530918006 Val_Acc:  nan\n",
      "Epoch number: 3656/10000step_number: 0/29 Accuracy:  0.9463987740507407 Loss:  1.2777600837070018 Val_accuracy:  0.9260419504222283 Val_cost:  1.2777600837070018 Val_accuracy:  0.9260419504222283 Val_Acc:  nan\n",
      "Epoch number: 3657/10000step_number: 0/29 Accuracy:  0.9464328281968329 Loss:  1.277702448625034 Val_accuracy:  0.9260419504222283 Val_cost:  1.277702448625034 Val_accuracy:  0.9260419504222283 Val_Acc:  nan\n",
      "Epoch number: 3658/10000step_number: 0/29 Accuracy:  0.9464668823429252 Loss:  1.2776464087866781 Val_accuracy:  0.9260419504222283 Val_cost:  1.2776464087866781 Val_accuracy:  0.9260419504222283 Val_Acc:  nan\n",
      "Epoch number: 3659/10000step_number: 0/29 Accuracy:  0.9464668823429252 Loss:  1.2775916271674796 Val_accuracy:  0.925905747752656 Val_cost:  1.2775916271674796 Val_accuracy:  0.925905747752656 Val_Acc:  nan\n",
      "Epoch number: 3660/10000step_number: 0/29 Accuracy:  0.9464328281968329 Loss:  1.2775377667081622 Val_accuracy:  0.9257695450830836 Val_cost:  1.2775377667081622 Val_accuracy:  0.9257695450830836 Val_Acc:  nan\n",
      "Epoch number: 3661/10000step_number: 0/29 Accuracy:  0.9465009364890176 Loss:  1.2774845550976492 Val_accuracy:  0.9256333424135113 Val_cost:  1.2774845550976492 Val_accuracy:  0.9256333424135113 Val_Acc:  nan\n",
      "Epoch number: 3662/10000step_number: 0/29 Accuracy:  0.9465349906351098 Loss:  1.277431826023825 Val_accuracy:  0.925497139743939 Val_cost:  1.277431826023825 Val_accuracy:  0.925497139743939 Val_Acc:  nan\n",
      "Epoch number: 3663/10000step_number: 0/29 Accuracy:  0.9465690447812021 Loss:  1.2773794403927277 Val_accuracy:  0.925497139743939 Val_cost:  1.2773794403927277 Val_accuracy:  0.925497139743939 Val_Acc:  nan\n",
      "Epoch number: 3664/10000step_number: 0/29 Accuracy:  0.9466371530733867 Loss:  1.2773271617612136 Val_accuracy:  0.9256333424135113 Val_cost:  1.2773271617612136 Val_accuracy:  0.9256333424135113 Val_Acc:  nan\n",
      "Epoch number: 3665/10000step_number: 0/29 Accuracy:  0.946671207219479 Loss:  1.277274596280362 Val_accuracy:  0.9256333424135113 Val_cost:  1.277274596280362 Val_accuracy:  0.9256333424135113 Val_Acc:  nan\n",
      "Epoch number: 3666/10000step_number: 0/29 Accuracy:  0.9465009364890176 Loss:  1.2772213137634472 Val_accuracy:  0.925497139743939 Val_cost:  1.2772213137634472 Val_accuracy:  0.925497139743939 Val_Acc:  nan\n",
      "Epoch number: 3667/10000step_number: 0/29 Accuracy:  0.9465349906351098 Loss:  1.2771670942405886 Val_accuracy:  0.925905747752656 Val_cost:  1.2771670942405886 Val_accuracy:  0.925905747752656 Val_Acc:  nan\n",
      "Epoch number: 3668/10000step_number: 0/29 Accuracy:  0.9465349906351098 Loss:  1.2771120684193005 Val_accuracy:  0.9260419504222283 Val_cost:  1.2771120684193005 Val_accuracy:  0.9260419504222283 Val_Acc:  nan\n",
      "Epoch number: 3669/10000step_number: 0/29 Accuracy:  0.9465690447812021 Loss:  1.277056440402503 Val_accuracy:  0.9260419504222283 Val_cost:  1.277056440402503 Val_accuracy:  0.9260419504222283 Val_Acc:  nan\n",
      "Epoch number: 3670/10000step_number: 0/29 Accuracy:  0.9467733696577558 Loss:  1.2769997994261537 Val_accuracy:  0.9264505584309453 Val_cost:  1.2769997994261537 Val_accuracy:  0.9264505584309453 Val_Acc:  nan\n",
      "Epoch number: 3671/10000step_number: 0/29 Accuracy:  0.9468414779499404 Loss:  1.2769406502472258 Val_accuracy:  0.9264505584309453 Val_cost:  1.2769406502472258 Val_accuracy:  0.9264505584309453 Val_Acc:  nan\n",
      "Epoch number: 3672/10000step_number: 0/29 Accuracy:  0.9468414779499404 Loss:  1.2768771040147582 Val_accuracy:  0.9264505584309453 Val_cost:  1.2768771040147582 Val_accuracy:  0.9264505584309453 Val_Acc:  nan\n",
      "Epoch number: 3673/10000step_number: 0/29 Accuracy:  0.9468755320960327 Loss:  1.2768087305061575 Val_accuracy:  0.9267229637700899 Val_cost:  1.2768087305061575 Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 3674/10000step_number: 0/29 Accuracy:  0.9468414779499404 Loss:  1.2767379291117487 Val_accuracy:  0.9272677744483792 Val_cost:  1.2767379291117487 Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3675/10000step_number: 0/29 Accuracy:  0.9468414779499404 Loss:  1.2766685575705383 Val_accuracy:  0.9271315717788069 Val_cost:  1.2766685575705383 Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3676/10000step_number: 0/29 Accuracy:  0.9470798569725865 Loss:  1.2766018584728214 Val_accuracy:  0.9271315717788069 Val_cost:  1.2766018584728214 Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3677/10000step_number: 0/29 Accuracy:  0.9473182359952325 Loss:  1.2765338836405429 Val_accuracy:  0.9269953691092345 Val_cost:  1.2765338836405429 Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3678/10000step_number: 0/29 Accuracy:  0.9472160735569556 Loss:  1.276458784126513 Val_accuracy:  0.9269953691092345 Val_cost:  1.276458784126513 Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3679/10000step_number: 0/29 Accuracy:  0.947386344287417 Loss:  1.2763765491927461 Val_accuracy:  0.9269953691092345 Val_cost:  1.2763765491927461 Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3680/10000step_number: 0/29 Accuracy:  0.9475566150178785 Loss:  1.2762975002719121 Val_accuracy:  0.9269953691092345 Val_cost:  1.2762975002719121 Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3681/10000step_number: 0/29 Accuracy:  0.9475566150178785 Loss:  1.2762332342766254 Val_accuracy:  0.9271315717788069 Val_cost:  1.2762332342766254 Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3682/10000step_number: 0/29 Accuracy:  0.9477268857483399 Loss:  1.276178961742021 Val_accuracy:  0.9272677744483792 Val_cost:  1.276178961742021 Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3683/10000step_number: 0/29 Accuracy:  0.947863102332709 Loss:  1.2761153031075505 Val_accuracy:  0.9272677744483792 Val_cost:  1.2761153031075505 Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3684/10000step_number: 0/29 Accuracy:  0.9480674272092627 Loss:  1.2760327822778768 Val_accuracy:  0.9274039771179515 Val_cost:  1.2760327822778768 Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 3685/10000step_number: 0/29 Accuracy:  0.9479993189170781 Loss:  1.275948263044796 Val_accuracy:  0.9272677744483792 Val_cost:  1.275948263044796 Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3686/10000step_number: 0/29 Accuracy:  0.9479993189170781 Loss:  1.275896512398035 Val_accuracy:  0.9272677744483792 Val_cost:  1.275896512398035 Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3687/10000step_number: 0/29 Accuracy:  0.947863102332709 Loss:  1.2758732620294952 Val_accuracy:  0.9269953691092345 Val_cost:  1.2758732620294952 Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3688/10000step_number: 0/29 Accuracy:  0.9480674272092627 Loss:  1.2758131451011487 Val_accuracy:  0.9271315717788069 Val_cost:  1.2758131451011487 Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3689/10000step_number: 0/29 Accuracy:  0.9481695896475396 Loss:  1.275701165520558 Val_accuracy:  0.9269953691092345 Val_cost:  1.275701165520558 Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3690/10000step_number: 0/29 Accuracy:  0.9479993189170781 Loss:  1.2756053523499364 Val_accuracy:  0.9268591664396623 Val_cost:  1.2756053523499364 Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3691/10000step_number: 0/29 Accuracy:  0.9479993189170781 Loss:  1.2755827595505094 Val_accuracy:  0.9272677744483792 Val_cost:  1.2755827595505094 Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3692/10000step_number: 0/29 Accuracy:  0.9482376979397241 Loss:  1.275604799914721 Val_accuracy:  0.9275401797875238 Val_cost:  1.275604799914721 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3693/10000step_number: 0/29 Accuracy:  0.9484760769623701 Loss:  1.2755461133341541 Val_accuracy:  0.9279487877962408 Val_cost:  1.2755461133341541 Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3694/10000step_number: 0/29 Accuracy:  0.9484079686701856 Loss:  1.2754074547302403 Val_accuracy:  0.9272677744483792 Val_cost:  1.2754074547302403 Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3695/10000step_number: 0/29 Accuracy:  0.948339860378001 Loss:  1.2753133405677295 Val_accuracy:  0.9271315717788069 Val_cost:  1.2753133405677295 Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3696/10000step_number: 0/29 Accuracy:  0.9484079686701856 Loss:  1.2752725553747284 Val_accuracy:  0.9268591664396623 Val_cost:  1.2752725553747284 Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3697/10000step_number: 0/29 Accuracy:  0.948578239400647 Loss:  1.2751547709770978 Val_accuracy:  0.9271315717788069 Val_cost:  1.2751547709770978 Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3698/10000step_number: 0/29 Accuracy:  0.9484760769623701 Loss:  1.2749357503490657 Val_accuracy:  0.9268591664396623 Val_cost:  1.2749357503490657 Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3699/10000step_number: 0/29 Accuracy:  0.9484079686701856 Loss:  1.2748213826897237 Val_accuracy:  0.9271315717788069 Val_cost:  1.2748213826897237 Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3700/10000step_number: 0/29 Accuracy:  0.9484079686701856 Loss:  1.2746866896479079 Val_accuracy:  0.9274039771179515 Val_cost:  1.2746866896479079 Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 3701/10000step_number: 0/29 Accuracy:  0.9489528350076621 Loss:  1.2744029614211738 Val_accuracy:  0.9276763824570962 Val_cost:  1.2744029614211738 Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3702/10000step_number: 0/29 Accuracy:  0.949770134513877 Loss:  1.2742034369876578 Val_accuracy:  0.9274039771179515 Val_cost:  1.2742034369876578 Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 3703/10000step_number: 0/29 Accuracy:  0.950246892559169 Loss:  1.2754001683549243 Val_accuracy:  0.9279487877962408 Val_cost:  1.2754001683549243 Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3704/10000step_number: 0/29 Accuracy:  0.9498722969521539 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3705/10000step_number: 0/29 Accuracy:  0.9477949940405245 Loss:  nan Val_accuracy:  0.9269953691092345 Val_cost:  nan Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3706/10000step_number: 0/29 Accuracy:  0.9551847437425507 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 3707/10000step_number: 0/29 Accuracy:  0.9338327941426868 Loss:  nan Val_accuracy:  0.9151457368564424 Val_cost:  nan Val_accuracy:  0.9151457368564424 Val_Acc:  nan\n",
      "Epoch number: 3708/10000step_number: 0/29 Accuracy:  0.9473522901413247 Loss:  nan Val_accuracy:  0.9248161263960774 Val_cost:  nan Val_accuracy:  0.9248161263960774 Val_Acc:  nan\n",
      "Epoch number: 3709/10000step_number: 0/29 Accuracy:  0.9495658096373234 Loss:  nan Val_accuracy:  0.9290384091528194 Val_cost:  nan Val_accuracy:  0.9290384091528194 Val_Acc:  nan\n",
      "Epoch number: 3710/10000step_number: 0/29 Accuracy:  0.9562063681253192 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 3711/10000step_number: 0/29 Accuracy:  0.9537544696066746 Loss:  1.2797541410882765 Val_accuracy:  0.9286298011441024 Val_cost:  1.2797541410882765 Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 3712/10000step_number: 0/29 Accuracy:  0.9533117657074749 Loss:  1.2828062236928197 Val_accuracy:  0.9283573958049578 Val_cost:  1.2828062236928197 Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 3713/10000step_number: 0/29 Accuracy:  0.952971224246552 Loss:  1.2838357473977249 Val_accuracy:  0.9282211931353854 Val_cost:  1.2838357473977249 Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 3714/10000step_number: 0/29 Accuracy:  0.9523582496168909 Loss:  1.2842468515640828 Val_accuracy:  0.9269953691092345 Val_cost:  1.2842468515640828 Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3715/10000step_number: 0/29 Accuracy:  0.9517452749872297 Loss:  1.2843673837003529 Val_accuracy:  0.9265867611005175 Val_cost:  1.2843673837003529 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3716/10000step_number: 0/29 Accuracy:  0.9510982462114762 Loss:  1.2843574522178305 Val_accuracy:  0.925905747752656 Val_cost:  1.2843574522178305 Val_accuracy:  0.925905747752656 Val_Acc:  nan\n",
      "Epoch number: 3717/10000step_number: 0/29 Accuracy:  0.9503831091435382 Loss:  1.2842761852906233 Val_accuracy:  0.9256333424135113 Val_cost:  1.2842761852906233 Val_accuracy:  0.9256333424135113 Val_Acc:  nan\n",
      "Epoch number: 3718/10000step_number: 0/29 Accuracy:  0.9500425676826154 Loss:  1.2840848142514625 Val_accuracy:  0.9256333424135113 Val_cost:  1.2840848142514625 Val_accuracy:  0.9256333424135113 Val_Acc:  nan\n",
      "Epoch number: 3719/10000step_number: 0/29 Accuracy:  0.9496339179295079 Loss:  1.283832833138742 Val_accuracy:  0.9252247344047944 Val_cost:  1.283832833138742 Val_accuracy:  0.9252247344047944 Val_Acc:  nan\n",
      "Epoch number: 3720/10000step_number: 0/29 Accuracy:  0.9492252681764005 Loss:  1.283542854071023 Val_accuracy:  0.9252247344047944 Val_cost:  1.283542854071023 Val_accuracy:  0.9252247344047944 Val_Acc:  nan\n",
      "Epoch number: 3721/10000step_number: 0/29 Accuracy:  0.9490890515920314 Loss:  1.2832363474908453 Val_accuracy:  0.9252247344047944 Val_cost:  1.2832363474908453 Val_accuracy:  0.9252247344047944 Val_Acc:  nan\n",
      "Epoch number: 3722/10000step_number: 0/29 Accuracy:  0.9484079686701856 Loss:  1.282932875093437 Val_accuracy:  0.925088531735222 Val_cost:  1.282932875093437 Val_accuracy:  0.925088531735222 Val_Acc:  nan\n",
      "Epoch number: 3723/10000step_number: 0/29 Accuracy:  0.9481695896475396 Loss:  1.282645220377657 Val_accuracy:  0.9249523290656497 Val_cost:  1.282645220377657 Val_accuracy:  0.9249523290656497 Val_Acc:  nan\n",
      "Epoch number: 3724/10000step_number: 0/29 Accuracy:  0.9479312106248936 Loss:  1.2823797790164595 Val_accuracy:  0.9246799237265051 Val_cost:  1.2823797790164595 Val_accuracy:  0.9246799237265051 Val_Acc:  nan\n",
      "Epoch number: 3725/10000step_number: 0/29 Accuracy:  0.9480333730631705 Loss:  1.2821400586531504 Val_accuracy:  0.9248161263960774 Val_cost:  1.2821400586531504 Val_accuracy:  0.9248161263960774 Val_Acc:  nan\n",
      "Epoch number: 3726/10000step_number: 0/29 Accuracy:  0.9479652647709859 Loss:  1.2819256579793565 Val_accuracy:  0.9246799237265051 Val_cost:  1.2819256579793565 Val_accuracy:  0.9246799237265051 Val_Acc:  nan\n",
      "Epoch number: 3727/10000step_number: 0/29 Accuracy:  0.9479312106248936 Loss:  1.281734705788363 Val_accuracy:  0.9245437210569327 Val_cost:  1.281734705788363 Val_accuracy:  0.9245437210569327 Val_Acc:  nan\n",
      "Epoch number: 3728/10000step_number: 0/29 Accuracy:  0.9466030989272944 Loss:  1.2815654039984474 Val_accuracy:  0.9235903023699265 Val_cost:  1.2815654039984474 Val_accuracy:  0.9235903023699265 Val_Acc:  nan\n",
      "Epoch number: 3729/10000step_number: 0/29 Accuracy:  0.9465009364890176 Loss:  1.2814171659942641 Val_accuracy:  0.9235903023699265 Val_cost:  1.2814171659942641 Val_accuracy:  0.9235903023699265 Val_Acc:  nan\n",
      "Epoch number: 3730/10000step_number: 0/29 Accuracy:  0.9465349906351098 Loss:  1.2812895220967397 Val_accuracy:  0.9235903023699265 Val_cost:  1.2812895220967397 Val_accuracy:  0.9235903023699265 Val_Acc:  nan\n",
      "Epoch number: 3731/10000step_number: 0/29 Accuracy:  0.9463987740507407 Loss:  1.2811813789087518 Val_accuracy:  0.9235903023699265 Val_cost:  1.2811813789087518 Val_accuracy:  0.9235903023699265 Val_Acc:  nan\n",
      "Epoch number: 3732/10000step_number: 0/29 Accuracy:  0.9463987740507407 Loss:  1.2810908968979033 Val_accuracy:  0.9235903023699265 Val_cost:  1.2810908968979033 Val_accuracy:  0.9235903023699265 Val_Acc:  nan\n",
      "Epoch number: 3733/10000step_number: 0/29 Accuracy:  0.9463306657585561 Loss:  1.2810157547524683 Val_accuracy:  0.9237265050394988 Val_cost:  1.2810157547524683 Val_accuracy:  0.9237265050394988 Val_Acc:  nan\n",
      "Epoch number: 3734/10000step_number: 0/29 Accuracy:  0.9464328281968329 Loss:  1.2809531352164683 Val_accuracy:  0.9235903023699265 Val_cost:  1.2809531352164683 Val_accuracy:  0.9235903023699265 Val_Acc:  nan\n",
      "Epoch number: 3735/10000step_number: 0/29 Accuracy:  0.9465009364890176 Loss:  1.2808998782942536 Val_accuracy:  0.9237265050394988 Val_cost:  1.2808998782942536 Val_accuracy:  0.9237265050394988 Val_Acc:  nan\n",
      "Epoch number: 3736/10000step_number: 0/29 Accuracy:  0.9464668823429252 Loss:  1.2808528993840427 Val_accuracy:  0.9238627077090711 Val_cost:  1.2808528993840427 Val_accuracy:  0.9238627077090711 Val_Acc:  nan\n",
      "Epoch number: 3737/10000step_number: 0/29 Accuracy:  0.9465690447812021 Loss:  1.2808096407815106 Val_accuracy:  0.9237265050394988 Val_cost:  1.2808096407815106 Val_accuracy:  0.9237265050394988 Val_Acc:  nan\n",
      "Epoch number: 3738/10000step_number: 0/29 Accuracy:  0.9465690447812021 Loss:  1.2807682017282993 Val_accuracy:  0.9237265050394988 Val_cost:  1.2807682017282993 Val_accuracy:  0.9237265050394988 Val_Acc:  nan\n",
      "Epoch number: 3739/10000step_number: 0/29 Accuracy:  0.9467052613655712 Loss:  1.2807272950359843 Val_accuracy:  0.9238627077090711 Val_cost:  1.2807272950359843 Val_accuracy:  0.9238627077090711 Val_Acc:  nan\n",
      "Epoch number: 3740/10000step_number: 0/29 Accuracy:  0.9468074238038481 Loss:  1.280686144286083 Val_accuracy:  0.9239989103786435 Val_cost:  1.280686144286083 Val_accuracy:  0.9239989103786435 Val_Acc:  nan\n",
      "Epoch number: 3741/10000step_number: 0/29 Accuracy:  0.946909586242125 Loss:  1.2806442932812911 Val_accuracy:  0.9239989103786435 Val_cost:  1.2806442932812911 Val_accuracy:  0.9239989103786435 Val_Acc:  nan\n",
      "Epoch number: 3742/10000step_number: 0/29 Accuracy:  0.9470458028264941 Loss:  1.2806013979498867 Val_accuracy:  0.9242713157177881 Val_cost:  1.2806013979498867 Val_accuracy:  0.9242713157177881 Val_Acc:  nan\n",
      "Epoch number: 3743/10000step_number: 0/29 Accuracy:  0.9470458028264941 Loss:  1.280557135863273 Val_accuracy:  0.9245437210569327 Val_cost:  1.280557135863273 Val_accuracy:  0.9245437210569327 Val_Acc:  nan\n",
      "Epoch number: 3744/10000step_number: 0/29 Accuracy:  0.946909586242125 Loss:  1.2805112489952437 Val_accuracy:  0.9246799237265051 Val_cost:  1.2805112489952437 Val_accuracy:  0.9246799237265051 Val_Acc:  nan\n",
      "Epoch number: 3745/10000step_number: 0/29 Accuracy:  0.9469436403882172 Loss:  1.2804636167560461 Val_accuracy:  0.9245437210569327 Val_cost:  1.2804636167560461 Val_accuracy:  0.9245437210569327 Val_Acc:  nan\n",
      "Epoch number: 3746/10000step_number: 0/29 Accuracy:  0.946909586242125 Loss:  1.2804142742602576 Val_accuracy:  0.9248161263960774 Val_cost:  1.2804142742602576 Val_accuracy:  0.9248161263960774 Val_Acc:  nan\n",
      "Epoch number: 3747/10000step_number: 0/29 Accuracy:  0.9468414779499404 Loss:  1.2803633823691403 Val_accuracy:  0.925088531735222 Val_cost:  1.2803633823691403 Val_accuracy:  0.925088531735222 Val_Acc:  nan\n",
      "Epoch number: 3748/10000step_number: 0/29 Accuracy:  0.9468074238038481 Loss:  1.280311187210854 Val_accuracy:  0.9257695450830836 Val_cost:  1.280311187210854 Val_accuracy:  0.9257695450830836 Val_Acc:  nan\n",
      "Epoch number: 3749/10000step_number: 0/29 Accuracy:  0.946909586242125 Loss:  1.2802579865644463 Val_accuracy:  0.9257695450830836 Val_cost:  1.2802579865644463 Val_accuracy:  0.9257695450830836 Val_Acc:  nan\n",
      "Epoch number: 3750/10000step_number: 0/29 Accuracy:  0.9469776945343096 Loss:  1.2802041086514104 Val_accuracy:  0.9257695450830836 Val_cost:  1.2802041086514104 Val_accuracy:  0.9257695450830836 Val_Acc:  nan\n",
      "Epoch number: 3751/10000step_number: 0/29 Accuracy:  0.9470458028264941 Loss:  1.2801499039695396 Val_accuracy:  0.9256333424135113 Val_cost:  1.2801499039695396 Val_accuracy:  0.9256333424135113 Val_Acc:  nan\n",
      "Epoch number: 3752/10000step_number: 0/29 Accuracy:  0.9469776945343096 Loss:  1.2800957454335167 Val_accuracy:  0.9256333424135113 Val_cost:  1.2800957454335167 Val_accuracy:  0.9256333424135113 Val_Acc:  nan\n",
      "Epoch number: 3753/10000step_number: 0/29 Accuracy:  0.9469776945343096 Loss:  1.2800420302470206 Val_accuracy:  0.9260419504222283 Val_cost:  1.2800420302470206 Val_accuracy:  0.9260419504222283 Val_Acc:  nan\n",
      "Epoch number: 3754/10000step_number: 0/29 Accuracy:  0.947147965264771 Loss:  1.2799891786970412 Val_accuracy:  0.9261781530918006 Val_cost:  1.2799891786970412 Val_accuracy:  0.9261781530918006 Val_Acc:  nan\n",
      "Epoch number: 3755/10000step_number: 0/29 Accuracy:  0.9469436403882172 Loss:  1.2799376276676946 Val_accuracy:  0.9261781530918006 Val_cost:  1.2799376276676946 Val_accuracy:  0.9261781530918006 Val_Acc:  nan\n",
      "Epoch number: 3756/10000step_number: 0/29 Accuracy:  0.9469776945343096 Loss:  1.279887818944117 Val_accuracy:  0.9261781530918006 Val_cost:  1.279887818944117 Val_accuracy:  0.9261781530918006 Val_Acc:  nan\n",
      "Epoch number: 3757/10000step_number: 0/29 Accuracy:  0.9470798569725865 Loss:  1.279840184158906 Val_accuracy:  0.9261781530918006 Val_cost:  1.279840184158906 Val_accuracy:  0.9261781530918006 Val_Acc:  nan\n",
      "Epoch number: 3758/10000step_number: 0/29 Accuracy:  0.9470117486804018 Loss:  1.2797951291580143 Val_accuracy:  0.9264505584309453 Val_cost:  1.2797951291580143 Val_accuracy:  0.9264505584309453 Val_Acc:  nan\n",
      "Epoch number: 3759/10000step_number: 0/29 Accuracy:  0.9470798569725865 Loss:  1.2797530203619958 Val_accuracy:  0.9265867611005175 Val_cost:  1.2797530203619958 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3760/10000step_number: 0/29 Accuracy:  0.9471820194108632 Loss:  1.2797141746655207 Val_accuracy:  0.9267229637700899 Val_cost:  1.2797141746655207 Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 3761/10000step_number: 0/29 Accuracy:  0.9472160735569556 Loss:  1.2796788532387855 Val_accuracy:  0.9265867611005175 Val_cost:  1.2796788532387855 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3762/10000step_number: 0/29 Accuracy:  0.9474885067256938 Loss:  1.2796472588300098 Val_accuracy:  0.9265867611005175 Val_cost:  1.2796472588300098 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3763/10000step_number: 0/29 Accuracy:  0.9475225608717861 Loss:  1.2796195359149092 Val_accuracy:  0.9265867611005175 Val_cost:  1.2796195359149092 Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3764/10000step_number: 0/29 Accuracy:  0.9475225608717861 Loss:  1.279595773021049 Val_accuracy:  0.9268591664396623 Val_cost:  1.279595773021049 Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3765/10000step_number: 0/29 Accuracy:  0.9475225608717861 Loss:  1.2795760064815482 Val_accuracy:  0.9268591664396623 Val_cost:  1.2795760064815482 Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3766/10000step_number: 0/29 Accuracy:  0.947624723310063 Loss:  1.279560224701232 Val_accuracy:  0.9269953691092345 Val_cost:  1.279560224701232 Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3767/10000step_number: 0/29 Accuracy:  0.9476587774561552 Loss:  1.2795483719275853 Val_accuracy:  0.9269953691092345 Val_cost:  1.2795483719275853 Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3768/10000step_number: 0/29 Accuracy:  0.9476928316022476 Loss:  1.279540350685714 Val_accuracy:  0.9268591664396623 Val_cost:  1.279540350685714 Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3769/10000step_number: 0/29 Accuracy:  0.9477949940405245 Loss:  1.2795360224603816 Val_accuracy:  0.9268591664396623 Val_cost:  1.2795360224603816 Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3770/10000step_number: 0/29 Accuracy:  0.9478290481866167 Loss:  1.2795352067259351 Val_accuracy:  0.9268591664396623 Val_cost:  1.2795352067259351 Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3771/10000step_number: 0/29 Accuracy:  0.9477949940405245 Loss:  1.2795376788557884 Val_accuracy:  0.9268591664396623 Val_cost:  1.2795376788557884 Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3772/10000step_number: 0/29 Accuracy:  0.9479312106248936 Loss:  1.2795431677059474 Val_accuracy:  0.9271315717788069 Val_cost:  1.2795431677059474 Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3773/10000step_number: 0/29 Accuracy:  0.9479312106248936 Loss:  1.27955135378427 Val_accuracy:  0.9271315717788069 Val_cost:  1.27955135378427 Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3774/10000step_number: 0/29 Accuracy:  0.9479312106248936 Loss:  1.2795618689410964 Val_accuracy:  0.9274039771179515 Val_cost:  1.2795618689410964 Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 3775/10000step_number: 0/29 Accuracy:  0.9479993189170781 Loss:  1.2795742984621976 Val_accuracy:  0.9275401797875238 Val_cost:  1.2795742984621976 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3776/10000step_number: 0/29 Accuracy:  0.9479993189170781 Loss:  1.2795881862743212 Val_accuracy:  0.9275401797875238 Val_cost:  1.2795881862743212 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3777/10000step_number: 0/29 Accuracy:  0.948101481355355 Loss:  1.2796030436336567 Val_accuracy:  0.9275401797875238 Val_cost:  1.2796030436336567 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3778/10000step_number: 0/29 Accuracy:  0.9481695896475396 Loss:  1.2796183611441647 Val_accuracy:  0.9275401797875238 Val_cost:  1.2796183611441647 Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3779/10000step_number: 0/29 Accuracy:  0.9481355355014472 Loss:  1.2796336233110661 Val_accuracy:  0.9276763824570962 Val_cost:  1.2796336233110661 Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3780/10000step_number: 0/29 Accuracy:  0.9482036437936319 Loss:  1.2796483242199845 Val_accuracy:  0.9278125851266685 Val_cost:  1.2796483242199845 Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3781/10000step_number: 0/29 Accuracy:  0.9482376979397241 Loss:  1.2796619825231061 Val_accuracy:  0.9278125851266685 Val_cost:  1.2796619825231061 Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3782/10000step_number: 0/29 Accuracy:  0.948339860378001 Loss:  1.2796741538444756 Val_accuracy:  0.9278125851266685 Val_cost:  1.2796741538444756 Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3783/10000step_number: 0/29 Accuracy:  0.948339860378001 Loss:  1.2796844390080506 Val_accuracy:  0.9280849904658132 Val_cost:  1.2796844390080506 Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 3784/10000step_number: 0/29 Accuracy:  0.948339860378001 Loss:  1.2796924870330193 Val_accuracy:  0.9279487877962408 Val_cost:  1.2796924870330193 Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3785/10000step_number: 0/29 Accuracy:  0.948339860378001 Loss:  1.279697992441753 Val_accuracy:  0.9280849904658132 Val_cost:  1.279697992441753 Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 3786/10000step_number: 0/29 Accuracy:  0.9484079686701856 Loss:  1.279700686932707 Val_accuracy:  0.9283573958049578 Val_cost:  1.279700686932707 Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 3787/10000step_number: 0/29 Accuracy:  0.9485101311084625 Loss:  1.2797003259110766 Val_accuracy:  0.9283573958049578 Val_cost:  1.2797003259110766 Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 3788/10000step_number: 0/29 Accuracy:  0.9484760769623701 Loss:  1.2796966711059021 Val_accuracy:  0.9282211931353854 Val_cost:  1.2796966711059021 Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 3789/10000step_number: 0/29 Accuracy:  0.9486804018389239 Loss:  1.2796894723362457 Val_accuracy:  0.9282211931353854 Val_cost:  1.2796894723362457 Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 3790/10000step_number: 0/29 Accuracy:  0.9486804018389239 Loss:  1.2796784554743785 Val_accuracy:  0.9284935984745301 Val_cost:  1.2796784554743785 Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 3791/10000step_number: 0/29 Accuracy:  0.9487825642772008 Loss:  1.2796633298917195 Val_accuracy:  0.9284935984745301 Val_cost:  1.2796633298917195 Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 3792/10000step_number: 0/29 Accuracy:  0.9488506725693853 Loss:  1.2796438331351665 Val_accuracy:  0.9282211931353854 Val_cost:  1.2796438331351665 Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 3793/10000step_number: 0/29 Accuracy:  0.9489187808615699 Loss:  1.27961982144698 Val_accuracy:  0.9282211931353854 Val_cost:  1.27961982144698 Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 3794/10000step_number: 0/29 Accuracy:  0.9489528350076621 Loss:  1.2795913782116912 Val_accuracy:  0.9280849904658132 Val_cost:  1.2795913782116912 Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 3795/10000step_number: 0/29 Accuracy:  0.9490890515920314 Loss:  1.2795588619069371 Val_accuracy:  0.9280849904658132 Val_cost:  1.2795588619069371 Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 3796/10000step_number: 0/29 Accuracy:  0.9491912140303082 Loss:  1.2795228171016706 Val_accuracy:  0.9279487877962408 Val_cost:  1.2795228171016706 Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3797/10000step_number: 0/29 Accuracy:  0.949293376468585 Loss:  1.2794837769240555 Val_accuracy:  0.9280849904658132 Val_cost:  1.2794837769240555 Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 3798/10000step_number: 0/29 Accuracy:  0.9493274306146774 Loss:  1.2794420970149853 Val_accuracy:  0.9280849904658132 Val_cost:  1.2794420970149853 Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 3799/10000step_number: 0/29 Accuracy:  0.9490890515920314 Loss:  1.2793979254504022 Val_accuracy:  0.9280849904658132 Val_cost:  1.2793979254504022 Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 3800/10000step_number: 0/29 Accuracy:  0.9491912140303082 Loss:  1.2793512779350769 Val_accuracy:  0.9279487877962408 Val_cost:  1.2793512779350769 Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3801/10000step_number: 0/29 Accuracy:  0.9491912140303082 Loss:  1.2793021270338165 Val_accuracy:  0.9279487877962408 Val_cost:  1.2793021270338165 Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3802/10000step_number: 0/29 Accuracy:  0.9492593223224928 Loss:  1.2792504552348534 Val_accuracy:  0.9279487877962408 Val_cost:  1.2792504552348534 Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3803/10000step_number: 0/29 Accuracy:  0.9491912140303082 Loss:  1.2791962731436415 Val_accuracy:  0.9279487877962408 Val_cost:  1.2791962731436415 Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3804/10000step_number: 0/29 Accuracy:  0.9491912140303082 Loss:  1.2791396202441718 Val_accuracy:  0.9282211931353854 Val_cost:  1.2791396202441718 Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 3805/10000step_number: 0/29 Accuracy:  0.9490890515920314 Loss:  1.2790805602392845 Val_accuracy:  0.9282211931353854 Val_cost:  1.2790805602392845 Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 3806/10000step_number: 0/29 Accuracy:  0.9490209432998468 Loss:  1.2790191756283018 Val_accuracy:  0.9282211931353854 Val_cost:  1.2790191756283018 Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 3807/10000step_number: 0/29 Accuracy:  0.9490209432998468 Loss:  1.2789555627474598 Val_accuracy:  0.9282211931353854 Val_cost:  1.2789555627474598 Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 3808/10000step_number: 0/29 Accuracy:  0.9490890515920314 Loss:  1.278889827577987 Val_accuracy:  0.9283573958049578 Val_cost:  1.278889827577987 Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 3809/10000step_number: 0/29 Accuracy:  0.9491231057381236 Loss:  1.2788220824275813 Val_accuracy:  0.9284935984745301 Val_cost:  1.2788220824275813 Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 3810/10000step_number: 0/29 Accuracy:  0.9491571598842159 Loss:  1.278752443495291 Val_accuracy:  0.9284935984745301 Val_cost:  1.278752443495291 Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 3811/10000step_number: 0/29 Accuracy:  0.9489868891537545 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 3812/10000step_number: 0/29 Accuracy:  0.9489528350076621 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 3813/10000step_number: 0/29 Accuracy:  0.949054997445939 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 3814/10000step_number: 0/29 Accuracy:  0.9491231057381236 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 3815/10000step_number: 0/29 Accuracy:  0.9490890515920314 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 3816/10000step_number: 0/29 Accuracy:  0.9491571598842159 Loss:  nan Val_accuracy:  0.9290384091528194 Val_cost:  nan Val_accuracy:  0.9290384091528194 Val_Acc:  nan\n",
      "Epoch number: 3817/10000step_number: 0/29 Accuracy:  0.9491571598842159 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 3818/10000step_number: 0/29 Accuracy:  0.9491231057381236 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 3819/10000step_number: 0/29 Accuracy:  0.9491231057381236 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 3820/10000step_number: 0/29 Accuracy:  0.9488506725693853 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 3821/10000step_number: 0/29 Accuracy:  0.9488506725693853 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 3822/10000step_number: 0/29 Accuracy:  0.948816618423293 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 3823/10000step_number: 0/29 Accuracy:  0.9487485101311085 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 3824/10000step_number: 0/29 Accuracy:  0.9487825642772008 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 3825/10000step_number: 0/29 Accuracy:  0.9486463476928316 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3826/10000step_number: 0/29 Accuracy:  0.9486122935467393 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3827/10000step_number: 0/29 Accuracy:  0.9486122935467393 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3828/10000step_number: 0/29 Accuracy:  0.9486463476928316 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3829/10000step_number: 0/29 Accuracy:  0.9484760769623701 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3830/10000step_number: 0/29 Accuracy:  0.9485441852545548 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3831/10000step_number: 0/29 Accuracy:  0.948578239400647 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3832/10000step_number: 0/29 Accuracy:  0.9486122935467393 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3833/10000step_number: 0/29 Accuracy:  0.9486122935467393 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3834/10000step_number: 0/29 Accuracy:  0.9486463476928316 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3835/10000step_number: 0/29 Accuracy:  0.9486122935467393 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3836/10000step_number: 0/29 Accuracy:  0.9486122935467393 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3837/10000step_number: 0/29 Accuracy:  0.9486463476928316 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3838/10000step_number: 0/29 Accuracy:  0.9486463476928316 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3839/10000step_number: 0/29 Accuracy:  0.948339860378001 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3840/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3841/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3842/10000step_number: 0/29 Accuracy:  0.9481695896475396 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3843/10000step_number: 0/29 Accuracy:  0.9481695896475396 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3844/10000step_number: 0/29 Accuracy:  0.9483058062319087 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3845/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3846/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3847/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3848/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3849/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3850/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3851/10000step_number: 0/29 Accuracy:  0.948339860378001 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3852/10000step_number: 0/29 Accuracy:  0.948339860378001 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3853/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3854/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3855/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3856/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3857/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3858/10000step_number: 0/29 Accuracy:  0.9482036437936319 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3859/10000step_number: 0/29 Accuracy:  0.948101481355355 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3860/10000step_number: 0/29 Accuracy:  0.948101481355355 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3861/10000step_number: 0/29 Accuracy:  0.948101481355355 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3862/10000step_number: 0/29 Accuracy:  0.9480333730631705 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3863/10000step_number: 0/29 Accuracy:  0.9481355355014472 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3864/10000step_number: 0/29 Accuracy:  0.9481695896475396 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3865/10000step_number: 0/29 Accuracy:  0.9481355355014472 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3866/10000step_number: 0/29 Accuracy:  0.9480674272092627 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3867/10000step_number: 0/29 Accuracy:  0.9481695896475396 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3868/10000step_number: 0/29 Accuracy:  0.9482376979397241 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3869/10000step_number: 0/29 Accuracy:  0.9481355355014472 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3870/10000step_number: 0/29 Accuracy:  0.9482036437936319 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3871/10000step_number: 0/29 Accuracy:  0.9482036437936319 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3872/10000step_number: 0/29 Accuracy:  0.9481695896475396 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3873/10000step_number: 0/29 Accuracy:  0.9482036437936319 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3874/10000step_number: 0/29 Accuracy:  0.9482036437936319 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3875/10000step_number: 0/29 Accuracy:  0.9482036437936319 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3876/10000step_number: 0/29 Accuracy:  0.9482376979397241 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3877/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3878/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3879/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3880/10000step_number: 0/29 Accuracy:  0.9482036437936319 Loss:  nan Val_accuracy:  0.9272677744483792 Val_cost:  nan Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3881/10000step_number: 0/29 Accuracy:  0.9481695896475396 Loss:  nan Val_accuracy:  0.9272677744483792 Val_cost:  nan Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3882/10000step_number: 0/29 Accuracy:  0.9482036437936319 Loss:  nan Val_accuracy:  0.9271315717788069 Val_cost:  nan Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3883/10000step_number: 0/29 Accuracy:  0.9484079686701856 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3884/10000step_number: 0/29 Accuracy:  0.9484079686701856 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3885/10000step_number: 0/29 Accuracy:  0.948339860378001 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3886/10000step_number: 0/29 Accuracy:  0.9484760769623701 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3887/10000step_number: 0/29 Accuracy:  0.948578239400647 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3888/10000step_number: 0/29 Accuracy:  0.948578239400647 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3889/10000step_number: 0/29 Accuracy:  0.9485101311084625 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3890/10000step_number: 0/29 Accuracy:  0.9484760769623701 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3891/10000step_number: 0/29 Accuracy:  0.9485101311084625 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3892/10000step_number: 0/29 Accuracy:  0.9484420228162779 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3893/10000step_number: 0/29 Accuracy:  0.948339860378001 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3894/10000step_number: 0/29 Accuracy:  0.948339860378001 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3895/10000step_number: 0/29 Accuracy:  0.948339860378001 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3896/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3897/10000step_number: 0/29 Accuracy:  0.9482376979397241 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3898/10000step_number: 0/29 Accuracy:  0.9484420228162779 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 3899/10000step_number: 0/29 Accuracy:  0.948578239400647 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 3900/10000step_number: 0/29 Accuracy:  0.9486804018389239 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 3901/10000step_number: 0/29 Accuracy:  0.9487485101311085 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 3902/10000step_number: 0/29 Accuracy:  0.9486122935467393 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 3903/10000step_number: 0/29 Accuracy:  0.9486804018389239 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 3904/10000step_number: 0/29 Accuracy:  0.9486804018389239 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 3905/10000step_number: 0/29 Accuracy:  0.9486463476928316 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 3906/10000step_number: 0/29 Accuracy:  0.9487485101311085 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 3907/10000step_number: 0/29 Accuracy:  0.9487144559850161 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 3908/10000step_number: 0/29 Accuracy:  0.9487485101311085 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3909/10000step_number: 0/29 Accuracy:  0.9488506725693853 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3910/10000step_number: 0/29 Accuracy:  0.9487485101311085 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3911/10000step_number: 0/29 Accuracy:  0.9489868891537545 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3912/10000step_number: 0/29 Accuracy:  0.9492593223224928 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3913/10000step_number: 0/29 Accuracy:  0.9490890515920314 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3914/10000step_number: 0/29 Accuracy:  0.9486804018389239 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3915/10000step_number: 0/29 Accuracy:  0.9485441852545548 Loss:  nan Val_accuracy:  0.9274039771179515 Val_cost:  nan Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 3916/10000step_number: 0/29 Accuracy:  0.9480674272092627 Loss:  nan Val_accuracy:  0.9268591664396623 Val_cost:  nan Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3917/10000step_number: 0/29 Accuracy:  0.9482036437936319 Loss:  nan Val_accuracy:  0.9267229637700899 Val_cost:  nan Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 3918/10000step_number: 0/29 Accuracy:  0.9482376979397241 Loss:  nan Val_accuracy:  0.9267229637700899 Val_cost:  nan Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 3919/10000step_number: 0/29 Accuracy:  0.9485441852545548 Loss:  nan Val_accuracy:  0.9257695450830836 Val_cost:  nan Val_accuracy:  0.9257695450830836 Val_Acc:  nan\n",
      "Epoch number: 3920/10000step_number: 0/29 Accuracy:  0.9485101311084625 Loss:  nan Val_accuracy:  0.9265867611005175 Val_cost:  nan Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3921/10000step_number: 0/29 Accuracy:  0.9515750042567682 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 3922/10000step_number: 0/29 Accuracy:  0.9536523071683978 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 3923/10000step_number: 0/29 Accuracy:  0.9404392984845905 Loss:  nan Val_accuracy:  0.9163715608825933 Val_cost:  nan Val_accuracy:  0.9163715608825933 Val_Acc:  nan\n",
      "Epoch number: 3924/10000step_number: 0/29 Accuracy:  0.9482717520858165 Loss:  nan Val_accuracy:  0.925905747752656 Val_cost:  nan Val_accuracy:  0.925905747752656 Val_Acc:  nan\n",
      "Epoch number: 3925/10000step_number: 0/29 Accuracy:  0.957840967137749 Loss:  nan Val_accuracy:  0.9342141105965677 Val_cost:  nan Val_accuracy:  0.9342141105965677 Val_Acc:  nan\n",
      "Epoch number: 3926/10000step_number: 0/29 Accuracy:  0.9544696066746127 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 3927/10000step_number: 0/29 Accuracy:  0.9528690618082751 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 3928/10000step_number: 0/29 Accuracy:  0.9520858164481526 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3929/10000step_number: 0/29 Accuracy:  0.9513366252341222 Loss:  nan Val_accuracy:  0.9271315717788069 Val_cost:  nan Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3930/10000step_number: 0/29 Accuracy:  0.9513706793802146 Loss:  nan Val_accuracy:  0.9274039771179515 Val_cost:  nan Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 3931/10000step_number: 0/29 Accuracy:  0.9508939213349226 Loss:  nan Val_accuracy:  0.9271315717788069 Val_cost:  nan Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3932/10000step_number: 0/29 Accuracy:  0.9503831091435382 Loss:  nan Val_accuracy:  0.9274039771179515 Val_cost:  nan Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 3933/10000step_number: 0/29 Accuracy:  0.9504171632896306 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3934/10000step_number: 0/29 Accuracy:  0.9502809467052614 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3935/10000step_number: 0/29 Accuracy:  0.9498722969521539 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3936/10000step_number: 0/29 Accuracy:  0.949770134513877 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3937/10000step_number: 0/29 Accuracy:  0.9497020262216925 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3938/10000step_number: 0/29 Accuracy:  0.9486122935467393 Loss:  nan Val_accuracy:  0.9269953691092345 Val_cost:  nan Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3939/10000step_number: 0/29 Accuracy:  0.9485101311084625 Loss:  nan Val_accuracy:  0.9268591664396623 Val_cost:  nan Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3940/10000step_number: 0/29 Accuracy:  0.948339860378001 Loss:  nan Val_accuracy:  0.9265867611005175 Val_cost:  nan Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3941/10000step_number: 0/29 Accuracy:  0.9481695896475396 Loss:  nan Val_accuracy:  0.9265867611005175 Val_cost:  nan Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3942/10000step_number: 0/29 Accuracy:  0.9481355355014472 Loss:  nan Val_accuracy:  0.9267229637700899 Val_cost:  nan Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 3943/10000step_number: 0/29 Accuracy:  0.948101481355355 Loss:  nan Val_accuracy:  0.9268591664396623 Val_cost:  nan Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3944/10000step_number: 0/29 Accuracy:  0.9481695896475396 Loss:  nan Val_accuracy:  0.9271315717788069 Val_cost:  nan Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3945/10000step_number: 0/29 Accuracy:  0.9478971564788012 Loss:  nan Val_accuracy:  0.9272677744483792 Val_cost:  nan Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3946/10000step_number: 0/29 Accuracy:  0.9479312106248936 Loss:  nan Val_accuracy:  0.9269953691092345 Val_cost:  nan Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3947/10000step_number: 0/29 Accuracy:  0.9479993189170781 Loss:  nan Val_accuracy:  0.9272677744483792 Val_cost:  nan Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3948/10000step_number: 0/29 Accuracy:  0.9478971564788012 Loss:  nan Val_accuracy:  0.9268591664396623 Val_cost:  nan Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3949/10000step_number: 0/29 Accuracy:  0.9478290481866167 Loss:  nan Val_accuracy:  0.9265867611005175 Val_cost:  nan Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3950/10000step_number: 0/29 Accuracy:  0.9480333730631705 Loss:  nan Val_accuracy:  0.9269953691092345 Val_cost:  nan Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 3951/10000step_number: 0/29 Accuracy:  0.9482036437936319 Loss:  nan Val_accuracy:  0.9268591664396623 Val_cost:  nan Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3952/10000step_number: 0/29 Accuracy:  0.9483058062319087 Loss:  nan Val_accuracy:  0.9268591664396623 Val_cost:  nan Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3953/10000step_number: 0/29 Accuracy:  0.948339860378001 Loss:  nan Val_accuracy:  0.9268591664396623 Val_cost:  nan Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 3954/10000step_number: 0/29 Accuracy:  0.9479993189170781 Loss:  nan Val_accuracy:  0.9263143557613729 Val_cost:  nan Val_accuracy:  0.9263143557613729 Val_Acc:  nan\n",
      "Epoch number: 3955/10000step_number: 0/29 Accuracy:  0.9481695896475396 Loss:  nan Val_accuracy:  0.9264505584309453 Val_cost:  nan Val_accuracy:  0.9264505584309453 Val_Acc:  nan\n",
      "Epoch number: 3956/10000step_number: 0/29 Accuracy:  0.9484420228162779 Loss:  nan Val_accuracy:  0.9267229637700899 Val_cost:  nan Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 3957/10000step_number: 0/29 Accuracy:  0.9484760769623701 Loss:  nan Val_accuracy:  0.9265867611005175 Val_cost:  nan Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3958/10000step_number: 0/29 Accuracy:  0.948578239400647 Loss:  nan Val_accuracy:  0.9265867611005175 Val_cost:  nan Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3959/10000step_number: 0/29 Accuracy:  0.9487485101311085 Loss:  nan Val_accuracy:  0.9264505584309453 Val_cost:  nan Val_accuracy:  0.9264505584309453 Val_Acc:  nan\n",
      "Epoch number: 3960/10000step_number: 0/29 Accuracy:  0.9487144559850161 Loss:  nan Val_accuracy:  0.9264505584309453 Val_cost:  nan Val_accuracy:  0.9264505584309453 Val_Acc:  nan\n",
      "Epoch number: 3961/10000step_number: 0/29 Accuracy:  0.9486463476928316 Loss:  nan Val_accuracy:  0.9263143557613729 Val_cost:  nan Val_accuracy:  0.9263143557613729 Val_Acc:  nan\n",
      "Epoch number: 3962/10000step_number: 0/29 Accuracy:  0.9486804018389239 Loss:  nan Val_accuracy:  0.9263143557613729 Val_cost:  nan Val_accuracy:  0.9263143557613729 Val_Acc:  nan\n",
      "Epoch number: 3963/10000step_number: 0/29 Accuracy:  0.9486463476928316 Loss:  nan Val_accuracy:  0.9264505584309453 Val_cost:  nan Val_accuracy:  0.9264505584309453 Val_Acc:  nan\n",
      "Epoch number: 3964/10000step_number: 0/29 Accuracy:  0.9486463476928316 Loss:  nan Val_accuracy:  0.9264505584309453 Val_cost:  nan Val_accuracy:  0.9264505584309453 Val_Acc:  nan\n",
      "Epoch number: 3965/10000step_number: 0/29 Accuracy:  0.9486804018389239 Loss:  nan Val_accuracy:  0.9265867611005175 Val_cost:  nan Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3966/10000step_number: 0/29 Accuracy:  0.9487485101311085 Loss:  nan Val_accuracy:  0.9265867611005175 Val_cost:  nan Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3967/10000step_number: 0/29 Accuracy:  0.948816618423293 Loss:  nan Val_accuracy:  0.9265867611005175 Val_cost:  nan Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 3968/10000step_number: 0/29 Accuracy:  0.9487825642772008 Loss:  nan Val_accuracy:  0.9267229637700899 Val_cost:  nan Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 3969/10000step_number: 0/29 Accuracy:  0.9487825642772008 Loss:  nan Val_accuracy:  0.9267229637700899 Val_cost:  nan Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 3970/10000step_number: 0/29 Accuracy:  0.9487485101311085 Loss:  nan Val_accuracy:  0.9271315717788069 Val_cost:  nan Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3971/10000step_number: 0/29 Accuracy:  0.9487485101311085 Loss:  nan Val_accuracy:  0.9271315717788069 Val_cost:  nan Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 3972/10000step_number: 0/29 Accuracy:  0.9487485101311085 Loss:  nan Val_accuracy:  0.9272677744483792 Val_cost:  nan Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 3973/10000step_number: 0/29 Accuracy:  0.9485441852545548 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3974/10000step_number: 0/29 Accuracy:  0.9485441852545548 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3975/10000step_number: 0/29 Accuracy:  0.9486122935467393 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3976/10000step_number: 0/29 Accuracy:  0.9486463476928316 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 3977/10000step_number: 0/29 Accuracy:  0.9484079686701856 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3978/10000step_number: 0/29 Accuracy:  0.9484420228162779 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3979/10000step_number: 0/29 Accuracy:  0.9485101311084625 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3980/10000step_number: 0/29 Accuracy:  0.9485441852545548 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3981/10000step_number: 0/29 Accuracy:  0.9486463476928316 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3982/10000step_number: 0/29 Accuracy:  0.9487825642772008 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 3983/10000step_number: 0/29 Accuracy:  0.9488847267154776 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3984/10000step_number: 0/29 Accuracy:  0.948816618423293 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3985/10000step_number: 0/29 Accuracy:  0.9489187808615699 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3986/10000step_number: 0/29 Accuracy:  0.9489187808615699 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 3987/10000step_number: 0/29 Accuracy:  0.9490209432998468 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3988/10000step_number: 0/29 Accuracy:  0.9490890515920314 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 3989/10000step_number: 0/29 Accuracy:  0.9491571598842159 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 3990/10000step_number: 0/29 Accuracy:  0.9492593223224928 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 3991/10000step_number: 0/29 Accuracy:  0.949293376468585 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 3992/10000step_number: 0/29 Accuracy:  0.9493274306146774 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 3993/10000step_number: 0/29 Accuracy:  0.9493614847607696 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 3994/10000step_number: 0/29 Accuracy:  0.9494295930529542 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 3995/10000step_number: 0/29 Accuracy:  0.9494295930529542 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 3996/10000step_number: 0/29 Accuracy:  0.9493274306146774 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 3997/10000step_number: 0/29 Accuracy:  0.949293376468585 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 3998/10000step_number: 0/29 Accuracy:  0.9493274306146774 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 3999/10000step_number: 0/29 Accuracy:  0.9494295930529542 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4000/10000step_number: 0/29 Accuracy:  0.9493955389068619 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4001/10000step_number: 0/29 Accuracy:  0.9494636471990465 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4002/10000step_number: 0/29 Accuracy:  0.9494295930529542 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4003/10000step_number: 0/29 Accuracy:  0.9494295930529542 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4004/10000step_number: 0/29 Accuracy:  0.9493955389068619 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4005/10000step_number: 0/29 Accuracy:  0.9495658096373234 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4006/10000step_number: 0/29 Accuracy:  0.9494295930529542 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 4007/10000step_number: 0/29 Accuracy:  0.9494636471990465 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 4008/10000step_number: 0/29 Accuracy:  0.9494636471990465 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 4009/10000step_number: 0/29 Accuracy:  0.9496679720756002 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4010/10000step_number: 0/29 Accuracy:  0.9498722969521539 Loss:  nan Val_accuracy:  0.9293108144919641 Val_cost:  nan Val_accuracy:  0.9293108144919641 Val_Acc:  nan\n",
      "Epoch number: 4011/10000step_number: 0/29 Accuracy:  0.9499063510982462 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4012/10000step_number: 0/29 Accuracy:  0.9498722969521539 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 4013/10000step_number: 0/29 Accuracy:  0.9498722969521539 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 4014/10000step_number: 0/29 Accuracy:  0.949770134513877 Loss:  nan Val_accuracy:  0.9290384091528194 Val_cost:  nan Val_accuracy:  0.9290384091528194 Val_Acc:  nan\n",
      "Epoch number: 4015/10000step_number: 0/29 Accuracy:  0.9498722969521539 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4016/10000step_number: 0/29 Accuracy:  0.9499404052443385 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4017/10000step_number: 0/29 Accuracy:  0.9498722969521539 Loss:  nan Val_accuracy:  0.9293108144919641 Val_cost:  nan Val_accuracy:  0.9293108144919641 Val_Acc:  nan\n",
      "Epoch number: 4018/10000step_number: 0/29 Accuracy:  0.9499404052443385 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4019/10000step_number: 0/29 Accuracy:  0.9496679720756002 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4020/10000step_number: 0/29 Accuracy:  0.9497360803677848 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 4021/10000step_number: 0/29 Accuracy:  0.9497360803677848 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4022/10000step_number: 0/29 Accuracy:  0.9496679720756002 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4023/10000step_number: 0/29 Accuracy:  0.9497020262216925 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4024/10000step_number: 0/29 Accuracy:  0.9497360803677848 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4025/10000step_number: 0/29 Accuracy:  0.949770134513877 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4026/10000step_number: 0/29 Accuracy:  0.9498382428060617 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 4027/10000step_number: 0/29 Accuracy:  0.9498722969521539 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4028/10000step_number: 0/29 Accuracy:  0.9498041886599694 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4029/10000step_number: 0/29 Accuracy:  0.9497020262216925 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4030/10000step_number: 0/29 Accuracy:  0.9496679720756002 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4031/10000step_number: 0/29 Accuracy:  0.9496339179295079 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4032/10000step_number: 0/29 Accuracy:  0.9497020262216925 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4033/10000step_number: 0/29 Accuracy:  0.9496339179295079 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4034/10000step_number: 0/29 Accuracy:  0.949770134513877 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 4035/10000step_number: 0/29 Accuracy:  0.9498722969521539 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4036/10000step_number: 0/29 Accuracy:  0.9498041886599694 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4037/10000step_number: 0/29 Accuracy:  0.9498041886599694 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4038/10000step_number: 0/29 Accuracy:  0.9498041886599694 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4039/10000step_number: 0/29 Accuracy:  0.949770134513877 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4040/10000step_number: 0/29 Accuracy:  0.9497360803677848 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4041/10000step_number: 0/29 Accuracy:  0.949770134513877 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4042/10000step_number: 0/29 Accuracy:  0.9496339179295079 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4043/10000step_number: 0/29 Accuracy:  0.9494295930529542 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4044/10000step_number: 0/29 Accuracy:  0.9495998637834157 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4045/10000step_number: 0/29 Accuracy:  0.9495998637834157 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4046/10000step_number: 0/29 Accuracy:  0.9495998637834157 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4047/10000step_number: 0/29 Accuracy:  0.9495998637834157 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4048/10000step_number: 0/29 Accuracy:  0.9495658096373234 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4049/10000step_number: 0/29 Accuracy:  0.949531755491231 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4050/10000step_number: 0/29 Accuracy:  0.949531755491231 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4051/10000step_number: 0/29 Accuracy:  0.9495658096373234 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4052/10000step_number: 0/29 Accuracy:  0.9496679720756002 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4053/10000step_number: 0/29 Accuracy:  0.9496679720756002 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4054/10000step_number: 0/29 Accuracy:  0.9497020262216925 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4055/10000step_number: 0/29 Accuracy:  0.949770134513877 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4056/10000step_number: 0/29 Accuracy:  0.949770134513877 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4057/10000step_number: 0/29 Accuracy:  0.9498041886599694 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4058/10000step_number: 0/29 Accuracy:  0.949770134513877 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 4059/10000step_number: 0/29 Accuracy:  0.9497360803677848 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4060/10000step_number: 0/29 Accuracy:  0.9498382428060617 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4061/10000step_number: 0/29 Accuracy:  0.9498382428060617 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4062/10000step_number: 0/29 Accuracy:  0.9498041886599694 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4063/10000step_number: 0/29 Accuracy:  0.949770134513877 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4064/10000step_number: 0/29 Accuracy:  0.9496679720756002 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4065/10000step_number: 0/29 Accuracy:  0.9497360803677848 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4066/10000step_number: 0/29 Accuracy:  0.9497020262216925 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4067/10000step_number: 0/29 Accuracy:  0.9497020262216925 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4068/10000step_number: 0/29 Accuracy:  0.9497360803677848 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4069/10000step_number: 0/29 Accuracy:  0.9497360803677848 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4070/10000step_number: 0/29 Accuracy:  0.949770134513877 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4071/10000step_number: 0/29 Accuracy:  0.949770134513877 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4072/10000step_number: 0/29 Accuracy:  0.949770134513877 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4073/10000step_number: 0/29 Accuracy:  0.949770134513877 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4074/10000step_number: 0/29 Accuracy:  0.9498382428060617 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4075/10000step_number: 0/29 Accuracy:  0.9498382428060617 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4076/10000step_number: 0/29 Accuracy:  0.949770134513877 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4077/10000step_number: 0/29 Accuracy:  0.9498382428060617 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4078/10000step_number: 0/29 Accuracy:  0.9498382428060617 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4079/10000step_number: 0/29 Accuracy:  0.9498041886599694 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4080/10000step_number: 0/29 Accuracy:  0.9499404052443385 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4081/10000step_number: 0/29 Accuracy:  0.9499744593904308 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4082/10000step_number: 0/29 Accuracy:  0.9499744593904308 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4083/10000step_number: 0/29 Accuracy:  0.9499404052443385 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4084/10000step_number: 0/29 Accuracy:  0.950008513536523 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4085/10000step_number: 0/29 Accuracy:  0.9499744593904308 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4086/10000step_number: 0/29 Accuracy:  0.9504171632896306 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 4087/10000step_number: 0/29 Accuracy:  0.9504171632896306 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 4088/10000step_number: 0/29 Accuracy:  0.9504171632896306 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 4089/10000step_number: 0/29 Accuracy:  0.9505193257279074 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4090/10000step_number: 0/29 Accuracy:  0.9506214881661842 Loss:  nan Val_accuracy:  0.9293108144919641 Val_cost:  nan Val_accuracy:  0.9293108144919641 Val_Acc:  nan\n",
      "Epoch number: 4091/10000step_number: 0/29 Accuracy:  0.9506555423122766 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4092/10000step_number: 0/29 Accuracy:  0.9507577047505534 Loss:  nan Val_accuracy:  0.9290384091528194 Val_cost:  nan Val_accuracy:  0.9290384091528194 Val_Acc:  nan\n",
      "Epoch number: 4093/10000step_number: 0/29 Accuracy:  0.9508939213349226 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4094/10000step_number: 0/29 Accuracy:  0.9509279754810148 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4095/10000step_number: 0/29 Accuracy:  0.9509279754810148 Loss:  nan Val_accuracy:  0.9290384091528194 Val_cost:  nan Val_accuracy:  0.9290384091528194 Val_Acc:  nan\n",
      "Epoch number: 4096/10000step_number: 0/29 Accuracy:  0.9509620296271071 Loss:  nan Val_accuracy:  0.9293108144919641 Val_cost:  nan Val_accuracy:  0.9293108144919641 Val_Acc:  nan\n",
      "Epoch number: 4097/10000step_number: 0/29 Accuracy:  0.9504852715818151 Loss:  nan Val_accuracy:  0.9293108144919641 Val_cost:  nan Val_accuracy:  0.9293108144919641 Val_Acc:  nan\n",
      "Epoch number: 4098/10000step_number: 0/29 Accuracy:  0.9506555423122766 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4099/10000step_number: 0/29 Accuracy:  0.9507236506044611 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4100/10000step_number: 0/29 Accuracy:  0.9511323003575686 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4101/10000step_number: 0/29 Accuracy:  0.9515068959645837 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4102/10000step_number: 0/29 Accuracy:  0.9518133832794142 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4103/10000step_number: 0/29 Accuracy:  0.9536523071683978 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4104/10000step_number: 0/29 Accuracy:  0.9551166354503661 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 4105/10000step_number: 0/29 Accuracy:  0.9568533969010727 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 4106/10000step_number: 0/29 Accuracy:  0.9455814745445258 Loss:  nan Val_accuracy:  0.9219558703350585 Val_cost:  nan Val_accuracy:  0.9219558703350585 Val_Acc:  nan\n",
      "Epoch number: 4107/10000step_number: 0/29 Accuracy:  0.9321641409841648 Loss:  nan Val_accuracy:  0.90738218469082 Val_cost:  nan Val_accuracy:  0.90738218469082 Val_Acc:  nan\n",
      "Epoch number: 4108/10000step_number: 0/29 Accuracy:  0.9539587944832283 Loss:  nan Val_accuracy:  0.9293108144919641 Val_cost:  nan Val_accuracy:  0.9293108144919641 Val_Acc:  nan\n",
      "Epoch number: 4109/10000step_number: 0/29 Accuracy:  0.958556104205687 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 4110/10000step_number: 0/29 Accuracy:  0.9548782564277201 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4111/10000step_number: 0/29 Accuracy:  0.9531414949770135 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 4112/10000step_number: 0/29 Accuracy:  0.9527668993699983 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4113/10000step_number: 0/29 Accuracy:  0.9527668993699983 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4114/10000step_number: 0/29 Accuracy:  0.9525285203473522 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4115/10000step_number: 0/29 Accuracy:  0.9526647369317215 Loss:  nan Val_accuracy:  0.9290384091528194 Val_cost:  nan Val_accuracy:  0.9290384091528194 Val_Acc:  nan\n",
      "Epoch number: 4116/10000step_number: 0/29 Accuracy:  0.9525966286395369 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4117/10000step_number: 0/29 Accuracy:  0.952017708155968 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4118/10000step_number: 0/29 Accuracy:  0.9518133832794142 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4119/10000step_number: 0/29 Accuracy:  0.9516431125489528 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4120/10000step_number: 0/29 Accuracy:  0.9516771666950451 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4121/10000step_number: 0/29 Accuracy:  0.9514387876723991 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4122/10000step_number: 0/29 Accuracy:  0.9513366252341222 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 4123/10000step_number: 0/29 Accuracy:  0.95130257108803 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4124/10000step_number: 0/29 Accuracy:  0.9512004086497531 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 4125/10000step_number: 0/29 Accuracy:  0.9511663545036608 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4126/10000step_number: 0/29 Accuracy:  0.9509960837731994 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4127/10000step_number: 0/29 Accuracy:  0.9509279754810148 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4128/10000step_number: 0/29 Accuracy:  0.9508598671888302 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4129/10000step_number: 0/29 Accuracy:  0.9508598671888302 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4130/10000step_number: 0/29 Accuracy:  0.9506895964583688 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4131/10000step_number: 0/29 Accuracy:  0.9505533798739997 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 4132/10000step_number: 0/29 Accuracy:  0.9504852715818151 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4133/10000step_number: 0/29 Accuracy:  0.9504512174357228 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 4134/10000step_number: 0/29 Accuracy:  0.9504512174357228 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 4135/10000step_number: 0/29 Accuracy:  0.9495998637834157 Loss:  nan Val_accuracy:  0.9272677744483792 Val_cost:  nan Val_accuracy:  0.9272677744483792 Val_Acc:  nan\n",
      "Epoch number: 4136/10000step_number: 0/29 Accuracy:  0.9495658096373234 Loss:  nan Val_accuracy:  0.9274039771179515 Val_cost:  nan Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 4137/10000step_number: 0/29 Accuracy:  0.9493614847607696 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4138/10000step_number: 0/29 Accuracy:  0.9493274306146774 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4139/10000step_number: 0/29 Accuracy:  0.9488847267154776 Loss:  nan Val_accuracy:  0.9271315717788069 Val_cost:  nan Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 4140/10000step_number: 0/29 Accuracy:  0.9487825642772008 Loss:  nan Val_accuracy:  0.9268591664396623 Val_cost:  nan Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 4141/10000step_number: 0/29 Accuracy:  0.9487825642772008 Loss:  nan Val_accuracy:  0.9268591664396623 Val_cost:  nan Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 4142/10000step_number: 0/29 Accuracy:  0.9487825642772008 Loss:  nan Val_accuracy:  0.9268591664396623 Val_cost:  nan Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 4143/10000step_number: 0/29 Accuracy:  0.948816618423293 Loss:  nan Val_accuracy:  0.9268591664396623 Val_cost:  nan Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 4144/10000step_number: 0/29 Accuracy:  0.9490209432998468 Loss:  nan Val_accuracy:  0.9268591664396623 Val_cost:  nan Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 4145/10000step_number: 0/29 Accuracy:  0.9491571598842159 Loss:  nan Val_accuracy:  0.9269953691092345 Val_cost:  nan Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 4146/10000step_number: 0/29 Accuracy:  0.9491912140303082 Loss:  nan Val_accuracy:  0.9269953691092345 Val_cost:  nan Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 4147/10000step_number: 0/29 Accuracy:  0.9493274306146774 Loss:  nan Val_accuracy:  0.9268591664396623 Val_cost:  nan Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 4148/10000step_number: 0/29 Accuracy:  0.9491912140303082 Loss:  nan Val_accuracy:  0.9269953691092345 Val_cost:  nan Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 4149/10000step_number: 0/29 Accuracy:  0.9491912140303082 Loss:  nan Val_accuracy:  0.9269953691092345 Val_cost:  nan Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 4150/10000step_number: 0/29 Accuracy:  0.949054997445939 Loss:  nan Val_accuracy:  0.9271315717788069 Val_cost:  nan Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 4151/10000step_number: 0/29 Accuracy:  0.9489528350076621 Loss:  nan Val_accuracy:  0.9271315717788069 Val_cost:  nan Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 4152/10000step_number: 0/29 Accuracy:  0.9489528350076621 Loss:  nan Val_accuracy:  0.9269953691092345 Val_cost:  nan Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 4153/10000step_number: 0/29 Accuracy:  0.9489868891537545 Loss:  nan Val_accuracy:  0.9267229637700899 Val_cost:  nan Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 4154/10000step_number: 0/29 Accuracy:  0.9490890515920314 Loss:  nan Val_accuracy:  0.9268591664396623 Val_cost:  nan Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 4155/10000step_number: 0/29 Accuracy:  0.9490890515920314 Loss:  nan Val_accuracy:  0.9268591664396623 Val_cost:  nan Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 4156/10000step_number: 0/29 Accuracy:  0.9490890515920314 Loss:  nan Val_accuracy:  0.9267229637700899 Val_cost:  nan Val_accuracy:  0.9267229637700899 Val_Acc:  nan\n",
      "Epoch number: 4157/10000step_number: 0/29 Accuracy:  0.9492252681764005 Loss:  nan Val_accuracy:  0.9268591664396623 Val_cost:  nan Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 4158/10000step_number: 0/29 Accuracy:  0.9491571598842159 Loss:  nan Val_accuracy:  0.9265867611005175 Val_cost:  nan Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 4159/10000step_number: 0/29 Accuracy:  0.949293376468585 Loss:  nan Val_accuracy:  0.9271315717788069 Val_cost:  nan Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 4160/10000step_number: 0/29 Accuracy:  0.9493955389068619 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4161/10000step_number: 0/29 Accuracy:  0.9496339179295079 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4162/10000step_number: 0/29 Accuracy:  0.9497360803677848 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4163/10000step_number: 0/29 Accuracy:  0.9496679720756002 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4164/10000step_number: 0/29 Accuracy:  0.9495998637834157 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4165/10000step_number: 0/29 Accuracy:  0.9496339179295079 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4166/10000step_number: 0/29 Accuracy:  0.9496339179295079 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4167/10000step_number: 0/29 Accuracy:  0.949531755491231 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 4168/10000step_number: 0/29 Accuracy:  0.9495658096373234 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 4169/10000step_number: 0/29 Accuracy:  0.9494977013451388 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4170/10000step_number: 0/29 Accuracy:  0.9497020262216925 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4171/10000step_number: 0/29 Accuracy:  0.9498041886599694 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4172/10000step_number: 0/29 Accuracy:  0.9498382428060617 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4173/10000step_number: 0/29 Accuracy:  0.9499744593904308 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4174/10000step_number: 0/29 Accuracy:  0.950008513536523 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4175/10000step_number: 0/29 Accuracy:  0.9499744593904308 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4176/10000step_number: 0/29 Accuracy:  0.9499744593904308 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 4177/10000step_number: 0/29 Accuracy:  0.9500425676826154 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4178/10000step_number: 0/29 Accuracy:  0.950008513536523 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4179/10000step_number: 0/29 Accuracy:  0.950008513536523 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4180/10000step_number: 0/29 Accuracy:  0.950008513536523 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4181/10000step_number: 0/29 Accuracy:  0.9501447301208922 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4182/10000step_number: 0/29 Accuracy:  0.9502128384130768 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4183/10000step_number: 0/29 Accuracy:  0.9502128384130768 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4184/10000step_number: 0/29 Accuracy:  0.9502128384130768 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4185/10000step_number: 0/29 Accuracy:  0.9502128384130768 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4186/10000step_number: 0/29 Accuracy:  0.950246892559169 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4187/10000step_number: 0/29 Accuracy:  0.9502128384130768 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4188/10000step_number: 0/29 Accuracy:  0.950246892559169 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4189/10000step_number: 0/29 Accuracy:  0.9504171632896306 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4190/10000step_number: 0/29 Accuracy:  0.9505533798739997 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4191/10000step_number: 0/29 Accuracy:  0.9506214881661842 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4192/10000step_number: 0/29 Accuracy:  0.9507236506044611 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4193/10000step_number: 0/29 Accuracy:  0.9507917588966457 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4194/10000step_number: 0/29 Accuracy:  0.9509279754810148 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4195/10000step_number: 0/29 Accuracy:  0.9509960837731994 Loss:  nan Val_accuracy:  0.9290384091528194 Val_cost:  nan Val_accuracy:  0.9290384091528194 Val_Acc:  nan\n",
      "Epoch number: 4196/10000step_number: 0/29 Accuracy:  0.9510301379192917 Loss:  nan Val_accuracy:  0.9290384091528194 Val_cost:  nan Val_accuracy:  0.9290384091528194 Val_Acc:  nan\n",
      "Epoch number: 4197/10000step_number: 0/29 Accuracy:  0.951064192065384 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4198/10000step_number: 0/29 Accuracy:  0.9512004086497531 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4199/10000step_number: 0/29 Accuracy:  0.95130257108803 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4200/10000step_number: 0/29 Accuracy:  0.9512685169419377 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4201/10000step_number: 0/29 Accuracy:  0.9512685169419377 Loss:  nan Val_accuracy:  0.9293108144919641 Val_cost:  nan Val_accuracy:  0.9293108144919641 Val_Acc:  nan\n",
      "Epoch number: 4202/10000step_number: 0/29 Accuracy:  0.9512685169419377 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4203/10000step_number: 0/29 Accuracy:  0.9513706793802146 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4204/10000step_number: 0/29 Accuracy:  0.9514387876723991 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4205/10000step_number: 0/29 Accuracy:  0.9514728418184915 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4206/10000step_number: 0/29 Accuracy:  0.951540950110676 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4207/10000step_number: 0/29 Accuracy:  0.951540950110676 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4208/10000step_number: 0/29 Accuracy:  0.951540950110676 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4209/10000step_number: 0/29 Accuracy:  0.9515068959645837 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4210/10000step_number: 0/29 Accuracy:  0.9515068959645837 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4211/10000step_number: 0/29 Accuracy:  0.9514728418184915 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4212/10000step_number: 0/29 Accuracy:  0.9515750042567682 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4213/10000step_number: 0/29 Accuracy:  0.951540950110676 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4214/10000step_number: 0/29 Accuracy:  0.9515750042567682 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4215/10000step_number: 0/29 Accuracy:  0.9516090584028606 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4216/10000step_number: 0/29 Accuracy:  0.9514728418184915 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4217/10000step_number: 0/29 Accuracy:  0.9514387876723991 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4218/10000step_number: 0/29 Accuracy:  0.9514047335263068 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4219/10000step_number: 0/29 Accuracy:  0.9513706793802146 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4220/10000step_number: 0/29 Accuracy:  0.9513706793802146 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4221/10000step_number: 0/29 Accuracy:  0.9513366252341222 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4222/10000step_number: 0/29 Accuracy:  0.95130257108803 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4223/10000step_number: 0/29 Accuracy:  0.95130257108803 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4224/10000step_number: 0/29 Accuracy:  0.95130257108803 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4225/10000step_number: 0/29 Accuracy:  0.9513366252341222 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4226/10000step_number: 0/29 Accuracy:  0.9513706793802146 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4227/10000step_number: 0/29 Accuracy:  0.9513706793802146 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4228/10000step_number: 0/29 Accuracy:  0.9513366252341222 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4229/10000step_number: 0/29 Accuracy:  0.9512685169419377 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4230/10000step_number: 0/29 Accuracy:  0.9513366252341222 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4231/10000step_number: 0/29 Accuracy:  0.95130257108803 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4232/10000step_number: 0/29 Accuracy:  0.9514047335263068 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4233/10000step_number: 0/29 Accuracy:  0.9514047335263068 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4234/10000step_number: 0/29 Accuracy:  0.9513706793802146 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4235/10000step_number: 0/29 Accuracy:  0.9513366252341222 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4236/10000step_number: 0/29 Accuracy:  0.9514387876723991 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4237/10000step_number: 0/29 Accuracy:  0.9514728418184915 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4238/10000step_number: 0/29 Accuracy:  0.9513706793802146 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4239/10000step_number: 0/29 Accuracy:  0.9514387876723991 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4240/10000step_number: 0/29 Accuracy:  0.9514047335263068 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4241/10000step_number: 0/29 Accuracy:  0.9513366252341222 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4242/10000step_number: 0/29 Accuracy:  0.9513706793802146 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4243/10000step_number: 0/29 Accuracy:  0.9514047335263068 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4244/10000step_number: 0/29 Accuracy:  0.9514047335263068 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4245/10000step_number: 0/29 Accuracy:  0.9514047335263068 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4246/10000step_number: 0/29 Accuracy:  0.9513366252341222 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4247/10000step_number: 0/29 Accuracy:  0.95130257108803 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4248/10000step_number: 0/29 Accuracy:  0.95130257108803 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4249/10000step_number: 0/29 Accuracy:  0.95130257108803 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4250/10000step_number: 0/29 Accuracy:  0.95130257108803 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4251/10000step_number: 0/29 Accuracy:  0.9512344627958454 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4252/10000step_number: 0/29 Accuracy:  0.9512004086497531 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4253/10000step_number: 0/29 Accuracy:  0.9512344627958454 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4254/10000step_number: 0/29 Accuracy:  0.9512004086497531 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4255/10000step_number: 0/29 Accuracy:  0.9512004086497531 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4256/10000step_number: 0/29 Accuracy:  0.9512685169419377 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4257/10000step_number: 0/29 Accuracy:  0.95130257108803 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4258/10000step_number: 0/29 Accuracy:  0.9512344627958454 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4259/10000step_number: 0/29 Accuracy:  0.9512004086497531 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4260/10000step_number: 0/29 Accuracy:  0.95130257108803 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4261/10000step_number: 0/29 Accuracy:  0.9513706793802146 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4262/10000step_number: 0/29 Accuracy:  0.9514047335263068 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4263/10000step_number: 0/29 Accuracy:  0.9514728418184915 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4264/10000step_number: 0/29 Accuracy:  0.951540950110676 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4265/10000step_number: 0/29 Accuracy:  0.951540950110676 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4266/10000step_number: 0/29 Accuracy:  0.9515068959645837 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4267/10000step_number: 0/29 Accuracy:  0.951540950110676 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4268/10000step_number: 0/29 Accuracy:  0.9516431125489528 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4269/10000step_number: 0/29 Accuracy:  0.9517452749872297 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4270/10000step_number: 0/29 Accuracy:  0.9518133832794142 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4271/10000step_number: 0/29 Accuracy:  0.951779329133322 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4272/10000step_number: 0/29 Accuracy:  0.951779329133322 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4273/10000step_number: 0/29 Accuracy:  0.9517112208411375 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4274/10000step_number: 0/29 Accuracy:  0.9519836540098757 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4275/10000step_number: 0/29 Accuracy:  0.9519495998637835 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4276/10000step_number: 0/29 Accuracy:  0.952017708155968 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4277/10000step_number: 0/29 Accuracy:  0.9520517623020602 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4278/10000step_number: 0/29 Accuracy:  0.9522220330325217 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4279/10000step_number: 0/29 Accuracy:  0.9523582496168909 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4280/10000step_number: 0/29 Accuracy:  0.9524263579090755 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4281/10000step_number: 0/29 Accuracy:  0.9523241954707986 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4282/10000step_number: 0/29 Accuracy:  0.95249446620126 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4283/10000step_number: 0/29 Accuracy:  0.9525285203473522 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4284/10000step_number: 0/29 Accuracy:  0.9529371701004598 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4285/10000step_number: 0/29 Accuracy:  0.9533117657074749 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4286/10000step_number: 0/29 Accuracy:  0.9535501447301209 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4287/10000step_number: 0/29 Accuracy:  0.9538225778988592 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4288/10000step_number: 0/29 Accuracy:  0.9542652817980589 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4289/10000step_number: 0/29 Accuracy:  0.9544696066746127 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4290/10000step_number: 0/29 Accuracy:  0.9547760939894432 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 4291/10000step_number: 0/29 Accuracy:  0.9549123105738123 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 4292/10000step_number: 0/29 Accuracy:  0.9548101481355356 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 4293/10000step_number: 0/29 Accuracy:  0.9549463647199047 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 4294/10000step_number: 0/29 Accuracy:  0.9546058232589818 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 4295/10000step_number: 0/29 Accuracy:  0.9545377149667972 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4296/10000step_number: 0/29 Accuracy:  0.9549463647199047 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 4297/10000step_number: 0/29 Accuracy:  0.9544696066746127 Loss:  nan Val_accuracy:  0.9316262598746935 Val_cost:  nan Val_accuracy:  0.9316262598746935 Val_Acc:  nan\n",
      "Epoch number: 4298/10000step_number: 0/29 Accuracy:  0.9545377149667972 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4299/10000step_number: 0/29 Accuracy:  0.9546058232589818 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4300/10000step_number: 0/29 Accuracy:  0.9556274476417503 Loss:  nan Val_accuracy:  0.9314900572051212 Val_cost:  nan Val_accuracy:  0.9314900572051212 Val_Acc:  nan\n",
      "Epoch number: 4301/10000step_number: 0/29 Accuracy:  0.9563425847096884 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4302/10000step_number: 0/29 Accuracy:  0.9588285373744253 Loss:  nan Val_accuracy:  0.9314900572051212 Val_cost:  nan Val_accuracy:  0.9314900572051212 Val_Acc:  nan\n",
      "Epoch number: 4303/10000step_number: 0/29 Accuracy:  0.9596798910267325 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 4304/10000step_number: 0/29 Accuracy:  0.9566150178784267 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4305/10000step_number: 0/29 Accuracy:  0.9516431125489528 Loss:  nan Val_accuracy:  0.9256333424135113 Val_cost:  nan Val_accuracy:  0.9256333424135113 Val_Acc:  nan\n",
      "Epoch number: 4306/10000step_number: 0/29 Accuracy:  0.9362506385152393 Loss:  nan Val_accuracy:  0.9113320621084173 Val_cost:  nan Val_accuracy:  0.9113320621084173 Val_Acc:  nan\n",
      "Epoch number: 4307/10000step_number: 0/29 Accuracy:  0.9547079856972587 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4308/10000step_number: 0/29 Accuracy:  0.9558317725183041 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4309/10000step_number: 0/29 Accuracy:  0.9563085305635961 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4310/10000step_number: 0/29 Accuracy:  0.9542993359441512 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4311/10000step_number: 0/29 Accuracy:  0.9536182530223055 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4312/10000step_number: 0/29 Accuracy:  0.953447982291844 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4313/10000step_number: 0/29 Accuracy:  0.9530393325387366 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 4314/10000step_number: 0/29 Accuracy:  0.9533117657074749 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4315/10000step_number: 0/29 Accuracy:  0.9530393325387366 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4316/10000step_number: 0/29 Accuracy:  0.9528690618082751 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4317/10000step_number: 0/29 Accuracy:  0.9529031159543675 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4318/10000step_number: 0/29 Accuracy:  0.9528350076621829 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4319/10000step_number: 0/29 Accuracy:  0.952732845223906 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4320/10000step_number: 0/29 Accuracy:  0.952732845223906 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4321/10000step_number: 0/29 Accuracy:  0.9526647369317215 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4322/10000step_number: 0/29 Accuracy:  0.9528009535160906 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4323/10000step_number: 0/29 Accuracy:  0.9529031159543675 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4324/10000step_number: 0/29 Accuracy:  0.9526987910778137 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4325/10000step_number: 0/29 Accuracy:  0.9525625744934446 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4326/10000step_number: 0/29 Accuracy:  0.9526647369317215 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4327/10000step_number: 0/29 Accuracy:  0.9526987910778137 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4328/10000step_number: 0/29 Accuracy:  0.9526647369317215 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 4329/10000step_number: 0/29 Accuracy:  0.9525625744934446 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 4330/10000step_number: 0/29 Accuracy:  0.9526647369317215 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4331/10000step_number: 0/29 Accuracy:  0.9525625744934446 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 4332/10000step_number: 0/29 Accuracy:  0.9528009535160906 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4333/10000step_number: 0/29 Accuracy:  0.9525285203473522 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 4334/10000step_number: 0/29 Accuracy:  0.9524263579090755 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 4335/10000step_number: 0/29 Accuracy:  0.9524263579090755 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4336/10000step_number: 0/29 Accuracy:  0.9523582496168909 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4337/10000step_number: 0/29 Accuracy:  0.952017708155968 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4338/10000step_number: 0/29 Accuracy:  0.9519495998637835 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4339/10000step_number: 0/29 Accuracy:  0.9512004086497531 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4340/10000step_number: 0/29 Accuracy:  0.9512004086497531 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4341/10000step_number: 0/29 Accuracy:  0.9512004086497531 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4342/10000step_number: 0/29 Accuracy:  0.9512344627958454 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4343/10000step_number: 0/29 Accuracy:  0.9508598671888302 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 4344/10000step_number: 0/29 Accuracy:  0.9508939213349226 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4345/10000step_number: 0/29 Accuracy:  0.9508258130427379 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4346/10000step_number: 0/29 Accuracy:  0.9508939213349226 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4347/10000step_number: 0/29 Accuracy:  0.9508258130427379 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4348/10000step_number: 0/29 Accuracy:  0.9508939213349226 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 4349/10000step_number: 0/29 Accuracy:  0.9509620296271071 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4350/10000step_number: 0/29 Accuracy:  0.9509620296271071 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 4351/10000step_number: 0/29 Accuracy:  0.9509620296271071 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4352/10000step_number: 0/29 Accuracy:  0.9509620296271071 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4353/10000step_number: 0/29 Accuracy:  0.9509960837731994 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4354/10000step_number: 0/29 Accuracy:  0.9510982462114762 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4355/10000step_number: 0/29 Accuracy:  0.9510301379192917 Loss:  nan Val_accuracy:  0.9274039771179515 Val_cost:  nan Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 4356/10000step_number: 0/29 Accuracy:  0.9510982462114762 Loss:  nan Val_accuracy:  0.9274039771179515 Val_cost:  nan Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 4357/10000step_number: 0/29 Accuracy:  0.9511323003575686 Loss:  nan Val_accuracy:  0.9274039771179515 Val_cost:  nan Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 4358/10000step_number: 0/29 Accuracy:  0.9511663545036608 Loss:  nan Val_accuracy:  0.9274039771179515 Val_cost:  nan Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 4359/10000step_number: 0/29 Accuracy:  0.9508258130427379 Loss:  nan Val_accuracy:  0.9268591664396623 Val_cost:  nan Val_accuracy:  0.9268591664396623 Val_Acc:  nan\n",
      "Epoch number: 4360/10000step_number: 0/29 Accuracy:  0.9508939213349226 Loss:  nan Val_accuracy:  0.9269953691092345 Val_cost:  nan Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 4361/10000step_number: 0/29 Accuracy:  0.9509620296271071 Loss:  nan Val_accuracy:  0.9271315717788069 Val_cost:  nan Val_accuracy:  0.9271315717788069 Val_Acc:  nan\n",
      "Epoch number: 4362/10000step_number: 0/29 Accuracy:  0.9508598671888302 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4363/10000step_number: 0/29 Accuracy:  0.9508598671888302 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4364/10000step_number: 0/29 Accuracy:  0.9510301379192917 Loss:  nan Val_accuracy:  0.9274039771179515 Val_cost:  nan Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 4365/10000step_number: 0/29 Accuracy:  0.9511323003575686 Loss:  nan Val_accuracy:  0.9274039771179515 Val_cost:  nan Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 4366/10000step_number: 0/29 Accuracy:  0.9512344627958454 Loss:  nan Val_accuracy:  0.9274039771179515 Val_cost:  nan Val_accuracy:  0.9274039771179515 Val_Acc:  nan\n",
      "Epoch number: 4367/10000step_number: 0/29 Accuracy:  0.9513366252341222 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4368/10000step_number: 0/29 Accuracy:  0.9513706793802146 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4369/10000step_number: 0/29 Accuracy:  0.9514728418184915 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 4370/10000step_number: 0/29 Accuracy:  0.9515068959645837 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4371/10000step_number: 0/29 Accuracy:  0.9515068959645837 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4372/10000step_number: 0/29 Accuracy:  0.9515750042567682 Loss:  nan Val_accuracy:  0.9279487877962408 Val_cost:  nan Val_accuracy:  0.9279487877962408 Val_Acc:  nan\n",
      "Epoch number: 4373/10000step_number: 0/29 Accuracy:  0.951540950110676 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 4374/10000step_number: 0/29 Accuracy:  0.9515750042567682 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 4375/10000step_number: 0/29 Accuracy:  0.951540950110676 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4376/10000step_number: 0/29 Accuracy:  0.9514728418184915 Loss:  nan Val_accuracy:  0.9276763824570962 Val_cost:  nan Val_accuracy:  0.9276763824570962 Val_Acc:  nan\n",
      "Epoch number: 4377/10000step_number: 0/29 Accuracy:  0.951540950110676 Loss:  nan Val_accuracy:  0.9275401797875238 Val_cost:  nan Val_accuracy:  0.9275401797875238 Val_Acc:  nan\n",
      "Epoch number: 4378/10000step_number: 0/29 Accuracy:  0.9516431125489528 Loss:  nan Val_accuracy:  0.9278125851266685 Val_cost:  nan Val_accuracy:  0.9278125851266685 Val_Acc:  nan\n",
      "Epoch number: 4379/10000step_number: 0/29 Accuracy:  0.9518474374255066 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4380/10000step_number: 0/29 Accuracy:  0.9519836540098757 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4381/10000step_number: 0/29 Accuracy:  0.9520858164481526 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4382/10000step_number: 0/29 Accuracy:  0.9522220330325217 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4383/10000step_number: 0/29 Accuracy:  0.9522901413247062 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 4384/10000step_number: 0/29 Accuracy:  0.9523241954707986 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 4385/10000step_number: 0/29 Accuracy:  0.9523241954707986 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 4386/10000step_number: 0/29 Accuracy:  0.9524263579090755 Loss:  nan Val_accuracy:  0.9290384091528194 Val_cost:  nan Val_accuracy:  0.9290384091528194 Val_Acc:  nan\n",
      "Epoch number: 4387/10000step_number: 0/29 Accuracy:  0.95249446620126 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4388/10000step_number: 0/29 Accuracy:  0.9525285203473522 Loss:  nan Val_accuracy:  0.9293108144919641 Val_cost:  nan Val_accuracy:  0.9293108144919641 Val_Acc:  nan\n",
      "Epoch number: 4389/10000step_number: 0/29 Accuracy:  0.9524263579090755 Loss:  nan Val_accuracy:  0.9293108144919641 Val_cost:  nan Val_accuracy:  0.9293108144919641 Val_Acc:  nan\n",
      "Epoch number: 4390/10000step_number: 0/29 Accuracy:  0.9525966286395369 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4391/10000step_number: 0/29 Accuracy:  0.9526306827856291 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4392/10000step_number: 0/29 Accuracy:  0.9525966286395369 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4393/10000step_number: 0/29 Accuracy:  0.9526987910778137 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4394/10000step_number: 0/29 Accuracy:  0.9528350076621829 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4395/10000step_number: 0/29 Accuracy:  0.9526647369317215 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4396/10000step_number: 0/29 Accuracy:  0.9526987910778137 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4397/10000step_number: 0/29 Accuracy:  0.952732845223906 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4398/10000step_number: 0/29 Accuracy:  0.9526987910778137 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4399/10000step_number: 0/29 Accuracy:  0.9528690618082751 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4400/10000step_number: 0/29 Accuracy:  0.952971224246552 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4401/10000step_number: 0/29 Accuracy:  0.9530393325387366 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4402/10000step_number: 0/29 Accuracy:  0.9530733866848289 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4403/10000step_number: 0/29 Accuracy:  0.9531074408309211 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4404/10000step_number: 0/29 Accuracy:  0.9531755491231058 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4405/10000step_number: 0/29 Accuracy:  0.9532777115613826 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4406/10000step_number: 0/29 Accuracy:  0.9532436574152903 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4407/10000step_number: 0/29 Accuracy:  0.9532777115613826 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4408/10000step_number: 0/29 Accuracy:  0.9533117657074749 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4409/10000step_number: 0/29 Accuracy:  0.9532777115613826 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4410/10000step_number: 0/29 Accuracy:  0.9533117657074749 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4411/10000step_number: 0/29 Accuracy:  0.9533798739996595 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4412/10000step_number: 0/29 Accuracy:  0.9533798739996595 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4413/10000step_number: 0/29 Accuracy:  0.9533798739996595 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4414/10000step_number: 0/29 Accuracy:  0.9534820364379363 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4415/10000step_number: 0/29 Accuracy:  0.953447982291844 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4416/10000step_number: 0/29 Accuracy:  0.9534139281457518 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4417/10000step_number: 0/29 Accuracy:  0.953447982291844 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4418/10000step_number: 0/29 Accuracy:  0.9534820364379363 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4419/10000step_number: 0/29 Accuracy:  0.953447982291844 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4420/10000step_number: 0/29 Accuracy:  0.9534820364379363 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4421/10000step_number: 0/29 Accuracy:  0.9534139281457518 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4422/10000step_number: 0/29 Accuracy:  0.9534820364379363 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4423/10000step_number: 0/29 Accuracy:  0.953447982291844 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4424/10000step_number: 0/29 Accuracy:  0.9534820364379363 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4425/10000step_number: 0/29 Accuracy:  0.953447982291844 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4426/10000step_number: 0/29 Accuracy:  0.9535160905840286 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4427/10000step_number: 0/29 Accuracy:  0.9536182530223055 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4428/10000step_number: 0/29 Accuracy:  0.95368636131449 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4429/10000step_number: 0/29 Accuracy:  0.9537204154605823 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4430/10000step_number: 0/29 Accuracy:  0.9535841988762132 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4431/10000step_number: 0/29 Accuracy:  0.9535841988762132 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4432/10000step_number: 0/29 Accuracy:  0.9534820364379363 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4433/10000step_number: 0/29 Accuracy:  0.9536523071683978 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4434/10000step_number: 0/29 Accuracy:  0.9535501447301209 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4435/10000step_number: 0/29 Accuracy:  0.9535841988762132 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4436/10000step_number: 0/29 Accuracy:  0.9536523071683978 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4437/10000step_number: 0/29 Accuracy:  0.9536182530223055 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4438/10000step_number: 0/29 Accuracy:  0.9537204154605823 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4439/10000step_number: 0/29 Accuracy:  0.9537544696066746 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4440/10000step_number: 0/29 Accuracy:  0.9536523071683978 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4441/10000step_number: 0/29 Accuracy:  0.95368636131449 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4442/10000step_number: 0/29 Accuracy:  0.95368636131449 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4443/10000step_number: 0/29 Accuracy:  0.95368636131449 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4444/10000step_number: 0/29 Accuracy:  0.95368636131449 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4445/10000step_number: 0/29 Accuracy:  0.9537204154605823 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4446/10000step_number: 0/29 Accuracy:  0.9537885237527669 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4447/10000step_number: 0/29 Accuracy:  0.9537544696066746 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4448/10000step_number: 0/29 Accuracy:  0.9537544696066746 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4449/10000step_number: 0/29 Accuracy:  0.9537544696066746 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4450/10000step_number: 0/29 Accuracy:  0.9538225778988592 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4451/10000step_number: 0/29 Accuracy:  0.9538566320449515 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4452/10000step_number: 0/29 Accuracy:  0.9539928486293207 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4453/10000step_number: 0/29 Accuracy:  0.9540269027754129 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4454/10000step_number: 0/29 Accuracy:  0.9540269027754129 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4455/10000step_number: 0/29 Accuracy:  0.9539928486293207 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4456/10000step_number: 0/29 Accuracy:  0.9539587944832283 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4457/10000step_number: 0/29 Accuracy:  0.9538906861910438 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4458/10000step_number: 0/29 Accuracy:  0.9539587944832283 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4459/10000step_number: 0/29 Accuracy:  0.9538906861910438 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4460/10000step_number: 0/29 Accuracy:  0.9538906861910438 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4461/10000step_number: 0/29 Accuracy:  0.953924740337136 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4462/10000step_number: 0/29 Accuracy:  0.9539587944832283 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4463/10000step_number: 0/29 Accuracy:  0.9540269027754129 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4464/10000step_number: 0/29 Accuracy:  0.9539587944832283 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4465/10000step_number: 0/29 Accuracy:  0.954163119359782 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4466/10000step_number: 0/29 Accuracy:  0.9542993359441512 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4467/10000step_number: 0/29 Accuracy:  0.9542312276519667 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4468/10000step_number: 0/29 Accuracy:  0.9542312276519667 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4469/10000step_number: 0/29 Accuracy:  0.9544355525285203 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4470/10000step_number: 0/29 Accuracy:  0.9545377149667972 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4471/10000step_number: 0/29 Accuracy:  0.9545717691128895 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4472/10000step_number: 0/29 Accuracy:  0.954639877405074 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4473/10000step_number: 0/29 Accuracy:  0.9547760939894432 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4474/10000step_number: 0/29 Accuracy:  0.9547760939894432 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4475/10000step_number: 0/29 Accuracy:  0.9548782564277201 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 4476/10000step_number: 0/29 Accuracy:  0.9550825813042738 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 4477/10000step_number: 0/29 Accuracy:  0.9553550144730121 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 4478/10000step_number: 0/29 Accuracy:  0.9553550144730121 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 4479/10000step_number: 0/29 Accuracy:  0.9555593393495658 Loss:  nan Val_accuracy:  0.9314900572051212 Val_cost:  nan Val_accuracy:  0.9314900572051212 Val_Acc:  nan\n",
      "Epoch number: 4480/10000step_number: 0/29 Accuracy:  0.9556615017878427 Loss:  nan Val_accuracy:  0.9314900572051212 Val_cost:  nan Val_accuracy:  0.9314900572051212 Val_Acc:  nan\n",
      "Epoch number: 4481/10000step_number: 0/29 Accuracy:  0.9559679891026732 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4482/10000step_number: 0/29 Accuracy:  0.9561382598331347 Loss:  nan Val_accuracy:  0.9316262598746935 Val_cost:  nan Val_accuracy:  0.9316262598746935 Val_Acc:  nan\n",
      "Epoch number: 4483/10000step_number: 0/29 Accuracy:  0.9568193427549804 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 4484/10000step_number: 0/29 Accuracy:  0.9571939383619956 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 4485/10000step_number: 0/29 Accuracy:  0.9576706964072876 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 4486/10000step_number: 0/29 Accuracy:  0.9580112378682104 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 4487/10000step_number: 0/29 Accuracy:  0.9579431295760259 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 4488/10000step_number: 0/29 Accuracy:  0.9581474544525796 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 4489/10000step_number: 0/29 Accuracy:  0.9580112378682104 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 4490/10000step_number: 0/29 Accuracy:  0.9565469095862421 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4491/10000step_number: 0/29 Accuracy:  0.952971224246552 Loss:  nan Val_accuracy:  0.9252247344047944 Val_cost:  nan Val_accuracy:  0.9252247344047944 Val_Acc:  nan\n",
      "Epoch number: 4492/10000step_number: 0/29 Accuracy:  0.9466371530733867 Loss:  nan Val_accuracy:  0.920049032961046 Val_cost:  nan Val_accuracy:  0.920049032961046 Val_Acc:  nan\n",
      "Epoch number: 4493/10000step_number: 0/29 Accuracy:  0.9603950280946705 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4494/10000step_number: 0/29 Accuracy:  0.9588625915205177 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4495/10000step_number: 0/29 Accuracy:  0.9608377319938702 Loss:  nan Val_accuracy:  0.9361209479705802 Val_cost:  nan Val_accuracy:  0.9361209479705802 Val_Acc:  nan\n",
      "Epoch number: 4496/10000step_number: 0/29 Accuracy:  0.9591009705431637 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4497/10000step_number: 0/29 Accuracy:  0.9557296100800272 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4498/10000step_number: 0/29 Accuracy:  0.9558998808104887 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4499/10000step_number: 0/29 Accuracy:  0.9563425847096884 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4500/10000step_number: 0/29 Accuracy:  0.9555593393495658 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4501/10000step_number: 0/29 Accuracy:  0.9554231227651967 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4502/10000step_number: 0/29 Accuracy:  0.955933934956581 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4503/10000step_number: 0/29 Accuracy:  0.9553209603269198 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4504/10000step_number: 0/29 Accuracy:  0.9551506895964583 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4505/10000step_number: 0/29 Accuracy:  0.9551847437425507 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4506/10000step_number: 0/29 Accuracy:  0.9550825813042738 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4507/10000step_number: 0/29 Accuracy:  0.9550144730120892 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4508/10000step_number: 0/29 Accuracy:  0.9547760939894432 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4509/10000step_number: 0/29 Accuracy:  0.9548782564277201 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4510/10000step_number: 0/29 Accuracy:  0.9548782564277201 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4511/10000step_number: 0/29 Accuracy:  0.9548442022816278 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4512/10000step_number: 0/29 Accuracy:  0.9547420398433509 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4513/10000step_number: 0/29 Accuracy:  0.9546739315511663 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4514/10000step_number: 0/29 Accuracy:  0.9547079856972587 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4515/10000step_number: 0/29 Accuracy:  0.9546739315511663 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4516/10000step_number: 0/29 Accuracy:  0.9545717691128895 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4517/10000step_number: 0/29 Accuracy:  0.9546058232589818 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4518/10000step_number: 0/29 Accuracy:  0.9546058232589818 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4519/10000step_number: 0/29 Accuracy:  0.9545377149667972 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4520/10000step_number: 0/29 Accuracy:  0.9543674442363358 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4521/10000step_number: 0/29 Accuracy:  0.9543333900902435 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4522/10000step_number: 0/29 Accuracy:  0.9543333900902435 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4523/10000step_number: 0/29 Accuracy:  0.9540950110675975 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4524/10000step_number: 0/29 Accuracy:  0.9540950110675975 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4525/10000step_number: 0/29 Accuracy:  0.9540269027754129 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4526/10000step_number: 0/29 Accuracy:  0.9540950110675975 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4527/10000step_number: 0/29 Accuracy:  0.9540269027754129 Loss:  nan Val_accuracy:  0.9293108144919641 Val_cost:  nan Val_accuracy:  0.9293108144919641 Val_Acc:  nan\n",
      "Epoch number: 4528/10000step_number: 0/29 Accuracy:  0.9531414949770135 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4529/10000step_number: 0/29 Accuracy:  0.9530052783926443 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4530/10000step_number: 0/29 Accuracy:  0.9528009535160906 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4531/10000step_number: 0/29 Accuracy:  0.9529031159543675 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4532/10000step_number: 0/29 Accuracy:  0.9529031159543675 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4533/10000step_number: 0/29 Accuracy:  0.9529371701004598 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 4534/10000step_number: 0/29 Accuracy:  0.952971224246552 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 4535/10000step_number: 0/29 Accuracy:  0.9530052783926443 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4536/10000step_number: 0/29 Accuracy:  0.9530733866848289 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 4537/10000step_number: 0/29 Accuracy:  0.9530052783926443 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 4538/10000step_number: 0/29 Accuracy:  0.9529031159543675 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4539/10000step_number: 0/29 Accuracy:  0.952971224246552 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4540/10000step_number: 0/29 Accuracy:  0.952971224246552 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4541/10000step_number: 0/29 Accuracy:  0.952971224246552 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4542/10000step_number: 0/29 Accuracy:  0.9530393325387366 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4543/10000step_number: 0/29 Accuracy:  0.9530393325387366 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4544/10000step_number: 0/29 Accuracy:  0.9531074408309211 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4545/10000step_number: 0/29 Accuracy:  0.953209603269198 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 4546/10000step_number: 0/29 Accuracy:  0.9532777115613826 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 4547/10000step_number: 0/29 Accuracy:  0.9533798739996595 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4548/10000step_number: 0/29 Accuracy:  0.9534139281457518 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4549/10000step_number: 0/29 Accuracy:  0.9535841988762132 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4550/10000step_number: 0/29 Accuracy:  0.9535841988762132 Loss:  nan Val_accuracy:  0.9286298011441024 Val_cost:  nan Val_accuracy:  0.9286298011441024 Val_Acc:  nan\n",
      "Epoch number: 4551/10000step_number: 0/29 Accuracy:  0.9532436574152903 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4552/10000step_number: 0/29 Accuracy:  0.953209603269198 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 4553/10000step_number: 0/29 Accuracy:  0.953209603269198 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4554/10000step_number: 0/29 Accuracy:  0.9528690618082751 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 4555/10000step_number: 0/29 Accuracy:  0.9530052783926443 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4556/10000step_number: 0/29 Accuracy:  0.9530733866848289 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4557/10000step_number: 0/29 Accuracy:  0.9531414949770135 Loss:  nan Val_accuracy:  0.9280849904658132 Val_cost:  nan Val_accuracy:  0.9280849904658132 Val_Acc:  nan\n",
      "Epoch number: 4558/10000step_number: 0/29 Accuracy:  0.9531414949770135 Loss:  nan Val_accuracy:  0.9282211931353854 Val_cost:  nan Val_accuracy:  0.9282211931353854 Val_Acc:  nan\n",
      "Epoch number: 4559/10000step_number: 0/29 Accuracy:  0.9531755491231058 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4560/10000step_number: 0/29 Accuracy:  0.953209603269198 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4561/10000step_number: 0/29 Accuracy:  0.953209603269198 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4562/10000step_number: 0/29 Accuracy:  0.953209603269198 Loss:  nan Val_accuracy:  0.9283573958049578 Val_cost:  nan Val_accuracy:  0.9283573958049578 Val_Acc:  nan\n",
      "Epoch number: 4563/10000step_number: 0/29 Accuracy:  0.9532436574152903 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 4564/10000step_number: 0/29 Accuracy:  0.9532436574152903 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 4565/10000step_number: 0/29 Accuracy:  0.9532777115613826 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 4566/10000step_number: 0/29 Accuracy:  0.9532777115613826 Loss:  nan Val_accuracy:  0.9289022064832471 Val_cost:  nan Val_accuracy:  0.9289022064832471 Val_Acc:  nan\n",
      "Epoch number: 4567/10000step_number: 0/29 Accuracy:  0.9532436574152903 Loss:  nan Val_accuracy:  0.9290384091528194 Val_cost:  nan Val_accuracy:  0.9290384091528194 Val_Acc:  nan\n",
      "Epoch number: 4568/10000step_number: 0/29 Accuracy:  0.953209603269198 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4569/10000step_number: 0/29 Accuracy:  0.9531074408309211 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4570/10000step_number: 0/29 Accuracy:  0.9531755491231058 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4571/10000step_number: 0/29 Accuracy:  0.9532436574152903 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4572/10000step_number: 0/29 Accuracy:  0.953209603269198 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4573/10000step_number: 0/29 Accuracy:  0.9531755491231058 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4574/10000step_number: 0/29 Accuracy:  0.9531755491231058 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4575/10000step_number: 0/29 Accuracy:  0.9530393325387366 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4576/10000step_number: 0/29 Accuracy:  0.9530052783926443 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4577/10000step_number: 0/29 Accuracy:  0.9530393325387366 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4578/10000step_number: 0/29 Accuracy:  0.9530393325387366 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4579/10000step_number: 0/29 Accuracy:  0.9530052783926443 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4580/10000step_number: 0/29 Accuracy:  0.9530393325387366 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4581/10000step_number: 0/29 Accuracy:  0.9529371701004598 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4582/10000step_number: 0/29 Accuracy:  0.9531414949770135 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4583/10000step_number: 0/29 Accuracy:  0.9531414949770135 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4584/10000step_number: 0/29 Accuracy:  0.9531755491231058 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4585/10000step_number: 0/29 Accuracy:  0.953209603269198 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4586/10000step_number: 0/29 Accuracy:  0.9532436574152903 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4587/10000step_number: 0/29 Accuracy:  0.9532436574152903 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4588/10000step_number: 0/29 Accuracy:  0.9533798739996595 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4589/10000step_number: 0/29 Accuracy:  0.953447982291844 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4590/10000step_number: 0/29 Accuracy:  0.9535841988762132 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4591/10000step_number: 0/29 Accuracy:  0.9535501447301209 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4592/10000step_number: 0/29 Accuracy:  0.9535841988762132 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4593/10000step_number: 0/29 Accuracy:  0.9538566320449515 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4594/10000step_number: 0/29 Accuracy:  0.9538566320449515 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4595/10000step_number: 0/29 Accuracy:  0.9539587944832283 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4596/10000step_number: 0/29 Accuracy:  0.9539587944832283 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4597/10000step_number: 0/29 Accuracy:  0.9539928486293207 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4598/10000step_number: 0/29 Accuracy:  0.9539587944832283 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4599/10000step_number: 0/29 Accuracy:  0.9539587944832283 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4600/10000step_number: 0/29 Accuracy:  0.9539587944832283 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4601/10000step_number: 0/29 Accuracy:  0.953924740337136 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4602/10000step_number: 0/29 Accuracy:  0.9540609569215052 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4603/10000step_number: 0/29 Accuracy:  0.9540950110675975 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4604/10000step_number: 0/29 Accuracy:  0.9540950110675975 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4605/10000step_number: 0/29 Accuracy:  0.9541290652136898 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4606/10000step_number: 0/29 Accuracy:  0.954163119359782 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4607/10000step_number: 0/29 Accuracy:  0.9541971735058743 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4608/10000step_number: 0/29 Accuracy:  0.9541971735058743 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4609/10000step_number: 0/29 Accuracy:  0.954163119359782 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4610/10000step_number: 0/29 Accuracy:  0.9542312276519667 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4611/10000step_number: 0/29 Accuracy:  0.9542993359441512 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4612/10000step_number: 0/29 Accuracy:  0.954401498382428 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4613/10000step_number: 0/29 Accuracy:  0.954401498382428 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4614/10000step_number: 0/29 Accuracy:  0.9544355525285203 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4615/10000step_number: 0/29 Accuracy:  0.9542993359441512 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4616/10000step_number: 0/29 Accuracy:  0.9542993359441512 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4617/10000step_number: 0/29 Accuracy:  0.9542993359441512 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4618/10000step_number: 0/29 Accuracy:  0.9543333900902435 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4619/10000step_number: 0/29 Accuracy:  0.9543674442363358 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4620/10000step_number: 0/29 Accuracy:  0.9544355525285203 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4621/10000step_number: 0/29 Accuracy:  0.9544696066746127 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4622/10000step_number: 0/29 Accuracy:  0.9545036608207049 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4623/10000step_number: 0/29 Accuracy:  0.9545377149667972 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4624/10000step_number: 0/29 Accuracy:  0.9544355525285203 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4625/10000step_number: 0/29 Accuracy:  0.9544696066746127 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4626/10000step_number: 0/29 Accuracy:  0.9544696066746127 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4627/10000step_number: 0/29 Accuracy:  0.9545377149667972 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4628/10000step_number: 0/29 Accuracy:  0.9545377149667972 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4629/10000step_number: 0/29 Accuracy:  0.9545717691128895 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4630/10000step_number: 0/29 Accuracy:  0.9547079856972587 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4631/10000step_number: 0/29 Accuracy:  0.9548101481355356 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4632/10000step_number: 0/29 Accuracy:  0.9547760939894432 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4633/10000step_number: 0/29 Accuracy:  0.9547079856972587 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4634/10000step_number: 0/29 Accuracy:  0.9546739315511663 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4635/10000step_number: 0/29 Accuracy:  0.954639877405074 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4636/10000step_number: 0/29 Accuracy:  0.9547420398433509 Loss:  nan Val_accuracy:  0.9314900572051212 Val_cost:  nan Val_accuracy:  0.9314900572051212 Val_Acc:  nan\n",
      "Epoch number: 4637/10000step_number: 0/29 Accuracy:  0.9548101481355356 Loss:  nan Val_accuracy:  0.9314900572051212 Val_cost:  nan Val_accuracy:  0.9314900572051212 Val_Acc:  nan\n",
      "Epoch number: 4638/10000step_number: 0/29 Accuracy:  0.9547420398433509 Loss:  nan Val_accuracy:  0.9314900572051212 Val_cost:  nan Val_accuracy:  0.9314900572051212 Val_Acc:  nan\n",
      "Epoch number: 4639/10000step_number: 0/29 Accuracy:  0.9548101481355356 Loss:  nan Val_accuracy:  0.9316262598746935 Val_cost:  nan Val_accuracy:  0.9316262598746935 Val_Acc:  nan\n",
      "Epoch number: 4640/10000step_number: 0/29 Accuracy:  0.9548101481355356 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 4641/10000step_number: 0/29 Accuracy:  0.9548782564277201 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 4642/10000step_number: 0/29 Accuracy:  0.9548782564277201 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 4643/10000step_number: 0/29 Accuracy:  0.9549804188659969 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 4644/10000step_number: 0/29 Accuracy:  0.9549463647199047 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 4645/10000step_number: 0/29 Accuracy:  0.9549123105738123 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 4646/10000step_number: 0/29 Accuracy:  0.9549804188659969 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 4647/10000step_number: 0/29 Accuracy:  0.9549123105738123 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 4648/10000step_number: 0/29 Accuracy:  0.9550485271581816 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 4649/10000step_number: 0/29 Accuracy:  0.9551847437425507 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 4650/10000step_number: 0/29 Accuracy:  0.9551847437425507 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 4651/10000step_number: 0/29 Accuracy:  0.955218797888643 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4652/10000step_number: 0/29 Accuracy:  0.9552528520347352 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 4653/10000step_number: 0/29 Accuracy:  0.9553890686191043 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 4654/10000step_number: 0/29 Accuracy:  0.955695555933935 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4655/10000step_number: 0/29 Accuracy:  0.9557296100800272 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 4656/10000step_number: 0/29 Accuracy:  0.9559679891026732 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 4657/10000step_number: 0/29 Accuracy:  0.9561382598331347 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 4658/10000step_number: 0/29 Accuracy:  0.9561042056870424 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 4659/10000step_number: 0/29 Accuracy:  0.9562404222714116 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 4660/10000step_number: 0/29 Accuracy:  0.9565469095862421 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 4661/10000step_number: 0/29 Accuracy:  0.9569215051932572 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 4662/10000step_number: 0/29 Accuracy:  0.9572279925080879 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 4663/10000step_number: 0/29 Accuracy:  0.9576706964072876 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 4664/10000step_number: 0/29 Accuracy:  0.9580452920143028 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 4665/10000step_number: 0/29 Accuracy:  0.9584539417674102 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 4666/10000step_number: 0/29 Accuracy:  0.9590669163970713 Loss:  nan Val_accuracy:  0.9340779079269954 Val_cost:  nan Val_accuracy:  0.9340779079269954 Val_Acc:  nan\n",
      "Epoch number: 4667/10000step_number: 0/29 Accuracy:  0.9598161076111017 Loss:  nan Val_accuracy:  0.93435031326614 Val_cost:  nan Val_accuracy:  0.93435031326614 Val_Acc:  nan\n",
      "Epoch number: 4668/10000step_number: 0/29 Accuracy:  0.9603609739485782 Loss:  nan Val_accuracy:  0.93435031326614 Val_cost:  nan Val_accuracy:  0.93435031326614 Val_Acc:  nan\n",
      "Epoch number: 4669/10000step_number: 0/29 Accuracy:  0.9607696237016857 Loss:  nan Val_accuracy:  0.9346227186052847 Val_cost:  nan Val_accuracy:  0.9346227186052847 Val_Acc:  nan\n",
      "Epoch number: 4670/10000step_number: 0/29 Accuracy:  0.9594755661501788 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 4671/10000step_number: 0/29 Accuracy:  0.9576706964072876 Loss:  nan Val_accuracy:  0.9314900572051212 Val_cost:  nan Val_accuracy:  0.9314900572051212 Val_Acc:  nan\n",
      "Epoch number: 4672/10000step_number: 0/29 Accuracy:  0.9523582496168909 Loss:  nan Val_accuracy:  0.925497139743939 Val_cost:  nan Val_accuracy:  0.925497139743939 Val_Acc:  nan\n",
      "Epoch number: 4673/10000step_number: 0/29 Accuracy:  0.9488506725693853 Loss:  nan Val_accuracy:  0.9225006810133478 Val_cost:  nan Val_accuracy:  0.9225006810133478 Val_Acc:  nan\n",
      "Epoch number: 4674/10000step_number: 0/29 Accuracy:  0.9582496168908564 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 4675/10000step_number: 0/29 Accuracy:  0.9480333730631705 Loss:  nan Val_accuracy:  0.9220920730046309 Val_cost:  nan Val_accuracy:  0.9220920730046309 Val_Acc:  nan\n",
      "Epoch number: 4676/10000step_number: 0/29 Accuracy:  0.960326919802486 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 4677/10000step_number: 0/29 Accuracy:  0.9593734037119019 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 4678/10000step_number: 0/29 Accuracy:  0.9586582666439639 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4679/10000step_number: 0/29 Accuracy:  0.9576366422611953 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 4680/10000step_number: 0/29 Accuracy:  0.9580112378682104 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 4681/10000step_number: 0/29 Accuracy:  0.9576706964072876 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4682/10000step_number: 0/29 Accuracy:  0.9573982632385493 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 4683/10000step_number: 0/29 Accuracy:  0.9571939383619956 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4684/10000step_number: 0/29 Accuracy:  0.9570577217776264 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4685/10000step_number: 0/29 Accuracy:  0.9570236676315341 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4686/10000step_number: 0/29 Accuracy:  0.9570577217776264 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4687/10000step_number: 0/29 Accuracy:  0.9569555593393496 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4688/10000step_number: 0/29 Accuracy:  0.9566831261706112 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4689/10000step_number: 0/29 Accuracy:  0.9564447471479652 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4690/10000step_number: 0/29 Accuracy:  0.9563425847096884 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4691/10000step_number: 0/29 Accuracy:  0.9561042056870424 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4692/10000step_number: 0/29 Accuracy:  0.9560360973948578 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4693/10000step_number: 0/29 Accuracy:  0.955933934956581 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4694/10000step_number: 0/29 Accuracy:  0.955933934956581 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4695/10000step_number: 0/29 Accuracy:  0.9558998808104887 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4696/10000step_number: 0/29 Accuracy:  0.9558658266643963 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4697/10000step_number: 0/29 Accuracy:  0.9557977183722118 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4698/10000step_number: 0/29 Accuracy:  0.9558317725183041 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4699/10000step_number: 0/29 Accuracy:  0.955933934956581 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4700/10000step_number: 0/29 Accuracy:  0.955933934956581 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4701/10000step_number: 0/29 Accuracy:  0.955933934956581 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4702/10000step_number: 0/29 Accuracy:  0.9558658266643963 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4703/10000step_number: 0/29 Accuracy:  0.9558658266643963 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4704/10000step_number: 0/29 Accuracy:  0.9558658266643963 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4705/10000step_number: 0/29 Accuracy:  0.9557977183722118 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4706/10000step_number: 0/29 Accuracy:  0.9557977183722118 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4707/10000step_number: 0/29 Accuracy:  0.955695555933935 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4708/10000step_number: 0/29 Accuracy:  0.955695555933935 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4709/10000step_number: 0/29 Accuracy:  0.9555933934956581 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4710/10000step_number: 0/29 Accuracy:  0.9555933934956581 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4711/10000step_number: 0/29 Accuracy:  0.9555933934956581 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4712/10000step_number: 0/29 Accuracy:  0.9555593393495658 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4713/10000step_number: 0/29 Accuracy:  0.9556615017878427 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4714/10000step_number: 0/29 Accuracy:  0.9555593393495658 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4715/10000step_number: 0/29 Accuracy:  0.9554231227651967 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4716/10000step_number: 0/29 Accuracy:  0.955218797888643 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4717/10000step_number: 0/29 Accuracy:  0.9551166354503661 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4718/10000step_number: 0/29 Accuracy:  0.9549463647199047 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4719/10000step_number: 0/29 Accuracy:  0.9549123105738123 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4720/10000step_number: 0/29 Accuracy:  0.9548782564277201 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4721/10000step_number: 0/29 Accuracy:  0.9548442022816278 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4722/10000step_number: 0/29 Accuracy:  0.9548782564277201 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4723/10000step_number: 0/29 Accuracy:  0.9550825813042738 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4724/10000step_number: 0/29 Accuracy:  0.9549804188659969 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4725/10000step_number: 0/29 Accuracy:  0.9548782564277201 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4726/10000step_number: 0/29 Accuracy:  0.9550144730120892 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4727/10000step_number: 0/29 Accuracy:  0.9550144730120892 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4728/10000step_number: 0/29 Accuracy:  0.9542652817980589 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4729/10000step_number: 0/29 Accuracy:  0.9542993359441512 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4730/10000step_number: 0/29 Accuracy:  0.9543333900902435 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4731/10000step_number: 0/29 Accuracy:  0.9545036608207049 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4732/10000step_number: 0/29 Accuracy:  0.9545377149667972 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4733/10000step_number: 0/29 Accuracy:  0.9546058232589818 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4734/10000step_number: 0/29 Accuracy:  0.9545717691128895 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4735/10000step_number: 0/29 Accuracy:  0.9546739315511663 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4736/10000step_number: 0/29 Accuracy:  0.9546739315511663 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4737/10000step_number: 0/29 Accuracy:  0.9546739315511663 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4738/10000step_number: 0/29 Accuracy:  0.954639877405074 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4739/10000step_number: 0/29 Accuracy:  0.9547079856972587 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4740/10000step_number: 0/29 Accuracy:  0.954639877405074 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4741/10000step_number: 0/29 Accuracy:  0.9547420398433509 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4742/10000step_number: 0/29 Accuracy:  0.9547079856972587 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4743/10000step_number: 0/29 Accuracy:  0.9547079856972587 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4744/10000step_number: 0/29 Accuracy:  0.9548101481355356 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4745/10000step_number: 0/29 Accuracy:  0.9548101481355356 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4746/10000step_number: 0/29 Accuracy:  0.9548101481355356 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4747/10000step_number: 0/29 Accuracy:  0.9549123105738123 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4748/10000step_number: 0/29 Accuracy:  0.9549804188659969 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4749/10000step_number: 0/29 Accuracy:  0.9549804188659969 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4750/10000step_number: 0/29 Accuracy:  0.9550144730120892 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4751/10000step_number: 0/29 Accuracy:  0.9551166354503661 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4752/10000step_number: 0/29 Accuracy:  0.9549804188659969 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4753/10000step_number: 0/29 Accuracy:  0.9550485271581816 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4754/10000step_number: 0/29 Accuracy:  0.9551166354503661 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4755/10000step_number: 0/29 Accuracy:  0.9551506895964583 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4756/10000step_number: 0/29 Accuracy:  0.9546058232589818 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4757/10000step_number: 0/29 Accuracy:  0.9545717691128895 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4758/10000step_number: 0/29 Accuracy:  0.9546058232589818 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4759/10000step_number: 0/29 Accuracy:  0.9546058232589818 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4760/10000step_number: 0/29 Accuracy:  0.954639877405074 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4761/10000step_number: 0/29 Accuracy:  0.954639877405074 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4762/10000step_number: 0/29 Accuracy:  0.9547420398433509 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4763/10000step_number: 0/29 Accuracy:  0.954401498382428 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4764/10000step_number: 0/29 Accuracy:  0.9543333900902435 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4765/10000step_number: 0/29 Accuracy:  0.9543674442363358 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4766/10000step_number: 0/29 Accuracy:  0.954163119359782 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4767/10000step_number: 0/29 Accuracy:  0.9540950110675975 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4768/10000step_number: 0/29 Accuracy:  0.9542652817980589 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4769/10000step_number: 0/29 Accuracy:  0.9542312276519667 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4770/10000step_number: 0/29 Accuracy:  0.9542312276519667 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4771/10000step_number: 0/29 Accuracy:  0.9542312276519667 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4772/10000step_number: 0/29 Accuracy:  0.9542993359441512 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4773/10000step_number: 0/29 Accuracy:  0.9542652817980589 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4774/10000step_number: 0/29 Accuracy:  0.9543333900902435 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4775/10000step_number: 0/29 Accuracy:  0.9543674442363358 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4776/10000step_number: 0/29 Accuracy:  0.9542652817980589 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4777/10000step_number: 0/29 Accuracy:  0.9541971735058743 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4778/10000step_number: 0/29 Accuracy:  0.954163119359782 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4779/10000step_number: 0/29 Accuracy:  0.9541290652136898 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4780/10000step_number: 0/29 Accuracy:  0.9542993359441512 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4781/10000step_number: 0/29 Accuracy:  0.954401498382428 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4782/10000step_number: 0/29 Accuracy:  0.9545377149667972 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4783/10000step_number: 0/29 Accuracy:  0.9545377149667972 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4784/10000step_number: 0/29 Accuracy:  0.9546739315511663 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4785/10000step_number: 0/29 Accuracy:  0.9547760939894432 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4786/10000step_number: 0/29 Accuracy:  0.9548782564277201 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4787/10000step_number: 0/29 Accuracy:  0.9548101481355356 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4788/10000step_number: 0/29 Accuracy:  0.9548782564277201 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4789/10000step_number: 0/29 Accuracy:  0.9549123105738123 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4790/10000step_number: 0/29 Accuracy:  0.9550144730120892 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4791/10000step_number: 0/29 Accuracy:  0.9550144730120892 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4792/10000step_number: 0/29 Accuracy:  0.9550825813042738 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4793/10000step_number: 0/29 Accuracy:  0.9551847437425507 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4794/10000step_number: 0/29 Accuracy:  0.9551166354503661 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 4795/10000step_number: 0/29 Accuracy:  0.955218797888643 Loss:  nan Val_accuracy:  0.9314900572051212 Val_cost:  nan Val_accuracy:  0.9314900572051212 Val_Acc:  nan\n",
      "Epoch number: 4796/10000step_number: 0/29 Accuracy:  0.9552869061808276 Loss:  nan Val_accuracy:  0.9314900572051212 Val_cost:  nan Val_accuracy:  0.9314900572051212 Val_Acc:  nan\n",
      "Epoch number: 4797/10000step_number: 0/29 Accuracy:  0.9553890686191043 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4798/10000step_number: 0/29 Accuracy:  0.9553890686191043 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4799/10000step_number: 0/29 Accuracy:  0.9554231227651967 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 4800/10000step_number: 0/29 Accuracy:  0.9554912310573812 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 4801/10000step_number: 0/29 Accuracy:  0.955457176911289 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 4802/10000step_number: 0/29 Accuracy:  0.9555933934956581 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 4803/10000step_number: 0/29 Accuracy:  0.9557296100800272 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 4804/10000step_number: 0/29 Accuracy:  0.9557636642261196 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 4805/10000step_number: 0/29 Accuracy:  0.9558317725183041 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 4806/10000step_number: 0/29 Accuracy:  0.955933934956581 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 4807/10000step_number: 0/29 Accuracy:  0.9557977183722118 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 4808/10000step_number: 0/29 Accuracy:  0.9557977183722118 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 4809/10000step_number: 0/29 Accuracy:  0.9559679891026732 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 4810/10000step_number: 0/29 Accuracy:  0.9558998808104887 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 4811/10000step_number: 0/29 Accuracy:  0.955933934956581 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 4812/10000step_number: 0/29 Accuracy:  0.9559679891026732 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 4813/10000step_number: 0/29 Accuracy:  0.9559679891026732 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 4814/10000step_number: 0/29 Accuracy:  0.9560701515409501 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 4815/10000step_number: 0/29 Accuracy:  0.956172313979227 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 4816/10000step_number: 0/29 Accuracy:  0.956172313979227 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 4817/10000step_number: 0/29 Accuracy:  0.9563766388557807 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 4818/10000step_number: 0/29 Accuracy:  0.9563425847096884 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 4819/10000step_number: 0/29 Accuracy:  0.9563425847096884 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 4820/10000step_number: 0/29 Accuracy:  0.9564447471479652 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 4821/10000step_number: 0/29 Accuracy:  0.9565469095862421 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 4822/10000step_number: 0/29 Accuracy:  0.956649072024519 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 4823/10000step_number: 0/29 Accuracy:  0.9567852886088881 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 4824/10000step_number: 0/29 Accuracy:  0.9567852886088881 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 4825/10000step_number: 0/29 Accuracy:  0.9567171803167036 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 4826/10000step_number: 0/29 Accuracy:  0.9567852886088881 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 4827/10000step_number: 0/29 Accuracy:  0.9568533969010727 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 4828/10000step_number: 0/29 Accuracy:  0.9570236676315341 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 4829/10000step_number: 0/29 Accuracy:  0.957125830069811 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 4830/10000step_number: 0/29 Accuracy:  0.9571939383619956 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 4831/10000step_number: 0/29 Accuracy:  0.9570577217776264 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 4832/10000step_number: 0/29 Accuracy:  0.9569215051932572 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 4833/10000step_number: 0/29 Accuracy:  0.9569896134854419 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 4834/10000step_number: 0/29 Accuracy:  0.957125830069811 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 4835/10000step_number: 0/29 Accuracy:  0.9569896134854419 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 4836/10000step_number: 0/29 Accuracy:  0.9569215051932572 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 4837/10000step_number: 0/29 Accuracy:  0.957125830069811 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 4838/10000step_number: 0/29 Accuracy:  0.9571598842159033 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 4839/10000step_number: 0/29 Accuracy:  0.9575004256768261 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 4840/10000step_number: 0/29 Accuracy:  0.9573301549463648 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 4841/10000step_number: 0/29 Accuracy:  0.9574663715307339 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 4842/10000step_number: 0/29 Accuracy:  0.9572279925080879 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 4843/10000step_number: 0/29 Accuracy:  0.9573982632385493 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 4844/10000step_number: 0/29 Accuracy:  0.9575004256768261 Loss:  nan Val_accuracy:  0.9344865159357123 Val_cost:  nan Val_accuracy:  0.9344865159357123 Val_Acc:  nan\n",
      "Epoch number: 4845/10000step_number: 0/29 Accuracy:  0.958079346160395 Loss:  nan Val_accuracy:  0.9350313266140017 Val_cost:  nan Val_accuracy:  0.9350313266140017 Val_Acc:  nan\n",
      "Epoch number: 4846/10000step_number: 0/29 Accuracy:  0.9586582666439639 Loss:  nan Val_accuracy:  0.9357123399618632 Val_cost:  nan Val_accuracy:  0.9357123399618632 Val_Acc:  nan\n",
      "Epoch number: 4847/10000step_number: 0/29 Accuracy:  0.9597139451728248 Loss:  nan Val_accuracy:  0.9354399346227186 Val_cost:  nan Val_accuracy:  0.9354399346227186 Val_Acc:  nan\n",
      "Epoch number: 4848/10000step_number: 0/29 Accuracy:  0.9601225949259322 Loss:  nan Val_accuracy:  0.9346227186052847 Val_cost:  nan Val_accuracy:  0.9346227186052847 Val_Acc:  nan\n",
      "Epoch number: 4849/10000step_number: 0/29 Accuracy:  0.9608717861399625 Loss:  nan Val_accuracy:  0.9344865159357123 Val_cost:  nan Val_accuracy:  0.9344865159357123 Val_Acc:  nan\n",
      "Epoch number: 4850/10000step_number: 0/29 Accuracy:  0.9579090754299336 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 4851/10000step_number: 0/29 Accuracy:  0.9612123276008854 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 4852/10000step_number: 0/29 Accuracy:  0.9372382087519155 Loss:  nan Val_accuracy:  0.911195859438845 Val_cost:  nan Val_accuracy:  0.911195859438845 Val_Acc:  nan\n",
      "Epoch number: 4853/10000step_number: 0/29 Accuracy:  0.9591009705431637 Loss:  nan Val_accuracy:  0.9316262598746935 Val_cost:  nan Val_accuracy:  0.9316262598746935 Val_Acc:  nan\n",
      "Epoch number: 4854/10000step_number: 0/29 Accuracy:  0.9563766388557807 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4855/10000step_number: 0/29 Accuracy:  0.9594755661501788 Loss:  nan Val_accuracy:  0.93435031326614 Val_cost:  nan Val_accuracy:  0.93435031326614 Val_Acc:  nan\n",
      "Epoch number: 4856/10000step_number: 0/29 Accuracy:  0.9585220500595948 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4857/10000step_number: 0/29 Accuracy:  0.960326919802486 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 4858/10000step_number: 0/29 Accuracy:  0.9596798910267325 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 4859/10000step_number: 0/29 Accuracy:  0.958794483228333 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 4860/10000step_number: 0/29 Accuracy:  0.958556104205687 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 4861/10000step_number: 0/29 Accuracy:  0.958079346160395 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4862/10000step_number: 0/29 Accuracy:  0.9580452920143028 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 4863/10000step_number: 0/29 Accuracy:  0.9579771837221182 Loss:  nan Val_accuracy:  0.9316262598746935 Val_cost:  nan Val_accuracy:  0.9316262598746935 Val_Acc:  nan\n",
      "Epoch number: 4864/10000step_number: 0/29 Accuracy:  0.9577047505533799 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 4865/10000step_number: 0/29 Accuracy:  0.9576366422611953 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4866/10000step_number: 0/29 Accuracy:  0.9574663715307339 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4867/10000step_number: 0/29 Accuracy:  0.9573301549463648 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 4868/10000step_number: 0/29 Accuracy:  0.9571598842159033 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4869/10000step_number: 0/29 Accuracy:  0.9569896134854419 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4870/10000step_number: 0/29 Accuracy:  0.9569896134854419 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4871/10000step_number: 0/29 Accuracy:  0.956887451047165 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4872/10000step_number: 0/29 Accuracy:  0.9567512344627959 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4873/10000step_number: 0/29 Accuracy:  0.956887451047165 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 4874/10000step_number: 0/29 Accuracy:  0.9569215051932572 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 4875/10000step_number: 0/29 Accuracy:  0.9567852886088881 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4876/10000step_number: 0/29 Accuracy:  0.9567512344627959 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4877/10000step_number: 0/29 Accuracy:  0.9567512344627959 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4878/10000step_number: 0/29 Accuracy:  0.9566831261706112 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4879/10000step_number: 0/29 Accuracy:  0.9567512344627959 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 4880/10000step_number: 0/29 Accuracy:  0.9567171803167036 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 4881/10000step_number: 0/29 Accuracy:  0.956649072024519 Loss:  nan Val_accuracy:  0.9314900572051212 Val_cost:  nan Val_accuracy:  0.9314900572051212 Val_Acc:  nan\n",
      "Epoch number: 4882/10000step_number: 0/29 Accuracy:  0.9566831261706112 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4883/10000step_number: 0/29 Accuracy:  0.9567852886088881 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 4884/10000step_number: 0/29 Accuracy:  0.9567852886088881 Loss:  nan Val_accuracy:  0.9314900572051212 Val_cost:  nan Val_accuracy:  0.9314900572051212 Val_Acc:  nan\n",
      "Epoch number: 4885/10000step_number: 0/29 Accuracy:  0.9568193427549804 Loss:  nan Val_accuracy:  0.9314900572051212 Val_cost:  nan Val_accuracy:  0.9314900572051212 Val_Acc:  nan\n",
      "Epoch number: 4886/10000step_number: 0/29 Accuracy:  0.9567852886088881 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 4887/10000step_number: 0/29 Accuracy:  0.9568533969010727 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4888/10000step_number: 0/29 Accuracy:  0.9568533969010727 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4889/10000step_number: 0/29 Accuracy:  0.9568193427549804 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4890/10000step_number: 0/29 Accuracy:  0.9566831261706112 Loss:  nan Val_accuracy:  0.9314900572051212 Val_cost:  nan Val_accuracy:  0.9314900572051212 Val_Acc:  nan\n",
      "Epoch number: 4891/10000step_number: 0/29 Accuracy:  0.956649072024519 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 4892/10000step_number: 0/29 Accuracy:  0.956649072024519 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4893/10000step_number: 0/29 Accuracy:  0.9564788012940576 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4894/10000step_number: 0/29 Accuracy:  0.9564788012940576 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4895/10000step_number: 0/29 Accuracy:  0.956649072024519 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4896/10000step_number: 0/29 Accuracy:  0.9566831261706112 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4897/10000step_number: 0/29 Accuracy:  0.9565128554401499 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4898/10000step_number: 0/29 Accuracy:  0.9565469095862421 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4899/10000step_number: 0/29 Accuracy:  0.9565469095862421 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4900/10000step_number: 0/29 Accuracy:  0.9565128554401499 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4901/10000step_number: 0/29 Accuracy:  0.9564788012940576 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4902/10000step_number: 0/29 Accuracy:  0.9564447471479652 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4903/10000step_number: 0/29 Accuracy:  0.956410693001873 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4904/10000step_number: 0/29 Accuracy:  0.9563425847096884 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4905/10000step_number: 0/29 Accuracy:  0.9563085305635961 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4906/10000step_number: 0/29 Accuracy:  0.9563085305635961 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4907/10000step_number: 0/29 Accuracy:  0.9562744764175038 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4908/10000step_number: 0/29 Accuracy:  0.9563425847096884 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4909/10000step_number: 0/29 Accuracy:  0.9563085305635961 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4910/10000step_number: 0/29 Accuracy:  0.9563085305635961 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4911/10000step_number: 0/29 Accuracy:  0.9563085305635961 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4912/10000step_number: 0/29 Accuracy:  0.9563425847096884 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4913/10000step_number: 0/29 Accuracy:  0.9560701515409501 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4914/10000step_number: 0/29 Accuracy:  0.9560701515409501 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4915/10000step_number: 0/29 Accuracy:  0.956172313979227 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4916/10000step_number: 0/29 Accuracy:  0.9560701515409501 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4917/10000step_number: 0/29 Accuracy:  0.9561382598331347 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4918/10000step_number: 0/29 Accuracy:  0.9561042056870424 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4919/10000step_number: 0/29 Accuracy:  0.9553209603269198 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4920/10000step_number: 0/29 Accuracy:  0.9550144730120892 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4921/10000step_number: 0/29 Accuracy:  0.9550485271581816 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4922/10000step_number: 0/29 Accuracy:  0.9551506895964583 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4923/10000step_number: 0/29 Accuracy:  0.9551847437425507 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4924/10000step_number: 0/29 Accuracy:  0.9550485271581816 Loss:  nan Val_accuracy:  0.9291746118223917 Val_cost:  nan Val_accuracy:  0.9291746118223917 Val_Acc:  nan\n",
      "Epoch number: 4925/10000step_number: 0/29 Accuracy:  0.9550485271581816 Loss:  nan Val_accuracy:  0.9294470171615363 Val_cost:  nan Val_accuracy:  0.9294470171615363 Val_Acc:  nan\n",
      "Epoch number: 4926/10000step_number: 0/29 Accuracy:  0.9551506895964583 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4927/10000step_number: 0/29 Accuracy:  0.955218797888643 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4928/10000step_number: 0/29 Accuracy:  0.9553550144730121 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4929/10000step_number: 0/29 Accuracy:  0.9552869061808276 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4930/10000step_number: 0/29 Accuracy:  0.9552869061808276 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4931/10000step_number: 0/29 Accuracy:  0.9552869061808276 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4932/10000step_number: 0/29 Accuracy:  0.9552869061808276 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4933/10000step_number: 0/29 Accuracy:  0.9553209603269198 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4934/10000step_number: 0/29 Accuracy:  0.9553890686191043 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4935/10000step_number: 0/29 Accuracy:  0.9553890686191043 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4936/10000step_number: 0/29 Accuracy:  0.955457176911289 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4937/10000step_number: 0/29 Accuracy:  0.9554912310573812 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4938/10000step_number: 0/29 Accuracy:  0.9553209603269198 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4939/10000step_number: 0/29 Accuracy:  0.9552869061808276 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4940/10000step_number: 0/29 Accuracy:  0.9553550144730121 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4941/10000step_number: 0/29 Accuracy:  0.9555252852034736 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4942/10000step_number: 0/29 Accuracy:  0.9555252852034736 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4943/10000step_number: 0/29 Accuracy:  0.9555593393495658 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4944/10000step_number: 0/29 Accuracy:  0.9555252852034736 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4945/10000step_number: 0/29 Accuracy:  0.9556615017878427 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4946/10000step_number: 0/29 Accuracy:  0.9556274476417503 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4947/10000step_number: 0/29 Accuracy:  0.9556615017878427 Loss:  nan Val_accuracy:  0.9302642331789703 Val_cost:  nan Val_accuracy:  0.9302642331789703 Val_Acc:  nan\n",
      "Epoch number: 4948/10000step_number: 0/29 Accuracy:  0.9558658266643963 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4949/10000step_number: 0/29 Accuracy:  0.9558998808104887 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4950/10000step_number: 0/29 Accuracy:  0.9558998808104887 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4951/10000step_number: 0/29 Accuracy:  0.9558998808104887 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4952/10000step_number: 0/29 Accuracy:  0.9560360973948578 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4953/10000step_number: 0/29 Accuracy:  0.9562404222714116 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4954/10000step_number: 0/29 Accuracy:  0.9562404222714116 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4955/10000step_number: 0/29 Accuracy:  0.9562404222714116 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4956/10000step_number: 0/29 Accuracy:  0.956172313979227 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4957/10000step_number: 0/29 Accuracy:  0.9562744764175038 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4958/10000step_number: 0/29 Accuracy:  0.955695555933935 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4959/10000step_number: 0/29 Accuracy:  0.9556615017878427 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4960/10000step_number: 0/29 Accuracy:  0.9556274476417503 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4961/10000step_number: 0/29 Accuracy:  0.9557977183722118 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4962/10000step_number: 0/29 Accuracy:  0.9557636642261196 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4963/10000step_number: 0/29 Accuracy:  0.955695555933935 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4964/10000step_number: 0/29 Accuracy:  0.9556615017878427 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 4965/10000step_number: 0/29 Accuracy:  0.9556615017878427 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4966/10000step_number: 0/29 Accuracy:  0.9555593393495658 Loss:  nan Val_accuracy:  0.9299918278398257 Val_cost:  nan Val_accuracy:  0.9299918278398257 Val_Acc:  nan\n",
      "Epoch number: 4967/10000step_number: 0/29 Accuracy:  0.9555252852034736 Loss:  nan Val_accuracy:  0.9298556251702533 Val_cost:  nan Val_accuracy:  0.9298556251702533 Val_Acc:  nan\n",
      "Epoch number: 4968/10000step_number: 0/29 Accuracy:  0.9555933934956581 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4969/10000step_number: 0/29 Accuracy:  0.9554912310573812 Loss:  nan Val_accuracy:  0.929719422500681 Val_cost:  nan Val_accuracy:  0.929719422500681 Val_Acc:  nan\n",
      "Epoch number: 4970/10000step_number: 0/29 Accuracy:  0.9555252852034736 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4971/10000step_number: 0/29 Accuracy:  0.9555252852034736 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4972/10000step_number: 0/29 Accuracy:  0.9556274476417503 Loss:  nan Val_accuracy:  0.930128030509398 Val_cost:  nan Val_accuracy:  0.930128030509398 Val_Acc:  nan\n",
      "Epoch number: 4973/10000step_number: 0/29 Accuracy:  0.9556615017878427 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4974/10000step_number: 0/29 Accuracy:  0.9557296100800272 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4975/10000step_number: 0/29 Accuracy:  0.9558317725183041 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4976/10000step_number: 0/29 Accuracy:  0.9558317725183041 Loss:  nan Val_accuracy:  0.9306728411876872 Val_cost:  nan Val_accuracy:  0.9306728411876872 Val_Acc:  nan\n",
      "Epoch number: 4977/10000step_number: 0/29 Accuracy:  0.9557296100800272 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4978/10000step_number: 0/29 Accuracy:  0.9558658266643963 Loss:  nan Val_accuracy:  0.9308090438572596 Val_cost:  nan Val_accuracy:  0.9308090438572596 Val_Acc:  nan\n",
      "Epoch number: 4979/10000step_number: 0/29 Accuracy:  0.9555933934956581 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4980/10000step_number: 0/29 Accuracy:  0.9556615017878427 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4981/10000step_number: 0/29 Accuracy:  0.9557296100800272 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4982/10000step_number: 0/29 Accuracy:  0.9557636642261196 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 4983/10000step_number: 0/29 Accuracy:  0.9558317725183041 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4984/10000step_number: 0/29 Accuracy:  0.9558317725183041 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4985/10000step_number: 0/29 Accuracy:  0.9559679891026732 Loss:  nan Val_accuracy:  0.930536638518115 Val_cost:  nan Val_accuracy:  0.930536638518115 Val_Acc:  nan\n",
      "Epoch number: 4986/10000step_number: 0/29 Accuracy:  0.9560701515409501 Loss:  nan Val_accuracy:  0.9310814491964042 Val_cost:  nan Val_accuracy:  0.9310814491964042 Val_Acc:  nan\n",
      "Epoch number: 4987/10000step_number: 0/29 Accuracy:  0.9560701515409501 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4988/10000step_number: 0/29 Accuracy:  0.9562063681253192 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4989/10000step_number: 0/29 Accuracy:  0.9562404222714116 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4990/10000step_number: 0/29 Accuracy:  0.9562744764175038 Loss:  nan Val_accuracy:  0.9312176518659766 Val_cost:  nan Val_accuracy:  0.9312176518659766 Val_Acc:  nan\n",
      "Epoch number: 4991/10000step_number: 0/29 Accuracy:  0.9563085305635961 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 4992/10000step_number: 0/29 Accuracy:  0.9564447471479652 Loss:  nan Val_accuracy:  0.9314900572051212 Val_cost:  nan Val_accuracy:  0.9314900572051212 Val_Acc:  nan\n",
      "Epoch number: 4993/10000step_number: 0/29 Accuracy:  0.9564788012940576 Loss:  nan Val_accuracy:  0.9314900572051212 Val_cost:  nan Val_accuracy:  0.9314900572051212 Val_Acc:  nan\n",
      "Epoch number: 4994/10000step_number: 0/29 Accuracy:  0.9564788012940576 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4995/10000step_number: 0/29 Accuracy:  0.9564447471479652 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4996/10000step_number: 0/29 Accuracy:  0.9563425847096884 Loss:  nan Val_accuracy:  0.9316262598746935 Val_cost:  nan Val_accuracy:  0.9316262598746935 Val_Acc:  nan\n",
      "Epoch number: 4997/10000step_number: 0/29 Accuracy:  0.9563766388557807 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4998/10000step_number: 0/29 Accuracy:  0.956410693001873 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 4999/10000step_number: 0/29 Accuracy:  0.956410693001873 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 5000/10000step_number: 0/29 Accuracy:  0.9564447471479652 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5001/10000step_number: 0/29 Accuracy:  0.9564788012940576 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5002/10000step_number: 0/29 Accuracy:  0.9564447471479652 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5003/10000step_number: 0/29 Accuracy:  0.9564788012940576 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5004/10000step_number: 0/29 Accuracy:  0.9564788012940576 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5005/10000step_number: 0/29 Accuracy:  0.9565128554401499 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5006/10000step_number: 0/29 Accuracy:  0.956649072024519 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5007/10000step_number: 0/29 Accuracy:  0.9566831261706112 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5008/10000step_number: 0/29 Accuracy:  0.9566831261706112 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5009/10000step_number: 0/29 Accuracy:  0.956649072024519 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5010/10000step_number: 0/29 Accuracy:  0.9567171803167036 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5011/10000step_number: 0/29 Accuracy:  0.9567512344627959 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5012/10000step_number: 0/29 Accuracy:  0.9567852886088881 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5013/10000step_number: 0/29 Accuracy:  0.9567512344627959 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5014/10000step_number: 0/29 Accuracy:  0.9568533969010727 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5015/10000step_number: 0/29 Accuracy:  0.956887451047165 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5016/10000step_number: 0/29 Accuracy:  0.956887451047165 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5017/10000step_number: 0/29 Accuracy:  0.9569555593393496 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5018/10000step_number: 0/29 Accuracy:  0.9570236676315341 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5019/10000step_number: 0/29 Accuracy:  0.9569555593393496 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5020/10000step_number: 0/29 Accuracy:  0.9569896134854419 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5021/10000step_number: 0/29 Accuracy:  0.9569896134854419 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5022/10000step_number: 0/29 Accuracy:  0.9569215051932572 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5023/10000step_number: 0/29 Accuracy:  0.9569215051932572 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5024/10000step_number: 0/29 Accuracy:  0.9569555593393496 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5025/10000step_number: 0/29 Accuracy:  0.9570236676315341 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5026/10000step_number: 0/29 Accuracy:  0.957125830069811 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5027/10000step_number: 0/29 Accuracy:  0.957125830069811 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5028/10000step_number: 0/29 Accuracy:  0.9570917759237187 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5029/10000step_number: 0/29 Accuracy:  0.957125830069811 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5030/10000step_number: 0/29 Accuracy:  0.9571598842159033 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5031/10000step_number: 0/29 Accuracy:  0.9571598842159033 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5032/10000step_number: 0/29 Accuracy:  0.9571939383619956 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5033/10000step_number: 0/29 Accuracy:  0.9571939383619956 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5034/10000step_number: 0/29 Accuracy:  0.9572279925080879 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5035/10000step_number: 0/29 Accuracy:  0.9571939383619956 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5036/10000step_number: 0/29 Accuracy:  0.9571939383619956 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5037/10000step_number: 0/29 Accuracy:  0.9571598842159033 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5038/10000step_number: 0/29 Accuracy:  0.9571939383619956 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5039/10000step_number: 0/29 Accuracy:  0.9572279925080879 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5040/10000step_number: 0/29 Accuracy:  0.9571939383619956 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5041/10000step_number: 0/29 Accuracy:  0.9571939383619956 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5042/10000step_number: 0/29 Accuracy:  0.9572279925080879 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5043/10000step_number: 0/29 Accuracy:  0.9571939383619956 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5044/10000step_number: 0/29 Accuracy:  0.9571939383619956 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5045/10000step_number: 0/29 Accuracy:  0.9571939383619956 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5046/10000step_number: 0/29 Accuracy:  0.9572279925080879 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5047/10000step_number: 0/29 Accuracy:  0.9571939383619956 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5048/10000step_number: 0/29 Accuracy:  0.9572279925080879 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5049/10000step_number: 0/29 Accuracy:  0.9572279925080879 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5050/10000step_number: 0/29 Accuracy:  0.9571939383619956 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5051/10000step_number: 0/29 Accuracy:  0.9572279925080879 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5052/10000step_number: 0/29 Accuracy:  0.9572620466541801 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5053/10000step_number: 0/29 Accuracy:  0.9572620466541801 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5054/10000step_number: 0/29 Accuracy:  0.957364209092457 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5055/10000step_number: 0/29 Accuracy:  0.9573982632385493 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5056/10000step_number: 0/29 Accuracy:  0.9575004256768261 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5057/10000step_number: 0/29 Accuracy:  0.9574663715307339 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5058/10000step_number: 0/29 Accuracy:  0.9575344798229184 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5059/10000step_number: 0/29 Accuracy:  0.9576706964072876 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5060/10000step_number: 0/29 Accuracy:  0.9576366422611953 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5061/10000step_number: 0/29 Accuracy:  0.9577388046994721 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5062/10000step_number: 0/29 Accuracy:  0.9577047505533799 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5063/10000step_number: 0/29 Accuracy:  0.957602588115103 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5064/10000step_number: 0/29 Accuracy:  0.9577388046994721 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5065/10000step_number: 0/29 Accuracy:  0.9577047505533799 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5066/10000step_number: 0/29 Accuracy:  0.9577047505533799 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5067/10000step_number: 0/29 Accuracy:  0.9576366422611953 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5068/10000step_number: 0/29 Accuracy:  0.9577388046994721 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5069/10000step_number: 0/29 Accuracy:  0.9577388046994721 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5070/10000step_number: 0/29 Accuracy:  0.9578750212838413 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5071/10000step_number: 0/29 Accuracy:  0.9579431295760259 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5072/10000step_number: 0/29 Accuracy:  0.9577388046994721 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5073/10000step_number: 0/29 Accuracy:  0.9577388046994721 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5074/10000step_number: 0/29 Accuracy:  0.9572961008002724 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5075/10000step_number: 0/29 Accuracy:  0.9572279925080879 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 5076/10000step_number: 0/29 Accuracy:  0.957602588115103 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5077/10000step_number: 0/29 Accuracy:  0.9587604290822408 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5078/10000step_number: 0/29 Accuracy:  0.9618253022305465 Loss:  nan Val_accuracy:  0.9372105693271588 Val_cost:  nan Val_accuracy:  0.9372105693271588 Val_Acc:  nan\n",
      "Epoch number: 5079/10000step_number: 0/29 Accuracy:  0.9618934105227311 Loss:  nan Val_accuracy:  0.9377553800054481 Val_cost:  nan Val_accuracy:  0.9377553800054481 Val_Acc:  nan\n",
      "Epoch number: 5080/10000step_number: 0/29 Accuracy:  0.9505874340200919 Loss:  nan Val_accuracy:  0.9265867611005175 Val_cost:  nan Val_accuracy:  0.9265867611005175 Val_Acc:  nan\n",
      "Epoch number: 5081/10000step_number: 0/29 Accuracy:  0.9570236676315341 Loss:  nan Val_accuracy:  0.9295832198311087 Val_cost:  nan Val_accuracy:  0.9295832198311087 Val_Acc:  nan\n",
      "Epoch number: 5082/10000step_number: 0/29 Accuracy:  0.9602588115103013 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 5083/10000step_number: 0/29 Accuracy:  0.9620636812531925 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5084/10000step_number: 0/29 Accuracy:  0.9617231397922698 Loss:  nan Val_accuracy:  0.9348951239444293 Val_cost:  nan Val_accuracy:  0.9348951239444293 Val_Acc:  nan\n",
      "Epoch number: 5085/10000step_number: 0/29 Accuracy:  0.9607696237016857 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5086/10000step_number: 0/29 Accuracy:  0.9602247573642091 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5087/10000step_number: 0/29 Accuracy:  0.9599182700493785 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5088/10000step_number: 0/29 Accuracy:  0.9599523241954708 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5089/10000step_number: 0/29 Accuracy:  0.9600204324876553 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5090/10000step_number: 0/29 Accuracy:  0.9598842159032862 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5091/10000step_number: 0/29 Accuracy:  0.9596798910267325 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5092/10000step_number: 0/29 Accuracy:  0.9593734037119019 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5093/10000step_number: 0/29 Accuracy:  0.9593734037119019 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5094/10000step_number: 0/29 Accuracy:  0.9593052954197173 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5095/10000step_number: 0/29 Accuracy:  0.9593734037119019 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5096/10000step_number: 0/29 Accuracy:  0.9592031329814404 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5097/10000step_number: 0/29 Accuracy:  0.9591690788353482 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5098/10000step_number: 0/29 Accuracy:  0.9591009705431637 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5099/10000step_number: 0/29 Accuracy:  0.9590669163970713 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5100/10000step_number: 0/29 Accuracy:  0.9589306998127022 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5101/10000step_number: 0/29 Accuracy:  0.9588966456666099 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5102/10000step_number: 0/29 Accuracy:  0.9589306998127022 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5103/10000step_number: 0/29 Accuracy:  0.9588625915205177 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5104/10000step_number: 0/29 Accuracy:  0.9580112378682104 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5105/10000step_number: 0/29 Accuracy:  0.9580112378682104 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5106/10000step_number: 0/29 Accuracy:  0.9580452920143028 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5107/10000step_number: 0/29 Accuracy:  0.9578750212838413 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5108/10000step_number: 0/29 Accuracy:  0.9578069129916568 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5109/10000step_number: 0/29 Accuracy:  0.9578069129916568 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5110/10000step_number: 0/29 Accuracy:  0.9578750212838413 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5111/10000step_number: 0/29 Accuracy:  0.9578069129916568 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5112/10000step_number: 0/29 Accuracy:  0.9576706964072876 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5113/10000step_number: 0/29 Accuracy:  0.9577047505533799 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5114/10000step_number: 0/29 Accuracy:  0.9575685339690108 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5115/10000step_number: 0/29 Accuracy:  0.9575685339690108 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5116/10000step_number: 0/29 Accuracy:  0.9575685339690108 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5117/10000step_number: 0/29 Accuracy:  0.9575344798229184 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5118/10000step_number: 0/29 Accuracy:  0.9576366422611953 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5119/10000step_number: 0/29 Accuracy:  0.9576706964072876 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5120/10000step_number: 0/29 Accuracy:  0.9576366422611953 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5121/10000step_number: 0/29 Accuracy:  0.957602588115103 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5122/10000step_number: 0/29 Accuracy:  0.9576706964072876 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5123/10000step_number: 0/29 Accuracy:  0.9577047505533799 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5124/10000step_number: 0/29 Accuracy:  0.9577728588455644 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5125/10000step_number: 0/29 Accuracy:  0.9578750212838413 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5126/10000step_number: 0/29 Accuracy:  0.9579431295760259 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5127/10000step_number: 0/29 Accuracy:  0.9579771837221182 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5128/10000step_number: 0/29 Accuracy:  0.9580452920143028 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5129/10000step_number: 0/29 Accuracy:  0.9581134003064873 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5130/10000step_number: 0/29 Accuracy:  0.9581474544525796 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5131/10000step_number: 0/29 Accuracy:  0.9581134003064873 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5132/10000step_number: 0/29 Accuracy:  0.9581474544525796 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5133/10000step_number: 0/29 Accuracy:  0.9591009705431637 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5134/10000step_number: 0/29 Accuracy:  0.9591350246892559 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5135/10000step_number: 0/29 Accuracy:  0.9591350246892559 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5136/10000step_number: 0/29 Accuracy:  0.9591690788353482 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5137/10000step_number: 0/29 Accuracy:  0.9591690788353482 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5138/10000step_number: 0/29 Accuracy:  0.9591350246892559 Loss:  nan Val_accuracy:  0.9340779079269954 Val_cost:  nan Val_accuracy:  0.9340779079269954 Val_Acc:  nan\n",
      "Epoch number: 5139/10000step_number: 0/29 Accuracy:  0.9591009705431637 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5140/10000step_number: 0/29 Accuracy:  0.9589988081048868 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5141/10000step_number: 0/29 Accuracy:  0.9589988081048868 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5142/10000step_number: 0/29 Accuracy:  0.9588966456666099 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5143/10000step_number: 0/29 Accuracy:  0.9588285373744253 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5144/10000step_number: 0/29 Accuracy:  0.9588285373744253 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5145/10000step_number: 0/29 Accuracy:  0.9588625915205177 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5146/10000step_number: 0/29 Accuracy:  0.9588966456666099 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5147/10000step_number: 0/29 Accuracy:  0.9589306998127022 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5148/10000step_number: 0/29 Accuracy:  0.9588625915205177 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5149/10000step_number: 0/29 Accuracy:  0.9588625915205177 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5150/10000step_number: 0/29 Accuracy:  0.9588285373744253 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5151/10000step_number: 0/29 Accuracy:  0.958794483228333 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5152/10000step_number: 0/29 Accuracy:  0.9586923207900562 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5153/10000step_number: 0/29 Accuracy:  0.9586923207900562 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5154/10000step_number: 0/29 Accuracy:  0.9587604290822408 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5155/10000step_number: 0/29 Accuracy:  0.958794483228333 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5156/10000step_number: 0/29 Accuracy:  0.958794483228333 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5157/10000step_number: 0/29 Accuracy:  0.958794483228333 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5158/10000step_number: 0/29 Accuracy:  0.9589306998127022 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5159/10000step_number: 0/29 Accuracy:  0.958794483228333 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5160/10000step_number: 0/29 Accuracy:  0.9588966456666099 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5161/10000step_number: 0/29 Accuracy:  0.9589988081048868 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5162/10000step_number: 0/29 Accuracy:  0.9589306998127022 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5163/10000step_number: 0/29 Accuracy:  0.9589647539587944 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5164/10000step_number: 0/29 Accuracy:  0.958794483228333 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5165/10000step_number: 0/29 Accuracy:  0.9587604290822408 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5166/10000step_number: 0/29 Accuracy:  0.9587263749361484 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5167/10000step_number: 0/29 Accuracy:  0.9579771837221182 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5168/10000step_number: 0/29 Accuracy:  0.9580452920143028 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5169/10000step_number: 0/29 Accuracy:  0.9580452920143028 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5170/10000step_number: 0/29 Accuracy:  0.9580452920143028 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5171/10000step_number: 0/29 Accuracy:  0.958079346160395 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5172/10000step_number: 0/29 Accuracy:  0.958079346160395 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5173/10000step_number: 0/29 Accuracy:  0.958079346160395 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5174/10000step_number: 0/29 Accuracy:  0.958079346160395 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5175/10000step_number: 0/29 Accuracy:  0.9580112378682104 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5176/10000step_number: 0/29 Accuracy:  0.9581815085986719 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5177/10000step_number: 0/29 Accuracy:  0.9582155627447642 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5178/10000step_number: 0/29 Accuracy:  0.958317725183041 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5179/10000step_number: 0/29 Accuracy:  0.958317725183041 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5180/10000step_number: 0/29 Accuracy:  0.9583858334752257 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5181/10000step_number: 0/29 Accuracy:  0.9582836710369488 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5182/10000step_number: 0/29 Accuracy:  0.9582496168908564 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5183/10000step_number: 0/29 Accuracy:  0.9582496168908564 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5184/10000step_number: 0/29 Accuracy:  0.9579771837221182 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5185/10000step_number: 0/29 Accuracy:  0.9579431295760259 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5186/10000step_number: 0/29 Accuracy:  0.9579431295760259 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5187/10000step_number: 0/29 Accuracy:  0.9579771837221182 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5188/10000step_number: 0/29 Accuracy:  0.9580112378682104 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5189/10000step_number: 0/29 Accuracy:  0.9580112378682104 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5190/10000step_number: 0/29 Accuracy:  0.9581474544525796 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5191/10000step_number: 0/29 Accuracy:  0.9581134003064873 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5192/10000step_number: 0/29 Accuracy:  0.9580452920143028 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5193/10000step_number: 0/29 Accuracy:  0.958079346160395 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5194/10000step_number: 0/29 Accuracy:  0.957840967137749 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5195/10000step_number: 0/29 Accuracy:  0.9578750212838413 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5196/10000step_number: 0/29 Accuracy:  0.9578750212838413 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5197/10000step_number: 0/29 Accuracy:  0.957840967137749 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5198/10000step_number: 0/29 Accuracy:  0.9576366422611953 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5199/10000step_number: 0/29 Accuracy:  0.9572620466541801 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5200/10000step_number: 0/29 Accuracy:  0.9572961008002724 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5201/10000step_number: 0/29 Accuracy:  0.9572620466541801 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5202/10000step_number: 0/29 Accuracy:  0.9572961008002724 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5203/10000step_number: 0/29 Accuracy:  0.957364209092457 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5204/10000step_number: 0/29 Accuracy:  0.9574323173846416 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5205/10000step_number: 0/29 Accuracy:  0.9574323173846416 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5206/10000step_number: 0/29 Accuracy:  0.9574323173846416 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5207/10000step_number: 0/29 Accuracy:  0.9574323173846416 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5208/10000step_number: 0/29 Accuracy:  0.9576366422611953 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5209/10000step_number: 0/29 Accuracy:  0.9576366422611953 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5210/10000step_number: 0/29 Accuracy:  0.9578069129916568 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5211/10000step_number: 0/29 Accuracy:  0.9579431295760259 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5212/10000step_number: 0/29 Accuracy:  0.9580452920143028 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5213/10000step_number: 0/29 Accuracy:  0.9579771837221182 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5214/10000step_number: 0/29 Accuracy:  0.9579771837221182 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5215/10000step_number: 0/29 Accuracy:  0.9580452920143028 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5216/10000step_number: 0/29 Accuracy:  0.9581134003064873 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5217/10000step_number: 0/29 Accuracy:  0.9581474544525796 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5218/10000step_number: 0/29 Accuracy:  0.9582836710369488 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5219/10000step_number: 0/29 Accuracy:  0.9581815085986719 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5220/10000step_number: 0/29 Accuracy:  0.9578069129916568 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5221/10000step_number: 0/29 Accuracy:  0.9578750212838413 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5222/10000step_number: 0/29 Accuracy:  0.9579090754299336 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5223/10000step_number: 0/29 Accuracy:  0.9580112378682104 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5224/10000step_number: 0/29 Accuracy:  0.958079346160395 Loss:  nan Val_accuracy:  0.9340779079269954 Val_cost:  nan Val_accuracy:  0.9340779079269954 Val_Acc:  nan\n",
      "Epoch number: 5225/10000step_number: 0/29 Accuracy:  0.9579431295760259 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5226/10000step_number: 0/29 Accuracy:  0.9578069129916568 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5227/10000step_number: 0/29 Accuracy:  0.9578069129916568 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5228/10000step_number: 0/29 Accuracy:  0.957840967137749 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5229/10000step_number: 0/29 Accuracy:  0.9578750212838413 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5230/10000step_number: 0/29 Accuracy:  0.9579431295760259 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5231/10000step_number: 0/29 Accuracy:  0.9579431295760259 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5232/10000step_number: 0/29 Accuracy:  0.9579431295760259 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5233/10000step_number: 0/29 Accuracy:  0.9579431295760259 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5234/10000step_number: 0/29 Accuracy:  0.9580112378682104 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5235/10000step_number: 0/29 Accuracy:  0.9581474544525796 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5236/10000step_number: 0/29 Accuracy:  0.9581474544525796 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5237/10000step_number: 0/29 Accuracy:  0.958079346160395 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5238/10000step_number: 0/29 Accuracy:  0.9581474544525796 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5239/10000step_number: 0/29 Accuracy:  0.958079346160395 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5240/10000step_number: 0/29 Accuracy:  0.9581474544525796 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5241/10000step_number: 0/29 Accuracy:  0.9582155627447642 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5242/10000step_number: 0/29 Accuracy:  0.9585220500595948 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5243/10000step_number: 0/29 Accuracy:  0.958556104205687 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5244/10000step_number: 0/29 Accuracy:  0.9586242124978717 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5245/10000step_number: 0/29 Accuracy:  0.9588625915205177 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5246/10000step_number: 0/29 Accuracy:  0.9591350246892559 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5247/10000step_number: 0/29 Accuracy:  0.9591009705431637 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5248/10000step_number: 0/29 Accuracy:  0.9592031329814404 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5249/10000step_number: 0/29 Accuracy:  0.9593052954197173 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5250/10000step_number: 0/29 Accuracy:  0.9594755661501788 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5251/10000step_number: 0/29 Accuracy:  0.9589306998127022 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5252/10000step_number: 0/29 Accuracy:  0.9597479993189171 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 5253/10000step_number: 0/29 Accuracy:  0.9603609739485782 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 5254/10000step_number: 0/29 Accuracy:  0.961518814915716 Loss:  nan Val_accuracy:  0.9340779079269954 Val_cost:  nan Val_accuracy:  0.9340779079269954 Val_Acc:  nan\n",
      "Epoch number: 5255/10000step_number: 0/29 Accuracy:  0.9493274306146774 Loss:  nan Val_accuracy:  0.9239989103786435 Val_cost:  nan Val_accuracy:  0.9239989103786435 Val_Acc:  nan\n",
      "Epoch number: 5256/10000step_number: 0/29 Accuracy:  0.9456836369828027 Loss:  nan Val_accuracy:  0.9215472623263415 Val_cost:  nan Val_accuracy:  0.9215472623263415 Val_Acc:  nan\n",
      "Epoch number: 5257/10000step_number: 0/29 Accuracy:  0.9635620636812532 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5258/10000step_number: 0/29 Accuracy:  0.9613825983313469 Loss:  nan Val_accuracy:  0.9340779079269954 Val_cost:  nan Val_accuracy:  0.9340779079269954 Val_Acc:  nan\n",
      "Epoch number: 5259/10000step_number: 0/29 Accuracy:  0.961042056870424 Loss:  nan Val_accuracy:  0.9353037319531463 Val_cost:  nan Val_accuracy:  0.9353037319531463 Val_Acc:  nan\n",
      "Epoch number: 5260/10000step_number: 0/29 Accuracy:  0.9618253022305465 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5261/10000step_number: 0/29 Accuracy:  0.9620977353992849 Loss:  nan Val_accuracy:  0.9353037319531463 Val_cost:  nan Val_accuracy:  0.9353037319531463 Val_Acc:  nan\n",
      "Epoch number: 5262/10000step_number: 0/29 Accuracy:  0.9605312446790397 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5263/10000step_number: 0/29 Accuracy:  0.9610080027243317 Loss:  nan Val_accuracy:  0.9348951239444293 Val_cost:  nan Val_accuracy:  0.9348951239444293 Val_Acc:  nan\n",
      "Epoch number: 5264/10000step_number: 0/29 Accuracy:  0.9614166524774391 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5265/10000step_number: 0/29 Accuracy:  0.9614166524774391 Loss:  nan Val_accuracy:  0.9353037319531463 Val_cost:  nan Val_accuracy:  0.9353037319531463 Val_Acc:  nan\n",
      "Epoch number: 5266/10000step_number: 0/29 Accuracy:  0.9614166524774391 Loss:  nan Val_accuracy:  0.9353037319531463 Val_cost:  nan Val_accuracy:  0.9353037319531463 Val_Acc:  nan\n",
      "Epoch number: 5267/10000step_number: 0/29 Accuracy:  0.9609739485782394 Loss:  nan Val_accuracy:  0.9346227186052847 Val_cost:  nan Val_accuracy:  0.9346227186052847 Val_Acc:  nan\n",
      "Epoch number: 5268/10000step_number: 0/29 Accuracy:  0.9600544866337477 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5269/10000step_number: 0/29 Accuracy:  0.9598842159032862 Loss:  nan Val_accuracy:  0.9342141105965677 Val_cost:  nan Val_accuracy:  0.9342141105965677 Val_Acc:  nan\n",
      "Epoch number: 5270/10000step_number: 0/29 Accuracy:  0.9599182700493785 Loss:  nan Val_accuracy:  0.9340779079269954 Val_cost:  nan Val_accuracy:  0.9340779079269954 Val_Acc:  nan\n",
      "Epoch number: 5271/10000step_number: 0/29 Accuracy:  0.9597820534650093 Loss:  nan Val_accuracy:  0.9340779079269954 Val_cost:  nan Val_accuracy:  0.9340779079269954 Val_Acc:  nan\n",
      "Epoch number: 5272/10000step_number: 0/29 Accuracy:  0.9596798910267325 Loss:  nan Val_accuracy:  0.9342141105965677 Val_cost:  nan Val_accuracy:  0.9342141105965677 Val_Acc:  nan\n",
      "Epoch number: 5273/10000step_number: 0/29 Accuracy:  0.9596798910267325 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5274/10000step_number: 0/29 Accuracy:  0.9599182700493785 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5275/10000step_number: 0/29 Accuracy:  0.9598161076111017 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5276/10000step_number: 0/29 Accuracy:  0.9596798910267325 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5277/10000step_number: 0/29 Accuracy:  0.959611782734548 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5278/10000step_number: 0/29 Accuracy:  0.9595777285884557 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5279/10000step_number: 0/29 Accuracy:  0.9595096202962711 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5280/10000step_number: 0/29 Accuracy:  0.9595436744423633 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5281/10000step_number: 0/29 Accuracy:  0.9595777285884557 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5282/10000step_number: 0/29 Accuracy:  0.9594074578579942 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5283/10000step_number: 0/29 Accuracy:  0.9593052954197173 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5284/10000step_number: 0/29 Accuracy:  0.9591350246892559 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5285/10000step_number: 0/29 Accuracy:  0.9589647539587944 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5286/10000step_number: 0/29 Accuracy:  0.9589306998127022 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5287/10000step_number: 0/29 Accuracy:  0.9588285373744253 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5288/10000step_number: 0/29 Accuracy:  0.958794483228333 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5289/10000step_number: 0/29 Accuracy:  0.9587604290822408 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5290/10000step_number: 0/29 Accuracy:  0.9586242124978717 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5291/10000step_number: 0/29 Accuracy:  0.9584879959135024 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5292/10000step_number: 0/29 Accuracy:  0.9585220500595948 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5293/10000step_number: 0/29 Accuracy:  0.958556104205687 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5294/10000step_number: 0/29 Accuracy:  0.958556104205687 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5295/10000step_number: 0/29 Accuracy:  0.9586242124978717 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 5296/10000step_number: 0/29 Accuracy:  0.958556104205687 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 5297/10000step_number: 0/29 Accuracy:  0.958556104205687 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 5298/10000step_number: 0/29 Accuracy:  0.9584198876213179 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 5299/10000step_number: 0/29 Accuracy:  0.9584879959135024 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 5300/10000step_number: 0/29 Accuracy:  0.9584539417674102 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 5301/10000step_number: 0/29 Accuracy:  0.9585220500595948 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 5302/10000step_number: 0/29 Accuracy:  0.958556104205687 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 5303/10000step_number: 0/29 Accuracy:  0.9584198876213179 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 5304/10000step_number: 0/29 Accuracy:  0.9584879959135024 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 5305/10000step_number: 0/29 Accuracy:  0.9583858334752257 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 5306/10000step_number: 0/29 Accuracy:  0.9584198876213179 Loss:  nan Val_accuracy:  0.9318986652138382 Val_cost:  nan Val_accuracy:  0.9318986652138382 Val_Acc:  nan\n",
      "Epoch number: 5307/10000step_number: 0/29 Accuracy:  0.9583858334752257 Loss:  nan Val_accuracy:  0.9320348678834105 Val_cost:  nan Val_accuracy:  0.9320348678834105 Val_Acc:  nan\n",
      "Epoch number: 5308/10000step_number: 0/29 Accuracy:  0.9583858334752257 Loss:  nan Val_accuracy:  0.9321710705529829 Val_cost:  nan Val_accuracy:  0.9321710705529829 Val_Acc:  nan\n",
      "Epoch number: 5309/10000step_number: 0/29 Accuracy:  0.958317725183041 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5310/10000step_number: 0/29 Accuracy:  0.9582836710369488 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5311/10000step_number: 0/29 Accuracy:  0.9582155627447642 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5312/10000step_number: 0/29 Accuracy:  0.958317725183041 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5313/10000step_number: 0/29 Accuracy:  0.9582836710369488 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5314/10000step_number: 0/29 Accuracy:  0.9582496168908564 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5315/10000step_number: 0/29 Accuracy:  0.9581474544525796 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5316/10000step_number: 0/29 Accuracy:  0.9581815085986719 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5317/10000step_number: 0/29 Accuracy:  0.9582496168908564 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5318/10000step_number: 0/29 Accuracy:  0.9583517793291333 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5319/10000step_number: 0/29 Accuracy:  0.9584198876213179 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5320/10000step_number: 0/29 Accuracy:  0.9584539417674102 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5321/10000step_number: 0/29 Accuracy:  0.9583858334752257 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5322/10000step_number: 0/29 Accuracy:  0.9584539417674102 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5323/10000step_number: 0/29 Accuracy:  0.9584198876213179 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5324/10000step_number: 0/29 Accuracy:  0.9584539417674102 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5325/10000step_number: 0/29 Accuracy:  0.9584198876213179 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5326/10000step_number: 0/29 Accuracy:  0.9582836710369488 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5327/10000step_number: 0/29 Accuracy:  0.9583858334752257 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5328/10000step_number: 0/29 Accuracy:  0.9583517793291333 Loss:  nan Val_accuracy:  0.9323072732225551 Val_cost:  nan Val_accuracy:  0.9323072732225551 Val_Acc:  nan\n",
      "Epoch number: 5329/10000step_number: 0/29 Accuracy:  0.9584879959135024 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5330/10000step_number: 0/29 Accuracy:  0.9584539417674102 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5331/10000step_number: 0/29 Accuracy:  0.9584198876213179 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5332/10000step_number: 0/29 Accuracy:  0.9584198876213179 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5333/10000step_number: 0/29 Accuracy:  0.9584879959135024 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5334/10000step_number: 0/29 Accuracy:  0.9584879959135024 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5335/10000step_number: 0/29 Accuracy:  0.9585220500595948 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5336/10000step_number: 0/29 Accuracy:  0.9585901583517793 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5337/10000step_number: 0/29 Accuracy:  0.9586242124978717 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5338/10000step_number: 0/29 Accuracy:  0.9585901583517793 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5339/10000step_number: 0/29 Accuracy:  0.958556104205687 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5340/10000step_number: 0/29 Accuracy:  0.958556104205687 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5341/10000step_number: 0/29 Accuracy:  0.958556104205687 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5342/10000step_number: 0/29 Accuracy:  0.9584198876213179 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5343/10000step_number: 0/29 Accuracy:  0.9584198876213179 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5344/10000step_number: 0/29 Accuracy:  0.9584198876213179 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5345/10000step_number: 0/29 Accuracy:  0.9584879959135024 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5346/10000step_number: 0/29 Accuracy:  0.9587263749361484 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5347/10000step_number: 0/29 Accuracy:  0.9587604290822408 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5348/10000step_number: 0/29 Accuracy:  0.9588285373744253 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5349/10000step_number: 0/29 Accuracy:  0.9588625915205177 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5350/10000step_number: 0/29 Accuracy:  0.9588966456666099 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5351/10000step_number: 0/29 Accuracy:  0.9587263749361484 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5352/10000step_number: 0/29 Accuracy:  0.9587604290822408 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5353/10000step_number: 0/29 Accuracy:  0.9587604290822408 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5354/10000step_number: 0/29 Accuracy:  0.9588285373744253 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5355/10000step_number: 0/29 Accuracy:  0.9588625915205177 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5356/10000step_number: 0/29 Accuracy:  0.9589306998127022 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5357/10000step_number: 0/29 Accuracy:  0.9589306998127022 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5358/10000step_number: 0/29 Accuracy:  0.9589306998127022 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5359/10000step_number: 0/29 Accuracy:  0.9588625915205177 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5360/10000step_number: 0/29 Accuracy:  0.9588285373744253 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5361/10000step_number: 0/29 Accuracy:  0.9589306998127022 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5362/10000step_number: 0/29 Accuracy:  0.9589647539587944 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5363/10000step_number: 0/29 Accuracy:  0.9589647539587944 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5364/10000step_number: 0/29 Accuracy:  0.9589647539587944 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5365/10000step_number: 0/29 Accuracy:  0.9588966456666099 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5366/10000step_number: 0/29 Accuracy:  0.9588966456666099 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5367/10000step_number: 0/29 Accuracy:  0.9590328622509791 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5368/10000step_number: 0/29 Accuracy:  0.9591009705431637 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5369/10000step_number: 0/29 Accuracy:  0.9591350246892559 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5370/10000step_number: 0/29 Accuracy:  0.9591350246892559 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5371/10000step_number: 0/29 Accuracy:  0.9591350246892559 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5372/10000step_number: 0/29 Accuracy:  0.9593052954197173 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5373/10000step_number: 0/29 Accuracy:  0.9589306998127022 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5374/10000step_number: 0/29 Accuracy:  0.9589988081048868 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5375/10000step_number: 0/29 Accuracy:  0.9589306998127022 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5376/10000step_number: 0/29 Accuracy:  0.9589988081048868 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5377/10000step_number: 0/29 Accuracy:  0.9590328622509791 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5378/10000step_number: 0/29 Accuracy:  0.9589988081048868 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5379/10000step_number: 0/29 Accuracy:  0.9590328622509791 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5380/10000step_number: 0/29 Accuracy:  0.9589647539587944 Loss:  nan Val_accuracy:  0.9324434758921275 Val_cost:  nan Val_accuracy:  0.9324434758921275 Val_Acc:  nan\n",
      "Epoch number: 5381/10000step_number: 0/29 Accuracy:  0.9588966456666099 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5382/10000step_number: 0/29 Accuracy:  0.9588285373744253 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5383/10000step_number: 0/29 Accuracy:  0.9588285373744253 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5384/10000step_number: 0/29 Accuracy:  0.9587263749361484 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5385/10000step_number: 0/29 Accuracy:  0.9587263749361484 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5386/10000step_number: 0/29 Accuracy:  0.9587263749361484 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5387/10000step_number: 0/29 Accuracy:  0.9588285373744253 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5388/10000step_number: 0/29 Accuracy:  0.9586923207900562 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5389/10000step_number: 0/29 Accuracy:  0.9586923207900562 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5390/10000step_number: 0/29 Accuracy:  0.9586242124978717 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5391/10000step_number: 0/29 Accuracy:  0.9586582666439639 Loss:  nan Val_accuracy:  0.9327158812312721 Val_cost:  nan Val_accuracy:  0.9327158812312721 Val_Acc:  nan\n",
      "Epoch number: 5392/10000step_number: 0/29 Accuracy:  0.9586923207900562 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5393/10000step_number: 0/29 Accuracy:  0.9586923207900562 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5394/10000step_number: 0/29 Accuracy:  0.9587263749361484 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5395/10000step_number: 0/29 Accuracy:  0.9587604290822408 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5396/10000step_number: 0/29 Accuracy:  0.9586923207900562 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5397/10000step_number: 0/29 Accuracy:  0.9587604290822408 Loss:  nan Val_accuracy:  0.9328520839008445 Val_cost:  nan Val_accuracy:  0.9328520839008445 Val_Acc:  nan\n",
      "Epoch number: 5398/10000step_number: 0/29 Accuracy:  0.958794483228333 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5399/10000step_number: 0/29 Accuracy:  0.958794483228333 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5400/10000step_number: 0/29 Accuracy:  0.9587604290822408 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5401/10000step_number: 0/29 Accuracy:  0.9588625915205177 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5402/10000step_number: 0/29 Accuracy:  0.9588625915205177 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5403/10000step_number: 0/29 Accuracy:  0.9588966456666099 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5404/10000step_number: 0/29 Accuracy:  0.9588966456666099 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5405/10000step_number: 0/29 Accuracy:  0.9589647539587944 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5406/10000step_number: 0/29 Accuracy:  0.9590328622509791 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5407/10000step_number: 0/29 Accuracy:  0.9591009705431637 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5408/10000step_number: 0/29 Accuracy:  0.9591690788353482 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5409/10000step_number: 0/29 Accuracy:  0.9592712412736251 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5410/10000step_number: 0/29 Accuracy:  0.9592371871275328 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5411/10000step_number: 0/29 Accuracy:  0.9592712412736251 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5412/10000step_number: 0/29 Accuracy:  0.9592371871275328 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5413/10000step_number: 0/29 Accuracy:  0.9592371871275328 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5414/10000step_number: 0/29 Accuracy:  0.9593734037119019 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5415/10000step_number: 0/29 Accuracy:  0.9592031329814404 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5416/10000step_number: 0/29 Accuracy:  0.9592371871275328 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5417/10000step_number: 0/29 Accuracy:  0.9595436744423633 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5418/10000step_number: 0/29 Accuracy:  0.9595777285884557 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5419/10000step_number: 0/29 Accuracy:  0.9597479993189171 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5420/10000step_number: 0/29 Accuracy:  0.9597139451728248 Loss:  nan Val_accuracy:  0.9340779079269954 Val_cost:  nan Val_accuracy:  0.9340779079269954 Val_Acc:  nan\n",
      "Epoch number: 5421/10000step_number: 0/29 Accuracy:  0.959850161757194 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5422/10000step_number: 0/29 Accuracy:  0.959850161757194 Loss:  nan Val_accuracy:  0.9342141105965677 Val_cost:  nan Val_accuracy:  0.9342141105965677 Val_Acc:  nan\n",
      "Epoch number: 5423/10000step_number: 0/29 Accuracy:  0.9602247573642091 Loss:  nan Val_accuracy:  0.9347589212748569 Val_cost:  nan Val_accuracy:  0.9347589212748569 Val_Acc:  nan\n",
      "Epoch number: 5424/10000step_number: 0/29 Accuracy:  0.9604631363868551 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5425/10000step_number: 0/29 Accuracy:  0.9604971905329474 Loss:  nan Val_accuracy:  0.9347589212748569 Val_cost:  nan Val_accuracy:  0.9347589212748569 Val_Acc:  nan\n",
      "Epoch number: 5426/10000step_number: 0/29 Accuracy:  0.9605312446790397 Loss:  nan Val_accuracy:  0.9350313266140017 Val_cost:  nan Val_accuracy:  0.9350313266140017 Val_Acc:  nan\n",
      "Epoch number: 5427/10000step_number: 0/29 Accuracy:  0.9604971905329474 Loss:  nan Val_accuracy:  0.9350313266140017 Val_cost:  nan Val_accuracy:  0.9350313266140017 Val_Acc:  nan\n",
      "Epoch number: 5428/10000step_number: 0/29 Accuracy:  0.9607015154095011 Loss:  nan Val_accuracy:  0.9350313266140017 Val_cost:  nan Val_accuracy:  0.9350313266140017 Val_Acc:  nan\n",
      "Epoch number: 5429/10000step_number: 0/29 Accuracy:  0.9609058402860549 Loss:  nan Val_accuracy:  0.9353037319531463 Val_cost:  nan Val_accuracy:  0.9353037319531463 Val_Acc:  nan\n",
      "Epoch number: 5430/10000step_number: 0/29 Accuracy:  0.961042056870424 Loss:  nan Val_accuracy:  0.9348951239444293 Val_cost:  nan Val_accuracy:  0.9348951239444293 Val_Acc:  nan\n",
      "Epoch number: 5431/10000step_number: 0/29 Accuracy:  0.9615528690618083 Loss:  nan Val_accuracy:  0.9350313266140017 Val_cost:  nan Val_accuracy:  0.9350313266140017 Val_Acc:  nan\n",
      "Epoch number: 5432/10000step_number: 0/29 Accuracy:  0.9624382768602078 Loss:  nan Val_accuracy:  0.9355761372922909 Val_cost:  nan Val_accuracy:  0.9355761372922909 Val_Acc:  nan\n",
      "Epoch number: 5433/10000step_number: 0/29 Accuracy:  0.9629831431976843 Loss:  nan Val_accuracy:  0.9355761372922909 Val_cost:  nan Val_accuracy:  0.9355761372922909 Val_Acc:  nan\n",
      "Epoch number: 5434/10000step_number: 0/29 Accuracy:  0.9637663885578069 Loss:  nan Val_accuracy:  0.9357123399618632 Val_cost:  nan Val_accuracy:  0.9357123399618632 Val_Acc:  nan\n",
      "Epoch number: 5435/10000step_number: 0/29 Accuracy:  0.9645836880640218 Loss:  nan Val_accuracy:  0.9358485426314356 Val_cost:  nan Val_accuracy:  0.9358485426314356 Val_Acc:  nan\n",
      "Epoch number: 5436/10000step_number: 0/29 Accuracy:  0.9652307168397752 Loss:  nan Val_accuracy:  0.9363933533097248 Val_cost:  nan Val_accuracy:  0.9363933533097248 Val_Acc:  nan\n",
      "Epoch number: 5437/10000step_number: 0/29 Accuracy:  0.960803677847778 Loss:  nan Val_accuracy:  0.9325796785616998 Val_cost:  nan Val_accuracy:  0.9325796785616998 Val_Acc:  nan\n",
      "Epoch number: 5438/10000step_number: 0/29 Accuracy:  0.9601566490720245 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5439/10000step_number: 0/29 Accuracy:  0.9613825983313469 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5440/10000step_number: 0/29 Accuracy:  0.9587263749361484 Loss:  nan Val_accuracy:  0.9313538545355489 Val_cost:  nan Val_accuracy:  0.9313538545355489 Val_Acc:  nan\n",
      "Epoch number: 5441/10000step_number: 0/29 Accuracy:  0.9571598842159033 Loss:  nan Val_accuracy:  0.930945246526832 Val_cost:  nan Val_accuracy:  0.930945246526832 Val_Acc:  nan\n",
      "Epoch number: 5442/10000step_number: 0/29 Accuracy:  0.9628809807594074 Loss:  nan Val_accuracy:  0.9363933533097248 Val_cost:  nan Val_accuracy:  0.9363933533097248 Val_Acc:  nan\n",
      "Epoch number: 5443/10000step_number: 0/29 Accuracy:  0.9621317895453771 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5444/10000step_number: 0/29 Accuracy:  0.9609398944321471 Loss:  nan Val_accuracy:  0.93435031326614 Val_cost:  nan Val_accuracy:  0.93435031326614 Val_Acc:  nan\n",
      "Epoch number: 5445/10000step_number: 0/29 Accuracy:  0.9609058402860549 Loss:  nan Val_accuracy:  0.9350313266140017 Val_cost:  nan Val_accuracy:  0.9350313266140017 Val_Acc:  nan\n",
      "Epoch number: 5446/10000step_number: 0/29 Accuracy:  0.9618253022305465 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5447/10000step_number: 0/29 Accuracy:  0.9614166524774391 Loss:  nan Val_accuracy:  0.9342141105965677 Val_cost:  nan Val_accuracy:  0.9342141105965677 Val_Acc:  nan\n",
      "Epoch number: 5448/10000step_number: 0/29 Accuracy:  0.9620977353992849 Loss:  nan Val_accuracy:  0.9354399346227186 Val_cost:  nan Val_accuracy:  0.9354399346227186 Val_Acc:  nan\n",
      "Epoch number: 5449/10000step_number: 0/29 Accuracy:  0.9618593563766389 Loss:  nan Val_accuracy:  0.9353037319531463 Val_cost:  nan Val_accuracy:  0.9353037319531463 Val_Acc:  nan\n",
      "Epoch number: 5450/10000step_number: 0/29 Accuracy:  0.9618253022305465 Loss:  nan Val_accuracy:  0.9348951239444293 Val_cost:  nan Val_accuracy:  0.9348951239444293 Val_Acc:  nan\n",
      "Epoch number: 5451/10000step_number: 0/29 Accuracy:  0.9617912480844543 Loss:  nan Val_accuracy:  0.9348951239444293 Val_cost:  nan Val_accuracy:  0.9348951239444293 Val_Acc:  nan\n",
      "Epoch number: 5452/10000step_number: 0/29 Accuracy:  0.9615869232079005 Loss:  nan Val_accuracy:  0.9350313266140017 Val_cost:  nan Val_accuracy:  0.9350313266140017 Val_Acc:  nan\n",
      "Epoch number: 5453/10000step_number: 0/29 Accuracy:  0.9615528690618083 Loss:  nan Val_accuracy:  0.9348951239444293 Val_cost:  nan Val_accuracy:  0.9348951239444293 Val_Acc:  nan\n",
      "Epoch number: 5454/10000step_number: 0/29 Accuracy:  0.9614847607696237 Loss:  nan Val_accuracy:  0.9348951239444293 Val_cost:  nan Val_accuracy:  0.9348951239444293 Val_Acc:  nan\n",
      "Epoch number: 5455/10000step_number: 0/29 Accuracy:  0.9614847607696237 Loss:  nan Val_accuracy:  0.9350313266140017 Val_cost:  nan Val_accuracy:  0.9350313266140017 Val_Acc:  nan\n",
      "Epoch number: 5456/10000step_number: 0/29 Accuracy:  0.9614847607696237 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5457/10000step_number: 0/29 Accuracy:  0.9614166524774391 Loss:  nan Val_accuracy:  0.9353037319531463 Val_cost:  nan Val_accuracy:  0.9353037319531463 Val_Acc:  nan\n",
      "Epoch number: 5458/10000step_number: 0/29 Accuracy:  0.9614507066235314 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5459/10000step_number: 0/29 Accuracy:  0.9613485441852545 Loss:  nan Val_accuracy:  0.9350313266140017 Val_cost:  nan Val_accuracy:  0.9350313266140017 Val_Acc:  nan\n",
      "Epoch number: 5460/10000step_number: 0/29 Accuracy:  0.9612463817469777 Loss:  nan Val_accuracy:  0.9347589212748569 Val_cost:  nan Val_accuracy:  0.9347589212748569 Val_Acc:  nan\n",
      "Epoch number: 5461/10000step_number: 0/29 Accuracy:  0.9611442193087009 Loss:  nan Val_accuracy:  0.9348951239444293 Val_cost:  nan Val_accuracy:  0.9348951239444293 Val_Acc:  nan\n",
      "Epoch number: 5462/10000step_number: 0/29 Accuracy:  0.9610761110165162 Loss:  nan Val_accuracy:  0.9347589212748569 Val_cost:  nan Val_accuracy:  0.9347589212748569 Val_Acc:  nan\n",
      "Epoch number: 5463/10000step_number: 0/29 Accuracy:  0.9609058402860549 Loss:  nan Val_accuracy:  0.9346227186052847 Val_cost:  nan Val_accuracy:  0.9346227186052847 Val_Acc:  nan\n",
      "Epoch number: 5464/10000step_number: 0/29 Accuracy:  0.9609058402860549 Loss:  nan Val_accuracy:  0.9344865159357123 Val_cost:  nan Val_accuracy:  0.9344865159357123 Val_Acc:  nan\n",
      "Epoch number: 5465/10000step_number: 0/29 Accuracy:  0.960803677847778 Loss:  nan Val_accuracy:  0.9344865159357123 Val_cost:  nan Val_accuracy:  0.9344865159357123 Val_Acc:  nan\n",
      "Epoch number: 5466/10000step_number: 0/29 Accuracy:  0.9607696237016857 Loss:  nan Val_accuracy:  0.9346227186052847 Val_cost:  nan Val_accuracy:  0.9346227186052847 Val_Acc:  nan\n",
      "Epoch number: 5467/10000step_number: 0/29 Accuracy:  0.9606674612634089 Loss:  nan Val_accuracy:  0.9344865159357123 Val_cost:  nan Val_accuracy:  0.9344865159357123 Val_Acc:  nan\n",
      "Epoch number: 5468/10000step_number: 0/29 Accuracy:  0.9607355695555934 Loss:  nan Val_accuracy:  0.9346227186052847 Val_cost:  nan Val_accuracy:  0.9346227186052847 Val_Acc:  nan\n",
      "Epoch number: 5469/10000step_number: 0/29 Accuracy:  0.9606334071173165 Loss:  nan Val_accuracy:  0.9346227186052847 Val_cost:  nan Val_accuracy:  0.9346227186052847 Val_Acc:  nan\n",
      "Epoch number: 5470/10000step_number: 0/29 Accuracy:  0.9607696237016857 Loss:  nan Val_accuracy:  0.9344865159357123 Val_cost:  nan Val_accuracy:  0.9344865159357123 Val_Acc:  nan\n",
      "Epoch number: 5471/10000step_number: 0/29 Accuracy:  0.9607696237016857 Loss:  nan Val_accuracy:  0.93435031326614 Val_cost:  nan Val_accuracy:  0.93435031326614 Val_Acc:  nan\n",
      "Epoch number: 5472/10000step_number: 0/29 Accuracy:  0.9608717861399625 Loss:  nan Val_accuracy:  0.93435031326614 Val_cost:  nan Val_accuracy:  0.93435031326614 Val_Acc:  nan\n",
      "Epoch number: 5473/10000step_number: 0/29 Accuracy:  0.9609058402860549 Loss:  nan Val_accuracy:  0.93435031326614 Val_cost:  nan Val_accuracy:  0.93435031326614 Val_Acc:  nan\n",
      "Epoch number: 5474/10000step_number: 0/29 Accuracy:  0.9609398944321471 Loss:  nan Val_accuracy:  0.9342141105965677 Val_cost:  nan Val_accuracy:  0.9342141105965677 Val_Acc:  nan\n",
      "Epoch number: 5475/10000step_number: 0/29 Accuracy:  0.9609058402860549 Loss:  nan Val_accuracy:  0.93435031326614 Val_cost:  nan Val_accuracy:  0.93435031326614 Val_Acc:  nan\n",
      "Epoch number: 5476/10000step_number: 0/29 Accuracy:  0.9610080027243317 Loss:  nan Val_accuracy:  0.9342141105965677 Val_cost:  nan Val_accuracy:  0.9342141105965677 Val_Acc:  nan\n",
      "Epoch number: 5477/10000step_number: 0/29 Accuracy:  0.9610080027243317 Loss:  nan Val_accuracy:  0.9342141105965677 Val_cost:  nan Val_accuracy:  0.9342141105965677 Val_Acc:  nan\n",
      "Epoch number: 5478/10000step_number: 0/29 Accuracy:  0.961042056870424 Loss:  nan Val_accuracy:  0.9344865159357123 Val_cost:  nan Val_accuracy:  0.9344865159357123 Val_Acc:  nan\n",
      "Epoch number: 5479/10000step_number: 0/29 Accuracy:  0.9610761110165162 Loss:  nan Val_accuracy:  0.9347589212748569 Val_cost:  nan Val_accuracy:  0.9347589212748569 Val_Acc:  nan\n",
      "Epoch number: 5480/10000step_number: 0/29 Accuracy:  0.9611101651626085 Loss:  nan Val_accuracy:  0.9348951239444293 Val_cost:  nan Val_accuracy:  0.9348951239444293 Val_Acc:  nan\n",
      "Epoch number: 5481/10000step_number: 0/29 Accuracy:  0.9611101651626085 Loss:  nan Val_accuracy:  0.9350313266140017 Val_cost:  nan Val_accuracy:  0.9350313266140017 Val_Acc:  nan\n",
      "Epoch number: 5482/10000step_number: 0/29 Accuracy:  0.9611101651626085 Loss:  nan Val_accuracy:  0.9350313266140017 Val_cost:  nan Val_accuracy:  0.9350313266140017 Val_Acc:  nan\n",
      "Epoch number: 5483/10000step_number: 0/29 Accuracy:  0.9610761110165162 Loss:  nan Val_accuracy:  0.9350313266140017 Val_cost:  nan Val_accuracy:  0.9350313266140017 Val_Acc:  nan\n",
      "Epoch number: 5484/10000step_number: 0/29 Accuracy:  0.9609398944321471 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5485/10000step_number: 0/29 Accuracy:  0.9609398944321471 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5486/10000step_number: 0/29 Accuracy:  0.9609398944321471 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5487/10000step_number: 0/29 Accuracy:  0.9609398944321471 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5488/10000step_number: 0/29 Accuracy:  0.9601225949259322 Loss:  nan Val_accuracy:  0.9346227186052847 Val_cost:  nan Val_accuracy:  0.9346227186052847 Val_Acc:  nan\n",
      "Epoch number: 5489/10000step_number: 0/29 Accuracy:  0.9597820534650093 Loss:  nan Val_accuracy:  0.9340779079269954 Val_cost:  nan Val_accuracy:  0.9340779079269954 Val_Acc:  nan\n",
      "Epoch number: 5490/10000step_number: 0/29 Accuracy:  0.9596798910267325 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5491/10000step_number: 0/29 Accuracy:  0.9596798910267325 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5492/10000step_number: 0/29 Accuracy:  0.9597139451728248 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5493/10000step_number: 0/29 Accuracy:  0.9596458368806402 Loss:  nan Val_accuracy:  0.9340779079269954 Val_cost:  nan Val_accuracy:  0.9340779079269954 Val_Acc:  nan\n",
      "Epoch number: 5494/10000step_number: 0/29 Accuracy:  0.9597139451728248 Loss:  nan Val_accuracy:  0.9340779079269954 Val_cost:  nan Val_accuracy:  0.9340779079269954 Val_Acc:  nan\n",
      "Epoch number: 5495/10000step_number: 0/29 Accuracy:  0.9597820534650093 Loss:  nan Val_accuracy:  0.9342141105965677 Val_cost:  nan Val_accuracy:  0.9342141105965677 Val_Acc:  nan\n",
      "Epoch number: 5496/10000step_number: 0/29 Accuracy:  0.9597820534650093 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5497/10000step_number: 0/29 Accuracy:  0.9597820534650093 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5498/10000step_number: 0/29 Accuracy:  0.9597820534650093 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5499/10000step_number: 0/29 Accuracy:  0.959850161757194 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5500/10000step_number: 0/29 Accuracy:  0.9599182700493785 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5501/10000step_number: 0/29 Accuracy:  0.9598161076111017 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5502/10000step_number: 0/29 Accuracy:  0.9597479993189171 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5503/10000step_number: 0/29 Accuracy:  0.9597820534650093 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5504/10000step_number: 0/29 Accuracy:  0.9598842159032862 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5505/10000step_number: 0/29 Accuracy:  0.959850161757194 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5506/10000step_number: 0/29 Accuracy:  0.9599182700493785 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5507/10000step_number: 0/29 Accuracy:  0.9598161076111017 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5508/10000step_number: 0/29 Accuracy:  0.9595777285884557 Loss:  nan Val_accuracy:  0.9329882865704168 Val_cost:  nan Val_accuracy:  0.9329882865704168 Val_Acc:  nan\n",
      "Epoch number: 5509/10000step_number: 0/29 Accuracy:  0.9595777285884557 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5510/10000step_number: 0/29 Accuracy:  0.9595777285884557 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 5511/10000step_number: 0/29 Accuracy:  0.9595436744423633 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5512/10000step_number: 0/29 Accuracy:  0.959611782734548 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5513/10000step_number: 0/29 Accuracy:  0.959611782734548 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5514/10000step_number: 0/29 Accuracy:  0.959611782734548 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5515/10000step_number: 0/29 Accuracy:  0.9596458368806402 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5516/10000step_number: 0/29 Accuracy:  0.9596798910267325 Loss:  nan Val_accuracy:  0.9333968945791338 Val_cost:  nan Val_accuracy:  0.9333968945791338 Val_Acc:  nan\n",
      "Epoch number: 5517/10000step_number: 0/29 Accuracy:  0.9597139451728248 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5518/10000step_number: 0/29 Accuracy:  0.9597479993189171 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5519/10000step_number: 0/29 Accuracy:  0.9598161076111017 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5520/10000step_number: 0/29 Accuracy:  0.9598842159032862 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5521/10000step_number: 0/29 Accuracy:  0.9598842159032862 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5522/10000step_number: 0/29 Accuracy:  0.9599523241954708 Loss:  nan Val_accuracy:  0.9332606919095614 Val_cost:  nan Val_accuracy:  0.9332606919095614 Val_Acc:  nan\n",
      "Epoch number: 5523/10000step_number: 0/29 Accuracy:  0.9599523241954708 Loss:  nan Val_accuracy:  0.9336692999182784 Val_cost:  nan Val_accuracy:  0.9336692999182784 Val_Acc:  nan\n",
      "Epoch number: 5524/10000step_number: 0/29 Accuracy:  0.9599182700493785 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 5525/10000step_number: 0/29 Accuracy:  0.9600204324876553 Loss:  nan Val_accuracy:  0.9338055025878507 Val_cost:  nan Val_accuracy:  0.9338055025878507 Val_Acc:  nan\n",
      "Epoch number: 5526/10000step_number: 0/29 Accuracy:  0.96008854077984 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5527/10000step_number: 0/29 Accuracy:  0.9601225949259322 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5528/10000step_number: 0/29 Accuracy:  0.96008854077984 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5529/10000step_number: 0/29 Accuracy:  0.9601225949259322 Loss:  nan Val_accuracy:  0.933941705257423 Val_cost:  nan Val_accuracy:  0.933941705257423 Val_Acc:  nan\n",
      "Epoch number: 5530/10000step_number: 0/29 Accuracy:  0.9601225949259322 Loss:  nan Val_accuracy:  0.9342141105965677 Val_cost:  nan Val_accuracy:  0.9342141105965677 Val_Acc:  nan\n",
      "Epoch number: 5531/10000step_number: 0/29 Accuracy:  0.9601907032181168 Loss:  nan Val_accuracy:  0.9342141105965677 Val_cost:  nan Val_accuracy:  0.9342141105965677 Val_Acc:  nan\n",
      "Epoch number: 5532/10000step_number: 0/29 Accuracy:  0.960326919802486 Loss:  nan Val_accuracy:  0.9342141105965677 Val_cost:  nan Val_accuracy:  0.9342141105965677 Val_Acc:  nan\n",
      "Epoch number: 5533/10000step_number: 0/29 Accuracy:  0.9605312446790397 Loss:  nan Val_accuracy:  0.93435031326614 Val_cost:  nan Val_accuracy:  0.93435031326614 Val_Acc:  nan\n",
      "Epoch number: 5534/10000step_number: 0/29 Accuracy:  0.960565298825132 Loss:  nan Val_accuracy:  0.93435031326614 Val_cost:  nan Val_accuracy:  0.93435031326614 Val_Acc:  nan\n",
      "Epoch number: 5535/10000step_number: 0/29 Accuracy:  0.9606674612634089 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5536/10000step_number: 0/29 Accuracy:  0.9605993529712242 Loss:  nan Val_accuracy:  0.9348951239444293 Val_cost:  nan Val_accuracy:  0.9348951239444293 Val_Acc:  nan\n",
      "Epoch number: 5537/10000step_number: 0/29 Accuracy:  0.9606674612634089 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5538/10000step_number: 0/29 Accuracy:  0.9607355695555934 Loss:  nan Val_accuracy:  0.9354399346227186 Val_cost:  nan Val_accuracy:  0.9354399346227186 Val_Acc:  nan\n",
      "Epoch number: 5539/10000step_number: 0/29 Accuracy:  0.9607015154095011 Loss:  nan Val_accuracy:  0.9357123399618632 Val_cost:  nan Val_accuracy:  0.9357123399618632 Val_Acc:  nan\n",
      "Epoch number: 5540/10000step_number: 0/29 Accuracy:  0.9608377319938702 Loss:  nan Val_accuracy:  0.9355761372922909 Val_cost:  nan Val_accuracy:  0.9355761372922909 Val_Acc:  nan\n",
      "Epoch number: 5541/10000step_number: 0/29 Accuracy:  0.9610080027243317 Loss:  nan Val_accuracy:  0.9357123399618632 Val_cost:  nan Val_accuracy:  0.9357123399618632 Val_Acc:  nan\n",
      "Epoch number: 5542/10000step_number: 0/29 Accuracy:  0.9611101651626085 Loss:  nan Val_accuracy:  0.9357123399618632 Val_cost:  nan Val_accuracy:  0.9357123399618632 Val_Acc:  nan\n",
      "Epoch number: 5543/10000step_number: 0/29 Accuracy:  0.9611782734547931 Loss:  nan Val_accuracy:  0.9354399346227186 Val_cost:  nan Val_accuracy:  0.9354399346227186 Val_Acc:  nan\n",
      "Epoch number: 5544/10000step_number: 0/29 Accuracy:  0.9611782734547931 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5545/10000step_number: 0/29 Accuracy:  0.9613144900391623 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5546/10000step_number: 0/29 Accuracy:  0.9614166524774391 Loss:  nan Val_accuracy:  0.9354399346227186 Val_cost:  nan Val_accuracy:  0.9354399346227186 Val_Acc:  nan\n",
      "Epoch number: 5547/10000step_number: 0/29 Accuracy:  0.9616209773539929 Loss:  nan Val_accuracy:  0.9357123399618632 Val_cost:  nan Val_accuracy:  0.9357123399618632 Val_Acc:  nan\n",
      "Epoch number: 5548/10000step_number: 0/29 Accuracy:  0.9615528690618083 Loss:  nan Val_accuracy:  0.9354399346227186 Val_cost:  nan Val_accuracy:  0.9354399346227186 Val_Acc:  nan\n",
      "Epoch number: 5549/10000step_number: 0/29 Accuracy:  0.9615869232079005 Loss:  nan Val_accuracy:  0.9355761372922909 Val_cost:  nan Val_accuracy:  0.9355761372922909 Val_Acc:  nan\n",
      "Epoch number: 5550/10000step_number: 0/29 Accuracy:  0.9615528690618083 Loss:  nan Val_accuracy:  0.9354399346227186 Val_cost:  nan Val_accuracy:  0.9354399346227186 Val_Acc:  nan\n",
      "Epoch number: 5551/10000step_number: 0/29 Accuracy:  0.9613485441852545 Loss:  nan Val_accuracy:  0.9348951239444293 Val_cost:  nan Val_accuracy:  0.9348951239444293 Val_Acc:  nan\n",
      "Epoch number: 5552/10000step_number: 0/29 Accuracy:  0.9613825983313469 Loss:  nan Val_accuracy:  0.9351675292835739 Val_cost:  nan Val_accuracy:  0.9351675292835739 Val_Acc:  nan\n",
      "Epoch number: 5553/10000step_number: 0/29 Accuracy:  0.9616550315000851 Loss:  nan Val_accuracy:  0.9353037319531463 Val_cost:  nan Val_accuracy:  0.9353037319531463 Val_Acc:  nan\n",
      "Epoch number: 5554/10000step_number: 0/29 Accuracy:  0.961995572961008 Loss:  nan Val_accuracy:  0.9348951239444293 Val_cost:  nan Val_accuracy:  0.9348951239444293 Val_Acc:  nan\n",
      "Epoch number: 5555/10000step_number: 0/29 Accuracy:  0.9626085475906692 Loss:  nan Val_accuracy:  0.9342141105965677 Val_cost:  nan Val_accuracy:  0.9342141105965677 Val_Acc:  nan\n",
      "Epoch number: 5556/10000step_number: 0/29 Accuracy:  0.9613144900391623 Loss:  nan Val_accuracy:  0.9304004358485426 Val_cost:  nan Val_accuracy:  0.9304004358485426 Val_Acc:  nan\n",
      "Epoch number: 5557/10000step_number: 0/29 Accuracy:  0.9624042227141154 Loss:  nan Val_accuracy:  0.9340779079269954 Val_cost:  nan Val_accuracy:  0.9340779079269954 Val_Acc:  nan\n",
      "Epoch number: 5558/10000step_number: 0/29 Accuracy:  0.953209603269198 Loss:  nan Val_accuracy:  0.9237265050394988 Val_cost:  nan Val_accuracy:  0.9237265050394988 Val_Acc:  nan\n",
      "Epoch number: 5559/10000step_number: 0/29 Accuracy:  0.9551847437425507 Loss:  nan Val_accuracy:  0.9284935984745301 Val_cost:  nan Val_accuracy:  0.9284935984745301 Val_Acc:  nan\n",
      "Epoch number: 5560/10000step_number: 0/29 Accuracy:  0.971973437766048 Loss:  nan Val_accuracy:  0.9402070280577499 Val_cost:  nan Val_accuracy:  0.9402070280577499 Val_Acc:  nan\n",
      "Epoch number: 5561/10000step_number: 0/29 Accuracy:  0.9689085646177422 Loss:  nan Val_accuracy:  0.9415690547534732 Val_cost:  nan Val_accuracy:  0.9415690547534732 Val_Acc:  nan\n",
      "Epoch number: 5562/10000step_number: 0/29 Accuracy:  0.9711220841137409 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5563/10000step_number: 0/29 Accuracy:  0.9697939724161416 Loss:  nan Val_accuracy:  0.9406156360664669 Val_cost:  nan Val_accuracy:  0.9406156360664669 Val_Acc:  nan\n",
      "Epoch number: 5564/10000step_number: 0/29 Accuracy:  0.9699642431466031 Loss:  nan Val_accuracy:  0.9419776627621902 Val_cost:  nan Val_accuracy:  0.9419776627621902 Val_Acc:  nan\n",
      "Epoch number: 5565/10000step_number: 0/29 Accuracy:  0.9702026221692491 Loss:  nan Val_accuracy:  0.9419776627621902 Val_cost:  nan Val_accuracy:  0.9419776627621902 Val_Acc:  nan\n",
      "Epoch number: 5566/10000step_number: 0/29 Accuracy:  0.97006640558488 Loss:  nan Val_accuracy:  0.9421138654317625 Val_cost:  nan Val_accuracy:  0.9421138654317625 Val_Acc:  nan\n",
      "Epoch number: 5567/10000step_number: 0/29 Accuracy:  0.9698961348544185 Loss:  nan Val_accuracy:  0.9418414600926178 Val_cost:  nan Val_accuracy:  0.9418414600926178 Val_Acc:  nan\n",
      "Epoch number: 5568/10000step_number: 0/29 Accuracy:  0.9696577558317725 Loss:  nan Val_accuracy:  0.9411604467447562 Val_cost:  nan Val_accuracy:  0.9411604467447562 Val_Acc:  nan\n",
      "Epoch number: 5569/10000step_number: 0/29 Accuracy:  0.9696918099778649 Loss:  nan Val_accuracy:  0.9410242440751839 Val_cost:  nan Val_accuracy:  0.9410242440751839 Val_Acc:  nan\n",
      "Epoch number: 5570/10000step_number: 0/29 Accuracy:  0.9696577558317725 Loss:  nan Val_accuracy:  0.9411604467447562 Val_cost:  nan Val_accuracy:  0.9411604467447562 Val_Acc:  nan\n",
      "Epoch number: 5571/10000step_number: 0/29 Accuracy:  0.9695555933934956 Loss:  nan Val_accuracy:  0.9410242440751839 Val_cost:  nan Val_accuracy:  0.9410242440751839 Val_Acc:  nan\n",
      "Epoch number: 5572/10000step_number: 0/29 Accuracy:  0.9694874851013111 Loss:  nan Val_accuracy:  0.9411604467447562 Val_cost:  nan Val_accuracy:  0.9411604467447562 Val_Acc:  nan\n",
      "Epoch number: 5573/10000step_number: 0/29 Accuracy:  0.9695555933934956 Loss:  nan Val_accuracy:  0.9411604467447562 Val_cost:  nan Val_accuracy:  0.9411604467447562 Val_Acc:  nan\n",
      "Epoch number: 5574/10000step_number: 0/29 Accuracy:  0.9694534309552189 Loss:  nan Val_accuracy:  0.9411604467447562 Val_cost:  nan Val_accuracy:  0.9411604467447562 Val_Acc:  nan\n",
      "Epoch number: 5575/10000step_number: 0/29 Accuracy:  0.9691469436403882 Loss:  nan Val_accuracy:  0.9412966494143286 Val_cost:  nan Val_accuracy:  0.9412966494143286 Val_Acc:  nan\n",
      "Epoch number: 5576/10000step_number: 0/29 Accuracy:  0.9689426187638345 Loss:  nan Val_accuracy:  0.9412966494143286 Val_cost:  nan Val_accuracy:  0.9412966494143286 Val_Acc:  nan\n",
      "Epoch number: 5577/10000step_number: 0/29 Accuracy:  0.96887451047165 Loss:  nan Val_accuracy:  0.9412966494143286 Val_cost:  nan Val_accuracy:  0.9412966494143286 Val_Acc:  nan\n",
      "Epoch number: 5578/10000step_number: 0/29 Accuracy:  0.96887451047165 Loss:  nan Val_accuracy:  0.9418414600926178 Val_cost:  nan Val_accuracy:  0.9418414600926178 Val_Acc:  nan\n",
      "Epoch number: 5579/10000step_number: 0/29 Accuracy:  0.9688064021794653 Loss:  nan Val_accuracy:  0.9417052574230454 Val_cost:  nan Val_accuracy:  0.9417052574230454 Val_Acc:  nan\n",
      "Epoch number: 5580/10000step_number: 0/29 Accuracy:  0.968636131449004 Loss:  nan Val_accuracy:  0.9414328520839008 Val_cost:  nan Val_accuracy:  0.9414328520839008 Val_Acc:  nan\n",
      "Epoch number: 5581/10000step_number: 0/29 Accuracy:  0.968636131449004 Loss:  nan Val_accuracy:  0.9414328520839008 Val_cost:  nan Val_accuracy:  0.9414328520839008 Val_Acc:  nan\n",
      "Epoch number: 5582/10000step_number: 0/29 Accuracy:  0.968636131449004 Loss:  nan Val_accuracy:  0.9414328520839008 Val_cost:  nan Val_accuracy:  0.9414328520839008 Val_Acc:  nan\n",
      "Epoch number: 5583/10000step_number: 0/29 Accuracy:  0.9686701855950962 Loss:  nan Val_accuracy:  0.9414328520839008 Val_cost:  nan Val_accuracy:  0.9414328520839008 Val_Acc:  nan\n",
      "Epoch number: 5584/10000step_number: 0/29 Accuracy:  0.9687723480333731 Loss:  nan Val_accuracy:  0.9414328520839008 Val_cost:  nan Val_accuracy:  0.9414328520839008 Val_Acc:  nan\n",
      "Epoch number: 5585/10000step_number: 0/29 Accuracy:  0.9687723480333731 Loss:  nan Val_accuracy:  0.9418414600926178 Val_cost:  nan Val_accuracy:  0.9418414600926178 Val_Acc:  nan\n",
      "Epoch number: 5586/10000step_number: 0/29 Accuracy:  0.9687042397411885 Loss:  nan Val_accuracy:  0.9419776627621902 Val_cost:  nan Val_accuracy:  0.9419776627621902 Val_Acc:  nan\n",
      "Epoch number: 5587/10000step_number: 0/29 Accuracy:  0.9686701855950962 Loss:  nan Val_accuracy:  0.9415690547534732 Val_cost:  nan Val_accuracy:  0.9415690547534732 Val_Acc:  nan\n",
      "Epoch number: 5588/10000step_number: 0/29 Accuracy:  0.9684999148646347 Loss:  nan Val_accuracy:  0.9411604467447562 Val_cost:  nan Val_accuracy:  0.9411604467447562 Val_Acc:  nan\n",
      "Epoch number: 5589/10000step_number: 0/29 Accuracy:  0.9685680231568193 Loss:  nan Val_accuracy:  0.9411604467447562 Val_cost:  nan Val_accuracy:  0.9411604467447562 Val_Acc:  nan\n",
      "Epoch number: 5590/10000step_number: 0/29 Accuracy:  0.9684658607185425 Loss:  nan Val_accuracy:  0.9412966494143286 Val_cost:  nan Val_accuracy:  0.9412966494143286 Val_Acc:  nan\n",
      "Epoch number: 5591/10000step_number: 0/29 Accuracy:  0.9684999148646347 Loss:  nan Val_accuracy:  0.9412966494143286 Val_cost:  nan Val_accuracy:  0.9412966494143286 Val_Acc:  nan\n",
      "Epoch number: 5592/10000step_number: 0/29 Accuracy:  0.9686020773029116 Loss:  nan Val_accuracy:  0.9414328520839008 Val_cost:  nan Val_accuracy:  0.9414328520839008 Val_Acc:  nan\n",
      "Epoch number: 5593/10000step_number: 0/29 Accuracy:  0.9681253192576196 Loss:  nan Val_accuracy:  0.9414328520839008 Val_cost:  nan Val_accuracy:  0.9414328520839008 Val_Acc:  nan\n",
      "Epoch number: 5594/10000step_number: 0/29 Accuracy:  0.9681593734037119 Loss:  nan Val_accuracy:  0.9417052574230454 Val_cost:  nan Val_accuracy:  0.9417052574230454 Val_Acc:  nan\n",
      "Epoch number: 5595/10000step_number: 0/29 Accuracy:  0.9682274816958965 Loss:  nan Val_accuracy:  0.9417052574230454 Val_cost:  nan Val_accuracy:  0.9417052574230454 Val_Acc:  nan\n",
      "Epoch number: 5596/10000step_number: 0/29 Accuracy:  0.9681934275498042 Loss:  nan Val_accuracy:  0.9417052574230454 Val_cost:  nan Val_accuracy:  0.9417052574230454 Val_Acc:  nan\n",
      "Epoch number: 5597/10000step_number: 0/29 Accuracy:  0.9681593734037119 Loss:  nan Val_accuracy:  0.9418414600926178 Val_cost:  nan Val_accuracy:  0.9418414600926178 Val_Acc:  nan\n",
      "Epoch number: 5598/10000step_number: 0/29 Accuracy:  0.9681593734037119 Loss:  nan Val_accuracy:  0.9418414600926178 Val_cost:  nan Val_accuracy:  0.9418414600926178 Val_Acc:  nan\n",
      "Epoch number: 5599/10000step_number: 0/29 Accuracy:  0.9681593734037119 Loss:  nan Val_accuracy:  0.9419776627621902 Val_cost:  nan Val_accuracy:  0.9419776627621902 Val_Acc:  nan\n",
      "Epoch number: 5600/10000step_number: 0/29 Accuracy:  0.9681593734037119 Loss:  nan Val_accuracy:  0.9419776627621902 Val_cost:  nan Val_accuracy:  0.9419776627621902 Val_Acc:  nan\n",
      "Epoch number: 5601/10000step_number: 0/29 Accuracy:  0.9681593734037119 Loss:  nan Val_accuracy:  0.9419776627621902 Val_cost:  nan Val_accuracy:  0.9419776627621902 Val_Acc:  nan\n",
      "Epoch number: 5602/10000step_number: 0/29 Accuracy:  0.9681253192576196 Loss:  nan Val_accuracy:  0.9419776627621902 Val_cost:  nan Val_accuracy:  0.9419776627621902 Val_Acc:  nan\n",
      "Epoch number: 5603/10000step_number: 0/29 Accuracy:  0.9681934275498042 Loss:  nan Val_accuracy:  0.9421138654317625 Val_cost:  nan Val_accuracy:  0.9421138654317625 Val_Acc:  nan\n",
      "Epoch number: 5604/10000step_number: 0/29 Accuracy:  0.9682615358419887 Loss:  nan Val_accuracy:  0.9421138654317625 Val_cost:  nan Val_accuracy:  0.9421138654317625 Val_Acc:  nan\n",
      "Epoch number: 5605/10000step_number: 0/29 Accuracy:  0.9682615358419887 Loss:  nan Val_accuracy:  0.9421138654317625 Val_cost:  nan Val_accuracy:  0.9421138654317625 Val_Acc:  nan\n",
      "Epoch number: 5606/10000step_number: 0/29 Accuracy:  0.9681934275498042 Loss:  nan Val_accuracy:  0.9419776627621902 Val_cost:  nan Val_accuracy:  0.9419776627621902 Val_Acc:  nan\n",
      "Epoch number: 5607/10000step_number: 0/29 Accuracy:  0.9681593734037119 Loss:  nan Val_accuracy:  0.9419776627621902 Val_cost:  nan Val_accuracy:  0.9419776627621902 Val_Acc:  nan\n",
      "Epoch number: 5608/10000step_number: 0/29 Accuracy:  0.9681593734037119 Loss:  nan Val_accuracy:  0.9419776627621902 Val_cost:  nan Val_accuracy:  0.9419776627621902 Val_Acc:  nan\n",
      "Epoch number: 5609/10000step_number: 0/29 Accuracy:  0.9681934275498042 Loss:  nan Val_accuracy:  0.9419776627621902 Val_cost:  nan Val_accuracy:  0.9419776627621902 Val_Acc:  nan\n",
      "Epoch number: 5610/10000step_number: 0/29 Accuracy:  0.9682274816958965 Loss:  nan Val_accuracy:  0.9421138654317625 Val_cost:  nan Val_accuracy:  0.9421138654317625 Val_Acc:  nan\n",
      "Epoch number: 5611/10000step_number: 0/29 Accuracy:  0.9682274816958965 Loss:  nan Val_accuracy:  0.9421138654317625 Val_cost:  nan Val_accuracy:  0.9421138654317625 Val_Acc:  nan\n",
      "Epoch number: 5612/10000step_number: 0/29 Accuracy:  0.9682615358419887 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5613/10000step_number: 0/29 Accuracy:  0.9683296441341733 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5614/10000step_number: 0/29 Accuracy:  0.9683296441341733 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5615/10000step_number: 0/29 Accuracy:  0.9681253192576196 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5616/10000step_number: 0/29 Accuracy:  0.9681253192576196 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5617/10000step_number: 0/29 Accuracy:  0.9681253192576196 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5618/10000step_number: 0/29 Accuracy:  0.9679550485271582 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5619/10000step_number: 0/29 Accuracy:  0.9679550485271582 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5620/10000step_number: 0/29 Accuracy:  0.9678528860888813 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5621/10000step_number: 0/29 Accuracy:  0.9678869402349736 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5622/10000step_number: 0/29 Accuracy:  0.9677507236506044 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5623/10000step_number: 0/29 Accuracy:  0.9676826153584199 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5624/10000step_number: 0/29 Accuracy:  0.9677507236506044 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5625/10000step_number: 0/29 Accuracy:  0.9678188319427891 Loss:  nan Val_accuracy:  0.9422500681013348 Val_cost:  nan Val_accuracy:  0.9422500681013348 Val_Acc:  nan\n",
      "Epoch number: 5626/10000step_number: 0/29 Accuracy:  0.9678528860888813 Loss:  nan Val_accuracy:  0.9422500681013348 Val_cost:  nan Val_accuracy:  0.9422500681013348 Val_Acc:  nan\n",
      "Epoch number: 5627/10000step_number: 0/29 Accuracy:  0.9679209943810659 Loss:  nan Val_accuracy:  0.9422500681013348 Val_cost:  nan Val_accuracy:  0.9422500681013348 Val_Acc:  nan\n",
      "Epoch number: 5628/10000step_number: 0/29 Accuracy:  0.9682274816958965 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5629/10000step_number: 0/29 Accuracy:  0.9682274816958965 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5630/10000step_number: 0/29 Accuracy:  0.9682955899880811 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5631/10000step_number: 0/29 Accuracy:  0.9683296441341733 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5632/10000step_number: 0/29 Accuracy:  0.9683636982802656 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5633/10000step_number: 0/29 Accuracy:  0.9683636982802656 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5634/10000step_number: 0/29 Accuracy:  0.9683296441341733 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5635/10000step_number: 0/29 Accuracy:  0.9682615358419887 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 5636/10000step_number: 0/29 Accuracy:  0.9682955899880811 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5637/10000step_number: 0/29 Accuracy:  0.9683296441341733 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 5638/10000step_number: 0/29 Accuracy:  0.9683636982802656 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5639/10000step_number: 0/29 Accuracy:  0.9684658607185425 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5640/10000step_number: 0/29 Accuracy:  0.9682274816958965 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5641/10000step_number: 0/29 Accuracy:  0.9681934275498042 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5642/10000step_number: 0/29 Accuracy:  0.9681934275498042 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5643/10000step_number: 0/29 Accuracy:  0.9681934275498042 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5644/10000step_number: 0/29 Accuracy:  0.9681253192576196 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 5645/10000step_number: 0/29 Accuracy:  0.9682274816958965 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5646/10000step_number: 0/29 Accuracy:  0.9681934275498042 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5647/10000step_number: 0/29 Accuracy:  0.9682274816958965 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5648/10000step_number: 0/29 Accuracy:  0.9682615358419887 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5649/10000step_number: 0/29 Accuracy:  0.9683296441341733 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5650/10000step_number: 0/29 Accuracy:  0.9683296441341733 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5651/10000step_number: 0/29 Accuracy:  0.9683636982802656 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 5652/10000step_number: 0/29 Accuracy:  0.9683296441341733 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5653/10000step_number: 0/29 Accuracy:  0.968397752426358 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5654/10000step_number: 0/29 Accuracy:  0.968397752426358 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5655/10000step_number: 0/29 Accuracy:  0.9684318065724502 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5656/10000step_number: 0/29 Accuracy:  0.9684318065724502 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5657/10000step_number: 0/29 Accuracy:  0.9684318065724502 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5658/10000step_number: 0/29 Accuracy:  0.9684658607185425 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5659/10000step_number: 0/29 Accuracy:  0.968397752426358 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5660/10000step_number: 0/29 Accuracy:  0.9684318065724502 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5661/10000step_number: 0/29 Accuracy:  0.9684999148646347 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5662/10000step_number: 0/29 Accuracy:  0.9684999148646347 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5663/10000step_number: 0/29 Accuracy:  0.9684658607185425 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5664/10000step_number: 0/29 Accuracy:  0.9676485612123276 Loss:  nan Val_accuracy:  0.9421138654317625 Val_cost:  nan Val_accuracy:  0.9421138654317625 Val_Acc:  nan\n",
      "Epoch number: 5665/10000step_number: 0/29 Accuracy:  0.9672399114592202 Loss:  nan Val_accuracy:  0.9414328520839008 Val_cost:  nan Val_accuracy:  0.9414328520839008 Val_Acc:  nan\n",
      "Epoch number: 5666/10000step_number: 0/29 Accuracy:  0.9673080197514047 Loss:  nan Val_accuracy:  0.9415690547534732 Val_cost:  nan Val_accuracy:  0.9415690547534732 Val_Acc:  nan\n",
      "Epoch number: 5667/10000step_number: 0/29 Accuracy:  0.9672058573131279 Loss:  nan Val_accuracy:  0.9417052574230454 Val_cost:  nan Val_accuracy:  0.9417052574230454 Val_Acc:  nan\n",
      "Epoch number: 5668/10000step_number: 0/29 Accuracy:  0.9672058573131279 Loss:  nan Val_accuracy:  0.9417052574230454 Val_cost:  nan Val_accuracy:  0.9417052574230454 Val_Acc:  nan\n",
      "Epoch number: 5669/10000step_number: 0/29 Accuracy:  0.9672058573131279 Loss:  nan Val_accuracy:  0.9418414600926178 Val_cost:  nan Val_accuracy:  0.9418414600926178 Val_Acc:  nan\n",
      "Epoch number: 5670/10000step_number: 0/29 Accuracy:  0.9672739656053124 Loss:  nan Val_accuracy:  0.9417052574230454 Val_cost:  nan Val_accuracy:  0.9417052574230454 Val_Acc:  nan\n",
      "Epoch number: 5671/10000step_number: 0/29 Accuracy:  0.9672739656053124 Loss:  nan Val_accuracy:  0.9419776627621902 Val_cost:  nan Val_accuracy:  0.9419776627621902 Val_Acc:  nan\n",
      "Epoch number: 5672/10000step_number: 0/29 Accuracy:  0.9673761280435893 Loss:  nan Val_accuracy:  0.9421138654317625 Val_cost:  nan Val_accuracy:  0.9421138654317625 Val_Acc:  nan\n",
      "Epoch number: 5673/10000step_number: 0/29 Accuracy:  0.9673080197514047 Loss:  nan Val_accuracy:  0.9418414600926178 Val_cost:  nan Val_accuracy:  0.9418414600926178 Val_Acc:  nan\n",
      "Epoch number: 5674/10000step_number: 0/29 Accuracy:  0.9674442363357739 Loss:  nan Val_accuracy:  0.9419776627621902 Val_cost:  nan Val_accuracy:  0.9419776627621902 Val_Acc:  nan\n",
      "Epoch number: 5675/10000step_number: 0/29 Accuracy:  0.9675463987740507 Loss:  nan Val_accuracy:  0.9417052574230454 Val_cost:  nan Val_accuracy:  0.9417052574230454 Val_Acc:  nan\n",
      "Epoch number: 5676/10000step_number: 0/29 Accuracy:  0.9676145070662353 Loss:  nan Val_accuracy:  0.9421138654317625 Val_cost:  nan Val_accuracy:  0.9421138654317625 Val_Acc:  nan\n",
      "Epoch number: 5677/10000step_number: 0/29 Accuracy:  0.9676485612123276 Loss:  nan Val_accuracy:  0.9421138654317625 Val_cost:  nan Val_accuracy:  0.9421138654317625 Val_Acc:  nan\n",
      "Epoch number: 5678/10000step_number: 0/29 Accuracy:  0.9677507236506044 Loss:  nan Val_accuracy:  0.9421138654317625 Val_cost:  nan Val_accuracy:  0.9421138654317625 Val_Acc:  nan\n",
      "Epoch number: 5679/10000step_number: 0/29 Accuracy:  0.9677847777966967 Loss:  nan Val_accuracy:  0.9421138654317625 Val_cost:  nan Val_accuracy:  0.9421138654317625 Val_Acc:  nan\n",
      "Epoch number: 5680/10000step_number: 0/29 Accuracy:  0.9676826153584199 Loss:  nan Val_accuracy:  0.9422500681013348 Val_cost:  nan Val_accuracy:  0.9422500681013348 Val_Acc:  nan\n",
      "Epoch number: 5681/10000step_number: 0/29 Accuracy:  0.9677847777966967 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5682/10000step_number: 0/29 Accuracy:  0.9678528860888813 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5683/10000step_number: 0/29 Accuracy:  0.9679550485271582 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5684/10000step_number: 0/29 Accuracy:  0.9679891026732504 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5685/10000step_number: 0/29 Accuracy:  0.9680231568193427 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5686/10000step_number: 0/29 Accuracy:  0.9680231568193427 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5687/10000step_number: 0/29 Accuracy:  0.9680912651115273 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5688/10000step_number: 0/29 Accuracy:  0.9681253192576196 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5689/10000step_number: 0/29 Accuracy:  0.9682274816958965 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5690/10000step_number: 0/29 Accuracy:  0.9682274816958965 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5691/10000step_number: 0/29 Accuracy:  0.9682615358419887 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5692/10000step_number: 0/29 Accuracy:  0.9682615358419887 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5693/10000step_number: 0/29 Accuracy:  0.9682955899880811 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5694/10000step_number: 0/29 Accuracy:  0.9683296441341733 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5695/10000step_number: 0/29 Accuracy:  0.9683636982802656 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5696/10000step_number: 0/29 Accuracy:  0.9683636982802656 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5697/10000step_number: 0/29 Accuracy:  0.9683636982802656 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5698/10000step_number: 0/29 Accuracy:  0.9685680231568193 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5699/10000step_number: 0/29 Accuracy:  0.9687042397411885 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5700/10000step_number: 0/29 Accuracy:  0.9687723480333731 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5701/10000step_number: 0/29 Accuracy:  0.9687723480333731 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 5702/10000step_number: 0/29 Accuracy:  0.9688064021794653 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5703/10000step_number: 0/29 Accuracy:  0.96887451047165 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5704/10000step_number: 0/29 Accuracy:  0.96887451047165 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5705/10000step_number: 0/29 Accuracy:  0.9690107270560191 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5706/10000step_number: 0/29 Accuracy:  0.9690447812021113 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5707/10000step_number: 0/29 Accuracy:  0.9690447812021113 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5708/10000step_number: 0/29 Accuracy:  0.9690107270560191 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5709/10000step_number: 0/29 Accuracy:  0.9690107270560191 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5710/10000step_number: 0/29 Accuracy:  0.9690447812021113 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5711/10000step_number: 0/29 Accuracy:  0.9690107270560191 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5712/10000step_number: 0/29 Accuracy:  0.9690107270560191 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5713/10000step_number: 0/29 Accuracy:  0.9690107270560191 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 5714/10000step_number: 0/29 Accuracy:  0.9690788353482036 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 5715/10000step_number: 0/29 Accuracy:  0.9690788353482036 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5716/10000step_number: 0/29 Accuracy:  0.9691469436403882 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 5717/10000step_number: 0/29 Accuracy:  0.9692150519325727 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 5718/10000step_number: 0/29 Accuracy:  0.9692150519325727 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 5719/10000step_number: 0/29 Accuracy:  0.9691809977864805 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 5720/10000step_number: 0/29 Accuracy:  0.9692150519325727 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 5721/10000step_number: 0/29 Accuracy:  0.9692491060786651 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 5722/10000step_number: 0/29 Accuracy:  0.9693172143708496 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 5723/10000step_number: 0/29 Accuracy:  0.969351268516942 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 5724/10000step_number: 0/29 Accuracy:  0.969351268516942 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5725/10000step_number: 0/29 Accuracy:  0.9693853226630342 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 5726/10000step_number: 0/29 Accuracy:  0.9694193768091265 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5727/10000step_number: 0/29 Accuracy:  0.9694534309552189 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5728/10000step_number: 0/29 Accuracy:  0.9694534309552189 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5729/10000step_number: 0/29 Accuracy:  0.969351268516942 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 5730/10000step_number: 0/29 Accuracy:  0.9694534309552189 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 5731/10000step_number: 0/29 Accuracy:  0.9696237016856802 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 5732/10000step_number: 0/29 Accuracy:  0.9696237016856802 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 5733/10000step_number: 0/29 Accuracy:  0.969589647539588 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 5734/10000step_number: 0/29 Accuracy:  0.9696577558317725 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 5735/10000step_number: 0/29 Accuracy:  0.9698961348544185 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5736/10000step_number: 0/29 Accuracy:  0.9699301890005109 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 5737/10000step_number: 0/29 Accuracy:  0.9699642431466031 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 5738/10000step_number: 0/29 Accuracy:  0.9700323514387876 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 5739/10000step_number: 0/29 Accuracy:  0.9699642431466031 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 5740/10000step_number: 0/29 Accuracy:  0.9700323514387876 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5741/10000step_number: 0/29 Accuracy:  0.9700323514387876 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 5742/10000step_number: 0/29 Accuracy:  0.9700323514387876 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5743/10000step_number: 0/29 Accuracy:  0.9701004597309723 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 5744/10000step_number: 0/29 Accuracy:  0.9702026221692491 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 5745/10000step_number: 0/29 Accuracy:  0.9702026221692491 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 5746/10000step_number: 0/29 Accuracy:  0.9703388387536183 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 5747/10000step_number: 0/29 Accuracy:  0.9704410011918951 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 5748/10000step_number: 0/29 Accuracy:  0.9701685680231569 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 5749/10000step_number: 0/29 Accuracy:  0.970304784607526 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 5750/10000step_number: 0/29 Accuracy:  0.9707134343606334 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 5751/10000step_number: 0/29 Accuracy:  0.9708155967989103 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 5752/10000step_number: 0/29 Accuracy:  0.970543163630172 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 5753/10000step_number: 0/29 Accuracy:  0.969828026562234 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 5754/10000step_number: 0/29 Accuracy:  0.9708155967989103 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5755/10000step_number: 0/29 Accuracy:  0.9660139621998979 Loss:  nan Val_accuracy:  0.9403432307273223 Val_cost:  nan Val_accuracy:  0.9403432307273223 Val_Acc:  nan\n",
      "Epoch number: 5756/10000step_number: 0/29 Accuracy:  0.9575344798229184 Loss:  nan Val_accuracy:  0.9287660038136748 Val_cost:  nan Val_accuracy:  0.9287660038136748 Val_Acc:  nan\n",
      "Epoch number: 5757/10000step_number: 0/29 Accuracy:  0.9703728928997105 Loss:  nan Val_accuracy:  0.9391174067011714 Val_cost:  nan Val_accuracy:  0.9391174067011714 Val_Acc:  nan\n",
      "Epoch number: 5758/10000step_number: 0/29 Accuracy:  0.9670696407287587 Loss:  nan Val_accuracy:  0.9384363933533098 Val_cost:  nan Val_accuracy:  0.9384363933533098 Val_Acc:  nan\n",
      "Epoch number: 5759/10000step_number: 0/29 Accuracy:  0.9724161416652477 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 5760/10000step_number: 0/29 Accuracy:  0.9725864123957092 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 5761/10000step_number: 0/29 Accuracy:  0.9714626255746637 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 5762/10000step_number: 0/29 Accuracy:  0.9713604631363869 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 5763/10000step_number: 0/29 Accuracy:  0.9712242465520177 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 5764/10000step_number: 0/29 Accuracy:  0.9711220841137409 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 5765/10000step_number: 0/29 Accuracy:  0.971019921675464 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 5766/10000step_number: 0/29 Accuracy:  0.9708155967989103 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 5767/10000step_number: 0/29 Accuracy:  0.9705091094840796 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 5768/10000step_number: 0/29 Accuracy:  0.9704410011918951 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 5769/10000step_number: 0/29 Accuracy:  0.970304784607526 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 5770/10000step_number: 0/29 Accuracy:  0.970304784607526 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 5771/10000step_number: 0/29 Accuracy:  0.9702366763153414 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5772/10000step_number: 0/29 Accuracy:  0.9702026221692491 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 5773/10000step_number: 0/29 Accuracy:  0.97006640558488 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 5774/10000step_number: 0/29 Accuracy:  0.97006640558488 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5775/10000step_number: 0/29 Accuracy:  0.9700323514387876 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5776/10000step_number: 0/29 Accuracy:  0.9701004597309723 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5777/10000step_number: 0/29 Accuracy:  0.9700323514387876 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 5778/10000step_number: 0/29 Accuracy:  0.97006640558488 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 5779/10000step_number: 0/29 Accuracy:  0.9699642431466031 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5780/10000step_number: 0/29 Accuracy:  0.969828026562234 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5781/10000step_number: 0/29 Accuracy:  0.9695215392474034 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5782/10000step_number: 0/29 Accuracy:  0.9694534309552189 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5783/10000step_number: 0/29 Accuracy:  0.9694874851013111 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5784/10000step_number: 0/29 Accuracy:  0.9693853226630342 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 5785/10000step_number: 0/29 Accuracy:  0.9693172143708496 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5786/10000step_number: 0/29 Accuracy:  0.9692491060786651 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5787/10000step_number: 0/29 Accuracy:  0.9692491060786651 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 5788/10000step_number: 0/29 Accuracy:  0.9692150519325727 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 5789/10000step_number: 0/29 Accuracy:  0.9691469436403882 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 5790/10000step_number: 0/29 Accuracy:  0.969112889494296 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5791/10000step_number: 0/29 Accuracy:  0.9692150519325727 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5792/10000step_number: 0/29 Accuracy:  0.9693172143708496 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 5793/10000step_number: 0/29 Accuracy:  0.9691469436403882 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5794/10000step_number: 0/29 Accuracy:  0.9691469436403882 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5795/10000step_number: 0/29 Accuracy:  0.9690107270560191 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5796/10000step_number: 0/29 Accuracy:  0.969112889494296 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5797/10000step_number: 0/29 Accuracy:  0.9687382938872807 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5798/10000step_number: 0/29 Accuracy:  0.9687382938872807 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5799/10000step_number: 0/29 Accuracy:  0.9688404563255576 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5800/10000step_number: 0/29 Accuracy:  0.96887451047165 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5801/10000step_number: 0/29 Accuracy:  0.9688404563255576 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 5802/10000step_number: 0/29 Accuracy:  0.96887451047165 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 5803/10000step_number: 0/29 Accuracy:  0.9690107270560191 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5804/10000step_number: 0/29 Accuracy:  0.9690107270560191 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5805/10000step_number: 0/29 Accuracy:  0.9689426187638345 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5806/10000step_number: 0/29 Accuracy:  0.9690788353482036 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5807/10000step_number: 0/29 Accuracy:  0.9690447812021113 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 5808/10000step_number: 0/29 Accuracy:  0.969112889494296 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 5809/10000step_number: 0/29 Accuracy:  0.9691809977864805 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 5810/10000step_number: 0/29 Accuracy:  0.9692491060786651 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5811/10000step_number: 0/29 Accuracy:  0.9692491060786651 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5812/10000step_number: 0/29 Accuracy:  0.9693172143708496 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 5813/10000step_number: 0/29 Accuracy:  0.9694193768091265 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5814/10000step_number: 0/29 Accuracy:  0.9694193768091265 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 5815/10000step_number: 0/29 Accuracy:  0.9693853226630342 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5816/10000step_number: 0/29 Accuracy:  0.9693853226630342 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5817/10000step_number: 0/29 Accuracy:  0.969351268516942 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5818/10000step_number: 0/29 Accuracy:  0.9692150519325727 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5819/10000step_number: 0/29 Accuracy:  0.9692150519325727 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5820/10000step_number: 0/29 Accuracy:  0.9692150519325727 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5821/10000step_number: 0/29 Accuracy:  0.969112889494296 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5822/10000step_number: 0/29 Accuracy:  0.9690788353482036 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 5823/10000step_number: 0/29 Accuracy:  0.9689426187638345 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5824/10000step_number: 0/29 Accuracy:  0.9689426187638345 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5825/10000step_number: 0/29 Accuracy:  0.9688064021794653 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5826/10000step_number: 0/29 Accuracy:  0.9688064021794653 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5827/10000step_number: 0/29 Accuracy:  0.9687382938872807 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5828/10000step_number: 0/29 Accuracy:  0.9687382938872807 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5829/10000step_number: 0/29 Accuracy:  0.9685339690107271 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5830/10000step_number: 0/29 Accuracy:  0.9686020773029116 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5831/10000step_number: 0/29 Accuracy:  0.9686020773029116 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5832/10000step_number: 0/29 Accuracy:  0.968636131449004 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5833/10000step_number: 0/29 Accuracy:  0.9686701855950962 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 5834/10000step_number: 0/29 Accuracy:  0.9685680231568193 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 5835/10000step_number: 0/29 Accuracy:  0.968636131449004 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5836/10000step_number: 0/29 Accuracy:  0.968636131449004 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5837/10000step_number: 0/29 Accuracy:  0.9686020773029116 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5838/10000step_number: 0/29 Accuracy:  0.968636131449004 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5839/10000step_number: 0/29 Accuracy:  0.9689766729099267 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5840/10000step_number: 0/29 Accuracy:  0.9693853226630342 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5841/10000step_number: 0/29 Accuracy:  0.9693853226630342 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5842/10000step_number: 0/29 Accuracy:  0.9694874851013111 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 5843/10000step_number: 0/29 Accuracy:  0.9694534309552189 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 5844/10000step_number: 0/29 Accuracy:  0.9684999148646347 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5845/10000step_number: 0/29 Accuracy:  0.968397752426358 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 5846/10000step_number: 0/29 Accuracy:  0.9684318065724502 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 5847/10000step_number: 0/29 Accuracy:  0.968397752426358 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 5848/10000step_number: 0/29 Accuracy:  0.968397752426358 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5849/10000step_number: 0/29 Accuracy:  0.968397752426358 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 5850/10000step_number: 0/29 Accuracy:  0.9680572109654351 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5851/10000step_number: 0/29 Accuracy:  0.9680231568193427 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5852/10000step_number: 0/29 Accuracy:  0.9680572109654351 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5853/10000step_number: 0/29 Accuracy:  0.9680912651115273 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5854/10000step_number: 0/29 Accuracy:  0.9680912651115273 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5855/10000step_number: 0/29 Accuracy:  0.9681253192576196 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5856/10000step_number: 0/29 Accuracy:  0.9677507236506044 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5857/10000step_number: 0/29 Accuracy:  0.9677507236506044 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5858/10000step_number: 0/29 Accuracy:  0.9678188319427891 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5859/10000step_number: 0/29 Accuracy:  0.9678188319427891 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5860/10000step_number: 0/29 Accuracy:  0.9678869402349736 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5861/10000step_number: 0/29 Accuracy:  0.9679209943810659 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5862/10000step_number: 0/29 Accuracy:  0.9680231568193427 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5863/10000step_number: 0/29 Accuracy:  0.9681253192576196 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5864/10000step_number: 0/29 Accuracy:  0.9679891026732504 Loss:  nan Val_accuracy:  0.9422500681013348 Val_cost:  nan Val_accuracy:  0.9422500681013348 Val_Acc:  nan\n",
      "Epoch number: 5865/10000step_number: 0/29 Accuracy:  0.9681253192576196 Loss:  nan Val_accuracy:  0.9422500681013348 Val_cost:  nan Val_accuracy:  0.9422500681013348 Val_Acc:  nan\n",
      "Epoch number: 5866/10000step_number: 0/29 Accuracy:  0.9680912651115273 Loss:  nan Val_accuracy:  0.9421138654317625 Val_cost:  nan Val_accuracy:  0.9421138654317625 Val_Acc:  nan\n",
      "Epoch number: 5867/10000step_number: 0/29 Accuracy:  0.9681593734037119 Loss:  nan Val_accuracy:  0.9419776627621902 Val_cost:  nan Val_accuracy:  0.9419776627621902 Val_Acc:  nan\n",
      "Epoch number: 5868/10000step_number: 0/29 Accuracy:  0.9681934275498042 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5869/10000step_number: 0/29 Accuracy:  0.9682955899880811 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5870/10000step_number: 0/29 Accuracy:  0.9684318065724502 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5871/10000step_number: 0/29 Accuracy:  0.9684658607185425 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5872/10000step_number: 0/29 Accuracy:  0.9684318065724502 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5873/10000step_number: 0/29 Accuracy:  0.9685339690107271 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5874/10000step_number: 0/29 Accuracy:  0.9686020773029116 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5875/10000step_number: 0/29 Accuracy:  0.968636131449004 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5876/10000step_number: 0/29 Accuracy:  0.9687723480333731 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5877/10000step_number: 0/29 Accuracy:  0.9688404563255576 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5878/10000step_number: 0/29 Accuracy:  0.9688404563255576 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5879/10000step_number: 0/29 Accuracy:  0.9693172143708496 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 5880/10000step_number: 0/29 Accuracy:  0.9694193768091265 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 5881/10000step_number: 0/29 Accuracy:  0.969589647539588 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5882/10000step_number: 0/29 Accuracy:  0.969589647539588 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 5883/10000step_number: 0/29 Accuracy:  0.969589647539588 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 5884/10000step_number: 0/29 Accuracy:  0.9697258641239571 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 5885/10000step_number: 0/29 Accuracy:  0.9697258641239571 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5886/10000step_number: 0/29 Accuracy:  0.9697258641239571 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5887/10000step_number: 0/29 Accuracy:  0.9697939724161416 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 5888/10000step_number: 0/29 Accuracy:  0.969828026562234 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 5889/10000step_number: 0/29 Accuracy:  0.9698620807083262 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 5890/10000step_number: 0/29 Accuracy:  0.969828026562234 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 5891/10000step_number: 0/29 Accuracy:  0.9698620807083262 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 5892/10000step_number: 0/29 Accuracy:  0.9699301890005109 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 5893/10000step_number: 0/29 Accuracy:  0.9699642431466031 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 5894/10000step_number: 0/29 Accuracy:  0.9699982972926954 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 5895/10000step_number: 0/29 Accuracy:  0.9699982972926954 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 5896/10000step_number: 0/29 Accuracy:  0.97006640558488 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5897/10000step_number: 0/29 Accuracy:  0.97006640558488 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 5898/10000step_number: 0/29 Accuracy:  0.9700323514387876 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 5899/10000step_number: 0/29 Accuracy:  0.9699982972926954 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5900/10000step_number: 0/29 Accuracy:  0.9699642431466031 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5901/10000step_number: 0/29 Accuracy:  0.9699301890005109 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5902/10000step_number: 0/29 Accuracy:  0.9699301890005109 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5903/10000step_number: 0/29 Accuracy:  0.9699982972926954 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5904/10000step_number: 0/29 Accuracy:  0.9699301890005109 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 5905/10000step_number: 0/29 Accuracy:  0.97006640558488 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5906/10000step_number: 0/29 Accuracy:  0.9701685680231569 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5907/10000step_number: 0/29 Accuracy:  0.9701685680231569 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 5908/10000step_number: 0/29 Accuracy:  0.9704069470458029 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5909/10000step_number: 0/29 Accuracy:  0.9706793802145411 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 5910/10000step_number: 0/29 Accuracy:  0.970543163630172 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5911/10000step_number: 0/29 Accuracy:  0.9707474885067257 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5912/10000step_number: 0/29 Accuracy:  0.9710880299676485 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 5913/10000step_number: 0/29 Accuracy:  0.9713264089902945 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 5914/10000step_number: 0/29 Accuracy:  0.9722118167886941 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 5915/10000step_number: 0/29 Accuracy:  0.9728247914183552 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5916/10000step_number: 0/29 Accuracy:  0.9736420909245701 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 5917/10000step_number: 0/29 Accuracy:  0.9749020943299846 Loss:  nan Val_accuracy:  0.9457913375102152 Val_cost:  nan Val_accuracy:  0.9457913375102152 Val_Acc:  nan\n",
      "Epoch number: 5918/10000step_number: 0/29 Accuracy:  0.9746637153073386 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 5919/10000step_number: 0/29 Accuracy:  0.9743572279925081 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 5920/10000step_number: 0/29 Accuracy:  0.9755491231057382 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 5921/10000step_number: 0/29 Accuracy:  0.9727226289800783 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5922/10000step_number: 0/29 Accuracy:  0.9732334411714626 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 5923/10000step_number: 0/29 Accuracy:  0.9722458709347863 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5924/10000step_number: 0/29 Accuracy:  0.9708155967989103 Loss:  nan Val_accuracy:  0.9419776627621902 Val_cost:  nan Val_accuracy:  0.9419776627621902 Val_Acc:  nan\n",
      "Epoch number: 5925/10000step_number: 0/29 Accuracy:  0.9707134343606334 Loss:  nan Val_accuracy:  0.9422500681013348 Val_cost:  nan Val_accuracy:  0.9422500681013348 Val_Acc:  nan\n",
      "Epoch number: 5926/10000step_number: 0/29 Accuracy:  0.9711561382598332 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5927/10000step_number: 0/29 Accuracy:  0.9708496509450025 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5928/10000step_number: 0/29 Accuracy:  0.9710880299676485 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 5929/10000step_number: 0/29 Accuracy:  0.9711220841137409 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 5930/10000step_number: 0/29 Accuracy:  0.9710880299676485 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5931/10000step_number: 0/29 Accuracy:  0.9712923548442023 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5932/10000step_number: 0/29 Accuracy:  0.9713945172824792 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5933/10000step_number: 0/29 Accuracy:  0.9713264089902945 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5934/10000step_number: 0/29 Accuracy:  0.9713604631363869 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5935/10000step_number: 0/29 Accuracy:  0.9714285714285714 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5936/10000step_number: 0/29 Accuracy:  0.9713604631363869 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 5937/10000step_number: 0/29 Accuracy:  0.9713264089902945 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5938/10000step_number: 0/29 Accuracy:  0.9713945172824792 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 5939/10000step_number: 0/29 Accuracy:  0.9713945172824792 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5940/10000step_number: 0/29 Accuracy:  0.9710880299676485 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 5941/10000step_number: 0/29 Accuracy:  0.9710880299676485 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 5942/10000step_number: 0/29 Accuracy:  0.9707134343606334 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 5943/10000step_number: 0/29 Accuracy:  0.9696577558317725 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 5944/10000step_number: 0/29 Accuracy:  0.9696577558317725 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 5945/10000step_number: 0/29 Accuracy:  0.9692831602247574 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 5946/10000step_number: 0/29 Accuracy:  0.969112889494296 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 5947/10000step_number: 0/29 Accuracy:  0.9695215392474034 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 5948/10000step_number: 0/29 Accuracy:  0.9694193768091265 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5949/10000step_number: 0/29 Accuracy:  0.9691809977864805 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 5950/10000step_number: 0/29 Accuracy:  0.9685680231568193 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 5951/10000step_number: 0/29 Accuracy:  0.9685339690107271 Loss:  nan Val_accuracy:  0.9421138654317625 Val_cost:  nan Val_accuracy:  0.9421138654317625 Val_Acc:  nan\n",
      "Epoch number: 5952/10000step_number: 0/29 Accuracy:  0.9684999148646347 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5953/10000step_number: 0/29 Accuracy:  0.9683296441341733 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5954/10000step_number: 0/29 Accuracy:  0.9682955899880811 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5955/10000step_number: 0/29 Accuracy:  0.968397752426358 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5956/10000step_number: 0/29 Accuracy:  0.9684318065724502 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5957/10000step_number: 0/29 Accuracy:  0.9684318065724502 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5958/10000step_number: 0/29 Accuracy:  0.9684999148646347 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5959/10000step_number: 0/29 Accuracy:  0.9683636982802656 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5960/10000step_number: 0/29 Accuracy:  0.9683296441341733 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5961/10000step_number: 0/29 Accuracy:  0.9683296441341733 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5962/10000step_number: 0/29 Accuracy:  0.9683296441341733 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5963/10000step_number: 0/29 Accuracy:  0.9682955899880811 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5964/10000step_number: 0/29 Accuracy:  0.968397752426358 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5965/10000step_number: 0/29 Accuracy:  0.968397752426358 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 5966/10000step_number: 0/29 Accuracy:  0.9683296441341733 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5967/10000step_number: 0/29 Accuracy:  0.9683636982802656 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5968/10000step_number: 0/29 Accuracy:  0.9684318065724502 Loss:  nan Val_accuracy:  0.9422500681013348 Val_cost:  nan Val_accuracy:  0.9422500681013348 Val_Acc:  nan\n",
      "Epoch number: 5969/10000step_number: 0/29 Accuracy:  0.9685339690107271 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5970/10000step_number: 0/29 Accuracy:  0.9685680231568193 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5971/10000step_number: 0/29 Accuracy:  0.9686701855950962 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5972/10000step_number: 0/29 Accuracy:  0.9687042397411885 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5973/10000step_number: 0/29 Accuracy:  0.9687042397411885 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5974/10000step_number: 0/29 Accuracy:  0.9687382938872807 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 5975/10000step_number: 0/29 Accuracy:  0.9687723480333731 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5976/10000step_number: 0/29 Accuracy:  0.96887451047165 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5977/10000step_number: 0/29 Accuracy:  0.9690447812021113 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5978/10000step_number: 0/29 Accuracy:  0.9691469436403882 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 5979/10000step_number: 0/29 Accuracy:  0.969351268516942 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 5980/10000step_number: 0/29 Accuracy:  0.9693172143708496 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5981/10000step_number: 0/29 Accuracy:  0.9692831602247574 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 5982/10000step_number: 0/29 Accuracy:  0.9694193768091265 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5983/10000step_number: 0/29 Accuracy:  0.9697599182700494 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5984/10000step_number: 0/29 Accuracy:  0.9697599182700494 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5985/10000step_number: 0/29 Accuracy:  0.9698961348544185 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5986/10000step_number: 0/29 Accuracy:  0.9700323514387876 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 5987/10000step_number: 0/29 Accuracy:  0.9701685680231569 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 5988/10000step_number: 0/29 Accuracy:  0.9702707304614336 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5989/10000step_number: 0/29 Accuracy:  0.970304784607526 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 5990/10000step_number: 0/29 Accuracy:  0.9704069470458029 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 5991/10000step_number: 0/29 Accuracy:  0.9706453260684489 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 5992/10000step_number: 0/29 Accuracy:  0.9706453260684489 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 5993/10000step_number: 0/29 Accuracy:  0.9711220841137409 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 5994/10000step_number: 0/29 Accuracy:  0.97125830069811 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 5995/10000step_number: 0/29 Accuracy:  0.9713604631363869 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 5996/10000step_number: 0/29 Accuracy:  0.9720074919121403 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 5997/10000step_number: 0/29 Accuracy:  0.9720074919121403 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 5998/10000step_number: 0/29 Accuracy:  0.9725523582496169 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 5999/10000step_number: 0/29 Accuracy:  0.9725183041035246 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6000/10000step_number: 0/29 Accuracy:  0.973029116294909 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6001/10000step_number: 0/29 Accuracy:  0.9721437084965094 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6002/10000step_number: 0/29 Accuracy:  0.9725864123957092 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 6003/10000step_number: 0/29 Accuracy:  0.9701685680231569 Loss:  nan Val_accuracy:  0.9399346227186053 Val_cost:  nan Val_accuracy:  0.9399346227186053 Val_Acc:  nan\n",
      "Epoch number: 6004/10000step_number: 0/29 Accuracy:  0.9730972245870935 Loss:  nan Val_accuracy:  0.9410242440751839 Val_cost:  nan Val_accuracy:  0.9410242440751839 Val_Acc:  nan\n",
      "Epoch number: 6005/10000step_number: 0/29 Accuracy:  0.9619274646688234 Loss:  nan Val_accuracy:  0.9331244892399891 Val_cost:  nan Val_accuracy:  0.9331244892399891 Val_Acc:  nan\n",
      "Epoch number: 6006/10000step_number: 0/29 Accuracy:  0.966626936829559 Loss:  nan Val_accuracy:  0.9370743666575865 Val_cost:  nan Val_accuracy:  0.9370743666575865 Val_Acc:  nan\n",
      "Epoch number: 6007/10000step_number: 0/29 Accuracy:  0.9684658607185425 Loss:  nan Val_accuracy:  0.9358485426314356 Val_cost:  nan Val_accuracy:  0.9358485426314356 Val_Acc:  nan\n",
      "Epoch number: 6008/10000step_number: 0/29 Accuracy:  0.9773880469947216 Loss:  nan Val_accuracy:  0.9463361481885045 Val_cost:  nan Val_accuracy:  0.9463361481885045 Val_Acc:  nan\n",
      "Epoch number: 6009/10000step_number: 0/29 Accuracy:  0.9738804699472161 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 6010/10000step_number: 0/29 Accuracy:  0.9739485782394006 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6011/10000step_number: 0/29 Accuracy:  0.973029116294909 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6012/10000step_number: 0/29 Accuracy:  0.9731653328792781 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6013/10000step_number: 0/29 Accuracy:  0.9727226289800783 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 6014/10000step_number: 0/29 Accuracy:  0.9723480333730632 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 6015/10000step_number: 0/29 Accuracy:  0.9722799250808786 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 6016/10000step_number: 0/29 Accuracy:  0.9722118167886941 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 6017/10000step_number: 0/29 Accuracy:  0.9721096543504172 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6018/10000step_number: 0/29 Accuracy:  0.9720415460582326 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6019/10000step_number: 0/29 Accuracy:  0.9723480333730632 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6020/10000step_number: 0/29 Accuracy:  0.9722118167886941 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6021/10000step_number: 0/29 Accuracy:  0.9721437084965094 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6022/10000step_number: 0/29 Accuracy:  0.9721096543504172 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6023/10000step_number: 0/29 Accuracy:  0.9720415460582326 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6024/10000step_number: 0/29 Accuracy:  0.9719053294738634 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6025/10000step_number: 0/29 Accuracy:  0.9719393836199557 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6026/10000step_number: 0/29 Accuracy:  0.971735058743402 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6027/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6028/10000step_number: 0/29 Accuracy:  0.9716328963051252 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6029/10000step_number: 0/29 Accuracy:  0.9715647880129406 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6030/10000step_number: 0/29 Accuracy:  0.9715647880129406 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6031/10000step_number: 0/29 Accuracy:  0.9715988421590329 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6032/10000step_number: 0/29 Accuracy:  0.9716328963051252 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6033/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6034/10000step_number: 0/29 Accuracy:  0.971735058743402 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6035/10000step_number: 0/29 Accuracy:  0.971735058743402 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6036/10000step_number: 0/29 Accuracy:  0.9716669504512174 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6037/10000step_number: 0/29 Accuracy:  0.9713945172824792 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 6038/10000step_number: 0/29 Accuracy:  0.9713945172824792 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 6039/10000step_number: 0/29 Accuracy:  0.9712242465520177 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6040/10000step_number: 0/29 Accuracy:  0.9711901924059254 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6041/10000step_number: 0/29 Accuracy:  0.9710880299676485 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6042/10000step_number: 0/29 Accuracy:  0.9711561382598332 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6043/10000step_number: 0/29 Accuracy:  0.9711220841137409 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6044/10000step_number: 0/29 Accuracy:  0.9711901924059254 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6045/10000step_number: 0/29 Accuracy:  0.9711561382598332 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6046/10000step_number: 0/29 Accuracy:  0.9711561382598332 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6047/10000step_number: 0/29 Accuracy:  0.9712242465520177 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6048/10000step_number: 0/29 Accuracy:  0.9713264089902945 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6049/10000step_number: 0/29 Accuracy:  0.9712923548442023 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6050/10000step_number: 0/29 Accuracy:  0.9711901924059254 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6051/10000step_number: 0/29 Accuracy:  0.9711561382598332 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6052/10000step_number: 0/29 Accuracy:  0.9711901924059254 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6053/10000step_number: 0/29 Accuracy:  0.9712242465520177 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6054/10000step_number: 0/29 Accuracy:  0.9712242465520177 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6055/10000step_number: 0/29 Accuracy:  0.9711220841137409 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6056/10000step_number: 0/29 Accuracy:  0.971019921675464 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6057/10000step_number: 0/29 Accuracy:  0.9710539758215563 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6058/10000step_number: 0/29 Accuracy:  0.9709858675293717 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6059/10000step_number: 0/29 Accuracy:  0.9709858675293717 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6060/10000step_number: 0/29 Accuracy:  0.9708837050910949 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6061/10000step_number: 0/29 Accuracy:  0.970543163630172 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6062/10000step_number: 0/29 Accuracy:  0.9705772177762643 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6063/10000step_number: 0/29 Accuracy:  0.9706453260684489 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6064/10000step_number: 0/29 Accuracy:  0.9705772177762643 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6065/10000step_number: 0/29 Accuracy:  0.9705772177762643 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6066/10000step_number: 0/29 Accuracy:  0.9706112719223565 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6067/10000step_number: 0/29 Accuracy:  0.970543163630172 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6068/10000step_number: 0/29 Accuracy:  0.9705091094840796 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6069/10000step_number: 0/29 Accuracy:  0.9705772177762643 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6070/10000step_number: 0/29 Accuracy:  0.9706112719223565 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6071/10000step_number: 0/29 Accuracy:  0.9706793802145411 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6072/10000step_number: 0/29 Accuracy:  0.9707134343606334 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6073/10000step_number: 0/29 Accuracy:  0.9707134343606334 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6074/10000step_number: 0/29 Accuracy:  0.9703728928997105 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 6075/10000step_number: 0/29 Accuracy:  0.9704069470458029 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 6076/10000step_number: 0/29 Accuracy:  0.9704069470458029 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 6077/10000step_number: 0/29 Accuracy:  0.9704410011918951 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 6078/10000step_number: 0/29 Accuracy:  0.9696577558317725 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 6079/10000step_number: 0/29 Accuracy:  0.9697258641239571 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 6080/10000step_number: 0/29 Accuracy:  0.9697258641239571 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 6081/10000step_number: 0/29 Accuracy:  0.969828026562234 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 6082/10000step_number: 0/29 Accuracy:  0.9698620807083262 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 6083/10000step_number: 0/29 Accuracy:  0.9698620807083262 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 6084/10000step_number: 0/29 Accuracy:  0.9698620807083262 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 6085/10000step_number: 0/29 Accuracy:  0.9698620807083262 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 6086/10000step_number: 0/29 Accuracy:  0.9698620807083262 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 6087/10000step_number: 0/29 Accuracy:  0.9693853226630342 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 6088/10000step_number: 0/29 Accuracy:  0.9692831602247574 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 6089/10000step_number: 0/29 Accuracy:  0.9693172143708496 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 6090/10000step_number: 0/29 Accuracy:  0.9692150519325727 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 6091/10000step_number: 0/29 Accuracy:  0.9692831602247574 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 6092/10000step_number: 0/29 Accuracy:  0.9692491060786651 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 6093/10000step_number: 0/29 Accuracy:  0.9692491060786651 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 6094/10000step_number: 0/29 Accuracy:  0.969351268516942 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 6095/10000step_number: 0/29 Accuracy:  0.9693172143708496 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 6096/10000step_number: 0/29 Accuracy:  0.9694193768091265 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 6097/10000step_number: 0/29 Accuracy:  0.9694534309552189 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 6098/10000step_number: 0/29 Accuracy:  0.9694534309552189 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 6099/10000step_number: 0/29 Accuracy:  0.9693853226630342 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 6100/10000step_number: 0/29 Accuracy:  0.9693853226630342 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 6101/10000step_number: 0/29 Accuracy:  0.9694534309552189 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 6102/10000step_number: 0/29 Accuracy:  0.9698961348544185 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6103/10000step_number: 0/29 Accuracy:  0.9700323514387876 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6104/10000step_number: 0/29 Accuracy:  0.9700323514387876 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6105/10000step_number: 0/29 Accuracy:  0.9702026221692491 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6106/10000step_number: 0/29 Accuracy:  0.970304784607526 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 6107/10000step_number: 0/29 Accuracy:  0.9705091094840796 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 6108/10000step_number: 0/29 Accuracy:  0.970543163630172 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6109/10000step_number: 0/29 Accuracy:  0.970543163630172 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6110/10000step_number: 0/29 Accuracy:  0.9709518133832794 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6111/10000step_number: 0/29 Accuracy:  0.971019921675464 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6112/10000step_number: 0/29 Accuracy:  0.9711561382598332 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6113/10000step_number: 0/29 Accuracy:  0.9712923548442023 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6114/10000step_number: 0/29 Accuracy:  0.9713264089902945 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6115/10000step_number: 0/29 Accuracy:  0.971496679720756 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6116/10000step_number: 0/29 Accuracy:  0.9715307338668483 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6117/10000step_number: 0/29 Accuracy:  0.9715988421590329 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6118/10000step_number: 0/29 Accuracy:  0.9715307338668483 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6119/10000step_number: 0/29 Accuracy:  0.9715307338668483 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6120/10000step_number: 0/29 Accuracy:  0.9715307338668483 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6121/10000step_number: 0/29 Accuracy:  0.9712923548442023 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6122/10000step_number: 0/29 Accuracy:  0.9713264089902945 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6123/10000step_number: 0/29 Accuracy:  0.9713945172824792 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6124/10000step_number: 0/29 Accuracy:  0.9710880299676485 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6125/10000step_number: 0/29 Accuracy:  0.9708837050910949 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6126/10000step_number: 0/29 Accuracy:  0.9709177592371872 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6127/10000step_number: 0/29 Accuracy:  0.9708837050910949 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6128/10000step_number: 0/29 Accuracy:  0.971496679720756 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6129/10000step_number: 0/29 Accuracy:  0.97125830069811 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 6130/10000step_number: 0/29 Accuracy:  0.9725523582496169 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 6131/10000step_number: 0/29 Accuracy:  0.9727226289800783 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 6132/10000step_number: 0/29 Accuracy:  0.9710539758215563 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 6133/10000step_number: 0/29 Accuracy:  0.9697939724161416 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6134/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6135/10000step_number: 0/29 Accuracy:  0.9613144900391623 Loss:  nan Val_accuracy:  0.9317624625442659 Val_cost:  nan Val_accuracy:  0.9317624625442659 Val_Acc:  nan\n",
      "Epoch number: 6136/10000step_number: 0/29 Accuracy:  0.9689426187638345 Loss:  nan Val_accuracy:  0.9387087986924544 Val_cost:  nan Val_accuracy:  0.9387087986924544 Val_Acc:  nan\n",
      "Epoch number: 6137/10000step_number: 0/29 Accuracy:  0.9634258470968841 Loss:  nan Val_accuracy:  0.9340779079269954 Val_cost:  nan Val_accuracy:  0.9340779079269954 Val_Acc:  nan\n",
      "Epoch number: 6138/10000step_number: 0/29 Accuracy:  0.9713264089902945 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 6139/10000step_number: 0/29 Accuracy:  0.9688064021794653 Loss:  nan Val_accuracy:  0.9404794333968945 Val_cost:  nan Val_accuracy:  0.9404794333968945 Val_Acc:  nan\n",
      "Epoch number: 6140/10000step_number: 0/29 Accuracy:  0.9752426357909075 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6141/10000step_number: 0/29 Accuracy:  0.9733015494636472 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6142/10000step_number: 0/29 Accuracy:  0.9750042567682615 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6143/10000step_number: 0/29 Accuracy:  0.9743572279925081 Loss:  nan Val_accuracy:  0.9467447561972214 Val_cost:  nan Val_accuracy:  0.9467447561972214 Val_Acc:  nan\n",
      "Epoch number: 6144/10000step_number: 0/29 Accuracy:  0.9745956070151541 Loss:  nan Val_accuracy:  0.9468809588667938 Val_cost:  nan Val_accuracy:  0.9468809588667938 Val_Acc:  nan\n",
      "Epoch number: 6145/10000step_number: 0/29 Accuracy:  0.9739145240933084 Loss:  nan Val_accuracy:  0.9464723508580768 Val_cost:  nan Val_accuracy:  0.9464723508580768 Val_Acc:  nan\n",
      "Epoch number: 6146/10000step_number: 0/29 Accuracy:  0.9738804699472161 Loss:  nan Val_accuracy:  0.9459275401797875 Val_cost:  nan Val_accuracy:  0.9459275401797875 Val_Acc:  nan\n",
      "Epoch number: 6147/10000step_number: 0/29 Accuracy:  0.9736420909245701 Loss:  nan Val_accuracy:  0.9459275401797875 Val_cost:  nan Val_accuracy:  0.9459275401797875 Val_Acc:  nan\n",
      "Epoch number: 6148/10000step_number: 0/29 Accuracy:  0.9734377660480164 Loss:  nan Val_accuracy:  0.9460637428493599 Val_cost:  nan Val_accuracy:  0.9460637428493599 Val_Acc:  nan\n",
      "Epoch number: 6149/10000step_number: 0/29 Accuracy:  0.9733696577558317 Loss:  nan Val_accuracy:  0.9457913375102152 Val_cost:  nan Val_accuracy:  0.9457913375102152 Val_Acc:  nan\n",
      "Epoch number: 6150/10000step_number: 0/29 Accuracy:  0.9732334411714626 Loss:  nan Val_accuracy:  0.9457913375102152 Val_cost:  nan Val_accuracy:  0.9457913375102152 Val_Acc:  nan\n",
      "Epoch number: 6151/10000step_number: 0/29 Accuracy:  0.973029116294909 Loss:  nan Val_accuracy:  0.9456551348406429 Val_cost:  nan Val_accuracy:  0.9456551348406429 Val_Acc:  nan\n",
      "Epoch number: 6152/10000step_number: 0/29 Accuracy:  0.9728588455644475 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6153/10000step_number: 0/29 Accuracy:  0.9727226289800783 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6154/10000step_number: 0/29 Accuracy:  0.9724501958113401 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6155/10000step_number: 0/29 Accuracy:  0.9724842499574323 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6156/10000step_number: 0/29 Accuracy:  0.9724161416652477 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6157/10000step_number: 0/29 Accuracy:  0.9724161416652477 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6158/10000step_number: 0/29 Accuracy:  0.9724501958113401 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6159/10000step_number: 0/29 Accuracy:  0.9724501958113401 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6160/10000step_number: 0/29 Accuracy:  0.9724842499574323 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6161/10000step_number: 0/29 Accuracy:  0.9725523582496169 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6162/10000step_number: 0/29 Accuracy:  0.9725183041035246 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6163/10000step_number: 0/29 Accuracy:  0.9723820875191554 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6164/10000step_number: 0/29 Accuracy:  0.9723480333730632 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6165/10000step_number: 0/29 Accuracy:  0.9723820875191554 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6166/10000step_number: 0/29 Accuracy:  0.9722458709347863 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6167/10000step_number: 0/29 Accuracy:  0.9722118167886941 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6168/10000step_number: 0/29 Accuracy:  0.9722118167886941 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6169/10000step_number: 0/29 Accuracy:  0.9721437084965094 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6170/10000step_number: 0/29 Accuracy:  0.9721777626426017 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6171/10000step_number: 0/29 Accuracy:  0.9721437084965094 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6172/10000step_number: 0/29 Accuracy:  0.9720415460582326 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6173/10000step_number: 0/29 Accuracy:  0.9720415460582326 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6174/10000step_number: 0/29 Accuracy:  0.9720415460582326 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6175/10000step_number: 0/29 Accuracy:  0.9720074919121403 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6176/10000step_number: 0/29 Accuracy:  0.9720415460582326 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6177/10000step_number: 0/29 Accuracy:  0.9718031670355866 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6178/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6179/10000step_number: 0/29 Accuracy:  0.9718031670355866 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6180/10000step_number: 0/29 Accuracy:  0.971735058743402 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6181/10000step_number: 0/29 Accuracy:  0.971735058743402 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6182/10000step_number: 0/29 Accuracy:  0.9717691128894943 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6183/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6184/10000step_number: 0/29 Accuracy:  0.9718031670355866 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6185/10000step_number: 0/29 Accuracy:  0.9718031670355866 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6186/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6187/10000step_number: 0/29 Accuracy:  0.9719053294738634 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6188/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6189/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6190/10000step_number: 0/29 Accuracy:  0.9718031670355866 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6191/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6192/10000step_number: 0/29 Accuracy:  0.9716669504512174 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6193/10000step_number: 0/29 Accuracy:  0.9716328963051252 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6194/10000step_number: 0/29 Accuracy:  0.9716328963051252 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6195/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6196/10000step_number: 0/29 Accuracy:  0.971496679720756 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6197/10000step_number: 0/29 Accuracy:  0.9715988421590329 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6198/10000step_number: 0/29 Accuracy:  0.9715647880129406 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6199/10000step_number: 0/29 Accuracy:  0.9715647880129406 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6200/10000step_number: 0/29 Accuracy:  0.9715647880129406 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6201/10000step_number: 0/29 Accuracy:  0.9715647880129406 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6202/10000step_number: 0/29 Accuracy:  0.9715307338668483 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6203/10000step_number: 0/29 Accuracy:  0.971496679720756 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6204/10000step_number: 0/29 Accuracy:  0.9715307338668483 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6205/10000step_number: 0/29 Accuracy:  0.9713945172824792 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6206/10000step_number: 0/29 Accuracy:  0.9714285714285714 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6207/10000step_number: 0/29 Accuracy:  0.9713604631363869 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6208/10000step_number: 0/29 Accuracy:  0.9714285714285714 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6209/10000step_number: 0/29 Accuracy:  0.9713945172824792 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6210/10000step_number: 0/29 Accuracy:  0.9713604631363869 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6211/10000step_number: 0/29 Accuracy:  0.9713945172824792 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6212/10000step_number: 0/29 Accuracy:  0.9713604631363869 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6213/10000step_number: 0/29 Accuracy:  0.9714285714285714 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6214/10000step_number: 0/29 Accuracy:  0.9714626255746637 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6215/10000step_number: 0/29 Accuracy:  0.9714626255746637 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6216/10000step_number: 0/29 Accuracy:  0.9714626255746637 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6217/10000step_number: 0/29 Accuracy:  0.9713604631363869 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6218/10000step_number: 0/29 Accuracy:  0.9711901924059254 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6219/10000step_number: 0/29 Accuracy:  0.9712242465520177 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6220/10000step_number: 0/29 Accuracy:  0.9712242465520177 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6221/10000step_number: 0/29 Accuracy:  0.9712242465520177 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6222/10000step_number: 0/29 Accuracy:  0.9712242465520177 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6223/10000step_number: 0/29 Accuracy:  0.9712242465520177 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6224/10000step_number: 0/29 Accuracy:  0.9712242465520177 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6225/10000step_number: 0/29 Accuracy:  0.9709177592371872 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6226/10000step_number: 0/29 Accuracy:  0.9709518133832794 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6227/10000step_number: 0/29 Accuracy:  0.9709177592371872 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6228/10000step_number: 0/29 Accuracy:  0.9709177592371872 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6229/10000step_number: 0/29 Accuracy:  0.9701345138770645 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 6230/10000step_number: 0/29 Accuracy:  0.9701004597309723 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6231/10000step_number: 0/29 Accuracy:  0.9701685680231569 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6232/10000step_number: 0/29 Accuracy:  0.9702366763153414 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6233/10000step_number: 0/29 Accuracy:  0.9702026221692491 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6234/10000step_number: 0/29 Accuracy:  0.9702026221692491 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6235/10000step_number: 0/29 Accuracy:  0.9702026221692491 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6236/10000step_number: 0/29 Accuracy:  0.9702026221692491 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6237/10000step_number: 0/29 Accuracy:  0.9702026221692491 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6238/10000step_number: 0/29 Accuracy:  0.9702026221692491 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6239/10000step_number: 0/29 Accuracy:  0.970304784607526 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6240/10000step_number: 0/29 Accuracy:  0.9704069470458029 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6241/10000step_number: 0/29 Accuracy:  0.9704750553379874 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6242/10000step_number: 0/29 Accuracy:  0.9703728928997105 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6243/10000step_number: 0/29 Accuracy:  0.9704410011918951 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6244/10000step_number: 0/29 Accuracy:  0.9705091094840796 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6245/10000step_number: 0/29 Accuracy:  0.9705091094840796 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6246/10000step_number: 0/29 Accuracy:  0.9706112719223565 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6247/10000step_number: 0/29 Accuracy:  0.9705772177762643 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6248/10000step_number: 0/29 Accuracy:  0.9706793802145411 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6249/10000step_number: 0/29 Accuracy:  0.9706112719223565 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6250/10000step_number: 0/29 Accuracy:  0.9706793802145411 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6251/10000step_number: 0/29 Accuracy:  0.9707474885067257 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6252/10000step_number: 0/29 Accuracy:  0.9707474885067257 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6253/10000step_number: 0/29 Accuracy:  0.9708496509450025 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6254/10000step_number: 0/29 Accuracy:  0.971019921675464 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6255/10000step_number: 0/29 Accuracy:  0.9710539758215563 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6256/10000step_number: 0/29 Accuracy:  0.9710539758215563 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6257/10000step_number: 0/29 Accuracy:  0.9710880299676485 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6258/10000step_number: 0/29 Accuracy:  0.9710880299676485 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6259/10000step_number: 0/29 Accuracy:  0.9711901924059254 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6260/10000step_number: 0/29 Accuracy:  0.9712242465520177 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6261/10000step_number: 0/29 Accuracy:  0.9712923548442023 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6262/10000step_number: 0/29 Accuracy:  0.9713264089902945 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6263/10000step_number: 0/29 Accuracy:  0.9713604631363869 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6264/10000step_number: 0/29 Accuracy:  0.9714285714285714 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6265/10000step_number: 0/29 Accuracy:  0.9713945172824792 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6266/10000step_number: 0/29 Accuracy:  0.9714285714285714 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6267/10000step_number: 0/29 Accuracy:  0.9713945172824792 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6268/10000step_number: 0/29 Accuracy:  0.9713604631363869 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6269/10000step_number: 0/29 Accuracy:  0.9713604631363869 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6270/10000step_number: 0/29 Accuracy:  0.9711220841137409 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 6271/10000step_number: 0/29 Accuracy:  0.9711901924059254 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 6272/10000step_number: 0/29 Accuracy:  0.9711901924059254 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 6273/10000step_number: 0/29 Accuracy:  0.9711901924059254 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 6274/10000step_number: 0/29 Accuracy:  0.9711901924059254 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6275/10000step_number: 0/29 Accuracy:  0.9711561382598332 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6276/10000step_number: 0/29 Accuracy:  0.9710880299676485 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6277/10000step_number: 0/29 Accuracy:  0.9708496509450025 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6278/10000step_number: 0/29 Accuracy:  0.9709177592371872 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6279/10000step_number: 0/29 Accuracy:  0.9709518133832794 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6280/10000step_number: 0/29 Accuracy:  0.971019921675464 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6281/10000step_number: 0/29 Accuracy:  0.9710880299676485 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6282/10000step_number: 0/29 Accuracy:  0.9710880299676485 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6283/10000step_number: 0/29 Accuracy:  0.9711561382598332 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6284/10000step_number: 0/29 Accuracy:  0.9711561382598332 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6285/10000step_number: 0/29 Accuracy:  0.9709177592371872 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6286/10000step_number: 0/29 Accuracy:  0.9708496509450025 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6287/10000step_number: 0/29 Accuracy:  0.9707474885067257 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6288/10000step_number: 0/29 Accuracy:  0.9707134343606334 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6289/10000step_number: 0/29 Accuracy:  0.9711561382598332 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6290/10000step_number: 0/29 Accuracy:  0.97125830069811 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6291/10000step_number: 0/29 Accuracy:  0.9713264089902945 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6292/10000step_number: 0/29 Accuracy:  0.9716669504512174 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6293/10000step_number: 0/29 Accuracy:  0.9716328963051252 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6294/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6295/10000step_number: 0/29 Accuracy:  0.9724842499574323 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6296/10000step_number: 0/29 Accuracy:  0.9729950621488166 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6297/10000step_number: 0/29 Accuracy:  0.9712242465520177 Loss:  nan Val_accuracy:  0.9415690547534732 Val_cost:  nan Val_accuracy:  0.9415690547534732 Val_Acc:  nan\n",
      "Epoch number: 6298/10000step_number: 0/29 Accuracy:  0.9753107440830922 Loss:  nan Val_accuracy:  0.9459275401797875 Val_cost:  nan Val_accuracy:  0.9459275401797875 Val_Acc:  nan\n",
      "Epoch number: 6299/10000step_number: 0/29 Accuracy:  0.9747658777456155 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6300/10000step_number: 0/29 Accuracy:  0.9747318235995233 Loss:  nan Val_accuracy:  0.9466085535276492 Val_cost:  nan Val_accuracy:  0.9466085535276492 Val_Acc:  nan\n",
      "Epoch number: 6301/10000step_number: 0/29 Accuracy:  0.9745274987229695 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6302/10000step_number: 0/29 Accuracy:  0.9746296611612464 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6303/10000step_number: 0/29 Accuracy:  0.9757875021283842 Loss:  nan Val_accuracy:  0.9463361481885045 Val_cost:  nan Val_accuracy:  0.9463361481885045 Val_Acc:  nan\n",
      "Epoch number: 6304/10000step_number: 0/29 Accuracy:  0.9755831772518304 Loss:  nan Val_accuracy:  0.9463361481885045 Val_cost:  nan Val_accuracy:  0.9463361481885045 Val_Acc:  nan\n",
      "Epoch number: 6305/10000step_number: 0/29 Accuracy:  0.974697769453431 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6306/10000step_number: 0/29 Accuracy:  0.9746637153073386 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6307/10000step_number: 0/29 Accuracy:  0.9743912821386004 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6308/10000step_number: 0/29 Accuracy:  0.9737783075089392 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6309/10000step_number: 0/29 Accuracy:  0.9750383109143538 Loss:  nan Val_accuracy:  0.9459275401797875 Val_cost:  nan Val_accuracy:  0.9459275401797875 Val_Acc:  nan\n",
      "Epoch number: 6310/10000step_number: 0/29 Accuracy:  0.9757534479822918 Loss:  nan Val_accuracy:  0.9470171615363661 Val_cost:  nan Val_accuracy:  0.9470171615363661 Val_Acc:  nan\n",
      "Epoch number: 6311/10000step_number: 0/29 Accuracy:  0.9736080367784777 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6312/10000step_number: 0/29 Accuracy:  0.9745956070151541 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6313/10000step_number: 0/29 Accuracy:  0.9743912821386004 Loss:  nan Val_accuracy:  0.9457913375102152 Val_cost:  nan Val_accuracy:  0.9457913375102152 Val_Acc:  nan\n",
      "Epoch number: 6314/10000step_number: 0/29 Accuracy:  0.973982632385493 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6315/10000step_number: 0/29 Accuracy:  0.9734037119019241 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6316/10000step_number: 0/29 Accuracy:  0.9753447982291844 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6317/10000step_number: 0/29 Accuracy:  0.9742550655542312 Loss:  nan Val_accuracy:  0.9456551348406429 Val_cost:  nan Val_accuracy:  0.9456551348406429 Val_Acc:  nan\n",
      "Epoch number: 6318/10000step_number: 0/29 Accuracy:  0.9750042567682615 Loss:  nan Val_accuracy:  0.9467447561972214 Val_cost:  nan Val_accuracy:  0.9467447561972214 Val_Acc:  nan\n",
      "Epoch number: 6319/10000step_number: 0/29 Accuracy:  0.9729610080027243 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6320/10000step_number: 0/29 Accuracy:  0.9747658777456155 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6321/10000step_number: 0/29 Accuracy:  0.9760258811510302 Loss:  nan Val_accuracy:  0.9459275401797875 Val_cost:  nan Val_accuracy:  0.9459275401797875 Val_Acc:  nan\n",
      "Epoch number: 6322/10000step_number: 0/29 Accuracy:  0.9764004767580453 Loss:  nan Val_accuracy:  0.9470171615363661 Val_cost:  nan Val_accuracy:  0.9470171615363661 Val_Acc:  nan\n",
      "Epoch number: 6323/10000step_number: 0/29 Accuracy:  0.9736761450706624 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6324/10000step_number: 0/29 Accuracy:  0.9729610080027243 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6325/10000step_number: 0/29 Accuracy:  0.9739485782394006 Loss:  nan Val_accuracy:  0.9460637428493599 Val_cost:  nan Val_accuracy:  0.9460637428493599 Val_Acc:  nan\n",
      "Epoch number: 6326/10000step_number: 0/29 Accuracy:  0.9736420909245701 Loss:  nan Val_accuracy:  0.9459275401797875 Val_cost:  nan Val_accuracy:  0.9459275401797875 Val_Acc:  nan\n",
      "Epoch number: 6327/10000step_number: 0/29 Accuracy:  0.9729610080027243 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6328/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6329/10000step_number: 0/29 Accuracy:  0.9715988421590329 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6330/10000step_number: 0/29 Accuracy:  0.9722458709347863 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6331/10000step_number: 0/29 Accuracy:  0.971973437766048 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6332/10000step_number: 0/29 Accuracy:  0.9721437084965094 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6333/10000step_number: 0/29 Accuracy:  0.9722458709347863 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6334/10000step_number: 0/29 Accuracy:  0.9720415460582326 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6335/10000step_number: 0/29 Accuracy:  0.9719393836199557 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6336/10000step_number: 0/29 Accuracy:  0.9723139792269709 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6337/10000step_number: 0/29 Accuracy:  0.9722458709347863 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 6338/10000step_number: 0/29 Accuracy:  0.9724501958113401 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6339/10000step_number: 0/29 Accuracy:  0.9724161416652477 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6340/10000step_number: 0/29 Accuracy:  0.9721777626426017 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 6341/10000step_number: 0/29 Accuracy:  0.9725523582496169 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6342/10000step_number: 0/29 Accuracy:  0.9714626255746637 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6343/10000step_number: 0/29 Accuracy:  0.9721437084965094 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 6344/10000step_number: 0/29 Accuracy:  0.9714626255746637 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6345/10000step_number: 0/29 Accuracy:  0.9714626255746637 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 6346/10000step_number: 0/29 Accuracy:  0.9716669504512174 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 6347/10000step_number: 0/29 Accuracy:  0.9710880299676485 Loss:  nan Val_accuracy:  0.9421138654317625 Val_cost:  nan Val_accuracy:  0.9421138654317625 Val_Acc:  nan\n",
      "Epoch number: 6348/10000step_number: 0/29 Accuracy:  0.9722458709347863 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 6349/10000step_number: 0/29 Accuracy:  0.9720074919121403 Loss:  nan Val_accuracy:  0.9425224734404795 Val_cost:  nan Val_accuracy:  0.9425224734404795 Val_Acc:  nan\n",
      "Epoch number: 6350/10000step_number: 0/29 Accuracy:  0.9726204665418015 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 6351/10000step_number: 0/29 Accuracy:  0.9725183041035246 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6352/10000step_number: 0/29 Accuracy:  0.9728588455644475 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 6353/10000step_number: 0/29 Accuracy:  0.9727566831261706 Loss:  nan Val_accuracy:  0.9421138654317625 Val_cost:  nan Val_accuracy:  0.9421138654317625 Val_Acc:  nan\n",
      "Epoch number: 6354/10000step_number: 0/29 Accuracy:  0.9724842499574323 Loss:  nan Val_accuracy:  0.9415690547534732 Val_cost:  nan Val_accuracy:  0.9415690547534732 Val_Acc:  nan\n",
      "Epoch number: 6355/10000step_number: 0/29 Accuracy:  0.9738804699472161 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6356/10000step_number: 0/29 Accuracy:  0.9555593393495658 Loss:  nan Val_accuracy:  0.9269953691092345 Val_cost:  nan Val_accuracy:  0.9269953691092345 Val_Acc:  nan\n",
      "Epoch number: 6357/10000step_number: 0/29 Accuracy:  0.9602928656563937 Loss:  nan Val_accuracy:  0.93435031326614 Val_cost:  nan Val_accuracy:  0.93435031326614 Val_Acc:  nan\n",
      "Epoch number: 6358/10000step_number: 0/29 Accuracy:  0.973505874340201 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6359/10000step_number: 0/29 Accuracy:  0.9759237187127533 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 6360/10000step_number: 0/29 Accuracy:  0.9768431806572451 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6361/10000step_number: 0/29 Accuracy:  0.9760939894432147 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6362/10000step_number: 0/29 Accuracy:  0.9758215562744764 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 6363/10000step_number: 0/29 Accuracy:  0.9754469606674613 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6364/10000step_number: 0/29 Accuracy:  0.9755831772518304 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6365/10000step_number: 0/29 Accuracy:  0.9754469606674613 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6366/10000step_number: 0/29 Accuracy:  0.9754810148135535 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6367/10000step_number: 0/29 Accuracy:  0.9753107440830922 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6368/10000step_number: 0/29 Accuracy:  0.9751404733526307 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6369/10000step_number: 0/29 Accuracy:  0.9752085816448153 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6370/10000step_number: 0/29 Accuracy:  0.9750723650604461 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6371/10000step_number: 0/29 Accuracy:  0.9750383109143538 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6372/10000step_number: 0/29 Accuracy:  0.9747999318917078 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6373/10000step_number: 0/29 Accuracy:  0.973982632385493 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6374/10000step_number: 0/29 Accuracy:  0.9737783075089392 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6375/10000step_number: 0/29 Accuracy:  0.9736761450706624 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6376/10000step_number: 0/29 Accuracy:  0.9735399284862932 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6377/10000step_number: 0/29 Accuracy:  0.9735399284862932 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6378/10000step_number: 0/29 Accuracy:  0.9735399284862932 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6379/10000step_number: 0/29 Accuracy:  0.9734037119019241 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6380/10000step_number: 0/29 Accuracy:  0.9733696577558317 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6381/10000step_number: 0/29 Accuracy:  0.973267495317555 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6382/10000step_number: 0/29 Accuracy:  0.9730972245870935 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6383/10000step_number: 0/29 Accuracy:  0.9729269538566321 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6384/10000step_number: 0/29 Accuracy:  0.9728928997105397 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6385/10000step_number: 0/29 Accuracy:  0.9728247914183552 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6386/10000step_number: 0/29 Accuracy:  0.9726204665418015 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6387/10000step_number: 0/29 Accuracy:  0.9725183041035246 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6388/10000step_number: 0/29 Accuracy:  0.9723480333730632 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6389/10000step_number: 0/29 Accuracy:  0.9722118167886941 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6390/10000step_number: 0/29 Accuracy:  0.9721096543504172 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6391/10000step_number: 0/29 Accuracy:  0.9720074919121403 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6392/10000step_number: 0/29 Accuracy:  0.9720074919121403 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6393/10000step_number: 0/29 Accuracy:  0.971973437766048 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6394/10000step_number: 0/29 Accuracy:  0.971973437766048 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6395/10000step_number: 0/29 Accuracy:  0.9719053294738634 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6396/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6397/10000step_number: 0/29 Accuracy:  0.9719393836199557 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6398/10000step_number: 0/29 Accuracy:  0.9719053294738634 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6399/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6400/10000step_number: 0/29 Accuracy:  0.9717691128894943 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6401/10000step_number: 0/29 Accuracy:  0.9718031670355866 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6402/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6403/10000step_number: 0/29 Accuracy:  0.9716669504512174 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6404/10000step_number: 0/29 Accuracy:  0.971735058743402 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6405/10000step_number: 0/29 Accuracy:  0.971735058743402 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6406/10000step_number: 0/29 Accuracy:  0.9717691128894943 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6407/10000step_number: 0/29 Accuracy:  0.9717691128894943 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6408/10000step_number: 0/29 Accuracy:  0.971735058743402 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6409/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6410/10000step_number: 0/29 Accuracy:  0.9715988421590329 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6411/10000step_number: 0/29 Accuracy:  0.9715988421590329 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6412/10000step_number: 0/29 Accuracy:  0.9715307338668483 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6413/10000step_number: 0/29 Accuracy:  0.971496679720756 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6414/10000step_number: 0/29 Accuracy:  0.971496679720756 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6415/10000step_number: 0/29 Accuracy:  0.9715307338668483 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6416/10000step_number: 0/29 Accuracy:  0.971496679720756 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6417/10000step_number: 0/29 Accuracy:  0.971496679720756 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6418/10000step_number: 0/29 Accuracy:  0.9714626255746637 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6419/10000step_number: 0/29 Accuracy:  0.9715307338668483 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6420/10000step_number: 0/29 Accuracy:  0.971496679720756 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6421/10000step_number: 0/29 Accuracy:  0.971496679720756 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6422/10000step_number: 0/29 Accuracy:  0.9715647880129406 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6423/10000step_number: 0/29 Accuracy:  0.9715647880129406 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6424/10000step_number: 0/29 Accuracy:  0.9715988421590329 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6425/10000step_number: 0/29 Accuracy:  0.9716328963051252 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6426/10000step_number: 0/29 Accuracy:  0.971735058743402 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6427/10000step_number: 0/29 Accuracy:  0.971735058743402 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6428/10000step_number: 0/29 Accuracy:  0.971735058743402 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6429/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6430/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6431/10000step_number: 0/29 Accuracy:  0.9716669504512174 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6432/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6433/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6434/10000step_number: 0/29 Accuracy:  0.9716669504512174 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6435/10000step_number: 0/29 Accuracy:  0.9716669504512174 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6436/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6437/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6438/10000step_number: 0/29 Accuracy:  0.971735058743402 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6439/10000step_number: 0/29 Accuracy:  0.9717691128894943 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6440/10000step_number: 0/29 Accuracy:  0.9717691128894943 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6441/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6442/10000step_number: 0/29 Accuracy:  0.9717691128894943 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6443/10000step_number: 0/29 Accuracy:  0.9717691128894943 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6444/10000step_number: 0/29 Accuracy:  0.971735058743402 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6445/10000step_number: 0/29 Accuracy:  0.9717691128894943 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6446/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6447/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6448/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6449/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6450/10000step_number: 0/29 Accuracy:  0.9716669504512174 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6451/10000step_number: 0/29 Accuracy:  0.9716669504512174 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6452/10000step_number: 0/29 Accuracy:  0.971496679720756 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6453/10000step_number: 0/29 Accuracy:  0.9714626255746637 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6454/10000step_number: 0/29 Accuracy:  0.9713945172824792 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6455/10000step_number: 0/29 Accuracy:  0.9722458709347863 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6456/10000step_number: 0/29 Accuracy:  0.9723139792269709 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6457/10000step_number: 0/29 Accuracy:  0.9723139792269709 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6458/10000step_number: 0/29 Accuracy:  0.9722118167886941 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6459/10000step_number: 0/29 Accuracy:  0.9721096543504172 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6460/10000step_number: 0/29 Accuracy:  0.9721096543504172 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6461/10000step_number: 0/29 Accuracy:  0.9721437084965094 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6462/10000step_number: 0/29 Accuracy:  0.9722118167886941 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6463/10000step_number: 0/29 Accuracy:  0.9722118167886941 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6464/10000step_number: 0/29 Accuracy:  0.9722118167886941 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6465/10000step_number: 0/29 Accuracy:  0.9722118167886941 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6466/10000step_number: 0/29 Accuracy:  0.9723139792269709 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6467/10000step_number: 0/29 Accuracy:  0.9722799250808786 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6468/10000step_number: 0/29 Accuracy:  0.9723820875191554 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6469/10000step_number: 0/29 Accuracy:  0.9723480333730632 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6470/10000step_number: 0/29 Accuracy:  0.9723480333730632 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6471/10000step_number: 0/29 Accuracy:  0.9715988421590329 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6472/10000step_number: 0/29 Accuracy:  0.9715307338668483 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6473/10000step_number: 0/29 Accuracy:  0.9715988421590329 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6474/10000step_number: 0/29 Accuracy:  0.9715988421590329 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6475/10000step_number: 0/29 Accuracy:  0.9715988421590329 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6476/10000step_number: 0/29 Accuracy:  0.9716328963051252 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6477/10000step_number: 0/29 Accuracy:  0.9715988421590329 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6478/10000step_number: 0/29 Accuracy:  0.9715647880129406 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6479/10000step_number: 0/29 Accuracy:  0.9715988421590329 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6480/10000step_number: 0/29 Accuracy:  0.9715307338668483 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6481/10000step_number: 0/29 Accuracy:  0.971496679720756 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6482/10000step_number: 0/29 Accuracy:  0.9714285714285714 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6483/10000step_number: 0/29 Accuracy:  0.9714626255746637 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6484/10000step_number: 0/29 Accuracy:  0.9713945172824792 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6485/10000step_number: 0/29 Accuracy:  0.9713945172824792 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6486/10000step_number: 0/29 Accuracy:  0.9713945172824792 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6487/10000step_number: 0/29 Accuracy:  0.9713264089902945 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6488/10000step_number: 0/29 Accuracy:  0.9713604631363869 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6489/10000step_number: 0/29 Accuracy:  0.9711901924059254 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6490/10000step_number: 0/29 Accuracy:  0.9711901924059254 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6491/10000step_number: 0/29 Accuracy:  0.97125830069811 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6492/10000step_number: 0/29 Accuracy:  0.9712923548442023 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6493/10000step_number: 0/29 Accuracy:  0.9712923548442023 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6494/10000step_number: 0/29 Accuracy:  0.9712923548442023 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6495/10000step_number: 0/29 Accuracy:  0.9713604631363869 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6496/10000step_number: 0/29 Accuracy:  0.9714626255746637 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6497/10000step_number: 0/29 Accuracy:  0.9714626255746637 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6498/10000step_number: 0/29 Accuracy:  0.9714626255746637 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6499/10000step_number: 0/29 Accuracy:  0.9715307338668483 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6500/10000step_number: 0/29 Accuracy:  0.9715988421590329 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6501/10000step_number: 0/29 Accuracy:  0.9715988421590329 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6502/10000step_number: 0/29 Accuracy:  0.9716669504512174 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6503/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6504/10000step_number: 0/29 Accuracy:  0.9717691128894943 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6505/10000step_number: 0/29 Accuracy:  0.9718031670355866 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6506/10000step_number: 0/29 Accuracy:  0.9717691128894943 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6507/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6508/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6509/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6510/10000step_number: 0/29 Accuracy:  0.9720415460582326 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6511/10000step_number: 0/29 Accuracy:  0.9721096543504172 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6512/10000step_number: 0/29 Accuracy:  0.9722118167886941 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6513/10000step_number: 0/29 Accuracy:  0.9723139792269709 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6514/10000step_number: 0/29 Accuracy:  0.9723139792269709 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6515/10000step_number: 0/29 Accuracy:  0.9723139792269709 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6516/10000step_number: 0/29 Accuracy:  0.9724842499574323 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6517/10000step_number: 0/29 Accuracy:  0.9724842499574323 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6518/10000step_number: 0/29 Accuracy:  0.9725523582496169 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6519/10000step_number: 0/29 Accuracy:  0.9725523582496169 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6520/10000step_number: 0/29 Accuracy:  0.9724842499574323 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6521/10000step_number: 0/29 Accuracy:  0.9724842499574323 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6522/10000step_number: 0/29 Accuracy:  0.9722118167886941 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6523/10000step_number: 0/29 Accuracy:  0.9721096543504172 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6524/10000step_number: 0/29 Accuracy:  0.9722118167886941 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6525/10000step_number: 0/29 Accuracy:  0.9724161416652477 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6526/10000step_number: 0/29 Accuracy:  0.9723480333730632 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6527/10000step_number: 0/29 Accuracy:  0.9731993870253703 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6528/10000step_number: 0/29 Accuracy:  0.9730972245870935 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6529/10000step_number: 0/29 Accuracy:  0.9734718201941086 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6530/10000step_number: 0/29 Accuracy:  0.9741529031159544 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6531/10000step_number: 0/29 Accuracy:  0.9746296611612464 Loss:  nan Val_accuracy:  0.9456551348406429 Val_cost:  nan Val_accuracy:  0.9456551348406429 Val_Acc:  nan\n",
      "Epoch number: 6532/10000step_number: 0/29 Accuracy:  0.9751404733526307 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6533/10000step_number: 0/29 Accuracy:  0.9739485782394006 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6534/10000step_number: 0/29 Accuracy:  0.9734037119019241 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 6535/10000step_number: 0/29 Accuracy:  0.9771496679720756 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6536/10000step_number: 0/29 Accuracy:  0.9472501277030478 Loss:  nan Val_accuracy:  0.920457640969763 Val_cost:  nan Val_accuracy:  0.920457640969763 Val_Acc:  nan\n",
      "Epoch number: 6537/10000step_number: 0/29 Accuracy:  0.9659799080538055 Loss:  nan Val_accuracy:  0.9402070280577499 Val_cost:  nan Val_accuracy:  0.9402070280577499 Val_Acc:  nan\n",
      "Epoch number: 6538/10000step_number: 0/29 Accuracy:  0.9647880129405755 Loss:  nan Val_accuracy:  0.9344865159357123 Val_cost:  nan Val_accuracy:  0.9344865159357123 Val_Acc:  nan\n",
      "Epoch number: 6539/10000step_number: 0/29 Accuracy:  0.9766729099267836 Loss:  nan Val_accuracy:  0.9466085535276492 Val_cost:  nan Val_accuracy:  0.9466085535276492 Val_Acc:  nan\n",
      "Epoch number: 6540/10000step_number: 0/29 Accuracy:  0.9773199387025371 Loss:  nan Val_accuracy:  0.9460637428493599 Val_cost:  nan Val_accuracy:  0.9460637428493599 Val_Acc:  nan\n",
      "Epoch number: 6541/10000step_number: 0/29 Accuracy:  0.9768772348033373 Loss:  nan Val_accuracy:  0.9470171615363661 Val_cost:  nan Val_accuracy:  0.9470171615363661 Val_Acc:  nan\n",
      "Epoch number: 6542/10000step_number: 0/29 Accuracy:  0.9767069640728758 Loss:  nan Val_accuracy:  0.9475619722146554 Val_cost:  nan Val_accuracy:  0.9475619722146554 Val_Acc:  nan\n",
      "Epoch number: 6543/10000step_number: 0/29 Accuracy:  0.9767750723650604 Loss:  nan Val_accuracy:  0.9472895668755108 Val_cost:  nan Val_accuracy:  0.9472895668755108 Val_Acc:  nan\n",
      "Epoch number: 6544/10000step_number: 0/29 Accuracy:  0.9769112889494296 Loss:  nan Val_accuracy:  0.9475619722146554 Val_cost:  nan Val_accuracy:  0.9475619722146554 Val_Acc:  nan\n",
      "Epoch number: 6545/10000step_number: 0/29 Accuracy:  0.9768772348033373 Loss:  nan Val_accuracy:  0.9474257695450831 Val_cost:  nan Val_accuracy:  0.9474257695450831 Val_Acc:  nan\n",
      "Epoch number: 6546/10000step_number: 0/29 Accuracy:  0.9767410182189682 Loss:  nan Val_accuracy:  0.9475619722146554 Val_cost:  nan Val_accuracy:  0.9475619722146554 Val_Acc:  nan\n",
      "Epoch number: 6547/10000step_number: 0/29 Accuracy:  0.9766729099267836 Loss:  nan Val_accuracy:  0.9475619722146554 Val_cost:  nan Val_accuracy:  0.9475619722146554 Val_Acc:  nan\n",
      "Epoch number: 6548/10000step_number: 0/29 Accuracy:  0.9765366933424144 Loss:  nan Val_accuracy:  0.9475619722146554 Val_cost:  nan Val_accuracy:  0.9475619722146554 Val_Acc:  nan\n",
      "Epoch number: 6549/10000step_number: 0/29 Accuracy:  0.9762983143197684 Loss:  nan Val_accuracy:  0.9471533642059384 Val_cost:  nan Val_accuracy:  0.9471533642059384 Val_Acc:  nan\n",
      "Epoch number: 6550/10000step_number: 0/29 Accuracy:  0.9762302060275838 Loss:  nan Val_accuracy:  0.9467447561972214 Val_cost:  nan Val_accuracy:  0.9467447561972214 Val_Acc:  nan\n",
      "Epoch number: 6551/10000step_number: 0/29 Accuracy:  0.9761961518814916 Loss:  nan Val_accuracy:  0.9468809588667938 Val_cost:  nan Val_accuracy:  0.9468809588667938 Val_Acc:  nan\n",
      "Epoch number: 6552/10000step_number: 0/29 Accuracy:  0.9760258811510302 Loss:  nan Val_accuracy:  0.9467447561972214 Val_cost:  nan Val_accuracy:  0.9467447561972214 Val_Acc:  nan\n",
      "Epoch number: 6553/10000step_number: 0/29 Accuracy:  0.9759577728588456 Loss:  nan Val_accuracy:  0.9468809588667938 Val_cost:  nan Val_accuracy:  0.9468809588667938 Val_Acc:  nan\n",
      "Epoch number: 6554/10000step_number: 0/29 Accuracy:  0.9760939894432147 Loss:  nan Val_accuracy:  0.9467447561972214 Val_cost:  nan Val_accuracy:  0.9467447561972214 Val_Acc:  nan\n",
      "Epoch number: 6555/10000step_number: 0/29 Accuracy:  0.9759577728588456 Loss:  nan Val_accuracy:  0.9467447561972214 Val_cost:  nan Val_accuracy:  0.9467447561972214 Val_Acc:  nan\n",
      "Epoch number: 6556/10000step_number: 0/29 Accuracy:  0.9760939894432147 Loss:  nan Val_accuracy:  0.9470171615363661 Val_cost:  nan Val_accuracy:  0.9470171615363661 Val_Acc:  nan\n",
      "Epoch number: 6557/10000step_number: 0/29 Accuracy:  0.9757534479822918 Loss:  nan Val_accuracy:  0.9459275401797875 Val_cost:  nan Val_accuracy:  0.9459275401797875 Val_Acc:  nan\n",
      "Epoch number: 6558/10000step_number: 0/29 Accuracy:  0.9756853396901073 Loss:  nan Val_accuracy:  0.9463361481885045 Val_cost:  nan Val_accuracy:  0.9463361481885045 Val_Acc:  nan\n",
      "Epoch number: 6559/10000step_number: 0/29 Accuracy:  0.9753107440830922 Loss:  nan Val_accuracy:  0.9460637428493599 Val_cost:  nan Val_accuracy:  0.9460637428493599 Val_Acc:  nan\n",
      "Epoch number: 6560/10000step_number: 0/29 Accuracy:  0.9752766899369998 Loss:  nan Val_accuracy:  0.9460637428493599 Val_cost:  nan Val_accuracy:  0.9460637428493599 Val_Acc:  nan\n",
      "Epoch number: 6561/10000step_number: 0/29 Accuracy:  0.9752085816448153 Loss:  nan Val_accuracy:  0.9460637428493599 Val_cost:  nan Val_accuracy:  0.9460637428493599 Val_Acc:  nan\n",
      "Epoch number: 6562/10000step_number: 0/29 Accuracy:  0.9751064192065384 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6563/10000step_number: 0/29 Accuracy:  0.9751404733526307 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6564/10000step_number: 0/29 Accuracy:  0.9750042567682615 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6565/10000step_number: 0/29 Accuracy:  0.974936148476077 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6566/10000step_number: 0/29 Accuracy:  0.974936148476077 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6567/10000step_number: 0/29 Accuracy:  0.9749020943299846 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6568/10000step_number: 0/29 Accuracy:  0.9747999318917078 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6569/10000step_number: 0/29 Accuracy:  0.974697769453431 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6570/10000step_number: 0/29 Accuracy:  0.9745956070151541 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6571/10000step_number: 0/29 Accuracy:  0.9745274987229695 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6572/10000step_number: 0/29 Accuracy:  0.9744934445768773 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6573/10000step_number: 0/29 Accuracy:  0.9744253362846926 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6574/10000step_number: 0/29 Accuracy:  0.9742891197003235 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6575/10000step_number: 0/29 Accuracy:  0.9743231738464158 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6576/10000step_number: 0/29 Accuracy:  0.9742550655542312 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6577/10000step_number: 0/29 Accuracy:  0.974221011408139 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6578/10000step_number: 0/29 Accuracy:  0.9741869572620466 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6579/10000step_number: 0/29 Accuracy:  0.9741188489698621 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6580/10000step_number: 0/29 Accuracy:  0.9740847948237698 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6581/10000step_number: 0/29 Accuracy:  0.9740166865315852 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6582/10000step_number: 0/29 Accuracy:  0.973982632385493 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6583/10000step_number: 0/29 Accuracy:  0.973744253362847 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6584/10000step_number: 0/29 Accuracy:  0.973744253362847 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6585/10000step_number: 0/29 Accuracy:  0.9736761450706624 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6586/10000step_number: 0/29 Accuracy:  0.9736080367784777 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6587/10000step_number: 0/29 Accuracy:  0.9734718201941086 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6588/10000step_number: 0/29 Accuracy:  0.9734037119019241 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6589/10000step_number: 0/29 Accuracy:  0.9734037119019241 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6590/10000step_number: 0/29 Accuracy:  0.9734037119019241 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6591/10000step_number: 0/29 Accuracy:  0.9733015494636472 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6592/10000step_number: 0/29 Accuracy:  0.9732334411714626 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6593/10000step_number: 0/29 Accuracy:  0.9731312787331857 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6594/10000step_number: 0/29 Accuracy:  0.9730972245870935 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6595/10000step_number: 0/29 Accuracy:  0.9730631704410012 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6596/10000step_number: 0/29 Accuracy:  0.9729950621488166 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6597/10000step_number: 0/29 Accuracy:  0.9729610080027243 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6598/10000step_number: 0/29 Accuracy:  0.9729269538566321 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6599/10000step_number: 0/29 Accuracy:  0.9729610080027243 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6600/10000step_number: 0/29 Accuracy:  0.9729950621488166 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6601/10000step_number: 0/29 Accuracy:  0.973029116294909 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6602/10000step_number: 0/29 Accuracy:  0.9729950621488166 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6603/10000step_number: 0/29 Accuracy:  0.9729950621488166 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6604/10000step_number: 0/29 Accuracy:  0.9729950621488166 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6605/10000step_number: 0/29 Accuracy:  0.9729610080027243 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6606/10000step_number: 0/29 Accuracy:  0.9729610080027243 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6607/10000step_number: 0/29 Accuracy:  0.9729610080027243 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6608/10000step_number: 0/29 Accuracy:  0.9729950621488166 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6609/10000step_number: 0/29 Accuracy:  0.9729950621488166 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6610/10000step_number: 0/29 Accuracy:  0.973029116294909 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6611/10000step_number: 0/29 Accuracy:  0.9730631704410012 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6612/10000step_number: 0/29 Accuracy:  0.9729610080027243 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6613/10000step_number: 0/29 Accuracy:  0.9729950621488166 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6614/10000step_number: 0/29 Accuracy:  0.9729610080027243 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6615/10000step_number: 0/29 Accuracy:  0.9729269538566321 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6616/10000step_number: 0/29 Accuracy:  0.9729269538566321 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6617/10000step_number: 0/29 Accuracy:  0.9728588455644475 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6618/10000step_number: 0/29 Accuracy:  0.9728928997105397 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6619/10000step_number: 0/29 Accuracy:  0.9729269538566321 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6620/10000step_number: 0/29 Accuracy:  0.9729269538566321 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6621/10000step_number: 0/29 Accuracy:  0.9728928997105397 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6622/10000step_number: 0/29 Accuracy:  0.9728588455644475 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6623/10000step_number: 0/29 Accuracy:  0.9728928997105397 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6624/10000step_number: 0/29 Accuracy:  0.9729269538566321 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6625/10000step_number: 0/29 Accuracy:  0.9728588455644475 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6626/10000step_number: 0/29 Accuracy:  0.9728588455644475 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6627/10000step_number: 0/29 Accuracy:  0.9728247914183552 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6628/10000step_number: 0/29 Accuracy:  0.9727226289800783 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6629/10000step_number: 0/29 Accuracy:  0.9727226289800783 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6630/10000step_number: 0/29 Accuracy:  0.9726885748339861 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6631/10000step_number: 0/29 Accuracy:  0.9726885748339861 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6632/10000step_number: 0/29 Accuracy:  0.9725864123957092 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6633/10000step_number: 0/29 Accuracy:  0.9725864123957092 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6634/10000step_number: 0/29 Accuracy:  0.9724842499574323 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6635/10000step_number: 0/29 Accuracy:  0.9724842499574323 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6636/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6637/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6638/10000step_number: 0/29 Accuracy:  0.9716328963051252 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6639/10000step_number: 0/29 Accuracy:  0.9716328963051252 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6640/10000step_number: 0/29 Accuracy:  0.9716328963051252 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6641/10000step_number: 0/29 Accuracy:  0.971735058743402 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6642/10000step_number: 0/29 Accuracy:  0.9718031670355866 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6643/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6644/10000step_number: 0/29 Accuracy:  0.9719393836199557 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6645/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6646/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6647/10000step_number: 0/29 Accuracy:  0.9719053294738634 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6648/10000step_number: 0/29 Accuracy:  0.9719053294738634 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6649/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6650/10000step_number: 0/29 Accuracy:  0.9719053294738634 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6651/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6652/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6653/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6654/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6655/10000step_number: 0/29 Accuracy:  0.9726885748339861 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6656/10000step_number: 0/29 Accuracy:  0.9725183041035246 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6657/10000step_number: 0/29 Accuracy:  0.9725864123957092 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6658/10000step_number: 0/29 Accuracy:  0.9725523582496169 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6659/10000step_number: 0/29 Accuracy:  0.9723820875191554 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6660/10000step_number: 0/29 Accuracy:  0.9723139792269709 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6661/10000step_number: 0/29 Accuracy:  0.9722799250808786 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6662/10000step_number: 0/29 Accuracy:  0.9722458709347863 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6663/10000step_number: 0/29 Accuracy:  0.9722799250808786 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6664/10000step_number: 0/29 Accuracy:  0.9722799250808786 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6665/10000step_number: 0/29 Accuracy:  0.9723480333730632 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6666/10000step_number: 0/29 Accuracy:  0.9724161416652477 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6667/10000step_number: 0/29 Accuracy:  0.9723480333730632 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6668/10000step_number: 0/29 Accuracy:  0.9723820875191554 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6669/10000step_number: 0/29 Accuracy:  0.9723820875191554 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6670/10000step_number: 0/29 Accuracy:  0.9723480333730632 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6671/10000step_number: 0/29 Accuracy:  0.9723480333730632 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6672/10000step_number: 0/29 Accuracy:  0.9714626255746637 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 6673/10000step_number: 0/29 Accuracy:  0.971496679720756 Loss:  nan Val_accuracy:  0.9427948787796241 Val_cost:  nan Val_accuracy:  0.9427948787796241 Val_Acc:  nan\n",
      "Epoch number: 6674/10000step_number: 0/29 Accuracy:  0.9715647880129406 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 6675/10000step_number: 0/29 Accuracy:  0.9715988421590329 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 6676/10000step_number: 0/29 Accuracy:  0.9716328963051252 Loss:  nan Val_accuracy:  0.9429310814491964 Val_cost:  nan Val_accuracy:  0.9429310814491964 Val_Acc:  nan\n",
      "Epoch number: 6677/10000step_number: 0/29 Accuracy:  0.9716328963051252 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 6678/10000step_number: 0/29 Accuracy:  0.9716669504512174 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 6679/10000step_number: 0/29 Accuracy:  0.9716669504512174 Loss:  nan Val_accuracy:  0.9430672841187687 Val_cost:  nan Val_accuracy:  0.9430672841187687 Val_Acc:  nan\n",
      "Epoch number: 6680/10000step_number: 0/29 Accuracy:  0.9716669504512174 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 6681/10000step_number: 0/29 Accuracy:  0.9717010045973097 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 6682/10000step_number: 0/29 Accuracy:  0.9717691128894943 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 6683/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 6684/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 6685/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 6686/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 6687/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6688/10000step_number: 0/29 Accuracy:  0.9718031670355866 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6689/10000step_number: 0/29 Accuracy:  0.9713604631363869 Loss:  nan Val_accuracy:  0.9433396894579134 Val_cost:  nan Val_accuracy:  0.9433396894579134 Val_Acc:  nan\n",
      "Epoch number: 6690/10000step_number: 0/29 Accuracy:  0.9713604631363869 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 6691/10000step_number: 0/29 Accuracy:  0.9713604631363869 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6692/10000step_number: 0/29 Accuracy:  0.9713945172824792 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6693/10000step_number: 0/29 Accuracy:  0.971496679720756 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6694/10000step_number: 0/29 Accuracy:  0.971496679720756 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6695/10000step_number: 0/29 Accuracy:  0.971496679720756 Loss:  nan Val_accuracy:  0.943612094797058 Val_cost:  nan Val_accuracy:  0.943612094797058 Val_Acc:  nan\n",
      "Epoch number: 6696/10000step_number: 0/29 Accuracy:  0.9715307338668483 Loss:  nan Val_accuracy:  0.9437482974666304 Val_cost:  nan Val_accuracy:  0.9437482974666304 Val_Acc:  nan\n",
      "Epoch number: 6697/10000step_number: 0/29 Accuracy:  0.9716328963051252 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6698/10000step_number: 0/29 Accuracy:  0.9716328963051252 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6699/10000step_number: 0/29 Accuracy:  0.9716328963051252 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6700/10000step_number: 0/29 Accuracy:  0.9716669504512174 Loss:  nan Val_accuracy:  0.9438845001362026 Val_cost:  nan Val_accuracy:  0.9438845001362026 Val_Acc:  nan\n",
      "Epoch number: 6701/10000step_number: 0/29 Accuracy:  0.9716669504512174 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6702/10000step_number: 0/29 Accuracy:  0.971735058743402 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6703/10000step_number: 0/29 Accuracy:  0.971735058743402 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6704/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6705/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6706/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6707/10000step_number: 0/29 Accuracy:  0.9719393836199557 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6708/10000step_number: 0/29 Accuracy:  0.971973437766048 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6709/10000step_number: 0/29 Accuracy:  0.9720415460582326 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6710/10000step_number: 0/29 Accuracy:  0.9721096543504172 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6711/10000step_number: 0/29 Accuracy:  0.9721096543504172 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6712/10000step_number: 0/29 Accuracy:  0.9721777626426017 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6713/10000step_number: 0/29 Accuracy:  0.9721777626426017 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6714/10000step_number: 0/29 Accuracy:  0.9722799250808786 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6715/10000step_number: 0/29 Accuracy:  0.9723480333730632 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6716/10000step_number: 0/29 Accuracy:  0.9724501958113401 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6717/10000step_number: 0/29 Accuracy:  0.9724842499574323 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6718/10000step_number: 0/29 Accuracy:  0.9725183041035246 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6719/10000step_number: 0/29 Accuracy:  0.9724842499574323 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6720/10000step_number: 0/29 Accuracy:  0.9723820875191554 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6721/10000step_number: 0/29 Accuracy:  0.9724842499574323 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6722/10000step_number: 0/29 Accuracy:  0.9724501958113401 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6723/10000step_number: 0/29 Accuracy:  0.9723480333730632 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6724/10000step_number: 0/29 Accuracy:  0.9724501958113401 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6725/10000step_number: 0/29 Accuracy:  0.9723139792269709 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6726/10000step_number: 0/29 Accuracy:  0.9728247914183552 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6727/10000step_number: 0/29 Accuracy:  0.9736761450706624 Loss:  nan Val_accuracy:  0.9456551348406429 Val_cost:  nan Val_accuracy:  0.9456551348406429 Val_Acc:  nan\n",
      "Epoch number: 6728/10000step_number: 0/29 Accuracy:  0.9738123616550315 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6729/10000step_number: 0/29 Accuracy:  0.9741188489698621 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6730/10000step_number: 0/29 Accuracy:  0.9752085816448153 Loss:  nan Val_accuracy:  0.9461999455189322 Val_cost:  nan Val_accuracy:  0.9461999455189322 Val_Acc:  nan\n",
      "Epoch number: 6731/10000step_number: 0/29 Accuracy:  0.9756172313979227 Loss:  nan Val_accuracy:  0.9457913375102152 Val_cost:  nan Val_accuracy:  0.9457913375102152 Val_Acc:  nan\n",
      "Epoch number: 6732/10000step_number: 0/29 Accuracy:  0.9753107440830922 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6733/10000step_number: 0/29 Accuracy:  0.9730631704410012 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6734/10000step_number: 0/29 Accuracy:  0.964958283671037 Loss:  nan Val_accuracy:  0.933533097248706 Val_cost:  nan Val_accuracy:  0.933533097248706 Val_Acc:  nan\n",
      "Epoch number: 6735/10000step_number: 0/29 Accuracy:  0.9661842329303593 Loss:  nan Val_accuracy:  0.9374829746663035 Val_cost:  nan Val_accuracy:  0.9374829746663035 Val_Acc:  nan\n",
      "Epoch number: 6736/10000step_number: 0/29 Accuracy:  0.9653669334241444 Loss:  nan Val_accuracy:  0.9372105693271588 Val_cost:  nan Val_accuracy:  0.9372105693271588 Val_Acc:  nan\n",
      "Epoch number: 6737/10000step_number: 0/29 Accuracy:  0.971019921675464 Loss:  nan Val_accuracy:  0.9426586761100517 Val_cost:  nan Val_accuracy:  0.9426586761100517 Val_Acc:  nan\n",
      "Epoch number: 6738/10000step_number: 0/29 Accuracy:  0.9711561382598332 Loss:  nan Val_accuracy:  0.9391174067011714 Val_cost:  nan Val_accuracy:  0.9391174067011714 Val_Acc:  nan\n",
      "Epoch number: 6739/10000step_number: 0/29 Accuracy:  0.9768431806572451 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6740/10000step_number: 0/29 Accuracy:  0.9779329133321982 Loss:  nan Val_accuracy:  0.9478343775538001 Val_cost:  nan Val_accuracy:  0.9478343775538001 Val_Acc:  nan\n",
      "Epoch number: 6741/10000step_number: 0/29 Accuracy:  0.9781372382087519 Loss:  nan Val_accuracy:  0.9475619722146554 Val_cost:  nan Val_accuracy:  0.9475619722146554 Val_Acc:  nan\n",
      "Epoch number: 6742/10000step_number: 0/29 Accuracy:  0.9780691299165674 Loss:  nan Val_accuracy:  0.9474257695450831 Val_cost:  nan Val_accuracy:  0.9474257695450831 Val_Acc:  nan\n",
      "Epoch number: 6743/10000step_number: 0/29 Accuracy:  0.9777626426017367 Loss:  nan Val_accuracy:  0.9475619722146554 Val_cost:  nan Val_accuracy:  0.9475619722146554 Val_Acc:  nan\n",
      "Epoch number: 6744/10000step_number: 0/29 Accuracy:  0.9773880469947216 Loss:  nan Val_accuracy:  0.9478343775538001 Val_cost:  nan Val_accuracy:  0.9478343775538001 Val_Acc:  nan\n",
      "Epoch number: 6745/10000step_number: 0/29 Accuracy:  0.9771156138259833 Loss:  nan Val_accuracy:  0.9470171615363661 Val_cost:  nan Val_accuracy:  0.9470171615363661 Val_Acc:  nan\n",
      "Epoch number: 6746/10000step_number: 0/29 Accuracy:  0.9771156138259833 Loss:  nan Val_accuracy:  0.9471533642059384 Val_cost:  nan Val_accuracy:  0.9471533642059384 Val_Acc:  nan\n",
      "Epoch number: 6747/10000step_number: 0/29 Accuracy:  0.9770815596798911 Loss:  nan Val_accuracy:  0.9471533642059384 Val_cost:  nan Val_accuracy:  0.9471533642059384 Val_Acc:  nan\n",
      "Epoch number: 6748/10000step_number: 0/29 Accuracy:  0.9768431806572451 Loss:  nan Val_accuracy:  0.9466085535276492 Val_cost:  nan Val_accuracy:  0.9466085535276492 Val_Acc:  nan\n",
      "Epoch number: 6749/10000step_number: 0/29 Accuracy:  0.9768772348033373 Loss:  nan Val_accuracy:  0.9468809588667938 Val_cost:  nan Val_accuracy:  0.9468809588667938 Val_Acc:  nan\n",
      "Epoch number: 6750/10000step_number: 0/29 Accuracy:  0.9768431806572451 Loss:  nan Val_accuracy:  0.9467447561972214 Val_cost:  nan Val_accuracy:  0.9467447561972214 Val_Acc:  nan\n",
      "Epoch number: 6751/10000step_number: 0/29 Accuracy:  0.9768772348033373 Loss:  nan Val_accuracy:  0.9467447561972214 Val_cost:  nan Val_accuracy:  0.9467447561972214 Val_Acc:  nan\n",
      "Epoch number: 6752/10000step_number: 0/29 Accuracy:  0.9764685850502298 Loss:  nan Val_accuracy:  0.9460637428493599 Val_cost:  nan Val_accuracy:  0.9460637428493599 Val_Acc:  nan\n",
      "Epoch number: 6753/10000step_number: 0/29 Accuracy:  0.976366422611953 Loss:  nan Val_accuracy:  0.9460637428493599 Val_cost:  nan Val_accuracy:  0.9460637428493599 Val_Acc:  nan\n",
      "Epoch number: 6754/10000step_number: 0/29 Accuracy:  0.9761961518814916 Loss:  nan Val_accuracy:  0.9461999455189322 Val_cost:  nan Val_accuracy:  0.9461999455189322 Val_Acc:  nan\n",
      "Epoch number: 6755/10000step_number: 0/29 Accuracy:  0.9760939894432147 Loss:  nan Val_accuracy:  0.9460637428493599 Val_cost:  nan Val_accuracy:  0.9460637428493599 Val_Acc:  nan\n",
      "Epoch number: 6756/10000step_number: 0/29 Accuracy:  0.9759918270049378 Loss:  nan Val_accuracy:  0.9457913375102152 Val_cost:  nan Val_accuracy:  0.9457913375102152 Val_Acc:  nan\n",
      "Epoch number: 6757/10000step_number: 0/29 Accuracy:  0.9759577728588456 Loss:  nan Val_accuracy:  0.9456551348406429 Val_cost:  nan Val_accuracy:  0.9456551348406429 Val_Acc:  nan\n",
      "Epoch number: 6758/10000step_number: 0/29 Accuracy:  0.9759918270049378 Loss:  nan Val_accuracy:  0.9457913375102152 Val_cost:  nan Val_accuracy:  0.9457913375102152 Val_Acc:  nan\n",
      "Epoch number: 6759/10000step_number: 0/29 Accuracy:  0.9759577728588456 Loss:  nan Val_accuracy:  0.9459275401797875 Val_cost:  nan Val_accuracy:  0.9459275401797875 Val_Acc:  nan\n",
      "Epoch number: 6760/10000step_number: 0/29 Accuracy:  0.9757534479822918 Loss:  nan Val_accuracy:  0.9459275401797875 Val_cost:  nan Val_accuracy:  0.9459275401797875 Val_Acc:  nan\n",
      "Epoch number: 6761/10000step_number: 0/29 Accuracy:  0.9756853396901073 Loss:  nan Val_accuracy:  0.9456551348406429 Val_cost:  nan Val_accuracy:  0.9456551348406429 Val_Acc:  nan\n",
      "Epoch number: 6762/10000step_number: 0/29 Accuracy:  0.9756172313979227 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6763/10000step_number: 0/29 Accuracy:  0.9755831772518304 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6764/10000step_number: 0/29 Accuracy:  0.9755491231057382 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6765/10000step_number: 0/29 Accuracy:  0.9755150689596458 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6766/10000step_number: 0/29 Accuracy:  0.9754469606674613 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6767/10000step_number: 0/29 Accuracy:  0.974459390430785 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6768/10000step_number: 0/29 Accuracy:  0.9742550655542312 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6769/10000step_number: 0/29 Accuracy:  0.9741869572620466 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6770/10000step_number: 0/29 Accuracy:  0.9741188489698621 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6771/10000step_number: 0/29 Accuracy:  0.9740166865315852 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6772/10000step_number: 0/29 Accuracy:  0.973982632385493 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6773/10000step_number: 0/29 Accuracy:  0.973982632385493 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6774/10000step_number: 0/29 Accuracy:  0.9738123616550315 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6775/10000step_number: 0/29 Accuracy:  0.9736761450706624 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6776/10000step_number: 0/29 Accuracy:  0.9743231738464158 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6777/10000step_number: 0/29 Accuracy:  0.9742891197003235 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6778/10000step_number: 0/29 Accuracy:  0.9742550655542312 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6779/10000step_number: 0/29 Accuracy:  0.9741529031159544 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6780/10000step_number: 0/29 Accuracy:  0.9740507406776775 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6781/10000step_number: 0/29 Accuracy:  0.9739145240933084 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6782/10000step_number: 0/29 Accuracy:  0.9737783075089392 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6783/10000step_number: 0/29 Accuracy:  0.9737101992167546 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6784/10000step_number: 0/29 Accuracy:  0.9736761450706624 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6785/10000step_number: 0/29 Accuracy:  0.9735739826323855 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6786/10000step_number: 0/29 Accuracy:  0.9734377660480164 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6787/10000step_number: 0/29 Accuracy:  0.9733696577558317 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6788/10000step_number: 0/29 Accuracy:  0.9733356036097395 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6789/10000step_number: 0/29 Accuracy:  0.9733015494636472 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6790/10000step_number: 0/29 Accuracy:  0.9731653328792781 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6791/10000step_number: 0/29 Accuracy:  0.973029116294909 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6792/10000step_number: 0/29 Accuracy:  0.9730631704410012 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6793/10000step_number: 0/29 Accuracy:  0.973029116294909 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6794/10000step_number: 0/29 Accuracy:  0.973029116294909 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6795/10000step_number: 0/29 Accuracy:  0.9730631704410012 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6796/10000step_number: 0/29 Accuracy:  0.9729950621488166 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6797/10000step_number: 0/29 Accuracy:  0.9729950621488166 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6798/10000step_number: 0/29 Accuracy:  0.9728928997105397 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6799/10000step_number: 0/29 Accuracy:  0.9728247914183552 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6800/10000step_number: 0/29 Accuracy:  0.972790737272263 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6801/10000step_number: 0/29 Accuracy:  0.972790737272263 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6802/10000step_number: 0/29 Accuracy:  0.972790737272263 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6803/10000step_number: 0/29 Accuracy:  0.9727566831261706 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6804/10000step_number: 0/29 Accuracy:  0.9728588455644475 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6805/10000step_number: 0/29 Accuracy:  0.9728247914183552 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6806/10000step_number: 0/29 Accuracy:  0.9728247914183552 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6807/10000step_number: 0/29 Accuracy:  0.972790737272263 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6808/10000step_number: 0/29 Accuracy:  0.9728247914183552 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6809/10000step_number: 0/29 Accuracy:  0.9728588455644475 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6810/10000step_number: 0/29 Accuracy:  0.9728928997105397 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6811/10000step_number: 0/29 Accuracy:  0.9728928997105397 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6812/10000step_number: 0/29 Accuracy:  0.9729269538566321 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6813/10000step_number: 0/29 Accuracy:  0.9728588455644475 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6814/10000step_number: 0/29 Accuracy:  0.9728247914183552 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6815/10000step_number: 0/29 Accuracy:  0.972790737272263 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6816/10000step_number: 0/29 Accuracy:  0.972790737272263 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6817/10000step_number: 0/29 Accuracy:  0.9727566831261706 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6818/10000step_number: 0/29 Accuracy:  0.972790737272263 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6819/10000step_number: 0/29 Accuracy:  0.9728247914183552 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6820/10000step_number: 0/29 Accuracy:  0.972790737272263 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6821/10000step_number: 0/29 Accuracy:  0.972790737272263 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6822/10000step_number: 0/29 Accuracy:  0.971973437766048 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6823/10000step_number: 0/29 Accuracy:  0.971973437766048 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6824/10000step_number: 0/29 Accuracy:  0.9720074919121403 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6825/10000step_number: 0/29 Accuracy:  0.9720074919121403 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6826/10000step_number: 0/29 Accuracy:  0.971973437766048 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6827/10000step_number: 0/29 Accuracy:  0.971973437766048 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6828/10000step_number: 0/29 Accuracy:  0.9719393836199557 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6829/10000step_number: 0/29 Accuracy:  0.9720074919121403 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6830/10000step_number: 0/29 Accuracy:  0.9720415460582326 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6831/10000step_number: 0/29 Accuracy:  0.9720415460582326 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6832/10000step_number: 0/29 Accuracy:  0.9720415460582326 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6833/10000step_number: 0/29 Accuracy:  0.9720756002043249 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6834/10000step_number: 0/29 Accuracy:  0.9720415460582326 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6835/10000step_number: 0/29 Accuracy:  0.9721437084965094 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6836/10000step_number: 0/29 Accuracy:  0.9721777626426017 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6837/10000step_number: 0/29 Accuracy:  0.9721437084965094 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6838/10000step_number: 0/29 Accuracy:  0.9721096543504172 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6839/10000step_number: 0/29 Accuracy:  0.9720756002043249 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6840/10000step_number: 0/29 Accuracy:  0.9720756002043249 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6841/10000step_number: 0/29 Accuracy:  0.9719393836199557 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6842/10000step_number: 0/29 Accuracy:  0.971973437766048 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6843/10000step_number: 0/29 Accuracy:  0.9719393836199557 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6844/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6845/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6846/10000step_number: 0/29 Accuracy:  0.9719393836199557 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6847/10000step_number: 0/29 Accuracy:  0.971973437766048 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6848/10000step_number: 0/29 Accuracy:  0.9719393836199557 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6849/10000step_number: 0/29 Accuracy:  0.971973437766048 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6850/10000step_number: 0/29 Accuracy:  0.971973437766048 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6851/10000step_number: 0/29 Accuracy:  0.9720074919121403 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6852/10000step_number: 0/29 Accuracy:  0.9720415460582326 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6853/10000step_number: 0/29 Accuracy:  0.9719393836199557 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6854/10000step_number: 0/29 Accuracy:  0.971973437766048 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6855/10000step_number: 0/29 Accuracy:  0.9719053294738634 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6856/10000step_number: 0/29 Accuracy:  0.9719393836199557 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6857/10000step_number: 0/29 Accuracy:  0.9719393836199557 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6858/10000step_number: 0/29 Accuracy:  0.971973437766048 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6859/10000step_number: 0/29 Accuracy:  0.9719053294738634 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6860/10000step_number: 0/29 Accuracy:  0.9717691128894943 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6861/10000step_number: 0/29 Accuracy:  0.9718031670355866 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6862/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6863/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6864/10000step_number: 0/29 Accuracy:  0.9718031670355866 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6865/10000step_number: 0/29 Accuracy:  0.9718712753277712 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6866/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6867/10000step_number: 0/29 Accuracy:  0.9719053294738634 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6868/10000step_number: 0/29 Accuracy:  0.9718372211816789 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6869/10000step_number: 0/29 Accuracy:  0.9719053294738634 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6870/10000step_number: 0/29 Accuracy:  0.9719053294738634 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6871/10000step_number: 0/29 Accuracy:  0.9719053294738634 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6872/10000step_number: 0/29 Accuracy:  0.9719393836199557 Loss:  nan Val_accuracy:  0.944020702805775 Val_cost:  nan Val_accuracy:  0.944020702805775 Val_Acc:  nan\n",
      "Epoch number: 6873/10000step_number: 0/29 Accuracy:  0.971973437766048 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6874/10000step_number: 0/29 Accuracy:  0.971973437766048 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6875/10000step_number: 0/29 Accuracy:  0.9720074919121403 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6876/10000step_number: 0/29 Accuracy:  0.9720415460582326 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6877/10000step_number: 0/29 Accuracy:  0.9720074919121403 Loss:  nan Val_accuracy:  0.9441569054753474 Val_cost:  nan Val_accuracy:  0.9441569054753474 Val_Acc:  nan\n",
      "Epoch number: 6878/10000step_number: 0/29 Accuracy:  0.9720756002043249 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6879/10000step_number: 0/29 Accuracy:  0.9721096543504172 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6880/10000step_number: 0/29 Accuracy:  0.9722118167886941 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6881/10000step_number: 0/29 Accuracy:  0.9722458709347863 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6882/10000step_number: 0/29 Accuracy:  0.9723139792269709 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6883/10000step_number: 0/29 Accuracy:  0.9723480333730632 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6884/10000step_number: 0/29 Accuracy:  0.9723820875191554 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6885/10000step_number: 0/29 Accuracy:  0.9724501958113401 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6886/10000step_number: 0/29 Accuracy:  0.9724842499574323 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6887/10000step_number: 0/29 Accuracy:  0.9725523582496169 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6888/10000step_number: 0/29 Accuracy:  0.9725864123957092 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 6889/10000step_number: 0/29 Accuracy:  0.9725864123957092 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6890/10000step_number: 0/29 Accuracy:  0.9726545206878937 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6891/10000step_number: 0/29 Accuracy:  0.9726885748339861 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6892/10000step_number: 0/29 Accuracy:  0.9726545206878937 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6893/10000step_number: 0/29 Accuracy:  0.9727226289800783 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6894/10000step_number: 0/29 Accuracy:  0.9728247914183552 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6895/10000step_number: 0/29 Accuracy:  0.9728588455644475 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6896/10000step_number: 0/29 Accuracy:  0.9728247914183552 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6897/10000step_number: 0/29 Accuracy:  0.9728928997105397 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6898/10000step_number: 0/29 Accuracy:  0.9728588455644475 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6899/10000step_number: 0/29 Accuracy:  0.9729950621488166 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6900/10000step_number: 0/29 Accuracy:  0.973029116294909 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6901/10000step_number: 0/29 Accuracy:  0.9730972245870935 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6902/10000step_number: 0/29 Accuracy:  0.9731993870253703 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6903/10000step_number: 0/29 Accuracy:  0.9729610080027243 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6904/10000step_number: 0/29 Accuracy:  0.972790737272263 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6905/10000step_number: 0/29 Accuracy:  0.9729610080027243 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6906/10000step_number: 0/29 Accuracy:  0.9728928997105397 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6907/10000step_number: 0/29 Accuracy:  0.9730631704410012 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6908/10000step_number: 0/29 Accuracy:  0.9733015494636472 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6909/10000step_number: 0/29 Accuracy:  0.9742550655542312 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6910/10000step_number: 0/29 Accuracy:  0.9743572279925081 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6911/10000step_number: 0/29 Accuracy:  0.9749702026221693 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6912/10000step_number: 0/29 Accuracy:  0.9759237187127533 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6913/10000step_number: 0/29 Accuracy:  0.9765026391963222 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6914/10000step_number: 0/29 Accuracy:  0.9759577728588456 Loss:  nan Val_accuracy:  0.9434758921274857 Val_cost:  nan Val_accuracy:  0.9434758921274857 Val_Acc:  nan\n",
      "Epoch number: 6915/10000step_number: 0/29 Accuracy:  0.9762302060275838 Loss:  nan Val_accuracy:  0.9463361481885045 Val_cost:  nan Val_accuracy:  0.9463361481885045 Val_Acc:  nan\n",
      "Epoch number: 6916/10000step_number: 0/29 Accuracy:  0.9750042567682615 Loss:  nan Val_accuracy:  0.9432034867883411 Val_cost:  nan Val_accuracy:  0.9432034867883411 Val_Acc:  nan\n",
      "Epoch number: 6917/10000step_number: 0/29 Accuracy:  0.9797377830750894 Loss:  nan Val_accuracy:  0.9476981748842277 Val_cost:  nan Val_accuracy:  0.9476981748842277 Val_Acc:  nan\n",
      "Epoch number: 6918/10000step_number: 0/29 Accuracy:  0.9779669674782905 Loss:  nan Val_accuracy:  0.9470171615363661 Val_cost:  nan Val_accuracy:  0.9470171615363661 Val_Acc:  nan\n",
      "Epoch number: 6919/10000step_number: 0/29 Accuracy:  0.9823940064702877 Loss:  nan Val_accuracy:  0.9479705802233723 Val_cost:  nan Val_accuracy:  0.9479705802233723 Val_Acc:  nan\n",
      "Epoch number: 6920/10000step_number: 0/29 Accuracy:  0.9793291333219819 Loss:  nan Val_accuracy:  0.9481067828929447 Val_cost:  nan Val_accuracy:  0.9481067828929447 Val_Acc:  nan\n",
      "Epoch number: 6921/10000step_number: 0/29 Accuracy:  0.9790567001532436 Loss:  nan Val_accuracy:  0.9461999455189322 Val_cost:  nan Val_accuracy:  0.9461999455189322 Val_Acc:  nan\n",
      "Epoch number: 6922/10000step_number: 0/29 Accuracy:  0.9761961518814916 Loss:  nan Val_accuracy:  0.9464723508580768 Val_cost:  nan Val_accuracy:  0.9464723508580768 Val_Acc:  nan\n",
      "Epoch number: 6923/10000step_number: 0/29 Accuracy:  0.9771156138259833 Loss:  nan Val_accuracy:  0.9461999455189322 Val_cost:  nan Val_accuracy:  0.9461999455189322 Val_Acc:  nan\n",
      "Epoch number: 6924/10000step_number: 0/29 Accuracy:  0.9754469606674613 Loss:  nan Val_accuracy:  0.9460637428493599 Val_cost:  nan Val_accuracy:  0.9460637428493599 Val_Acc:  nan\n",
      "Epoch number: 6925/10000step_number: 0/29 Accuracy:  0.9744934445768773 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6926/10000step_number: 0/29 Accuracy:  0.9745615528690618 Loss:  nan Val_accuracy:  0.9456551348406429 Val_cost:  nan Val_accuracy:  0.9456551348406429 Val_Acc:  nan\n",
      "Epoch number: 6927/10000step_number: 0/29 Accuracy:  0.9742550655542312 Loss:  nan Val_accuracy:  0.9457913375102152 Val_cost:  nan Val_accuracy:  0.9457913375102152 Val_Acc:  nan\n",
      "Epoch number: 6928/10000step_number: 0/29 Accuracy:  0.9741529031159544 Loss:  nan Val_accuracy:  0.9457913375102152 Val_cost:  nan Val_accuracy:  0.9457913375102152 Val_Acc:  nan\n",
      "Epoch number: 6929/10000step_number: 0/29 Accuracy:  0.9739485782394006 Loss:  nan Val_accuracy:  0.9456551348406429 Val_cost:  nan Val_accuracy:  0.9456551348406429 Val_Acc:  nan\n",
      "Epoch number: 6930/10000step_number: 0/29 Accuracy:  0.9739145240933084 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6931/10000step_number: 0/29 Accuracy:  0.9738123616550315 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6932/10000step_number: 0/29 Accuracy:  0.973744253362847 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6933/10000step_number: 0/29 Accuracy:  0.9736761450706624 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6934/10000step_number: 0/29 Accuracy:  0.9736080367784777 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6935/10000step_number: 0/29 Accuracy:  0.9736420909245701 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6936/10000step_number: 0/29 Accuracy:  0.9735739826323855 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6937/10000step_number: 0/29 Accuracy:  0.9736761450706624 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6938/10000step_number: 0/29 Accuracy:  0.9736761450706624 Loss:  nan Val_accuracy:  0.9453827295014983 Val_cost:  nan Val_accuracy:  0.9453827295014983 Val_Acc:  nan\n",
      "Epoch number: 6939/10000step_number: 0/29 Accuracy:  0.9735739826323855 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6940/10000step_number: 0/29 Accuracy:  0.9735399284862932 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6941/10000step_number: 0/29 Accuracy:  0.9733696577558317 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6942/10000step_number: 0/29 Accuracy:  0.9733696577558317 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6943/10000step_number: 0/29 Accuracy:  0.9733015494636472 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6944/10000step_number: 0/29 Accuracy:  0.973267495317555 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 6945/10000step_number: 0/29 Accuracy:  0.9730972245870935 Loss:  nan Val_accuracy:  0.9452465268319259 Val_cost:  nan Val_accuracy:  0.9452465268319259 Val_Acc:  nan\n",
      "Epoch number: 6946/10000step_number: 0/29 Accuracy:  0.973029116294909 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6947/10000step_number: 0/29 Accuracy:  0.9730631704410012 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6948/10000step_number: 0/29 Accuracy:  0.9730631704410012 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6949/10000step_number: 0/29 Accuracy:  0.973029116294909 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6950/10000step_number: 0/29 Accuracy:  0.9729269538566321 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6951/10000step_number: 0/29 Accuracy:  0.9729269538566321 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6952/10000step_number: 0/29 Accuracy:  0.9729269538566321 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6953/10000step_number: 0/29 Accuracy:  0.9729269538566321 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6954/10000step_number: 0/29 Accuracy:  0.9726885748339861 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6955/10000step_number: 0/29 Accuracy:  0.9726885748339861 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6956/10000step_number: 0/29 Accuracy:  0.9726204665418015 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6957/10000step_number: 0/29 Accuracy:  0.9726204665418015 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6958/10000step_number: 0/29 Accuracy:  0.9726204665418015 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6959/10000step_number: 0/29 Accuracy:  0.9725523582496169 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6960/10000step_number: 0/29 Accuracy:  0.9725523582496169 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6961/10000step_number: 0/29 Accuracy:  0.9725523582496169 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6962/10000step_number: 0/29 Accuracy:  0.9725523582496169 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6963/10000step_number: 0/29 Accuracy:  0.9726204665418015 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6964/10000step_number: 0/29 Accuracy:  0.9726545206878937 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6965/10000step_number: 0/29 Accuracy:  0.9726545206878937 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6966/10000step_number: 0/29 Accuracy:  0.9727226289800783 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6967/10000step_number: 0/29 Accuracy:  0.9726885748339861 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6968/10000step_number: 0/29 Accuracy:  0.9725864123957092 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6969/10000step_number: 0/29 Accuracy:  0.9726204665418015 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6970/10000step_number: 0/29 Accuracy:  0.9727566831261706 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6971/10000step_number: 0/29 Accuracy:  0.9728588455644475 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6972/10000step_number: 0/29 Accuracy:  0.9728588455644475 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6973/10000step_number: 0/29 Accuracy:  0.9730631704410012 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6974/10000step_number: 0/29 Accuracy:  0.9730631704410012 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6975/10000step_number: 0/29 Accuracy:  0.973029116294909 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6976/10000step_number: 0/29 Accuracy:  0.9730972245870935 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6977/10000step_number: 0/29 Accuracy:  0.9730972245870935 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6978/10000step_number: 0/29 Accuracy:  0.9730631704410012 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6979/10000step_number: 0/29 Accuracy:  0.9730972245870935 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6980/10000step_number: 0/29 Accuracy:  0.9730972245870935 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 6981/10000step_number: 0/29 Accuracy:  0.9730972245870935 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 6982/10000step_number: 0/29 Accuracy:  0.9730972245870935 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6983/10000step_number: 0/29 Accuracy:  0.9729610080027243 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6984/10000step_number: 0/29 Accuracy:  0.9730631704410012 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6985/10000step_number: 0/29 Accuracy:  0.9730631704410012 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6986/10000step_number: 0/29 Accuracy:  0.9730972245870935 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 6987/10000step_number: 0/29 Accuracy:  0.9729269538566321 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6988/10000step_number: 0/29 Accuracy:  0.9728928997105397 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 6989/10000step_number: 0/29 Accuracy:  0.9732334411714626 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6990/10000step_number: 0/29 Accuracy:  0.9734377660480164 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6991/10000step_number: 0/29 Accuracy:  0.9738123616550315 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 6992/10000step_number: 0/29 Accuracy:  0.9751064192065384 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 6993/10000step_number: 0/29 Accuracy:  0.973505874340201 Loss:  nan Val_accuracy:  0.9411604467447562 Val_cost:  nan Val_accuracy:  0.9411604467447562 Val_Acc:  nan\n",
      "Epoch number: 6994/10000step_number: 0/29 Accuracy:  0.960565298825132 Loss:  nan Val_accuracy:  0.9354399346227186 Val_cost:  nan Val_accuracy:  0.9354399346227186 Val_Acc:  nan\n",
      "Epoch number: 6995/10000step_number: 0/29 Accuracy:  0.9690447812021113 Loss:  nan Val_accuracy:  0.9403432307273223 Val_cost:  nan Val_accuracy:  0.9403432307273223 Val_Acc:  nan\n",
      "Epoch number: 6996/10000step_number: 0/29 Accuracy:  0.9677507236506044 Loss:  nan Val_accuracy:  0.939389812040316 Val_cost:  nan Val_accuracy:  0.939389812040316 Val_Acc:  nan\n",
      "Epoch number: 6997/10000step_number: 0/29 Accuracy:  0.968636131449004 Loss:  nan Val_accuracy:  0.9403432307273223 Val_cost:  nan Val_accuracy:  0.9403432307273223 Val_Acc:  nan\n",
      "Epoch number: 6998/10000step_number: 0/29 Accuracy:  0.9754810148135535 Loss:  nan Val_accuracy:  0.9423862707709071 Val_cost:  nan Val_accuracy:  0.9423862707709071 Val_Acc:  nan\n",
      "Epoch number: 6999/10000step_number: 0/29 Accuracy:  0.9799080538055508 Loss:  nan Val_accuracy:  0.9467447561972214 Val_cost:  nan Val_accuracy:  0.9467447561972214 Val_Acc:  nan\n",
      "Epoch number: 7000/10000step_number: 0/29 Accuracy:  0.9776264260173676 Loss:  nan Val_accuracy:  0.9478343775538001 Val_cost:  nan Val_accuracy:  0.9478343775538001 Val_Acc:  nan\n",
      "Epoch number: 7001/10000step_number: 0/29 Accuracy:  0.9778307508939214 Loss:  nan Val_accuracy:  0.9476981748842277 Val_cost:  nan Val_accuracy:  0.9476981748842277 Val_Acc:  nan\n",
      "Epoch number: 7002/10000step_number: 0/29 Accuracy:  0.9780691299165674 Loss:  nan Val_accuracy:  0.9471533642059384 Val_cost:  nan Val_accuracy:  0.9471533642059384 Val_Acc:  nan\n",
      "Epoch number: 7003/10000step_number: 0/29 Accuracy:  0.9780691299165674 Loss:  nan Val_accuracy:  0.9472895668755108 Val_cost:  nan Val_accuracy:  0.9472895668755108 Val_Acc:  nan\n",
      "Epoch number: 7004/10000step_number: 0/29 Accuracy:  0.9779329133321982 Loss:  nan Val_accuracy:  0.9474257695450831 Val_cost:  nan Val_accuracy:  0.9474257695450831 Val_Acc:  nan\n",
      "Epoch number: 7005/10000step_number: 0/29 Accuracy:  0.9779669674782905 Loss:  nan Val_accuracy:  0.9474257695450831 Val_cost:  nan Val_accuracy:  0.9474257695450831 Val_Acc:  nan\n",
      "Epoch number: 7006/10000step_number: 0/29 Accuracy:  0.9779329133321982 Loss:  nan Val_accuracy:  0.9475619722146554 Val_cost:  nan Val_accuracy:  0.9475619722146554 Val_Acc:  nan\n",
      "Epoch number: 7007/10000step_number: 0/29 Accuracy:  0.9779329133321982 Loss:  nan Val_accuracy:  0.9475619722146554 Val_cost:  nan Val_accuracy:  0.9475619722146554 Val_Acc:  nan\n",
      "Epoch number: 7008/10000step_number: 0/29 Accuracy:  0.9779669674782905 Loss:  nan Val_accuracy:  0.9476981748842277 Val_cost:  nan Val_accuracy:  0.9476981748842277 Val_Acc:  nan\n",
      "Epoch number: 7009/10000step_number: 0/29 Accuracy:  0.9779669674782905 Loss:  nan Val_accuracy:  0.9478343775538001 Val_cost:  nan Val_accuracy:  0.9478343775538001 Val_Acc:  nan\n",
      "Epoch number: 7010/10000step_number: 0/29 Accuracy:  0.9774221011408138 Loss:  nan Val_accuracy:  0.9470171615363661 Val_cost:  nan Val_accuracy:  0.9470171615363661 Val_Acc:  nan\n",
      "Epoch number: 7011/10000step_number: 0/29 Accuracy:  0.9774561552869062 Loss:  nan Val_accuracy:  0.9472895668755108 Val_cost:  nan Val_accuracy:  0.9472895668755108 Val_Acc:  nan\n",
      "Epoch number: 7012/10000step_number: 0/29 Accuracy:  0.9773539928486293 Loss:  nan Val_accuracy:  0.9470171615363661 Val_cost:  nan Val_accuracy:  0.9470171615363661 Val_Acc:  nan\n",
      "Epoch number: 7013/10000step_number: 0/29 Accuracy:  0.9772518304103525 Loss:  nan Val_accuracy:  0.9468809588667938 Val_cost:  nan Val_accuracy:  0.9468809588667938 Val_Acc:  nan\n",
      "Epoch number: 7014/10000step_number: 0/29 Accuracy:  0.9770134513877065 Loss:  nan Val_accuracy:  0.9466085535276492 Val_cost:  nan Val_accuracy:  0.9466085535276492 Val_Acc:  nan\n",
      "Epoch number: 7015/10000step_number: 0/29 Accuracy:  0.9769112889494296 Loss:  nan Val_accuracy:  0.9467447561972214 Val_cost:  nan Val_accuracy:  0.9467447561972214 Val_Acc:  nan\n",
      "Epoch number: 7016/10000step_number: 0/29 Accuracy:  0.9766388557806913 Loss:  nan Val_accuracy:  0.9464723508580768 Val_cost:  nan Val_accuracy:  0.9464723508580768 Val_Acc:  nan\n",
      "Epoch number: 7017/10000step_number: 0/29 Accuracy:  0.9765707474885067 Loss:  nan Val_accuracy:  0.9464723508580768 Val_cost:  nan Val_accuracy:  0.9464723508580768 Val_Acc:  nan\n",
      "Epoch number: 7018/10000step_number: 0/29 Accuracy:  0.9765026391963222 Loss:  nan Val_accuracy:  0.9466085535276492 Val_cost:  nan Val_accuracy:  0.9466085535276492 Val_Acc:  nan\n",
      "Epoch number: 7019/10000step_number: 0/29 Accuracy:  0.976366422611953 Loss:  nan Val_accuracy:  0.9466085535276492 Val_cost:  nan Val_accuracy:  0.9466085535276492 Val_Acc:  nan\n",
      "Epoch number: 7020/10000step_number: 0/29 Accuracy:  0.9762302060275838 Loss:  nan Val_accuracy:  0.9463361481885045 Val_cost:  nan Val_accuracy:  0.9463361481885045 Val_Acc:  nan\n",
      "Epoch number: 7021/10000step_number: 0/29 Accuracy:  0.9762642601736762 Loss:  nan Val_accuracy:  0.9461999455189322 Val_cost:  nan Val_accuracy:  0.9461999455189322 Val_Acc:  nan\n",
      "Epoch number: 7022/10000step_number: 0/29 Accuracy:  0.9763323684658607 Loss:  nan Val_accuracy:  0.9463361481885045 Val_cost:  nan Val_accuracy:  0.9463361481885045 Val_Acc:  nan\n",
      "Epoch number: 7023/10000step_number: 0/29 Accuracy:  0.9762642601736762 Loss:  nan Val_accuracy:  0.9464723508580768 Val_cost:  nan Val_accuracy:  0.9464723508580768 Val_Acc:  nan\n",
      "Epoch number: 7024/10000step_number: 0/29 Accuracy:  0.9760939894432147 Loss:  nan Val_accuracy:  0.9464723508580768 Val_cost:  nan Val_accuracy:  0.9464723508580768 Val_Acc:  nan\n",
      "Epoch number: 7025/10000step_number: 0/29 Accuracy:  0.9759918270049378 Loss:  nan Val_accuracy:  0.9461999455189322 Val_cost:  nan Val_accuracy:  0.9461999455189322 Val_Acc:  nan\n",
      "Epoch number: 7026/10000step_number: 0/29 Accuracy:  0.975889664566661 Loss:  nan Val_accuracy:  0.9461999455189322 Val_cost:  nan Val_accuracy:  0.9461999455189322 Val_Acc:  nan\n",
      "Epoch number: 7027/10000step_number: 0/29 Accuracy:  0.9758215562744764 Loss:  nan Val_accuracy:  0.9461999455189322 Val_cost:  nan Val_accuracy:  0.9461999455189322 Val_Acc:  nan\n",
      "Epoch number: 7028/10000step_number: 0/29 Accuracy:  0.9758215562744764 Loss:  nan Val_accuracy:  0.9464723508580768 Val_cost:  nan Val_accuracy:  0.9464723508580768 Val_Acc:  nan\n",
      "Epoch number: 7029/10000step_number: 0/29 Accuracy:  0.9757875021283842 Loss:  nan Val_accuracy:  0.9464723508580768 Val_cost:  nan Val_accuracy:  0.9464723508580768 Val_Acc:  nan\n",
      "Epoch number: 7030/10000step_number: 0/29 Accuracy:  0.9757193938361995 Loss:  nan Val_accuracy:  0.9461999455189322 Val_cost:  nan Val_accuracy:  0.9461999455189322 Val_Acc:  nan\n",
      "Epoch number: 7031/10000step_number: 0/29 Accuracy:  0.9756853396901073 Loss:  nan Val_accuracy:  0.9461999455189322 Val_cost:  nan Val_accuracy:  0.9461999455189322 Val_Acc:  nan\n",
      "Epoch number: 7032/10000step_number: 0/29 Accuracy:  0.975651285544015 Loss:  nan Val_accuracy:  0.9461999455189322 Val_cost:  nan Val_accuracy:  0.9461999455189322 Val_Acc:  nan\n",
      "Epoch number: 7033/10000step_number: 0/29 Accuracy:  0.9755831772518304 Loss:  nan Val_accuracy:  0.9461999455189322 Val_cost:  nan Val_accuracy:  0.9461999455189322 Val_Acc:  nan\n",
      "Epoch number: 7034/10000step_number: 0/29 Accuracy:  0.9755150689596458 Loss:  nan Val_accuracy:  0.9457913375102152 Val_cost:  nan Val_accuracy:  0.9457913375102152 Val_Acc:  nan\n",
      "Epoch number: 7035/10000step_number: 0/29 Accuracy:  0.9754469606674613 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 7036/10000step_number: 0/29 Accuracy:  0.975412906521369 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 7037/10000step_number: 0/29 Accuracy:  0.975412906521369 Loss:  nan Val_accuracy:  0.9456551348406429 Val_cost:  nan Val_accuracy:  0.9456551348406429 Val_Acc:  nan\n",
      "Epoch number: 7038/10000step_number: 0/29 Accuracy:  0.9752766899369998 Loss:  nan Val_accuracy:  0.9456551348406429 Val_cost:  nan Val_accuracy:  0.9456551348406429 Val_Acc:  nan\n",
      "Epoch number: 7039/10000step_number: 0/29 Accuracy:  0.9752426357909075 Loss:  nan Val_accuracy:  0.9456551348406429 Val_cost:  nan Val_accuracy:  0.9456551348406429 Val_Acc:  nan\n",
      "Epoch number: 7040/10000step_number: 0/29 Accuracy:  0.975174527498723 Loss:  nan Val_accuracy:  0.9456551348406429 Val_cost:  nan Val_accuracy:  0.9456551348406429 Val_Acc:  nan\n",
      "Epoch number: 7041/10000step_number: 0/29 Accuracy:  0.9752085816448153 Loss:  nan Val_accuracy:  0.9456551348406429 Val_cost:  nan Val_accuracy:  0.9456551348406429 Val_Acc:  nan\n",
      "Epoch number: 7042/10000step_number: 0/29 Accuracy:  0.975174527498723 Loss:  nan Val_accuracy:  0.9456551348406429 Val_cost:  nan Val_accuracy:  0.9456551348406429 Val_Acc:  nan\n",
      "Epoch number: 7043/10000step_number: 0/29 Accuracy:  0.975174527498723 Loss:  nan Val_accuracy:  0.9456551348406429 Val_cost:  nan Val_accuracy:  0.9456551348406429 Val_Acc:  nan\n",
      "Epoch number: 7044/10000step_number: 0/29 Accuracy:  0.9751064192065384 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 7045/10000step_number: 0/29 Accuracy:  0.9750723650604461 Loss:  nan Val_accuracy:  0.9455189321710705 Val_cost:  nan Val_accuracy:  0.9455189321710705 Val_Acc:  nan\n",
      "Epoch number: 7046/10000step_number: 0/29 Accuracy:  0.974936148476077 Loss:  nan Val_accuracy:  0.9459275401797875 Val_cost:  nan Val_accuracy:  0.9459275401797875 Val_Acc:  nan\n",
      "Epoch number: 7047/10000step_number: 0/29 Accuracy:  0.9748680401838924 Loss:  nan Val_accuracy:  0.9461999455189322 Val_cost:  nan Val_accuracy:  0.9461999455189322 Val_Acc:  nan\n",
      "Epoch number: 7048/10000step_number: 0/29 Accuracy:  0.9748339860378001 Loss:  nan Val_accuracy:  0.9461999455189322 Val_cost:  nan Val_accuracy:  0.9461999455189322 Val_Acc:  nan\n",
      "Epoch number: 7049/10000step_number: 0/29 Accuracy:  0.9747658777456155 Loss:  nan Val_accuracy:  0.9461999455189322 Val_cost:  nan Val_accuracy:  0.9461999455189322 Val_Acc:  nan\n",
      "Epoch number: 7050/10000step_number: 0/29 Accuracy:  0.9746637153073386 Loss:  nan Val_accuracy:  0.9461999455189322 Val_cost:  nan Val_accuracy:  0.9461999455189322 Val_Acc:  nan\n",
      "Epoch number: 7051/10000step_number: 0/29 Accuracy:  0.9745956070151541 Loss:  nan Val_accuracy:  0.9460637428493599 Val_cost:  nan Val_accuracy:  0.9460637428493599 Val_Acc:  nan\n",
      "Epoch number: 7052/10000step_number: 0/29 Accuracy:  0.9745956070151541 Loss:  nan Val_accuracy:  0.9460637428493599 Val_cost:  nan Val_accuracy:  0.9460637428493599 Val_Acc:  nan\n",
      "Epoch number: 7053/10000step_number: 0/29 Accuracy:  0.9746296611612464 Loss:  nan Val_accuracy:  0.9459275401797875 Val_cost:  nan Val_accuracy:  0.9459275401797875 Val_Acc:  nan\n",
      "Epoch number: 7054/10000step_number: 0/29 Accuracy:  0.9743231738464158 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 7055/10000step_number: 0/29 Accuracy:  0.9742550655542312 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 7056/10000step_number: 0/29 Accuracy:  0.9742550655542312 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 7057/10000step_number: 0/29 Accuracy:  0.974221011408139 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 7058/10000step_number: 0/29 Accuracy:  0.974221011408139 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 7059/10000step_number: 0/29 Accuracy:  0.974221011408139 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 7060/10000step_number: 0/29 Accuracy:  0.9741869572620466 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 7061/10000step_number: 0/29 Accuracy:  0.9741869572620466 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 7062/10000step_number: 0/29 Accuracy:  0.9740847948237698 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 7063/10000step_number: 0/29 Accuracy:  0.9740847948237698 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 7064/10000step_number: 0/29 Accuracy:  0.9740847948237698 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 7065/10000step_number: 0/29 Accuracy:  0.9740166865315852 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 7066/10000step_number: 0/29 Accuracy:  0.9740166865315852 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 7067/10000step_number: 0/29 Accuracy:  0.9740847948237698 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 7068/10000step_number: 0/29 Accuracy:  0.9740847948237698 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 7069/10000step_number: 0/29 Accuracy:  0.9740507406776775 Loss:  nan Val_accuracy:  0.9451103241623536 Val_cost:  nan Val_accuracy:  0.9451103241623536 Val_Acc:  nan\n",
      "Epoch number: 7070/10000step_number: 0/29 Accuracy:  0.9741188489698621 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 7071/10000step_number: 0/29 Accuracy:  0.9741529031159544 Loss:  nan Val_accuracy:  0.9449741214927813 Val_cost:  nan Val_accuracy:  0.9449741214927813 Val_Acc:  nan\n",
      "Epoch number: 7072/10000step_number: 0/29 Accuracy:  0.9741529031159544 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 7073/10000step_number: 0/29 Accuracy:  0.9741529031159544 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 7074/10000step_number: 0/29 Accuracy:  0.9741188489698621 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 7075/10000step_number: 0/29 Accuracy:  0.9740166865315852 Loss:  nan Val_accuracy:  0.9448379188232089 Val_cost:  nan Val_accuracy:  0.9448379188232089 Val_Acc:  nan\n",
      "Epoch number: 7076/10000step_number: 0/29 Accuracy:  0.9740166865315852 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 7077/10000step_number: 0/29 Accuracy:  0.973982632385493 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 7078/10000step_number: 0/29 Accuracy:  0.973982632385493 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 7079/10000step_number: 0/29 Accuracy:  0.9730631704410012 Loss:  nan Val_accuracy:  0.9442931081449196 Val_cost:  nan Val_accuracy:  0.9442931081449196 Val_Acc:  nan\n",
      "Epoch number: 7080/10000step_number: 0/29 Accuracy:  0.9730972245870935 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 7081/10000step_number: 0/29 Accuracy:  0.9730972245870935 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 7082/10000step_number: 0/29 Accuracy:  0.9731312787331857 Loss:  nan Val_accuracy:  0.944429310814492 Val_cost:  nan Val_accuracy:  0.944429310814492 Val_Acc:  nan\n",
      "Epoch number: 7083/10000step_number: 0/29 Accuracy:  0.9731312787331857 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 7084/10000step_number: 0/29 Accuracy:  0.9730631704410012 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 7085/10000step_number: 0/29 Accuracy:  0.9730972245870935 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 7086/10000step_number: 0/29 Accuracy:  0.9731312787331857 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 7087/10000step_number: 0/29 Accuracy:  0.9731993870253703 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 7088/10000step_number: 0/29 Accuracy:  0.9731312787331857 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 7089/10000step_number: 0/29 Accuracy:  0.9730972245870935 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 7090/10000step_number: 0/29 Accuracy:  0.9730631704410012 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 7091/10000step_number: 0/29 Accuracy:  0.9730631704410012 Loss:  nan Val_accuracy:  0.9445655134840643 Val_cost:  nan Val_accuracy:  0.9445655134840643 Val_Acc:  nan\n",
      "Epoch number: 7092/10000step_number: 0/29 Accuracy:  0.9729950621488166 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n",
      "Epoch number: 7093/10000step_number: 0/29 Accuracy:  0.9729950621488166 Loss:  nan Val_accuracy:  0.9447017161536366 Val_cost:  nan Val_accuracy:  0.9447017161536366 Val_Acc:  nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-fd89c95d7a65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mNN\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mNeural_Network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m76\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m76\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#v7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-474eab7b441e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, y, epoch, X_test, y_test)\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mi1\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m                 \u001b[1;31m#print(\"Epoch number: \"+str(i1)+\"/\"+str(epoch)+ \"step_number: \"+str(i)+\"/\"+str(step_number),\"cost: \",error,\"accuracy: \",accuracy_score(self.forward_propagation_NN(X_test).argmax(axis=0), y_test.argmax(axis=0), normalize=True))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch number: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m\"step_number: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Accuracy: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_propagation_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Loss: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Val_accuracy: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_propagation_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Val_cost: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Val_accuracy: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_propagation_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Val_Acc: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_propagation_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-474eab7b441e>\u001b[0m in \u001b[0;36mforward_propagation_NN\u001b[1;34m(self, X_train)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward_propagation_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mZ1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"weight1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bias1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mA1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[0mZ2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"weight2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mA1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bias2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mA2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NN= Neural_Network(X_train,y_train,76,76,0.0001,1000) #v7\n",
    "NN.train(X_train,y_train,10000,X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1/10000step_number: 0/29 cost:  3.1367721370291965 accuracy:  0.21520021792427133\n",
      "Epoch number: 2/10000step_number: 0/29 cost:  2.7639655406763404 accuracy:  0.21520021792427133\n",
      "Epoch number: 3/10000step_number: 0/29 cost:  2.5900575564862667 accuracy:  0.21520021792427133\n",
      "Epoch number: 4/10000step_number: 0/29 cost:  2.5287090822506353 accuracy:  0.21520021792427133\n",
      "Epoch number: 5/10000step_number: 0/29 cost:  2.5085355893069736 accuracy:  0.21520021792427133\n",
      "Epoch number: 6/10000step_number: 0/29 cost:  2.5019577540073508 accuracy:  0.21520021792427133\n",
      "Epoch number: 7/10000step_number: 0/29 cost:  2.4998311178015973 accuracy:  0.21520021792427133\n",
      "Epoch number: 8/10000step_number: 0/29 cost:  2.4991404234304113 accuracy:  0.2094797058022337\n",
      "Epoch number: 9/10000step_number: 0/29 cost:  2.4989105678282475 accuracy:  0.2094797058022337\n",
      "Epoch number: 10/10000step_number: 0/29 cost:  2.498830602839086 accuracy:  0.2094797058022337\n",
      "Epoch number: 11/10000step_number: 0/29 cost:  2.4988005946874794 accuracy:  0.2094797058022337\n",
      "Epoch number: 12/10000step_number: 0/29 cost:  2.498787824674637 accuracy:  0.2094797058022337\n",
      "Epoch number: 13/10000step_number: 0/29 cost:  2.498781365319136 accuracy:  0.2094797058022337\n",
      "Epoch number: 14/10000step_number: 0/29 cost:  2.4987774808836622 accuracy:  0.2094797058022337\n",
      "Epoch number: 15/10000step_number: 0/29 cost:  2.4987748378800925 accuracy:  0.2094797058022337\n",
      "Epoch number: 16/10000step_number: 0/29 cost:  2.4987729132451677 accuracy:  0.2094797058022337\n",
      "Epoch number: 17/10000step_number: 0/29 cost:  2.498771464089099 accuracy:  0.2094797058022337\n",
      "Epoch number: 18/10000step_number: 0/29 cost:  2.498770352072894 accuracy:  0.2094797058022337\n",
      "Epoch number: 19/10000step_number: 0/29 cost:  2.4987694852262905 accuracy:  0.2094797058022337\n",
      "Epoch number: 20/10000step_number: 0/29 cost:  2.4987687977308948 accuracy:  0.2094797058022337\n",
      "Epoch number: 21/10000step_number: 0/29 cost:  2.4987682415812906 accuracy:  0.2094797058022337\n",
      "Epoch number: 22/10000step_number: 0/29 cost:  2.4987677819460457 accuracy:  0.2094797058022337\n",
      "Epoch number: 23/10000step_number: 0/29 cost:  2.498767393860833 accuracy:  0.2094797058022337\n",
      "Epoch number: 24/10000step_number: 0/29 cost:  2.4987670596395737 accuracy:  0.2094797058022337\n",
      "Epoch number: 25/10000step_number: 0/29 cost:  2.4987667668456823 accuracy:  0.2094797058022337\n",
      "Epoch number: 26/10000step_number: 0/29 cost:  2.498766506747722 accuracy:  0.2094797058022337\n",
      "Epoch number: 27/10000step_number: 0/29 cost:  2.498766273182512 accuracy:  0.2094797058022337\n",
      "Epoch number: 28/10000step_number: 0/29 cost:  2.498766061743201 accuracy:  0.2094797058022337\n",
      "Epoch number: 29/10000step_number: 0/29 cost:  2.4987658692140813 accuracy:  0.2094797058022337\n",
      "Epoch number: 30/10000step_number: 0/29 cost:  2.4987656931852813 accuracy:  0.2094797058022337\n",
      "Epoch number: 31/10000step_number: 0/29 cost:  2.4987655317943775 accuracy:  0.2094797058022337\n",
      "Epoch number: 32/10000step_number: 0/29 cost:  2.498765383555162 accuracy:  0.2094797058022337\n",
      "Epoch number: 33/10000step_number: 0/29 cost:  2.4987652472449935 accuracy:  0.2094797058022337\n",
      "Epoch number: 34/10000step_number: 0/29 cost:  2.4987651218308424 accuracy:  0.2094797058022337\n",
      "Epoch number: 35/10000step_number: 0/29 cost:  2.4987650064205083 accuracy:  0.2094797058022337\n",
      "Epoch number: 36/10000step_number: 0/29 cost:  2.4987649002300873 accuracy:  0.2094797058022337\n",
      "Epoch number: 37/10000step_number: 0/29 cost:  2.498764802561845 accuracy:  0.2094797058022337\n",
      "Epoch number: 38/10000step_number: 0/29 cost:  2.498764712788756 accuracy:  0.2094797058022337\n",
      "Epoch number: 39/10000step_number: 0/29 cost:  2.4987646303433313 accuracy:  0.2094797058022337\n",
      "Epoch number: 40/10000step_number: 0/29 cost:  2.4987645547092607 accuracy:  0.2094797058022337\n",
      "Epoch number: 41/10000step_number: 0/29 cost:  2.4987644854149087 accuracy:  0.2094797058022337\n",
      "Epoch number: 42/10000step_number: 0/29 cost:  2.4987644220280973 accuracy:  0.2094797058022337\n",
      "Epoch number: 43/10000step_number: 0/29 cost:  2.498764364151798 accuracy:  0.2094797058022337\n",
      "Epoch number: 44/10000step_number: 0/29 cost:  2.498764311420493 accuracy:  0.2094797058022337\n",
      "Epoch number: 45/10000step_number: 0/29 cost:  2.498764263497054 accuracy:  0.2094797058022337\n",
      "Epoch number: 46/10000step_number: 0/29 cost:  2.498764220070022 accuracy:  0.2094797058022337\n",
      "Epoch number: 47/10000step_number: 0/29 cost:  2.498764180851229 accuracy:  0.2094797058022337\n",
      "Epoch number: 48/10000step_number: 0/29 cost:  2.4987641455736918 accuracy:  0.2094797058022337\n",
      "Epoch number: 49/10000step_number: 0/29 cost:  2.498764113989737 accuracy:  0.2094797058022337\n",
      "Epoch number: 50/10000step_number: 0/29 cost:  2.498764085869339 accuracy:  0.2094797058022337\n",
      "Epoch number: 51/10000step_number: 0/29 cost:  2.4987640609986164 accuracy:  0.2094797058022337\n",
      "Epoch number: 52/10000step_number: 0/29 cost:  2.4987640391784987 accuracy:  0.2094797058022337\n",
      "Epoch number: 53/10000step_number: 0/29 cost:  2.4987640202235086 accuracy:  0.2094797058022337\n",
      "Epoch number: 54/10000step_number: 0/29 cost:  2.4987640039606775 accuracy:  0.2094797058022337\n",
      "Epoch number: 55/10000step_number: 0/29 cost:  2.498763990228555 accuracy:  0.2094797058022337\n",
      "Epoch number: 56/10000step_number: 0/29 cost:  2.4987639788763127 accuracy:  0.2094797058022337\n",
      "Epoch number: 57/10000step_number: 0/29 cost:  2.4987639697629302 accuracy:  0.2094797058022337\n",
      "Epoch number: 58/10000step_number: 0/29 cost:  2.4987639627564575 accuracy:  0.2094797058022337\n",
      "Epoch number: 59/10000step_number: 0/29 cost:  2.498763957733337 accuracy:  0.2094797058022337\n",
      "Epoch number: 60/10000step_number: 0/29 cost:  2.498763954577789 accuracy:  0.2094797058022337\n",
      "Epoch number: 61/10000step_number: 0/29 cost:  2.4987639531812476 accuracy:  0.2094797058022337\n",
      "Epoch number: 62/10000step_number: 0/29 cost:  2.498763953441842 accuracy:  0.2094797058022337\n",
      "Epoch number: 63/10000step_number: 0/29 cost:  2.4987639552639287 accuracy:  0.2094797058022337\n",
      "Epoch number: 64/10000step_number: 0/29 cost:  2.4987639585576518 accuracy:  0.2094797058022337\n",
      "Epoch number: 65/10000step_number: 0/29 cost:  2.4987639632385448 accuracy:  0.2094797058022337\n",
      "Epoch number: 66/10000step_number: 0/29 cost:  2.4987639692271664 accuracy:  0.2094797058022337\n",
      "Epoch number: 67/10000step_number: 0/29 cost:  2.4987639764487586 accuracy:  0.2094797058022337\n",
      "Epoch number: 68/10000step_number: 0/29 cost:  2.4987639848329337 accuracy:  0.2094797058022337\n",
      "Epoch number: 69/10000step_number: 0/29 cost:  2.4987639943133915 accuracy:  0.2094797058022337\n",
      "Epoch number: 70/10000step_number: 0/29 cost:  2.498764004827648 accuracy:  0.2094797058022337\n",
      "Epoch number: 71/10000step_number: 0/29 cost:  2.4987640163167932 accuracy:  0.2094797058022337\n",
      "Epoch number: 72/10000step_number: 0/29 cost:  2.498764028725259 accuracy:  0.2094797058022337\n",
      "Epoch number: 73/10000step_number: 0/29 cost:  2.4987640420006123 accuracy:  0.2094797058022337\n",
      "Epoch number: 74/10000step_number: 0/29 cost:  2.498764056093357 accuracy:  0.2094797058022337\n",
      "Epoch number: 75/10000step_number: 0/29 cost:  2.498764070956751 accuracy:  0.2094797058022337\n",
      "Epoch number: 76/10000step_number: 0/29 cost:  2.4987640865466334 accuracy:  0.2094797058022337\n",
      "Epoch number: 77/10000step_number: 0/29 cost:  2.4987641028212684 accuracy:  0.2094797058022337\n",
      "Epoch number: 78/10000step_number: 0/29 cost:  2.4987641197411885 accuracy:  0.2094797058022337\n",
      "Epoch number: 79/10000step_number: 0/29 cost:  2.4987641372690503 accuracy:  0.2094797058022337\n",
      "Epoch number: 80/10000step_number: 0/29 cost:  2.4987641553694933 accuracy:  0.2094797058022337\n",
      "Epoch number: 81/10000step_number: 0/29 cost:  2.498764174008992 accuracy:  0.2094797058022337\n",
      "Epoch number: 82/10000step_number: 0/29 cost:  2.498764193155717 accuracy:  0.2094797058022337\n",
      "Epoch number: 83/10000step_number: 0/29 cost:  2.4987642127793674 accuracy:  0.2094797058022337\n",
      "Epoch number: 84/10000step_number: 0/29 cost:  2.4987642328509936 accuracy:  0.2094797058022337\n",
      "Epoch number: 85/10000step_number: 0/29 cost:  2.498764253342777 accuracy:  0.2094797058022337\n",
      "Epoch number: 86/10000step_number: 0/29 cost:  2.4987642742277467 accuracy:  0.2094797058022337\n",
      "Epoch number: 87/10000step_number: 0/29 cost:  2.498764295479399 accuracy:  0.2094797058022337\n",
      "Epoch number: 88/10000step_number: 0/29 cost:  2.4987643170711555 accuracy:  0.2094797058022337\n",
      "Epoch number: 89/10000step_number: 0/29 cost:  2.498764338975553 accuracy:  0.2094797058022337\n",
      "Epoch number: 90/10000step_number: 0/29 cost:  2.49876436116301 accuracy:  0.2094797058022337\n",
      "Epoch number: 91/10000step_number: 0/29 cost:  2.498764383599857 accuracy:  0.2094797058022337\n",
      "Epoch number: 92/10000step_number: 0/29 cost:  2.49876440624512 accuracy:  0.2094797058022337\n",
      "Epoch number: 93/10000step_number: 0/29 cost:  2.498764429045097 accuracy:  0.2094797058022337\n",
      "Epoch number: 94/10000step_number: 0/29 cost:  2.4987644519238774 accuracy:  0.2094797058022337\n",
      "Epoch number: 95/10000step_number: 0/29 cost:  2.498764474766191 accuracy:  0.2094797058022337\n",
      "Epoch number: 96/10000step_number: 0/29 cost:  2.49876449738497 accuracy:  0.2094797058022337\n",
      "Epoch number: 97/10000step_number: 0/29 cost:  2.4987645194568757 accuracy:  0.2094797058022337\n",
      "Epoch number: 98/10000step_number: 0/29 cost:  2.4987645403861944 accuracy:  0.2094797058022337\n",
      "Epoch number: 99/10000step_number: 0/29 cost:  2.498764558995733 accuracy:  0.2094797058022337\n",
      "Epoch number: 100/10000step_number: 0/29 cost:  2.4987645727582817 accuracy:  0.2094797058022337\n",
      "Epoch number: 101/10000step_number: 0/29 cost:  2.4987645756544143 accuracy:  0.2094797058022337\n",
      "Epoch number: 102/10000step_number: 0/29 cost:  2.4987645512586907 accuracy:  0.2094797058022337\n",
      "Epoch number: 103/10000step_number: 0/29 cost:  2.4987644458402216 accuracy:  0.2094797058022337\n",
      "Epoch number: 104/10000step_number: 0/29 cost:  2.4987640395171846 accuracy:  0.2094797058022337\n",
      "Epoch number: 105/10000step_number: 0/29 cost:  2.498762338454807 accuracy:  0.2094797058022337\n",
      "Epoch number: 106/10000step_number: 0/29 cost:  2.4987572354330023 accuracy:  0.2094797058022337\n",
      "Epoch number: 107/10000step_number: 0/29 cost:  2.498729714937991 accuracy:  0.2094797058022337\n",
      "Epoch number: 108/10000step_number: 0/29 cost:  2.4985912935240613 accuracy:  0.2094797058022337\n",
      "Epoch number: 109/10000step_number: 0/29 cost:  2.4985458342056326 accuracy:  0.2094797058022337\n",
      "Epoch number: 110/10000step_number: 0/29 cost:  2.4984586547236503 accuracy:  0.2094797058022337\n",
      "Epoch number: 111/10000step_number: 0/29 cost:  2.4983427539611767 accuracy:  0.2094797058022337\n",
      "Epoch number: 112/10000step_number: 0/29 cost:  2.498209697957147 accuracy:  0.2094797058022337\n",
      "Epoch number: 113/10000step_number: 0/29 cost:  2.4980584088226565 accuracy:  0.2094797058022337\n",
      "Epoch number: 114/10000step_number: 0/29 cost:  2.497883502852911 accuracy:  0.2094797058022337\n",
      "Epoch number: 115/10000step_number: 0/29 cost:  2.4976780542157946 accuracy:  0.2094797058022337\n",
      "Epoch number: 116/10000step_number: 0/29 cost:  2.4974353947490076 accuracy:  0.2094797058022337\n",
      "Epoch number: 117/10000step_number: 0/29 cost:  2.4971505644940337 accuracy:  0.2094797058022337\n",
      "Epoch number: 118/10000step_number: 0/29 cost:  2.4968217301567166 accuracy:  0.2094797058022337\n",
      "Epoch number: 119/10000step_number: 0/29 cost:  2.4964505184870602 accuracy:  0.2094797058022337\n",
      "Epoch number: 120/10000step_number: 0/29 cost:  2.496040123918108 accuracy:  0.2094797058022337\n",
      "Epoch number: 121/10000step_number: 0/29 cost:  2.4955923008197014 accuracy:  0.2094797058022337\n",
      "Epoch number: 122/10000step_number: 0/29 cost:  2.495105976542577 accuracy:  0.2094797058022337\n",
      "Epoch number: 123/10000step_number: 0/29 cost:  2.4945782119726694 accuracy:  0.2094797058022337\n",
      "Epoch number: 124/10000step_number: 0/29 cost:  2.494005363697599 accuracy:  0.2094797058022337\n",
      "Epoch number: 125/10000step_number: 0/29 cost:  2.4933834865535935 accuracy:  0.2094797058022337\n",
      "Epoch number: 126/10000step_number: 0/29 cost:  2.4927085974098526 accuracy:  0.2094797058022337\n",
      "Epoch number: 127/10000step_number: 0/29 cost:  2.491977033482187 accuracy:  0.2094797058022337\n",
      "Epoch number: 128/10000step_number: 0/29 cost:  2.491185727031861 accuracy:  0.2094797058022337\n",
      "Epoch number: 129/10000step_number: 0/29 cost:  2.490332175225161 accuracy:  0.2094797058022337\n",
      "Epoch number: 130/10000step_number: 0/29 cost:  2.4894142137227915 accuracy:  0.2094797058022337\n",
      "Epoch number: 131/10000step_number: 0/29 cost:  2.4884299939735883 accuracy:  0.2094797058022337\n",
      "Epoch number: 132/10000step_number: 0/29 cost:  2.4873781773924306 accuracy:  0.2094797058022337\n",
      "Epoch number: 133/10000step_number: 0/29 cost:  2.4862580192172525 accuracy:  0.2094797058022337\n",
      "Epoch number: 134/10000step_number: 0/29 cost:  2.48506928767674 accuracy:  0.2094797058022337\n",
      "Epoch number: 135/10000step_number: 0/29 cost:  2.4838121866523672 accuracy:  0.2094797058022337\n",
      "Epoch number: 136/10000step_number: 0/29 cost:  2.482487273509841 accuracy:  0.2094797058022337\n",
      "Epoch number: 137/10000step_number: 0/29 cost:  2.4810951533445844 accuracy:  0.2094797058022337\n",
      "Epoch number: 138/10000step_number: 0/29 cost:  2.4796358567622434 accuracy:  0.2094797058022337\n",
      "Epoch number: 139/10000step_number: 0/29 cost:  2.478107774308414 accuracy:  0.2094797058022337\n",
      "Epoch number: 140/10000step_number: 0/29 cost:  2.4764943972091418 accuracy:  0.2094797058022337\n",
      "Epoch number: 141/10000step_number: 0/29 cost:  2.4742231420135585 accuracy:  0.2094797058022337\n",
      "Epoch number: 142/10000step_number: 0/29 cost:  2.471045746813712 accuracy:  0.2094797058022337\n",
      "Epoch number: 143/10000step_number: 0/29 cost:  2.4659752643355652 accuracy:  0.2094797058022337\n",
      "Epoch number: 144/10000step_number: 0/29 cost:  2.461715576678914 accuracy:  0.2094797058022337\n",
      "Epoch number: 145/10000step_number: 0/29 cost:  2.4569107176691416 accuracy:  0.2094797058022337\n",
      "Epoch number: 146/10000step_number: 0/29 cost:  2.4519549067121527 accuracy:  0.2094797058022337\n",
      "Epoch number: 147/10000step_number: 0/29 cost:  2.446807563728397 accuracy:  0.2094797058022337\n",
      "Epoch number: 148/10000step_number: 0/29 cost:  2.4414312239339755 accuracy:  0.2094797058022337\n",
      "Epoch number: 149/10000step_number: 0/29 cost:  2.4358468748808866 accuracy:  0.2094797058022337\n",
      "Epoch number: 150/10000step_number: 0/29 cost:  2.430068556336533 accuracy:  0.21370198855897576\n",
      "Epoch number: 151/10000step_number: 0/29 cost:  2.4239734003198925 accuracy:  0.3004630890765459\n",
      "Epoch number: 152/10000step_number: 0/29 cost:  2.4151977436631373 accuracy:  0.32620539362571505\n",
      "Epoch number: 153/10000step_number: 0/29 cost:  2.4064508605004367 accuracy:  0.34241351130482156\n",
      "Epoch number: 154/10000step_number: 0/29 cost:  2.3969102882515974 accuracy:  0.34758921274856985\n",
      "Epoch number: 155/10000step_number: 0/29 cost:  2.3874393324424843 accuracy:  0.35140288749659493\n",
      "Epoch number: 156/10000step_number: 0/29 cost:  2.378148482540043 accuracy:  0.3535821302097521\n",
      "Epoch number: 157/10000step_number: 0/29 cost:  2.369018485798855 accuracy:  0.3569871969490602\n",
      "Epoch number: 158/10000step_number: 0/29 cost:  2.359978759378645 accuracy:  0.3575320076273495\n",
      "Epoch number: 159/10000step_number: 0/29 cost:  2.3510148973539065 accuracy:  0.31585399073821846\n",
      "Epoch number: 160/10000step_number: 0/29 cost:  2.3421654901489175 accuracy:  0.32552438027785346\n",
      "Epoch number: 161/10000step_number: 0/29 cost:  2.3334943277755937 accuracy:  0.3351947698174884\n",
      "Epoch number: 162/10000step_number: 0/29 cost:  2.325015250231605 accuracy:  0.3400980659220921\n",
      "Epoch number: 163/10000step_number: 0/29 cost:  2.3156649200032557 accuracy:  0.34377553800054483\n",
      "Epoch number: 164/10000step_number: 0/29 cost:  2.3067682065977224 accuracy:  0.3470444020702806\n",
      "Epoch number: 165/10000step_number: 0/29 cost:  2.2974575069225094 accuracy:  0.35208390084445657\n",
      "Epoch number: 166/10000step_number: 0/29 cost:  2.2882753601882078 accuracy:  0.3541269408880414\n",
      "Epoch number: 167/10000step_number: 0/29 cost:  2.2795762796056187 accuracy:  0.3576682102969218\n",
      "Epoch number: 168/10000step_number: 0/29 cost:  2.271671843243059 accuracy:  0.359847453010079\n",
      "Epoch number: 169/10000step_number: 0/29 cost:  2.26447299795225 accuracy:  0.35971125034050666\n",
      "Epoch number: 170/10000step_number: 0/29 cost:  2.2564888957181317 accuracy:  0.3629801144102424\n",
      "Epoch number: 171/10000step_number: 0/29 cost:  2.2493692148557276 accuracy:  0.36529555979297196\n",
      "Epoch number: 172/10000step_number: 0/29 cost:  2.243296806312696 accuracy:  0.3667937891582675\n",
      "Epoch number: 173/10000step_number: 0/29 cost:  2.237825041742195 accuracy:  0.3680196131844184\n",
      "Epoch number: 174/10000step_number: 0/29 cost:  2.232855502819262 accuracy:  0.369517842549714\n",
      "Epoch number: 175/10000step_number: 0/29 cost:  2.2284219041474 accuracy:  0.37060746390629257\n",
      "Epoch number: 176/10000step_number: 0/29 cost:  2.2244732869365818 accuracy:  0.37183328793244347\n",
      "Epoch number: 177/10000step_number: 0/29 cost:  2.2209346726474606 accuracy:  0.3712884772541542\n",
      "Epoch number: 178/10000step_number: 0/29 cost:  2.2175667033547923 accuracy:  0.3719694906020158\n",
      "Epoch number: 179/10000step_number: 0/29 cost:  2.214312255331685 accuracy:  0.3723780986107328\n",
      "Epoch number: 180/10000step_number: 0/29 cost:  2.211194449590553 accuracy:  0.3731953146281667\n",
      "Epoch number: 181/10000step_number: 0/29 cost:  2.2082393688498487 accuracy:  0.37401253064560064\n",
      "Epoch number: 182/10000step_number: 0/29 cost:  2.2052857415992526 accuracy:  0.3748297466630346\n",
      "Epoch number: 183/10000step_number: 0/29 cost:  2.2024182615126473 accuracy:  0.3763279760283302\n",
      "Epoch number: 184/10000step_number: 0/29 cost:  2.1993152953234865 accuracy:  0.3746935439934623\n",
      "Epoch number: 185/10000step_number: 0/29 cost:  2.196188346067241 accuracy:  0.37292290928902205\n",
      "Epoch number: 186/10000step_number: 0/29 cost:  2.1933518316142226 accuracy:  0.3731953146281667\n",
      "Epoch number: 187/10000step_number: 0/29 cost:  2.189819708733955 accuracy:  0.3734677199673114\n",
      "Epoch number: 188/10000step_number: 0/29 cost:  2.186752042177153 accuracy:  0.3731953146281667\n",
      "Epoch number: 189/10000step_number: 0/29 cost:  2.183455727205933 accuracy:  0.3726505039498774\n",
      "Epoch number: 190/10000step_number: 0/29 cost:  2.179578039748117 accuracy:  0.3731953146281667\n",
      "Epoch number: 191/10000step_number: 0/29 cost:  2.1758577929103926 accuracy:  0.373740125306456\n",
      "Epoch number: 192/10000step_number: 0/29 cost:  2.1720773021065867 accuracy:  0.3760555706891855\n",
      "Epoch number: 193/10000step_number: 0/29 cost:  2.1685125236789884 accuracy:  0.37986924543721057\n",
      "Epoch number: 194/10000step_number: 0/29 cost:  2.164823783139595 accuracy:  0.3801416507763552\n",
      "Epoch number: 195/10000step_number: 0/29 cost:  2.1607965170044663 accuracy:  0.38477254154181423\n",
      "Epoch number: 196/10000step_number: 0/29 cost:  2.156812056881051 accuracy:  0.3904930536638518\n",
      "Epoch number: 197/10000step_number: 0/29 cost:  2.1526941742898633 accuracy:  0.3937619177335876\n",
      "Epoch number: 198/10000step_number: 0/29 cost:  2.1484007916190877 accuracy:  0.40098065922092074\n",
      "Epoch number: 199/10000step_number: 0/29 cost:  2.143402586074137 accuracy:  0.4227730863524925\n",
      "Epoch number: 200/10000step_number: 0/29 cost:  2.1384468524666618 accuracy:  0.508444565513484\n",
      "Epoch number: 201/10000step_number: 0/29 cost:  2.1334631751313173 accuracy:  0.5136202669572324\n",
      "Epoch number: 202/10000step_number: 0/29 cost:  2.1281662052348365 accuracy:  0.5222010351402887\n",
      "Epoch number: 203/10000step_number: 0/29 cost:  2.1225286693062357 accuracy:  0.5315990193407791\n",
      "Epoch number: 204/10000step_number: 0/29 cost:  2.1164308837018098 accuracy:  0.5380005448106783\n",
      "Epoch number: 205/10000step_number: 0/29 cost:  2.1098248594503177 accuracy:  0.5329610460365023\n",
      "Epoch number: 206/10000step_number: 0/29 cost:  2.102728416917785 accuracy:  0.5262871152274584\n",
      "Epoch number: 207/10000step_number: 0/29 cost:  2.094841818980668 accuracy:  0.518523563061836\n",
      "Epoch number: 208/10000step_number: 0/29 cost:  2.0859001552638423 accuracy:  0.5261509125578862\n",
      "Epoch number: 209/10000step_number: 0/29 cost:  2.076378409449772 accuracy:  0.5215200217924272\n",
      "Epoch number: 210/10000step_number: 0/29 cost:  2.0665565039012113 accuracy:  0.5193407790792699\n",
      "Epoch number: 211/10000step_number: 0/29 cost:  2.0561255269600545 accuracy:  0.518932171070553\n",
      "Epoch number: 212/10000step_number: 0/29 cost:  2.0457510412157855 accuracy:  0.518114955053119\n",
      "Epoch number: 213/10000step_number: 0/29 cost:  2.035607923371908 accuracy:  0.5166167256878235\n",
      "Epoch number: 214/10000step_number: 0/29 cost:  2.0248937031290595 accuracy:  0.5190683737401253\n",
      "Epoch number: 215/10000step_number: 0/29 cost:  2.0136499366610203 accuracy:  0.5190683737401253\n",
      "Epoch number: 216/10000step_number: 0/29 cost:  2.0029825979254063 accuracy:  0.5254698992100245\n",
      "Epoch number: 217/10000step_number: 0/29 cost:  1.9923392934350295 accuracy:  0.5279215472623263\n",
      "Epoch number: 218/10000step_number: 0/29 cost:  1.9819937916540675 accuracy:  0.5329610460365023\n",
      "Epoch number: 219/10000step_number: 0/29 cost:  1.972133231285461 accuracy:  0.537047126123672\n",
      "Epoch number: 220/10000step_number: 0/29 cost:  1.9628418802254128 accuracy:  0.536638518114955\n",
      "Epoch number: 221/10000step_number: 0/29 cost:  1.9541003996576756 accuracy:  0.5340506673930809\n",
      "Epoch number: 222/10000step_number: 0/29 cost:  1.9458207546277413 accuracy:  0.5332334513756469\n",
      "Epoch number: 223/10000step_number: 0/29 cost:  1.938086837490468 accuracy:  0.5347316807409426\n",
      "Epoch number: 224/10000step_number: 0/29 cost:  1.9306763839616028 accuracy:  0.5322800326886407\n",
      "Epoch number: 225/10000step_number: 0/29 cost:  1.92329878564704 accuracy:  0.5400435848542632\n",
      "Epoch number: 226/10000step_number: 0/29 cost:  1.916394980135849 accuracy:  0.5441296649414329\n",
      "Epoch number: 227/10000step_number: 0/29 cost:  1.9102019808320758 accuracy:  0.5442658676110051\n",
      "Epoch number: 228/10000step_number: 0/29 cost:  1.9044201658757245 accuracy:  0.541678016889131\n",
      "Epoch number: 229/10000step_number: 0/29 cost:  1.89875797448623 accuracy:  0.537455734132389\n",
      "Epoch number: 230/10000step_number: 0/29 cost:  1.8928757355447223 accuracy:  0.5375919368019613\n",
      "Epoch number: 231/10000step_number: 0/29 cost:  1.886896431660484 accuracy:  0.5412694088804141\n",
      "Epoch number: 232/10000step_number: 0/29 cost:  1.8812699710371827 accuracy:  0.5414056115499863\n",
      "Epoch number: 233/10000step_number: 0/29 cost:  1.8756216268965997 accuracy:  0.5444020702805775\n",
      "Epoch number: 234/10000step_number: 0/29 cost:  1.8693301087220526 accuracy:  0.547943339689458\n",
      "Epoch number: 235/10000step_number: 0/29 cost:  1.863535472881515 accuracy:  0.5480795423590302\n",
      "Epoch number: 236/10000step_number: 0/29 cost:  1.8579281627323303 accuracy:  0.5518932171070553\n",
      "Epoch number: 237/10000step_number: 0/29 cost:  1.8520425748548106 accuracy:  0.5533914464723508\n",
      "Epoch number: 238/10000step_number: 0/29 cost:  1.8458473466754077 accuracy:  0.5569327158812313\n",
      "Epoch number: 239/10000step_number: 0/29 cost:  1.8393691055234047 accuracy:  0.5580223372378098\n",
      "Epoch number: 240/10000step_number: 0/29 cost:  1.8327309185095801 accuracy:  0.5578861345682375\n",
      "Epoch number: 241/10000step_number: 0/29 cost:  1.8257710311050583 accuracy:  0.5574775265595205\n",
      "Epoch number: 242/10000step_number: 0/29 cost:  1.818395416470241 accuracy:  0.5588395532552438\n",
      "Epoch number: 243/10000step_number: 0/29 cost:  1.8107936072667437 accuracy:  0.5612912013075456\n",
      "Epoch number: 244/10000step_number: 0/29 cost:  1.8033177958586657 accuracy:  0.5645600653772814\n",
      "Epoch number: 245/10000step_number: 0/29 cost:  1.7957433628174 accuracy:  0.5674203214383002\n",
      "Epoch number: 246/10000step_number: 0/29 cost:  1.7879512493881848 accuracy:  0.5706891855080359\n",
      "Epoch number: 247/10000step_number: 0/29 cost:  1.7799294591763104 accuracy:  0.5727322255516208\n",
      "Epoch number: 248/10000step_number: 0/29 cost:  1.7718276740304315 accuracy:  0.5773631163170798\n",
      "Epoch number: 249/10000step_number: 0/29 cost:  1.7638137897870014 accuracy:  0.57913375102152\n",
      "Epoch number: 250/10000step_number: 0/29 cost:  1.7556456229198738 accuracy:  0.5798147643693816\n",
      "Epoch number: 251/10000step_number: 0/29 cost:  1.747386633684446 accuracy:  0.5813129937346772\n",
      "Epoch number: 252/10000step_number: 0/29 cost:  1.739147725803884 accuracy:  0.5843094524652683\n",
      "Epoch number: 253/10000step_number: 0/29 cost:  1.7309137769798235 accuracy:  0.5868973031871425\n",
      "Epoch number: 254/10000step_number: 0/29 cost:  1.7226969238876126 accuracy:  0.588804140561155\n",
      "Epoch number: 255/10000step_number: 0/29 cost:  1.7145025380514485 accuracy:  0.5912557886134568\n",
      "Epoch number: 256/10000step_number: 0/29 cost:  1.7063379535541203 accuracy:  0.593435031326614\n",
      "Epoch number: 257/10000step_number: 0/29 cost:  1.6982242844849196 accuracy:  0.5968400980659221\n",
      "Epoch number: 258/10000step_number: 0/29 cost:  1.6901597452687618 accuracy:  0.5968400980659221\n",
      "Epoch number: 259/10000step_number: 0/29 cost:  1.6821315706766904 accuracy:  0.6002451648052302\n",
      "Epoch number: 260/10000step_number: 0/29 cost:  1.6741442742962487 accuracy:  0.6041950422228276\n",
      "Epoch number: 261/10000step_number: 0/29 cost:  1.6661338168832716 accuracy:  0.6137292290928902\n",
      "Epoch number: 262/10000step_number: 0/29 cost:  1.6580460784268598 accuracy:  0.6175429038409153\n",
      "Epoch number: 263/10000step_number: 0/29 cost:  1.6500144737763915 accuracy:  0.6214927812585127\n",
      "Epoch number: 264/10000step_number: 0/29 cost:  1.6420047654644994 accuracy:  0.6299373467719968\n",
      "Epoch number: 265/10000step_number: 0/29 cost:  1.6339607727107228 accuracy:  0.6364750749114683\n",
      "Epoch number: 266/10000step_number: 0/29 cost:  1.6257867830100672 accuracy:  0.6431490057205121\n",
      "Epoch number: 267/10000step_number: 0/29 cost:  1.6176455487660533 accuracy:  0.6464178697902478\n",
      "Epoch number: 268/10000step_number: 0/29 cost:  1.6096391372222105 accuracy:  0.6518659765731408\n",
      "Epoch number: 269/10000step_number: 0/29 cost:  1.6017887131764383 accuracy:  0.6552710433124489\n",
      "Epoch number: 270/10000step_number: 0/29 cost:  1.5939562064797745 accuracy:  0.6612639607736311\n",
      "Epoch number: 271/10000step_number: 0/29 cost:  1.5860962673531431 accuracy:  0.6699809316262598\n",
      "Epoch number: 272/10000step_number: 0/29 cost:  1.5782176783095168 accuracy:  0.6812857532007628\n",
      "Epoch number: 273/10000step_number: 0/29 cost:  1.5702756889453524 accuracy:  0.686052846635794\n",
      "Epoch number: 274/10000step_number: 0/29 cost:  1.5622309902507936 accuracy:  0.6897303187142468\n",
      "Epoch number: 275/10000step_number: 0/29 cost:  1.5540576125231291 accuracy:  0.6954508308362843\n",
      "Epoch number: 276/10000step_number: 0/29 cost:  1.5457385007468256 accuracy:  0.7007627349496051\n",
      "Epoch number: 277/10000step_number: 0/29 cost:  1.5372671106596945 accuracy:  0.7067556524107873\n",
      "Epoch number: 278/10000step_number: 0/29 cost:  1.5286699347634323 accuracy:  0.7132933805502588\n",
      "Epoch number: 279/10000step_number: 0/29 cost:  1.5199999067308863 accuracy:  0.7224189594116045\n",
      "Epoch number: 280/10000step_number: 0/29 cost:  1.511309520272321 accuracy:  0.7267774448379188\n",
      "Epoch number: 281/10000step_number: 0/29 cost:  1.5027034600692808 accuracy:  0.7295014982293653\n",
      "Epoch number: 282/10000step_number: 0/29 cost:  1.4943077231522222 accuracy:  0.7312721329338056\n",
      "Epoch number: 283/10000step_number: 0/29 cost:  1.4862462792533557 accuracy:  0.7334513756469627\n",
      "Epoch number: 284/10000step_number: 0/29 cost:  1.4786160600712441 accuracy:  0.7352220103514029\n",
      "Epoch number: 285/10000step_number: 0/29 cost:  1.4714683741958607 accuracy:  0.7367202397166984\n",
      "Epoch number: 286/10000step_number: 0/29 cost:  1.4648068951248632 accuracy:  0.7388994824298556\n",
      "Epoch number: 287/10000step_number: 0/29 cost:  1.4586010417479214 accuracy:  0.7431217651865977\n",
      "Epoch number: 288/10000step_number: 0/29 cost:  1.4527692700988009 accuracy:  0.7450286025606102\n",
      "Epoch number: 289/10000step_number: 0/29 cost:  1.4471977357816637 accuracy:  0.7459820212476165\n",
      "Epoch number: 290/10000step_number: 0/29 cost:  1.4418153113674674 accuracy:  0.7442113865431762\n",
      "Epoch number: 291/10000step_number: 0/29 cost:  1.4365875474832046 accuracy:  0.7463906292563334\n",
      "Epoch number: 292/10000step_number: 0/29 cost:  1.4314897489405844 accuracy:  0.7476164532824844\n",
      "Epoch number: 293/10000step_number: 0/29 cost:  1.426505380544796 accuracy:  0.7496594933260692\n",
      "Epoch number: 294/10000step_number: 0/29 cost:  1.4216679941633044 accuracy:  0.7506129120130755\n",
      "Epoch number: 295/10000step_number: 0/29 cost:  1.4161697112738272 accuracy:  0.7523835467175156\n",
      "Epoch number: 296/10000step_number: 0/29 cost:  1.410949866612585 accuracy:  0.752928357395805\n",
      "Epoch number: 297/10000step_number: 0/29 cost:  1.4065150338450845 accuracy:  0.7532007627349496\n",
      "Epoch number: 298/10000step_number: 0/29 cost:  1.401658419938262 accuracy:  0.7549713974393898\n",
      "Epoch number: 299/10000step_number: 0/29 cost:  1.3975166391832914 accuracy:  0.7557886134568238\n",
      "Epoch number: 300/10000step_number: 0/29 cost:  1.3933767353007451 accuracy:  0.7568782348134023\n",
      "Epoch number: 301/10000step_number: 0/29 cost:  1.389243143880491 accuracy:  0.757967856169981\n",
      "Epoch number: 302/10000step_number: 0/29 cost:  1.3851309700581405 accuracy:  0.7585126668482702\n",
      "Epoch number: 303/10000step_number: 0/29 cost:  1.3810512724203496 accuracy:  0.7593298828657041\n",
      "Epoch number: 304/10000step_number: 0/29 cost:  1.3770056378679179 accuracy:  0.7593298828657041\n",
      "Epoch number: 305/10000step_number: 0/29 cost:  1.3730125674524416 accuracy:  0.7598746935439935\n",
      "Epoch number: 306/10000step_number: 0/29 cost:  1.3690405783625128 accuracy:  0.7597384908744211\n",
      "Epoch number: 307/10000step_number: 0/29 cost:  1.365095839046975 accuracy:  0.7594660855352765\n",
      "Epoch number: 308/10000step_number: 0/29 cost:  1.3611897972538956 accuracy:  0.7600108962135658\n",
      "Epoch number: 309/10000step_number: 0/29 cost:  1.3573383812766293 accuracy:  0.7611005175701444\n",
      "Epoch number: 310/10000step_number: 0/29 cost:  1.3535464520077627 accuracy:  0.7611005175701444\n",
      "Epoch number: 311/10000step_number: 0/29 cost:  1.3497975853194002 accuracy:  0.7620539362571507\n",
      "Epoch number: 312/10000step_number: 0/29 cost:  1.3460730714360845 accuracy:  0.7624625442658676\n",
      "Epoch number: 313/10000step_number: 0/29 cost:  1.3423596081019764 accuracy:  0.7631435576137292\n",
      "Epoch number: 314/10000step_number: 0/29 cost:  1.338651239352554 accuracy:  0.7632797602833016\n",
      "Epoch number: 315/10000step_number: 0/29 cost:  1.334946980657318 accuracy:  0.7638245709615908\n",
      "Epoch number: 316/10000step_number: 0/29 cost:  1.3312475838731925 accuracy:  0.7645055843094525\n",
      "Epoch number: 317/10000step_number: 0/29 cost:  1.327555192077767 accuracy:  0.7649141923181695\n",
      "Epoch number: 318/10000step_number: 0/29 cost:  1.3238709845099255 accuracy:  0.7654590029964587\n",
      "Epoch number: 319/10000step_number: 0/29 cost:  1.320193092553 accuracy:  0.7669572323617543\n",
      "Epoch number: 320/10000step_number: 0/29 cost:  1.3165253196019515 accuracy:  0.7669572323617543\n",
      "Epoch number: 321/10000step_number: 0/29 cost:  1.3128706766666596 accuracy:  0.7669572323617543\n",
      "Epoch number: 322/10000step_number: 0/29 cost:  1.3092293570774258 accuracy:  0.7677744483791882\n",
      "Epoch number: 323/10000step_number: 0/29 cost:  1.305610597126752 accuracy:  0.7691364750749115\n",
      "Epoch number: 324/10000step_number: 0/29 cost:  1.3020792146325038 accuracy:  0.770634704440207\n",
      "Epoch number: 325/10000step_number: 0/29 cost:  1.2986994077063414 accuracy:  0.7713157177880686\n",
      "Epoch number: 326/10000step_number: 0/29 cost:  1.2953689935531152 accuracy:  0.7719967311359303\n",
      "Epoch number: 327/10000step_number: 0/29 cost:  1.2920075485727984 accuracy:  0.7719967311359303\n",
      "Epoch number: 328/10000step_number: 0/29 cost:  1.2885948204463094 accuracy:  0.7729501498229365\n",
      "Epoch number: 329/10000step_number: 0/29 cost:  1.2851808634739146 accuracy:  0.7743121765186598\n",
      "Epoch number: 330/10000step_number: 0/29 cost:  1.2817696812611616 accuracy:  0.7773086352492509\n",
      "Epoch number: 331/10000step_number: 0/29 cost:  1.2783646736045413 accuracy:  0.7777172432579679\n",
      "Epoch number: 332/10000step_number: 0/29 cost:  1.274969014040104 accuracy:  0.7801688913102697\n",
      "Epoch number: 333/10000step_number: 0/29 cost:  1.2715859316688924 accuracy:  0.7809861073277036\n",
      "Epoch number: 334/10000step_number: 0/29 cost:  1.2682178375495523 accuracy:  0.7819395260147098\n",
      "Epoch number: 335/10000step_number: 0/29 cost:  1.264864376394998 accuracy:  0.7822119313538546\n",
      "Epoch number: 336/10000step_number: 0/29 cost:  1.2615224514442438 accuracy:  0.7839825660582947\n",
      "Epoch number: 337/10000step_number: 0/29 cost:  1.2581890136022613 accuracy:  0.7843911740670118\n",
      "Epoch number: 338/10000step_number: 0/29 cost:  1.2548633441269355 accuracy:  0.7842549713974394\n",
      "Epoch number: 339/10000step_number: 0/29 cost:  1.2515463042052175 accuracy:  0.7843911740670118\n",
      "Epoch number: 340/10000step_number: 0/29 cost:  1.2482388753481157 accuracy:  0.7842549713974394\n",
      "Epoch number: 341/10000step_number: 0/29 cost:  1.2449418299606778 accuracy:  0.7846635794061564\n",
      "Epoch number: 342/10000step_number: 0/29 cost:  1.2416557298123607 accuracy:  0.7846635794061564\n",
      "Epoch number: 343/10000step_number: 0/29 cost:  1.2383800664496425 accuracy:  0.7846635794061564\n",
      "Epoch number: 344/10000step_number: 0/29 cost:  1.2351093588953304 accuracy:  0.7854807954235903\n",
      "Epoch number: 345/10000step_number: 0/29 cost:  1.231868171643666 accuracy:  0.7857532007627349\n",
      "Epoch number: 346/10000step_number: 0/29 cost:  1.2286300119924913 accuracy:  0.7860256061018795\n",
      "Epoch number: 347/10000step_number: 0/29 cost:  1.2253746872841655 accuracy:  0.7865704167801689\n",
      "Epoch number: 348/10000step_number: 0/29 cost:  1.2221149256513062 accuracy:  0.7876600381367475\n",
      "Epoch number: 349/10000step_number: 0/29 cost:  1.2188489979234312 accuracy:  0.7922909289022065\n",
      "Epoch number: 350/10000step_number: 0/29 cost:  1.2155776032108825 accuracy:  0.7928357395804958\n",
      "Epoch number: 351/10000step_number: 0/29 cost:  1.212300457680327 accuracy:  0.7932443475892127\n",
      "Epoch number: 352/10000step_number: 0/29 cost:  1.2090173818918444 accuracy:  0.7931081449196404\n",
      "Epoch number: 353/10000step_number: 0/29 cost:  1.2057285358949394 accuracy:  0.7935167529283574\n",
      "Epoch number: 354/10000step_number: 0/29 cost:  1.2024344307039638 accuracy:  0.7932443475892127\n",
      "Epoch number: 355/10000step_number: 0/29 cost:  1.1991357785606138 accuracy:  0.7933805502587851\n",
      "Epoch number: 356/10000step_number: 0/29 cost:  1.1958336283719542 accuracy:  0.7933805502587851\n",
      "Epoch number: 357/10000step_number: 0/29 cost:  1.1925293365183398 accuracy:  0.7944701716153637\n",
      "Epoch number: 358/10000step_number: 0/29 cost:  1.1892246818938728 accuracy:  0.7951511849632252\n",
      "Epoch number: 359/10000step_number: 0/29 cost:  1.1859218961392752 accuracy:  0.7955597929719422\n",
      "Epoch number: 360/10000step_number: 0/29 cost:  1.1826237494650247 accuracy:  0.795014982293653\n",
      "Epoch number: 361/10000step_number: 0/29 cost:  1.1793309208327807 accuracy:  0.7948787796240806\n",
      "Epoch number: 362/10000step_number: 0/29 cost:  1.1760331373636277 accuracy:  0.7951511849632252\n",
      "Epoch number: 363/10000step_number: 0/29 cost:  1.1727226016307686 accuracy:  0.7951511849632252\n",
      "Epoch number: 364/10000step_number: 0/29 cost:  1.169419212224635 accuracy:  0.7955597929719422\n",
      "Epoch number: 365/10000step_number: 0/29 cost:  1.166124533609384 accuracy:  0.7961046036502315\n",
      "Epoch number: 366/10000step_number: 0/29 cost:  1.1628515485690747 accuracy:  0.7962408063198039\n",
      "Epoch number: 367/10000step_number: 0/29 cost:  1.159650164730063 accuracy:  0.7966494143285209\n",
      "Epoch number: 368/10000step_number: 0/29 cost:  1.1566218540880497 accuracy:  0.7970580223372378\n",
      "Epoch number: 369/10000step_number: 0/29 cost:  1.1538292817059614 accuracy:  0.7974666303459548\n",
      "Epoch number: 370/10000step_number: 0/29 cost:  1.1509360165894942 accuracy:  0.7982838463633887\n",
      "Epoch number: 371/10000step_number: 0/29 cost:  1.1478254417037548 accuracy:  0.7986924543721057\n",
      "Epoch number: 372/10000step_number: 0/29 cost:  1.144546935686214 accuracy:  0.7992372650503949\n",
      "Epoch number: 373/10000step_number: 0/29 cost:  1.1412137015388246 accuracy:  0.799645873059112\n",
      "Epoch number: 374/10000step_number: 0/29 cost:  1.1379964727472143 accuracy:  0.7997820757286843\n",
      "Epoch number: 375/10000step_number: 0/29 cost:  1.134940558203628 accuracy:  0.8008716970852628\n",
      "Epoch number: 376/10000step_number: 0/29 cost:  1.131987781458506 accuracy:  0.8010078997548352\n",
      "Epoch number: 377/10000step_number: 0/29 cost:  1.1290936868056507 accuracy:  0.8010078997548352\n",
      "Epoch number: 378/10000step_number: 0/29 cost:  1.1262464002836712 accuracy:  0.8012803050939798\n",
      "Epoch number: 379/10000step_number: 0/29 cost:  1.1234427187997276 accuracy:  0.8015527104331245\n",
      "Epoch number: 380/10000step_number: 0/29 cost:  1.1206793844124037 accuracy:  0.8018251157722691\n",
      "Epoch number: 381/10000step_number: 0/29 cost:  1.1179525613529955 accuracy:  0.8020975211114137\n",
      "Epoch number: 382/10000step_number: 0/29 cost:  1.115259319670375 accuracy:  0.8019613184418415\n",
      "Epoch number: 383/10000step_number: 0/29 cost:  1.1125984467829608 accuracy:  0.8029147371288478\n",
      "Epoch number: 384/10000step_number: 0/29 cost:  1.1099699213834533 accuracy:  0.80305093979842\n",
      "Epoch number: 385/10000step_number: 0/29 cost:  1.1073734672753472 accuracy:  0.803459547807137\n",
      "Epoch number: 386/10000step_number: 0/29 cost:  1.1048101838129274 accuracy:  0.8040043584854263\n",
      "Epoch number: 387/10000step_number: 0/29 cost:  1.102304506611469 accuracy:  0.8033233451375646\n",
      "Epoch number: 388/10000step_number: 0/29 cost:  1.0998848004642172 accuracy:  0.8035957504767094\n",
      "Epoch number: 389/10000step_number: 0/29 cost:  1.0975310989644598 accuracy:  0.8040043584854263\n",
      "Epoch number: 390/10000step_number: 0/29 cost:  1.095211509486669 accuracy:  0.803868155815854\n",
      "Epoch number: 391/10000step_number: 0/29 cost:  1.092917416360206 accuracy:  0.8044129664941433\n",
      "Epoch number: 392/10000step_number: 0/29 cost:  1.090651681085376 accuracy:  0.8050939798420049\n",
      "Epoch number: 393/10000step_number: 0/29 cost:  1.0884162027235027 accuracy:  0.8052301825115772\n",
      "Epoch number: 394/10000step_number: 0/29 cost:  1.0862108785605769 accuracy:  0.8060473985290112\n",
      "Epoch number: 395/10000step_number: 0/29 cost:  1.0840337175714247 accuracy:  0.8065922092073005\n",
      "Epoch number: 396/10000step_number: 0/29 cost:  1.0818809353036045 accuracy:  0.808090438572596\n",
      "Epoch number: 397/10000step_number: 0/29 cost:  1.07975414290706 accuracy:  0.8083628439117406\n",
      "Epoch number: 398/10000step_number: 0/29 cost:  1.0776962374041612 accuracy:  0.8091800599291746\n",
      "Epoch number: 399/10000step_number: 0/29 cost:  1.0757499648036646 accuracy:  0.8099972759466085\n",
      "Epoch number: 400/10000step_number: 0/29 cost:  1.0737461996364364 accuracy:  0.8097248706074639\n",
      "Epoch number: 401/10000step_number: 0/29 cost:  1.0717043095475285 accuracy:  0.8102696812857532\n",
      "Epoch number: 402/10000step_number: 0/29 cost:  1.0696326319178229 accuracy:  0.8104058839553255\n",
      "Epoch number: 403/10000step_number: 0/29 cost:  1.0675667054303535 accuracy:  0.8105420866248978\n",
      "Epoch number: 404/10000step_number: 0/29 cost:  1.0655169083668696 accuracy:  0.8104058839553255\n",
      "Epoch number: 405/10000step_number: 0/29 cost:  1.0634826290138235 accuracy:  0.8106782892944702\n",
      "Epoch number: 406/10000step_number: 0/29 cost:  1.0614616723721646 accuracy:  0.8110868973031872\n",
      "Epoch number: 407/10000step_number: 0/29 cost:  1.0594533265698516 accuracy:  0.8119041133206211\n",
      "Epoch number: 408/10000step_number: 0/29 cost:  1.057458095308678 accuracy:  0.8121765186597657\n",
      "Epoch number: 409/10000step_number: 0/29 cost:  1.0554774815080734 accuracy:  0.8127213293380551\n",
      "Epoch number: 410/10000step_number: 0/29 cost:  1.0535128925928081 accuracy:  0.8119041133206211\n",
      "Epoch number: 411/10000step_number: 0/29 cost:  1.05156480784718 accuracy:  0.8123127213293381\n",
      "Epoch number: 412/10000step_number: 0/29 cost:  1.0496324318038435 accuracy:  0.8125851266684827\n",
      "Epoch number: 413/10000step_number: 0/29 cost:  1.047714172481837 accuracy:  0.8129937346771997\n",
      "Epoch number: 414/10000step_number: 0/29 cost:  1.045808215198801 accuracy:  0.8132661400163443\n",
      "Epoch number: 415/10000step_number: 0/29 cost:  1.0439129982114739 accuracy:  0.813538545355489\n",
      "Epoch number: 416/10000step_number: 0/29 cost:  1.0420273458596605 accuracy:  0.813538545355489\n",
      "Epoch number: 417/10000step_number: 0/29 cost:  1.040150444539577 accuracy:  0.8142195587033506\n",
      "Epoch number: 418/10000step_number: 0/29 cost:  1.0382816409896483 accuracy:  0.8142195587033506\n",
      "Epoch number: 419/10000step_number: 0/29 cost:  1.0364202568561989 accuracy:  0.8142195587033506\n",
      "Epoch number: 420/10000step_number: 0/29 cost:  1.0345654260626935 accuracy:  0.8150367747207845\n",
      "Epoch number: 421/10000step_number: 0/29 cost:  1.0327160571150666 accuracy:  0.8149005720512122\n",
      "Epoch number: 422/10000step_number: 0/29 cost:  1.030870852223655 accuracy:  0.8155815853990738\n",
      "Epoch number: 423/10000step_number: 0/29 cost:  1.0290283586272015 accuracy:  0.8157177880686461\n",
      "Epoch number: 424/10000step_number: 0/29 cost:  1.0271869785330663 accuracy:  0.8159901934077908\n",
      "Epoch number: 425/10000step_number: 0/29 cost:  1.0253449834427777 accuracy:  0.81653500408608\n",
      "Epoch number: 426/10000step_number: 0/29 cost:  1.0235006127715676 accuracy:  0.8168074094252248\n",
      "Epoch number: 427/10000step_number: 0/29 cost:  1.0216522315113477 accuracy:  0.8168074094252248\n",
      "Epoch number: 428/10000step_number: 0/29 cost:  1.0197974269223178 accuracy:  0.816943612094797\n",
      "Epoch number: 429/10000step_number: 0/29 cost:  1.0179301086064758 accuracy:  0.8172160174339417\n",
      "Epoch number: 430/10000step_number: 0/29 cost:  1.0160438029023402 accuracy:  0.8172160174339417\n",
      "Epoch number: 431/10000step_number: 0/29 cost:  1.0141349034656137 accuracy:  0.817760828112231\n",
      "Epoch number: 432/10000step_number: 0/29 cost:  1.0122131231508398 accuracy:  0.818169436120948\n",
      "Epoch number: 433/10000step_number: 0/29 cost:  1.0102941892489155 accuracy:  0.8183056387905203\n",
      "Epoch number: 434/10000step_number: 0/29 cost:  1.0083805276250406 accuracy:  0.8184418414600926\n",
      "Epoch number: 435/10000step_number: 0/29 cost:  1.006468835987745 accuracy:  0.8183056387905203\n",
      "Epoch number: 436/10000step_number: 0/29 cost:  1.004558269050035 accuracy:  0.8184418414600926\n",
      "Epoch number: 437/10000step_number: 0/29 cost:  1.002653056044606 accuracy:  0.818578044129665\n",
      "Epoch number: 438/10000step_number: 0/29 cost:  1.0007592656043536 accuracy:  0.8184418414600926\n",
      "Epoch number: 439/10000step_number: 0/29 cost:  0.9988792643912128 accuracy:  0.8191228548079542\n",
      "Epoch number: 440/10000step_number: 0/29 cost:  0.9970108951425857 accuracy:  0.8193952601470988\n",
      "Epoch number: 441/10000step_number: 0/29 cost:  0.9951496924766328 accuracy:  0.8196676654862435\n",
      "Epoch number: 442/10000step_number: 0/29 cost:  0.9932912267240733 accuracy:  0.8199400708253882\n",
      "Epoch number: 443/10000step_number: 0/29 cost:  0.9914323156668323 accuracy:  0.8203486788341051\n",
      "Epoch number: 444/10000step_number: 0/29 cost:  0.9895711199557273 accuracy:  0.8203486788341051\n",
      "Epoch number: 445/10000step_number: 0/29 cost:  0.9877067883043283 accuracy:  0.8242985562517026\n",
      "Epoch number: 446/10000step_number: 0/29 cost:  0.985839065807067 accuracy:  0.8242985562517026\n",
      "Epoch number: 447/10000step_number: 0/29 cost:  0.9839680160986559 accuracy:  0.8244347589212748\n",
      "Epoch number: 448/10000step_number: 0/29 cost:  0.9820938519608242 accuracy:  0.8253881776082811\n",
      "Epoch number: 449/10000step_number: 0/29 cost:  0.9802168302586236 accuracy:  0.8255243802778535\n",
      "Epoch number: 450/10000step_number: 0/29 cost:  0.978337177632054 accuracy:  0.8256605829474257\n",
      "Epoch number: 451/10000step_number: 0/29 cost:  0.976455031606347 accuracy:  0.8256605829474257\n",
      "Epoch number: 452/10000step_number: 0/29 cost:  0.9745703926039362 accuracy:  0.826614001634432\n",
      "Epoch number: 453/10000step_number: 0/29 cost:  0.9726830895006049 accuracy:  0.826614001634432\n",
      "Epoch number: 454/10000step_number: 0/29 cost:  0.9707927754576283 accuracy:  0.827022609643149\n",
      "Epoch number: 455/10000step_number: 0/29 cost:  0.9688990260348528 accuracy:  0.8277036229910106\n",
      "Epoch number: 456/10000step_number: 0/29 cost:  0.9670018583119964 accuracy:  0.8279760283301553\n",
      "Epoch number: 457/10000step_number: 0/29 cost:  0.9651041061479778 accuracy:  0.8282484336692999\n",
      "Epoch number: 458/10000step_number: 0/29 cost:  0.9632211730264971 accuracy:  0.8302914737128848\n",
      "Epoch number: 459/10000step_number: 0/29 cost:  0.961401911421259 accuracy:  0.8298828657041678\n",
      "Epoch number: 460/10000step_number: 0/29 cost:  0.9596746922535913 accuracy:  0.8298828657041678\n",
      "Epoch number: 461/10000step_number: 0/29 cost:  0.957950017722123 accuracy:  0.8301552710433124\n",
      "Epoch number: 462/10000step_number: 0/29 cost:  0.9561848042369873 accuracy:  0.8302914737128848\n",
      "Epoch number: 463/10000step_number: 0/29 cost:  0.9543849170389938 accuracy:  0.8302914737128848\n",
      "Epoch number: 464/10000step_number: 0/29 cost:  0.9525583623988094 accuracy:  0.8301552710433124\n",
      "Epoch number: 465/10000step_number: 0/29 cost:  0.9507176746127034 accuracy:  0.8302914737128848\n",
      "Epoch number: 466/10000step_number: 0/29 cost:  0.9488651312503066 accuracy:  0.8307000817216017\n",
      "Epoch number: 467/10000step_number: 0/29 cost:  0.946998802888091 accuracy:  0.8305638790520294\n",
      "Epoch number: 468/10000step_number: 0/29 cost:  0.9451179960996166 accuracy:  0.8304276763824571\n",
      "Epoch number: 469/10000step_number: 0/29 cost:  0.943223841123063 accuracy:  0.8305638790520294\n",
      "Epoch number: 470/10000step_number: 0/29 cost:  0.9413207063748209 accuracy:  0.8308362843911741\n",
      "Epoch number: 471/10000step_number: 0/29 cost:  0.9394107511391214 accuracy:  0.8307000817216017\n",
      "Epoch number: 472/10000step_number: 0/29 cost:  0.9374946713914105 accuracy:  0.8305638790520294\n",
      "Epoch number: 473/10000step_number: 0/29 cost:  0.9355685221597564 accuracy:  0.8305638790520294\n",
      "Epoch number: 474/10000step_number: 0/29 cost:  0.9336287053532867 accuracy:  0.8311086897303187\n",
      "Epoch number: 475/10000step_number: 0/29 cost:  0.9316719888834649 accuracy:  0.8311086897303187\n",
      "Epoch number: 476/10000step_number: 0/29 cost:  0.9297017785132314 accuracy:  0.8309724870607464\n",
      "Epoch number: 477/10000step_number: 0/29 cost:  0.9277230211967386 accuracy:  0.8311086897303187\n",
      "Epoch number: 478/10000step_number: 0/29 cost:  0.9257408910013057 accuracy:  0.831653500408608\n",
      "Epoch number: 479/10000step_number: 0/29 cost:  0.923758142128664 accuracy:  0.8315172977390357\n",
      "Epoch number: 480/10000step_number: 0/29 cost:  0.9217769900427211 accuracy:  0.8319259057477526\n",
      "Epoch number: 481/10000step_number: 0/29 cost:  0.9197979351465009 accuracy:  0.8321983110868973\n",
      "Epoch number: 482/10000step_number: 0/29 cost:  0.9178216547783395 accuracy:  0.8323345137564696\n",
      "Epoch number: 483/10000step_number: 0/29 cost:  0.9158480390270237 accuracy:  0.832470716426042\n",
      "Epoch number: 484/10000step_number: 0/29 cost:  0.9138775733863616 accuracy:  0.8328793244347589\n",
      "Epoch number: 485/10000step_number: 0/29 cost:  0.9119104288920147 accuracy:  0.8328793244347589\n",
      "Epoch number: 486/10000step_number: 0/29 cost:  0.909947549584485 accuracy:  0.8331517297739036\n",
      "Epoch number: 487/10000step_number: 0/29 cost:  0.9079898604766513 accuracy:  0.8332879324434759\n",
      "Epoch number: 488/10000step_number: 0/29 cost:  0.906039142286915 accuracy:  0.8331517297739036\n",
      "Epoch number: 489/10000step_number: 0/29 cost:  0.9040972900724333 accuracy:  0.8327431217651866\n",
      "Epoch number: 490/10000step_number: 0/29 cost:  0.9021669310163202 accuracy:  0.8326069190956142\n",
      "Epoch number: 491/10000step_number: 0/29 cost:  0.9002506469083289 accuracy:  0.8330155271043312\n",
      "Epoch number: 492/10000step_number: 0/29 cost:  0.8983513366946907 accuracy:  0.8332879324434759\n",
      "Epoch number: 493/10000step_number: 0/29 cost:  0.8964714499276911 accuracy:  0.8331517297739036\n",
      "Epoch number: 494/10000step_number: 0/29 cost:  0.8946132239952835 accuracy:  0.8328793244347589\n",
      "Epoch number: 495/10000step_number: 0/29 cost:  0.8927780433931805 accuracy:  0.8328793244347589\n",
      "Epoch number: 496/10000step_number: 0/29 cost:  0.8909666390592238 accuracy:  0.8330155271043312\n",
      "Epoch number: 497/10000step_number: 0/29 cost:  0.8891786461412644 accuracy:  0.8332879324434759\n",
      "Epoch number: 498/10000step_number: 0/29 cost:  0.8874130257141406 accuracy:  0.8331517297739036\n",
      "Epoch number: 499/10000step_number: 0/29 cost:  0.8856681681926306 accuracy:  0.8334241351130482\n",
      "Epoch number: 500/10000step_number: 0/29 cost:  0.8839424413333083 accuracy:  0.8334241351130482\n",
      "Epoch number: 501/10000step_number: 0/29 cost:  0.8822339486729628 accuracy:  0.8335603377826205\n",
      "Epoch number: 502/10000step_number: 0/29 cost:  0.8805404087153732 accuracy:  0.8336965404521929\n",
      "Epoch number: 503/10000step_number: 0/29 cost:  0.8788585671671693 accuracy:  0.8339689457913375\n",
      "Epoch number: 504/10000step_number: 0/29 cost:  0.8771835412571937 accuracy:  0.8342413511304821\n",
      "Epoch number: 505/10000step_number: 0/29 cost:  0.8755065554273265 accuracy:  0.8349223644783438\n",
      "Epoch number: 506/10000step_number: 0/29 cost:  0.8738078132636681 accuracy:  0.8353309724870608\n",
      "Epoch number: 507/10000step_number: 0/29 cost:  0.8720206644107816 accuracy:  0.8351947698174884\n",
      "Epoch number: 508/10000step_number: 0/29 cost:  0.8696925504919852 accuracy:  0.8351947698174884\n",
      "Epoch number: 509/10000step_number: 0/29 cost:  0.8664117558992177 accuracy:  0.8356033778262054\n",
      "Epoch number: 510/10000step_number: 0/29 cost:  0.864474082349984 accuracy:  0.8351947698174884\n",
      "Epoch number: 511/10000step_number: 0/29 cost:  0.8627741818821733 accuracy:  0.835467175156633\n",
      "Epoch number: 512/10000step_number: 0/29 cost:  0.8609937810158976 accuracy:  0.8353309724870608\n",
      "Epoch number: 513/10000step_number: 0/29 cost:  0.8592772748214818 accuracy:  0.835467175156633\n",
      "Epoch number: 514/10000step_number: 0/29 cost:  0.85755967690404 accuracy:  0.8356033778262054\n",
      "Epoch number: 515/10000step_number: 0/29 cost:  0.8558636658266814 accuracy:  0.835467175156633\n",
      "Epoch number: 516/10000step_number: 0/29 cost:  0.8541789340390699 accuracy:  0.835467175156633\n",
      "Epoch number: 517/10000step_number: 0/29 cost:  0.8525088540732848 accuracy:  0.8356033778262054\n",
      "Epoch number: 518/10000step_number: 0/29 cost:  0.850853376853107 accuracy:  0.8356033778262054\n",
      "Epoch number: 519/10000step_number: 0/29 cost:  0.8492124535134681 accuracy:  0.8356033778262054\n",
      "Epoch number: 520/10000step_number: 0/29 cost:  0.847587158821075 accuracy:  0.8356033778262054\n",
      "Epoch number: 521/10000step_number: 0/29 cost:  0.8460032111099631 accuracy:  0.8356033778262054\n",
      "Epoch number: 522/10000step_number: 0/29 cost:  0.8444537734083409 accuracy:  0.8356033778262054\n",
      "Epoch number: 523/10000step_number: 0/29 cost:  0.8429207892574553 accuracy:  0.83587578316535\n",
      "Epoch number: 524/10000step_number: 0/29 cost:  0.8413977406680271 accuracy:  0.836284391174067\n",
      "Epoch number: 525/10000step_number: 0/29 cost:  0.839884779382744 accuracy:  0.8364205938436393\n",
      "Epoch number: 526/10000step_number: 0/29 cost:  0.8383813034180505 accuracy:  0.8368292018523563\n",
      "Epoch number: 527/10000step_number: 0/29 cost:  0.8368863510297785 accuracy:  0.837510215200218\n",
      "Epoch number: 528/10000step_number: 0/29 cost:  0.8353991659938756 accuracy:  0.8376464178697902\n",
      "Epoch number: 529/10000step_number: 0/29 cost:  0.8339190927804762 accuracy:  0.8380550258785072\n",
      "Epoch number: 530/10000step_number: 0/29 cost:  0.8324455194841992 accuracy:  0.8381912285480796\n",
      "Epoch number: 531/10000step_number: 0/29 cost:  0.830977811688178 accuracy:  0.8384636338872242\n",
      "Epoch number: 532/10000step_number: 0/29 cost:  0.8295152917436367 accuracy:  0.8394170525742305\n",
      "Epoch number: 533/10000step_number: 0/29 cost:  0.8280572311419158 accuracy:  0.8396894579133751\n",
      "Epoch number: 534/10000step_number: 0/29 cost:  0.8266028468190711 accuracy:  0.8399618632525198\n",
      "Epoch number: 535/10000step_number: 0/29 cost:  0.8251512945328251 accuracy:  0.8406428766003814\n",
      "Epoch number: 536/10000step_number: 0/29 cost:  0.8237016565633791 accuracy:  0.840915281939526\n",
      "Epoch number: 537/10000step_number: 0/29 cost:  0.8222529227395136 accuracy:  0.8407790792699537\n",
      "Epoch number: 538/10000step_number: 0/29 cost:  0.8208039630355133 accuracy:  0.8407790792699537\n",
      "Epoch number: 539/10000step_number: 0/29 cost:  0.8193534859843976 accuracy:  0.8414600926178153\n",
      "Epoch number: 540/10000step_number: 0/29 cost:  0.8178999678445834 accuracy:  0.841323889948243\n",
      "Epoch number: 541/10000step_number: 0/29 cost:  0.8164415153779516 accuracy:  0.8418687006265323\n",
      "Epoch number: 542/10000step_number: 0/29 cost:  0.8149756144781818 accuracy:  0.8420049032961046\n",
      "Epoch number: 543/10000step_number: 0/29 cost:  0.8134992403190111 accuracy:  0.8425497139743939\n",
      "Epoch number: 544/10000step_number: 0/29 cost:  0.8120115846993867 accuracy:  0.8424135113048216\n",
      "Epoch number: 545/10000step_number: 0/29 cost:  0.8105150667344261 accuracy:  0.8425497139743939\n",
      "Epoch number: 546/10000step_number: 0/29 cost:  0.8090094369462818 accuracy:  0.8429583219831108\n",
      "Epoch number: 547/10000step_number: 0/29 cost:  0.8074934761384939 accuracy:  0.8433669299918278\n",
      "Epoch number: 548/10000step_number: 0/29 cost:  0.8059677263551728 accuracy:  0.8433669299918278\n",
      "Epoch number: 549/10000step_number: 0/29 cost:  0.8044352259506248 accuracy:  0.8432307273222556\n",
      "Epoch number: 550/10000step_number: 0/29 cost:  0.8029014029954338 accuracy:  0.8433669299918278\n",
      "Epoch number: 551/10000step_number: 0/29 cost:  0.8013725134275528 accuracy:  0.8435031326614002\n",
      "Epoch number: 552/10000step_number: 0/29 cost:  0.7998532696989546 accuracy:  0.8439117406701171\n",
      "Epoch number: 553/10000step_number: 0/29 cost:  0.798345284088673 accuracy:  0.8439117406701171\n",
      "Epoch number: 554/10000step_number: 0/29 cost:  0.7968472129614117 accuracy:  0.8436393353309725\n",
      "Epoch number: 555/10000step_number: 0/29 cost:  0.7953564492151751 accuracy:  0.8439117406701171\n",
      "Epoch number: 556/10000step_number: 0/29 cost:  0.7938721646650392 accuracy:  0.8440479433396895\n",
      "Epoch number: 557/10000step_number: 0/29 cost:  0.7923990093662375 accuracy:  0.8441841460092617\n",
      "Epoch number: 558/10000step_number: 0/29 cost:  0.7909439740917162 accuracy:  0.8443203486788341\n",
      "Epoch number: 559/10000step_number: 0/29 cost:  0.7895048273208835 accuracy:  0.8444565513484065\n",
      "Epoch number: 560/10000step_number: 0/29 cost:  0.7880724183450807 accuracy:  0.8445927540179787\n",
      "Epoch number: 561/10000step_number: 0/29 cost:  0.786641270619954 accuracy:  0.8450013620266957\n",
      "Epoch number: 562/10000step_number: 0/29 cost:  0.7852102973197539 accuracy:  0.845137564696268\n",
      "Epoch number: 563/10000step_number: 0/29 cost:  0.7837800609765101 accuracy:  0.845137564696268\n",
      "Epoch number: 564/10000step_number: 0/29 cost:  0.7823513787626435 accuracy:  0.8450013620266957\n",
      "Epoch number: 565/10000step_number: 0/29 cost:  0.7809248353722146 accuracy:  0.8452737673658404\n",
      "Epoch number: 566/10000step_number: 0/29 cost:  0.7795006921766239 accuracy:  0.8454099700354127\n",
      "Epoch number: 567/10000step_number: 0/29 cost:  0.7780789782549656 accuracy:  0.845954780713702\n",
      "Epoch number: 568/10000step_number: 0/29 cost:  0.7766596240411436 accuracy:  0.845954780713702\n",
      "Epoch number: 569/10000step_number: 0/29 cost:  0.7752425422644833 accuracy:  0.845954780713702\n",
      "Epoch number: 570/10000step_number: 0/29 cost:  0.7738276491036228 accuracy:  0.846363388722419\n",
      "Epoch number: 571/10000step_number: 0/29 cost:  0.7724148553897674 accuracy:  0.8467719967311359\n",
      "Epoch number: 572/10000step_number: 0/29 cost:  0.7710040503163623 accuracy:  0.8474530100789975\n",
      "Epoch number: 573/10000step_number: 0/29 cost:  0.7695950866254441 accuracy:  0.8474530100789975\n",
      "Epoch number: 574/10000step_number: 0/29 cost:  0.7681877698029725 accuracy:  0.8475892127485699\n",
      "Epoch number: 575/10000step_number: 0/29 cost:  0.7667818524097402 accuracy:  0.8477254154181422\n",
      "Epoch number: 576/10000step_number: 0/29 cost:  0.7653770345682677 accuracy:  0.8477254154181422\n",
      "Epoch number: 577/10000step_number: 0/29 cost:  0.763972971217461 accuracy:  0.8478616180877145\n",
      "Epoch number: 578/10000step_number: 0/29 cost:  0.7625692857818465 accuracy:  0.8475892127485699\n",
      "Epoch number: 579/10000step_number: 0/29 cost:  0.761165588636571 accuracy:  0.8478616180877145\n",
      "Epoch number: 580/10000step_number: 0/29 cost:  0.7597614976109583 accuracy:  0.8479978207572868\n",
      "Epoch number: 581/10000step_number: 0/29 cost:  0.7583566572120768 accuracy:  0.8479978207572868\n",
      "Epoch number: 582/10000step_number: 0/29 cost:  0.7569507535773518 accuracy:  0.8485426314355762\n",
      "Epoch number: 583/10000step_number: 0/29 cost:  0.7555435233620863 accuracy:  0.8485426314355762\n",
      "Epoch number: 584/10000step_number: 0/29 cost:  0.7541347564020521 accuracy:  0.8482702260964315\n",
      "Epoch number: 585/10000step_number: 0/29 cost:  0.752724293404322 accuracy:  0.8479978207572868\n",
      "Epoch number: 586/10000step_number: 0/29 cost:  0.7513120206055064 accuracy:  0.8481340234268592\n",
      "Epoch number: 587/10000step_number: 0/29 cost:  0.7498978632216095 accuracy:  0.8485426314355762\n",
      "Epoch number: 588/10000step_number: 0/29 cost:  0.7484817789113059 accuracy:  0.8486788341051484\n",
      "Epoch number: 589/10000step_number: 0/29 cost:  0.7470637518047981 accuracy:  0.8485426314355762\n",
      "Epoch number: 590/10000step_number: 0/29 cost:  0.7456437871878538 accuracy:  0.8488150367747208\n",
      "Epoch number: 591/10000step_number: 0/29 cost:  0.7442219067367116 accuracy:  0.8488150367747208\n",
      "Epoch number: 592/10000step_number: 0/29 cost:  0.7427981442003968 accuracy:  0.8488150367747208\n",
      "Epoch number: 593/10000step_number: 0/29 cost:  0.7413725415165325 accuracy:  0.8488150367747208\n",
      "Epoch number: 594/10000step_number: 0/29 cost:  0.7399451454452204 accuracy:  0.8486788341051484\n",
      "Epoch number: 595/10000step_number: 0/29 cost:  0.7385160048706805 accuracy:  0.8489512394442931\n",
      "Epoch number: 596/10000step_number: 0/29 cost:  0.7370851689362311 accuracy:  0.8496322527921547\n",
      "Epoch number: 597/10000step_number: 0/29 cost:  0.7356526861432586 accuracy:  0.8496322527921547\n",
      "Epoch number: 598/10000step_number: 0/29 cost:  0.7342186044684786 accuracy:  0.8497684554617271\n",
      "Epoch number: 599/10000step_number: 0/29 cost:  0.7327829724693522 accuracy:  0.8497684554617271\n",
      "Epoch number: 600/10000step_number: 0/29 cost:  0.7313458413497547 accuracy:  0.8499046581312993\n",
      "Epoch number: 601/10000step_number: 0/29 cost:  0.7299072682662051 accuracy:  0.8500408608008717\n",
      "Epoch number: 602/10000step_number: 0/29 cost:  0.7284673221355579 accuracy:  0.850177063470444\n",
      "Epoch number: 603/10000step_number: 0/29 cost:  0.7270260950342103 accuracy:  0.8499046581312993\n",
      "Epoch number: 604/10000step_number: 0/29 cost:  0.7255837234404373 accuracy:  0.8499046581312993\n",
      "Epoch number: 605/10000step_number: 0/29 cost:  0.724140418386909 accuracy:  0.8499046581312993\n",
      "Epoch number: 606/10000step_number: 0/29 cost:  0.7226964872968334 accuracy:  0.8494960501225824\n",
      "Epoch number: 607/10000step_number: 0/29 cost:  0.7212523225043954 accuracy:  0.8494960501225824\n",
      "Epoch number: 608/10000step_number: 0/29 cost:  0.7198083654619775 accuracy:  0.8496322527921547\n",
      "Epoch number: 609/10000step_number: 0/29 cost:  0.7183650890450486 accuracy:  0.8496322527921547\n",
      "Epoch number: 610/10000step_number: 0/29 cost:  0.7169230067776237 accuracy:  0.8499046581312993\n",
      "Epoch number: 611/10000step_number: 0/29 cost:  0.715482678552507 accuracy:  0.8496322527921547\n",
      "Epoch number: 612/10000step_number: 0/29 cost:  0.7140446964211599 accuracy:  0.8494960501225824\n",
      "Epoch number: 613/10000step_number: 0/29 cost:  0.7126096581451201 accuracy:  0.8494960501225824\n",
      "Epoch number: 614/10000step_number: 0/29 cost:  0.7111781399377847 accuracy:  0.8494960501225824\n",
      "Epoch number: 615/10000step_number: 0/29 cost:  0.7097506745562426 accuracy:  0.8494960501225824\n",
      "Epoch number: 616/10000step_number: 0/29 cost:  0.7083277373621795 accuracy:  0.8493598474530101\n",
      "Epoch number: 617/10000step_number: 0/29 cost:  0.7069097418269592 accuracy:  0.8493598474530101\n",
      "Epoch number: 618/10000step_number: 0/29 cost:  0.7054970453728728 accuracy:  0.8494960501225824\n",
      "Epoch number: 619/10000step_number: 0/29 cost:  0.7040899653289665 accuracy:  0.8494960501225824\n",
      "Epoch number: 620/10000step_number: 0/29 cost:  0.7026888022720712 accuracy:  0.8496322527921547\n",
      "Epoch number: 621/10000step_number: 0/29 cost:  0.7012938621561825 accuracy:  0.850177063470444\n",
      "Epoch number: 622/10000step_number: 0/29 cost:  0.6999054547360762 accuracy:  0.8497684554617271\n",
      "Epoch number: 623/10000step_number: 0/29 cost:  0.6985238153277076 accuracy:  0.8499046581312993\n",
      "Epoch number: 624/10000step_number: 0/29 cost:  0.6971488438115407 accuracy:  0.8499046581312993\n",
      "Epoch number: 625/10000step_number: 0/29 cost:  0.6957795173318447 accuracy:  0.850177063470444\n",
      "Epoch number: 626/10000step_number: 0/29 cost:  0.694413013149997 accuracy:  0.8504494688095887\n",
      "Epoch number: 627/10000step_number: 0/29 cost:  0.6930443195154642 accuracy:  0.8503132661400163\n",
      "Epoch number: 628/10000step_number: 0/29 cost:  0.6916677781083842 accuracy:  0.8504494688095887\n",
      "Epoch number: 629/10000step_number: 0/29 cost:  0.6902801108622788 accuracy:  0.850177063470444\n",
      "Epoch number: 630/10000step_number: 0/29 cost:  0.6888819488834758 accuracy:  0.850177063470444\n",
      "Epoch number: 631/10000step_number: 0/29 cost:  0.6874775026845807 accuracy:  0.8508580768183056\n",
      "Epoch number: 632/10000step_number: 0/29 cost:  0.686073642459784 accuracy:  0.8508580768183056\n",
      "Epoch number: 633/10000step_number: 0/29 cost:  0.6846688348815184 accuracy:  0.850585671479161\n",
      "Epoch number: 634/10000step_number: 0/29 cost:  0.6832561349994829 accuracy:  0.850585671479161\n",
      "Epoch number: 635/10000step_number: 0/29 cost:  0.6818382069335512 accuracy:  0.850585671479161\n",
      "Epoch number: 636/10000step_number: 0/29 cost:  0.6804174677715412 accuracy:  0.8508580768183056\n",
      "Epoch number: 637/10000step_number: 0/29 cost:  0.6789952446781365 accuracy:  0.850994279487878\n",
      "Epoch number: 638/10000step_number: 0/29 cost:  0.6775730269320984 accuracy:  0.850994279487878\n",
      "Epoch number: 639/10000step_number: 0/29 cost:  0.6761525146040233 accuracy:  0.851402887496595\n",
      "Epoch number: 640/10000step_number: 0/29 cost:  0.6747352304328934 accuracy:  0.8516752928357396\n",
      "Epoch number: 641/10000step_number: 0/29 cost:  0.6733221775944119 accuracy:  0.8518114955053119\n",
      "Epoch number: 642/10000step_number: 0/29 cost:  0.6719137330203445 accuracy:  0.8518114955053119\n",
      "Epoch number: 643/10000step_number: 0/29 cost:  0.6705098208966606 accuracy:  0.8518114955053119\n",
      "Epoch number: 644/10000step_number: 0/29 cost:  0.6691102340783707 accuracy:  0.8522201035140289\n",
      "Epoch number: 645/10000step_number: 0/29 cost:  0.6677149402720436 accuracy:  0.8520839008444565\n",
      "Epoch number: 646/10000step_number: 0/29 cost:  0.6663242939581501 accuracy:  0.8522201035140289\n",
      "Epoch number: 647/10000step_number: 0/29 cost:  0.6649391477386338 accuracy:  0.8523563061836013\n",
      "Epoch number: 648/10000step_number: 0/29 cost:  0.6635608586516679 accuracy:  0.8524925088531735\n",
      "Epoch number: 649/10000step_number: 0/29 cost:  0.6621911426551458 accuracy:  0.8524925088531735\n",
      "Epoch number: 650/10000step_number: 0/29 cost:  0.6608317227080326 accuracy:  0.8527649141923181\n",
      "Epoch number: 651/10000step_number: 0/29 cost:  0.6594838274625694 accuracy:  0.8529011168618905\n",
      "Epoch number: 652/10000step_number: 0/29 cost:  0.6581477969349446 accuracy:  0.8530373195314628\n",
      "Epoch number: 653/10000step_number: 0/29 cost:  0.6568230947022623 accuracy:  0.8531735222010352\n",
      "Epoch number: 654/10000step_number: 0/29 cost:  0.6555087371002656 accuracy:  0.8531735222010352\n",
      "Epoch number: 655/10000step_number: 0/29 cost:  0.6542038218199827 accuracy:  0.8530373195314628\n",
      "Epoch number: 656/10000step_number: 0/29 cost:  0.6529078614881473 accuracy:  0.8531735222010352\n",
      "Epoch number: 657/10000step_number: 0/29 cost:  0.6516208735674256 accuracy:  0.8531735222010352\n",
      "Epoch number: 658/10000step_number: 0/29 cost:  0.650343317668195 accuracy:  0.8529011168618905\n",
      "Epoch number: 659/10000step_number: 0/29 cost:  0.649075966748219 accuracy:  0.8531735222010352\n",
      "Epoch number: 660/10000step_number: 0/29 cost:  0.6478197625056421 accuracy:  0.8533097248706074\n",
      "Epoch number: 661/10000step_number: 0/29 cost:  0.6465756842973334 accuracy:  0.8530373195314628\n",
      "Epoch number: 662/10000step_number: 0/29 cost:  0.6453446482326278 accuracy:  0.8534459275401798\n",
      "Epoch number: 663/10000step_number: 0/29 cost:  0.6441274417923495 accuracy:  0.8531735222010352\n",
      "Epoch number: 664/10000step_number: 0/29 cost:  0.6429246905747548 accuracy:  0.8535821302097522\n",
      "Epoch number: 665/10000step_number: 0/29 cost:  0.6417368493384704 accuracy:  0.8537183328793244\n",
      "Epoch number: 666/10000step_number: 0/29 cost:  0.6405642088876832 accuracy:  0.8537183328793244\n",
      "Epoch number: 667/10000step_number: 0/29 cost:  0.6394069118279972 accuracy:  0.8538545355488968\n",
      "Epoch number: 668/10000step_number: 0/29 cost:  0.6382649723066743 accuracy:  0.853990738218469\n",
      "Epoch number: 669/10000step_number: 0/29 cost:  0.6371382967123156 accuracy:  0.854399346227186\n",
      "Epoch number: 670/10000step_number: 0/29 cost:  0.6360267036748851 accuracy:  0.8542631435576137\n",
      "Epoch number: 671/10000step_number: 0/29 cost:  0.6349299425836404 accuracy:  0.8546717515663307\n",
      "Epoch number: 672/10000step_number: 0/29 cost:  0.6338477103130808 accuracy:  0.8546717515663307\n",
      "Epoch number: 673/10000step_number: 0/29 cost:  0.6327796660123974 accuracy:  0.8553527649141923\n",
      "Epoch number: 674/10000step_number: 0/29 cost:  0.6317254438155585 accuracy:  0.8557613729229093\n",
      "Epoch number: 675/10000step_number: 0/29 cost:  0.6306846633899398 accuracy:  0.8580768183056388\n",
      "Epoch number: 676/10000step_number: 0/29 cost:  0.6296569385515525 accuracy:  0.8580768183056388\n",
      "Epoch number: 677/10000step_number: 0/29 cost:  0.6286418846377931 accuracy:  0.8582130209752111\n",
      "Epoch number: 678/10000step_number: 0/29 cost:  0.627639125483375 accuracy:  0.8583492236447834\n",
      "Epoch number: 679/10000step_number: 0/29 cost:  0.62664830029823 accuracy:  0.8584854263143558\n",
      "Epoch number: 680/10000step_number: 0/29 cost:  0.6256690697632916 accuracy:  0.8586216289839281\n",
      "Epoch number: 681/10000step_number: 0/29 cost:  0.6247011200468803 accuracy:  0.8588940343230728\n",
      "Epoch number: 682/10000step_number: 0/29 cost:  0.6237441636903388 accuracy:  0.859030236992645\n",
      "Epoch number: 683/10000step_number: 0/29 cost:  0.622797937126102 accuracy:  0.859030236992645\n",
      "Epoch number: 684/10000step_number: 0/29 cost:  0.6218621953849881 accuracy:  0.859030236992645\n",
      "Epoch number: 685/10000step_number: 0/29 cost:  0.6209367050518054 accuracy:  0.8593026423317897\n",
      "Epoch number: 686/10000step_number: 0/29 cost:  0.6200212368087431 accuracy:  0.8591664396622174\n",
      "Epoch number: 687/10000step_number: 0/29 cost:  0.6191155590288606 accuracy:  0.8588940343230728\n",
      "Epoch number: 688/10000step_number: 0/29 cost:  0.6182194337135956 accuracy:  0.8593026423317897\n",
      "Epoch number: 689/10000step_number: 0/29 cost:  0.6173326154130007 accuracy:  0.859438845001362\n",
      "Epoch number: 690/10000step_number: 0/29 cost:  0.6164548526884746 accuracy:  0.8599836556796513\n",
      "Epoch number: 691/10000step_number: 0/29 cost:  0.6155858906663317 accuracy:  0.8608008716970853\n",
      "Epoch number: 692/10000step_number: 0/29 cost:  0.6147254729307999 accuracy:  0.8610732770362299\n",
      "Epoch number: 693/10000step_number: 0/29 cost:  0.6138733416485435 accuracy:  0.8613456823753746\n",
      "Epoch number: 694/10000step_number: 0/29 cost:  0.6130292359615509 accuracy:  0.8616180877145192\n",
      "Epoch number: 695/10000step_number: 0/29 cost:  0.6121928895870058 accuracy:  0.8617542903840916\n",
      "Epoch number: 696/10000step_number: 0/29 cost:  0.6113640287787013 accuracy:  0.8617542903840916\n",
      "Epoch number: 697/10000step_number: 0/29 cost:  0.6105423714237991 accuracy:  0.8622991010623808\n",
      "Epoch number: 698/10000step_number: 0/29 cost:  0.6097276274565702 accuracy:  0.8624353037319531\n",
      "Epoch number: 699/10000step_number: 0/29 cost:  0.6089195003041914 accuracy:  0.8625715064015255\n",
      "Epoch number: 700/10000step_number: 0/29 cost:  0.608117688869406 accuracy:  0.8631163170798147\n",
      "Epoch number: 701/10000step_number: 0/29 cost:  0.6073218895648228 accuracy:  0.8631163170798147\n",
      "Epoch number: 702/10000step_number: 0/29 cost:  0.6065317980466322 accuracy:  0.8633887224189594\n",
      "Epoch number: 703/10000step_number: 0/29 cost:  0.6057471104670665 accuracy:  0.8633887224189594\n",
      "Epoch number: 704/10000step_number: 0/29 cost:  0.6049675242247713 accuracy:  0.8633887224189594\n",
      "Epoch number: 705/10000step_number: 0/29 cost:  0.6041927383158738 accuracy:  0.8633887224189594\n",
      "Epoch number: 706/10000step_number: 0/29 cost:  0.6034224534641317 accuracy:  0.8633887224189594\n",
      "Epoch number: 707/10000step_number: 0/29 cost:  0.6026563722315641 accuracy:  0.8637973304276764\n",
      "Epoch number: 708/10000step_number: 0/29 cost:  0.6018941992873392 accuracy:  0.8637973304276764\n",
      "Epoch number: 709/10000step_number: 0/29 cost:  0.6011356419646322 accuracy:  0.8635249250885317\n",
      "Epoch number: 710/10000step_number: 0/29 cost:  0.6003804112021335 accuracy:  0.8639335330972487\n",
      "Epoch number: 711/10000step_number: 0/29 cost:  0.5996282229980451 accuracy:  0.864069735766821\n",
      "Epoch number: 712/10000step_number: 0/29 cost:  0.5988788006429405 accuracy:  0.8643421411059656\n",
      "Epoch number: 713/10000step_number: 0/29 cost:  0.598131878258624 accuracy:  0.8646145464451104\n",
      "Epoch number: 714/10000step_number: 0/29 cost:  0.5973872065060611 accuracy:  0.864886951784255\n",
      "Epoch number: 715/10000step_number: 0/29 cost:  0.596644561570923 accuracy:  0.8650231544538273\n",
      "Epoch number: 716/10000step_number: 0/29 cost:  0.5959037583263135 accuracy:  0.8647507491146826\n",
      "Epoch number: 717/10000step_number: 0/29 cost:  0.5951646673167318 accuracy:  0.864886951784255\n",
      "Epoch number: 718/10000step_number: 0/29 cost:  0.5944272323643074 accuracy:  0.8651593571233996\n",
      "Epoch number: 719/10000step_number: 0/29 cost:  0.593691481653302 accuracy:  0.8654317624625443\n",
      "Epoch number: 720/10000step_number: 0/29 cost:  0.592957522955946 accuracy:  0.8662489784799782\n",
      "Epoch number: 721/10000step_number: 0/29 cost:  0.5922255176680724 accuracy:  0.8665213838191228\n",
      "Epoch number: 722/10000step_number: 0/29 cost:  0.5914956390704288 accuracy:  0.8665213838191228\n",
      "Epoch number: 723/10000step_number: 0/29 cost:  0.5907680296646859 accuracy:  0.8663851811495505\n",
      "Epoch number: 724/10000step_number: 0/29 cost:  0.5900427715025152 accuracy:  0.8669299918278398\n",
      "Epoch number: 725/10000step_number: 0/29 cost:  0.5893198750820968 accuracy:  0.8673385998365568\n",
      "Epoch number: 726/10000step_number: 0/29 cost:  0.5885992870790719 accuracy:  0.8677472078452738\n",
      "Epoch number: 727/10000step_number: 0/29 cost:  0.5878809167057579 accuracy:  0.8680196131844184\n",
      "Epoch number: 728/10000step_number: 0/29 cost:  0.5871646769335626 accuracy:  0.8678834105148461\n",
      "Epoch number: 729/10000step_number: 0/29 cost:  0.586450526373784 accuracy:  0.8684282211931353\n",
      "Epoch number: 730/10000step_number: 0/29 cost:  0.5857384901513137 accuracy:  0.8684282211931353\n",
      "Epoch number: 731/10000step_number: 0/29 cost:  0.5850286478710802 accuracy:  0.8684282211931353\n",
      "Epoch number: 732/10000step_number: 0/29 cost:  0.5843210995593735 accuracy:  0.8689730318714247\n",
      "Epoch number: 733/10000step_number: 0/29 cost:  0.5836159331485165 accuracy:  0.8689730318714247\n",
      "Epoch number: 734/10000step_number: 0/29 cost:  0.5829132087610862 accuracy:  0.869109234540997\n",
      "Epoch number: 735/10000step_number: 0/29 cost:  0.5822129593423165 accuracy:  0.8696540452192864\n",
      "Epoch number: 736/10000step_number: 0/29 cost:  0.5815151992214974 accuracy:  0.8697902478888586\n",
      "Epoch number: 737/10000step_number: 0/29 cost:  0.580819933056655 accuracy:  0.8697902478888586\n",
      "Epoch number: 738/10000step_number: 0/29 cost:  0.5801271614797077 accuracy:  0.8707436665758649\n",
      "Epoch number: 739/10000step_number: 0/29 cost:  0.5794368827721676 accuracy:  0.8708798692454373\n",
      "Epoch number: 740/10000step_number: 0/29 cost:  0.5787490913782685 accuracy:  0.8708798692454373\n",
      "Epoch number: 741/10000step_number: 0/29 cost:  0.5780637745301582 accuracy:  0.8708798692454373\n",
      "Epoch number: 742/10000step_number: 0/29 cost:  0.5773809082447218 accuracy:  0.8711522745845819\n",
      "Epoch number: 743/10000step_number: 0/29 cost:  0.5767004537236964 accuracy:  0.8715608825932988\n",
      "Epoch number: 744/10000step_number: 0/29 cost:  0.5760223548557215 accuracy:  0.8716970852628712\n",
      "Epoch number: 745/10000step_number: 0/29 cost:  0.5753465371421372 accuracy:  0.8716970852628712\n",
      "Epoch number: 746/10000step_number: 0/29 cost:  0.5746729080185953 accuracy:  0.8716970852628712\n",
      "Epoch number: 747/10000step_number: 0/29 cost:  0.5740013582995106 accuracy:  0.8716970852628712\n",
      "Epoch number: 748/10000step_number: 0/29 cost:  0.5733317643862007 accuracy:  0.8722418959411604\n",
      "Epoch number: 749/10000step_number: 0/29 cost:  0.5726639909621634 accuracy:  0.872514301280305\n",
      "Epoch number: 750/10000step_number: 0/29 cost:  0.5719978941325982 accuracy:  0.8726505039498774\n",
      "Epoch number: 751/10000step_number: 0/29 cost:  0.5713333253754349 accuracy:  0.8726505039498774\n",
      "Epoch number: 752/10000step_number: 0/29 cost:  0.5706701374869624 accuracy:  0.872922909289022\n",
      "Epoch number: 753/10000step_number: 0/29 cost:  0.5700081957009513 accuracy:  0.8733315172977391\n",
      "Epoch number: 754/10000step_number: 0/29 cost:  0.5693474015347667 accuracy:  0.8737401253064561\n",
      "Epoch number: 755/10000step_number: 0/29 cost:  0.5686877326226616 accuracy:  0.8737401253064561\n",
      "Epoch number: 756/10000step_number: 0/29 cost:  0.568029187932845 accuracy:  0.8740125306456007\n",
      "Epoch number: 757/10000step_number: 0/29 cost:  0.5673714664352003 accuracy:  0.874148733315173\n",
      "Epoch number: 758/10000step_number: 0/29 cost:  0.5667141975602683 accuracy:  0.8740125306456007\n",
      "Epoch number: 759/10000step_number: 0/29 cost:  0.5660570730639564 accuracy:  0.8742849359847453\n",
      "Epoch number: 760/10000step_number: 0/29 cost:  0.5653998482352603 accuracy:  0.8742849359847453\n",
      "Epoch number: 761/10000step_number: 0/29 cost:  0.5647426017127776 accuracy:  0.8744211386543176\n",
      "Epoch number: 762/10000step_number: 0/29 cost:  0.5640853792543499 accuracy:  0.8742849359847453\n",
      "Epoch number: 763/10000step_number: 0/29 cost:  0.5634281467303017 accuracy:  0.8744211386543176\n",
      "Epoch number: 764/10000step_number: 0/29 cost:  0.5627708645300236 accuracy:  0.8744211386543176\n",
      "Epoch number: 765/10000step_number: 0/29 cost:  0.5621134924181537 accuracy:  0.8746935439934622\n",
      "Epoch number: 766/10000step_number: 0/29 cost:  0.561455986538314 accuracy:  0.8752383546717516\n",
      "Epoch number: 767/10000step_number: 0/29 cost:  0.5607982937762358 accuracy:  0.87455734132389\n",
      "Epoch number: 768/10000step_number: 0/29 cost:  0.5601403460056142 accuracy:  0.874965949332607\n",
      "Epoch number: 769/10000step_number: 0/29 cost:  0.5594820545482205 accuracy:  0.874965949332607\n",
      "Epoch number: 770/10000step_number: 0/29 cost:  0.558823304523477 accuracy:  0.8751021520021792\n",
      "Epoch number: 771/10000step_number: 0/29 cost:  0.5581639486375337 accuracy:  0.8746935439934622\n",
      "Epoch number: 772/10000step_number: 0/29 cost:  0.557503799744043 accuracy:  0.8752383546717516\n",
      "Epoch number: 773/10000step_number: 0/29 cost:  0.5568426217407423 accuracy:  0.8751021520021792\n",
      "Epoch number: 774/10000step_number: 0/29 cost:  0.5561801190019181 accuracy:  0.8751021520021792\n",
      "Epoch number: 775/10000step_number: 0/29 cost:  0.5555159257274077 accuracy:  0.8753745573413239\n",
      "Epoch number: 776/10000step_number: 0/29 cost:  0.5548495987397912 accuracy:  0.8753745573413239\n",
      "Epoch number: 777/10000step_number: 0/29 cost:  0.5541806210452977 accuracy:  0.8753745573413239\n",
      "Epoch number: 778/10000step_number: 0/29 cost:  0.5535084288842903 accuracy:  0.8753745573413239\n",
      "Epoch number: 779/10000step_number: 0/29 cost:  0.5528324787383563 accuracy:  0.8753745573413239\n",
      "Epoch number: 780/10000step_number: 0/29 cost:  0.552152363068986 accuracy:  0.8752383546717516\n",
      "Epoch number: 781/10000step_number: 0/29 cost:  0.5514679526444598 accuracy:  0.8753745573413239\n",
      "Epoch number: 782/10000step_number: 0/29 cost:  0.5507794983672303 accuracy:  0.8753745573413239\n",
      "Epoch number: 783/10000step_number: 0/29 cost:  0.55008761708475 accuracy:  0.8755107600108962\n",
      "Epoch number: 784/10000step_number: 0/29 cost:  0.5493931600313413 accuracy:  0.8756469626804685\n",
      "Epoch number: 785/10000step_number: 0/29 cost:  0.548697073787911 accuracy:  0.8755107600108962\n",
      "Epoch number: 786/10000step_number: 0/29 cost:  0.5480004049204936 accuracy:  0.8755107600108962\n",
      "Epoch number: 787/10000step_number: 0/29 cost:  0.5473045220676452 accuracy:  0.8756469626804685\n",
      "Epoch number: 788/10000step_number: 0/29 cost:  0.5466114379436177 accuracy:  0.8757831653500409\n",
      "Epoch number: 789/10000step_number: 0/29 cost:  0.5459238741477077 accuracy:  0.8757831653500409\n",
      "Epoch number: 790/10000step_number: 0/29 cost:  0.5452447491995369 accuracy:  0.8757831653500409\n",
      "Epoch number: 791/10000step_number: 0/29 cost:  0.5445763387419982 accuracy:  0.8757831653500409\n",
      "Epoch number: 792/10000step_number: 0/29 cost:  0.5439197634876738 accuracy:  0.8756469626804685\n",
      "Epoch number: 793/10000step_number: 0/29 cost:  0.5432750360757633 accuracy:  0.8753745573413239\n",
      "Epoch number: 794/10000step_number: 0/29 cost:  0.5426415669280552 accuracy:  0.8757831653500409\n",
      "Epoch number: 795/10000step_number: 0/29 cost:  0.5420189894356161 accuracy:  0.8759193680196132\n",
      "Epoch number: 796/10000step_number: 0/29 cost:  0.5414059743815307 accuracy:  0.8763279760283301\n",
      "Epoch number: 797/10000step_number: 0/29 cost:  0.5408008723582981 accuracy:  0.8767365840370471\n",
      "Epoch number: 798/10000step_number: 0/29 cost:  0.5402032024936866 accuracy:  0.8767365840370471\n",
      "Epoch number: 799/10000step_number: 0/29 cost:  0.5396124446262167 accuracy:  0.8770089893761918\n",
      "Epoch number: 800/10000step_number: 0/29 cost:  0.5390280539303574 accuracy:  0.8771451920457641\n",
      "Epoch number: 801/10000step_number: 0/29 cost:  0.5384495550587319 accuracy:  0.8776900027240534\n",
      "Epoch number: 802/10000step_number: 0/29 cost:  0.5378764936239478 accuracy:  0.8776900027240534\n",
      "Epoch number: 803/10000step_number: 0/29 cost:  0.5373084277687038 accuracy:  0.877962408063198\n",
      "Epoch number: 804/10000step_number: 0/29 cost:  0.5367449307905356 accuracy:  0.8780986107327704\n",
      "Epoch number: 805/10000step_number: 0/29 cost:  0.5361856212513897 accuracy:  0.8789158267502043\n",
      "Epoch number: 806/10000step_number: 0/29 cost:  0.5356302185707152 accuracy:  0.8789158267502043\n",
      "Epoch number: 807/10000step_number: 0/29 cost:  0.5350785575841953 accuracy:  0.8789158267502043\n",
      "Epoch number: 808/10000step_number: 0/29 cost:  0.5345304713906883 accuracy:  0.8794606374284936\n",
      "Epoch number: 809/10000step_number: 0/29 cost:  0.5339856959486883 accuracy:  0.8794606374284936\n",
      "Epoch number: 810/10000step_number: 0/29 cost:  0.5334439675105835 accuracy:  0.8793244347589213\n",
      "Epoch number: 811/10000step_number: 0/29 cost:  0.5329050897765062 accuracy:  0.8793244347589213\n",
      "Epoch number: 812/10000step_number: 0/29 cost:  0.5323689253249986 accuracy:  0.8800054481067829\n",
      "Epoch number: 813/10000step_number: 0/29 cost:  0.5318354061525786 accuracy:  0.8801416507763552\n",
      "Epoch number: 814/10000step_number: 0/29 cost:  0.5313045401567607 accuracy:  0.8802778534459276\n",
      "Epoch number: 815/10000step_number: 0/29 cost:  0.5307764046937048 accuracy:  0.8805502587850722\n",
      "Epoch number: 816/10000step_number: 0/29 cost:  0.5302511317247705 accuracy:  0.8804140561154998\n",
      "Epoch number: 817/10000step_number: 0/29 cost:  0.5297288793870228 accuracy:  0.8806864614546445\n",
      "Epoch number: 818/10000step_number: 0/29 cost:  0.5292097815201449 accuracy:  0.8806864614546445\n",
      "Epoch number: 819/10000step_number: 0/29 cost:  0.528693869481954 accuracy:  0.8806864614546445\n",
      "Epoch number: 820/10000step_number: 0/29 cost:  0.5281809775248175 accuracy:  0.8813674748025061\n",
      "Epoch number: 821/10000step_number: 0/29 cost:  0.5276706740914592 accuracy:  0.8813674748025061\n",
      "Epoch number: 822/10000step_number: 0/29 cost:  0.5271622756608342 accuracy:  0.8815036774720785\n",
      "Epoch number: 823/10000step_number: 0/29 cost:  0.5266549576303621 accuracy:  0.8824570961590847\n",
      "Epoch number: 824/10000step_number: 0/29 cost:  0.5261479094745766 accuracy:  0.8827295014982294\n",
      "Epoch number: 825/10000step_number: 0/29 cost:  0.5256404692442211 accuracy:  0.882593298828657\n",
      "Epoch number: 826/10000step_number: 0/29 cost:  0.5251322085008058 accuracy:  0.8817760828112231\n",
      "Epoch number: 827/10000step_number: 0/29 cost:  0.5246229626606812 accuracy:  0.8817760828112231\n",
      "Epoch number: 828/10000step_number: 0/29 cost:  0.5241128078818469 accuracy:  0.8819122854807955\n",
      "Epoch number: 829/10000step_number: 0/29 cost:  0.523601993737623 accuracy:  0.8819122854807955\n",
      "Epoch number: 830/10000step_number: 0/29 cost:  0.5230908551193273 accuracy:  0.8817760828112231\n",
      "Epoch number: 831/10000step_number: 0/29 cost:  0.5225797335399416 accuracy:  0.8817760828112231\n",
      "Epoch number: 832/10000step_number: 0/29 cost:  0.5220689269896271 accuracy:  0.8817760828112231\n",
      "Epoch number: 833/10000step_number: 0/29 cost:  0.5215586693328287 accuracy:  0.8816398801416507\n",
      "Epoch number: 834/10000step_number: 0/29 cost:  0.521049129562661 accuracy:  0.8817760828112231\n",
      "Epoch number: 835/10000step_number: 0/29 cost:  0.5205404203369165 accuracy:  0.8817760828112231\n",
      "Epoch number: 836/10000step_number: 0/29 cost:  0.5200326088488266 accuracy:  0.8819122854807955\n",
      "Epoch number: 837/10000step_number: 0/29 cost:  0.5195257268047572 accuracy:  0.8823208934895124\n",
      "Epoch number: 838/10000step_number: 0/29 cost:  0.5190197785707586 accuracy:  0.8823208934895124\n",
      "Epoch number: 839/10000step_number: 0/29 cost:  0.518514747556366 accuracy:  0.8823208934895124\n",
      "Epoch number: 840/10000step_number: 0/29 cost:  0.5180106011812671 accuracy:  0.882593298828657\n",
      "Epoch number: 841/10000step_number: 0/29 cost:  0.5175072947476599 accuracy:  0.8817760828112231\n",
      "Epoch number: 842/10000step_number: 0/29 cost:  0.5170047744431665 accuracy:  0.8817760828112231\n",
      "Epoch number: 843/10000step_number: 0/29 cost:  0.5165029796147498 accuracy:  0.8816398801416507\n",
      "Epoch number: 844/10000step_number: 0/29 cost:  0.5160018444065957 accuracy:  0.8816398801416507\n",
      "Epoch number: 845/10000step_number: 0/29 cost:  0.5155012988438595 accuracy:  0.8819122854807955\n",
      "Epoch number: 846/10000step_number: 0/29 cost:  0.515001269461566 accuracy:  0.8819122854807955\n",
      "Epoch number: 847/10000step_number: 0/29 cost:  0.5145016796139309 accuracy:  0.8821846908199401\n",
      "Epoch number: 848/10000step_number: 0/29 cost:  0.5140024496422672 accuracy:  0.8827295014982294\n",
      "Epoch number: 849/10000step_number: 0/29 cost:  0.513503497116705 accuracy:  0.8827295014982294\n",
      "Epoch number: 850/10000step_number: 0/29 cost:  0.5130047373852504 accuracy:  0.8827295014982294\n",
      "Epoch number: 851/10000step_number: 0/29 cost:  0.512506084652498 accuracy:  0.8827295014982294\n",
      "Epoch number: 852/10000step_number: 0/29 cost:  0.5120074537634285 accuracy:  0.8827295014982294\n",
      "Epoch number: 853/10000step_number: 0/29 cost:  0.5115087627856919 accuracy:  0.8835467175156633\n",
      "Epoch number: 854/10000step_number: 0/29 cost:  0.5110099363744731 accuracy:  0.8838191228548079\n",
      "Epoch number: 855/10000step_number: 0/29 cost:  0.5105109097823732 accuracy:  0.8836829201852356\n",
      "Epoch number: 856/10000step_number: 0/29 cost:  0.5100116332625936 accuracy:  0.8836829201852356\n",
      "Epoch number: 857/10000step_number: 0/29 cost:  0.5095120765284108 accuracy:  0.8850449468809589\n",
      "Epoch number: 858/10000step_number: 0/29 cost:  0.5090122328927231 accuracy:  0.8849087442113865\n",
      "Epoch number: 859/10000step_number: 0/29 cost:  0.5085121227257747 accuracy:  0.8849087442113865\n",
      "Epoch number: 860/10000step_number: 0/29 cost:  0.5080117959316954 accuracy:  0.8849087442113865\n",
      "Epoch number: 861/10000step_number: 0/29 cost:  0.507511333239129 accuracy:  0.8850449468809589\n",
      "Epoch number: 862/10000step_number: 0/29 cost:  0.507010846207562 accuracy:  0.8850449468809589\n",
      "Epoch number: 863/10000step_number: 0/29 cost:  0.5065104759511252 accuracy:  0.8847725415418142\n",
      "Epoch number: 864/10000step_number: 0/29 cost:  0.5060103906640009 accuracy:  0.8849087442113865\n",
      "Epoch number: 865/10000step_number: 0/29 cost:  0.5055107820901827 accuracy:  0.8849087442113865\n",
      "Epoch number: 866/10000step_number: 0/29 cost:  0.5050118611115785 accuracy:  0.8849087442113865\n",
      "Epoch number: 867/10000step_number: 0/29 cost:  0.504513852627914 accuracy:  0.8850449468809589\n",
      "Epoch number: 868/10000step_number: 0/29 cost:  0.5040169898633582 accuracy:  0.8853173522201035\n",
      "Epoch number: 869/10000step_number: 0/29 cost:  0.5035215081531778 accuracy:  0.8854535548896758\n",
      "Epoch number: 870/10000step_number: 0/29 cost:  0.5030276381423228 accuracy:  0.8854535548896758\n",
      "Epoch number: 871/10000step_number: 0/29 cost:  0.5025355981905681 accuracy:  0.8855897575592482\n",
      "Epoch number: 872/10000step_number: 0/29 cost:  0.5020455856852322 accuracy:  0.8857259602288204\n",
      "Epoch number: 873/10000step_number: 0/29 cost:  0.5015577670168742 accuracy:  0.8857259602288204\n",
      "Epoch number: 874/10000step_number: 0/29 cost:  0.5010722663080763 accuracy:  0.8857259602288204\n",
      "Epoch number: 875/10000step_number: 0/29 cost:  0.5005891536924751 accuracy:  0.8857259602288204\n",
      "Epoch number: 876/10000step_number: 0/29 cost:  0.5001084349520961 accuracy:  0.8858621628983928\n",
      "Epoch number: 877/10000step_number: 0/29 cost:  0.499630045304323 accuracy:  0.8859983655679652\n",
      "Epoch number: 878/10000step_number: 0/29 cost:  0.49915385053034067 accuracy:  0.8858621628983928\n",
      "Epoch number: 879/10000step_number: 0/29 cost:  0.49867965789404217 accuracy:  0.8858621628983928\n",
      "Epoch number: 880/10000step_number: 0/29 cost:  0.498207237155012 accuracy:  0.8861345682375374\n",
      "Epoch number: 881/10000step_number: 0/29 cost:  0.4977363488703135 accuracy:  0.8869517842549713\n",
      "Epoch number: 882/10000step_number: 0/29 cost:  0.4972667746096121 accuracy:  0.8872241895941161\n",
      "Epoch number: 883/10000step_number: 0/29 cost:  0.49679834370576226 accuracy:  0.8873603922636883\n",
      "Epoch number: 884/10000step_number: 0/29 cost:  0.4963309545630033 accuracy:  0.8872241895941161\n",
      "Epoch number: 885/10000step_number: 0/29 cost:  0.4958645941788272 accuracy:  0.8874965949332607\n",
      "Epoch number: 886/10000step_number: 0/29 cost:  0.49539936558672265 accuracy:  0.8874965949332607\n",
      "Epoch number: 887/10000step_number: 0/29 cost:  0.49493553570749693 accuracy:  0.887632797602833\n",
      "Epoch number: 888/10000step_number: 0/29 cost:  0.4944735863934236 accuracy:  0.887632797602833\n",
      "Epoch number: 889/10000step_number: 0/29 cost:  0.4940140276138169 accuracy:  0.8879052029419776\n",
      "Epoch number: 890/10000step_number: 0/29 cost:  0.49355618469285295 accuracy:  0.88804140561155\n",
      "Epoch number: 891/10000step_number: 0/29 cost:  0.49309707151826404 accuracy:  0.88804140561155\n",
      "Epoch number: 892/10000step_number: 0/29 cost:  0.49263490848283015 accuracy:  0.88804140561155\n",
      "Epoch number: 893/10000step_number: 0/29 cost:  0.4921704641385155 accuracy:  0.8877690002724054\n",
      "Epoch number: 894/10000step_number: 0/29 cost:  0.49170421019398913 accuracy:  0.8879052029419776\n",
      "Epoch number: 895/10000step_number: 0/29 cost:  0.4912359521119848 accuracy:  0.88804140561155\n",
      "Epoch number: 896/10000step_number: 0/29 cost:  0.49076519158532383 accuracy:  0.8889948242985563\n",
      "Epoch number: 897/10000step_number: 0/29 cost:  0.49029122982151413 accuracy:  0.8891310269681286\n",
      "Epoch number: 898/10000step_number: 0/29 cost:  0.48981315645879137 accuracy:  0.8891310269681286\n",
      "Epoch number: 899/10000step_number: 0/29 cost:  0.48932981082926336 accuracy:  0.8891310269681286\n",
      "Epoch number: 900/10000step_number: 0/29 cost:  0.4888397283727203 accuracy:  0.8889948242985563\n",
      "Epoch number: 901/10000step_number: 0/29 cost:  0.488341059491626 accuracy:  0.8894034323072733\n",
      "Epoch number: 902/10000step_number: 0/29 cost:  0.48783145159724123 accuracy:  0.8895396349768455\n",
      "Epoch number: 903/10000step_number: 0/29 cost:  0.48730788601780817 accuracy:  0.8896758376464179\n",
      "Epoch number: 904/10000step_number: 0/29 cost:  0.48676645782589323 accuracy:  0.8895396349768455\n",
      "Epoch number: 905/10000step_number: 0/29 cost:  0.4862020893200249 accuracy:  0.8894034323072733\n",
      "Epoch number: 906/10000step_number: 0/29 cost:  0.48560818338791034 accuracy:  0.8896758376464179\n",
      "Epoch number: 907/10000step_number: 0/29 cost:  0.4849762752352356 accuracy:  0.8898120403159901\n",
      "Epoch number: 908/10000step_number: 0/29 cost:  0.484295879141028 accuracy:  0.891446472350858\n",
      "Epoch number: 909/10000step_number: 0/29 cost:  0.48355503854984355 accuracy:  0.8913102696812858\n",
      "Epoch number: 910/10000step_number: 0/29 cost:  0.4827426438747293 accuracy:  0.891446472350858\n",
      "Epoch number: 911/10000step_number: 0/29 cost:  0.4818541030328904 accuracy:  0.8915826750204304\n",
      "Epoch number: 912/10000step_number: 0/29 cost:  0.480900938719245 accuracy:  0.8915826750204304\n",
      "Epoch number: 913/10000step_number: 0/29 cost:  0.47991958705753407 accuracy:  0.891446472350858\n",
      "Epoch number: 914/10000step_number: 0/29 cost:  0.4789672284244327 accuracy:  0.891446472350858\n",
      "Epoch number: 915/10000step_number: 0/29 cost:  0.478098264859239 accuracy:  0.8915826750204304\n",
      "Epoch number: 916/10000step_number: 0/29 cost:  0.4773388622768451 accuracy:  0.8915826750204304\n",
      "Epoch number: 917/10000step_number: 0/29 cost:  0.47668290848974515 accuracy:  0.8915826750204304\n",
      "Epoch number: 918/10000step_number: 0/29 cost:  0.4761071121455153 accuracy:  0.8915826750204304\n",
      "Epoch number: 919/10000step_number: 0/29 cost:  0.4755867152744512 accuracy:  0.891446472350858\n",
      "Epoch number: 920/10000step_number: 0/29 cost:  0.47510239931544235 accuracy:  0.8913102696812858\n",
      "Epoch number: 921/10000step_number: 0/29 cost:  0.47464094916692373 accuracy:  0.8913102696812858\n",
      "Epoch number: 922/10000step_number: 0/29 cost:  0.4741938501574148 accuracy:  0.8911740670117134\n",
      "Epoch number: 923/10000step_number: 0/29 cost:  0.47375568950272956 accuracy:  0.8907654590029964\n",
      "Epoch number: 924/10000step_number: 0/29 cost:  0.4733228791354524 accuracy:  0.8907654590029964\n",
      "Epoch number: 925/10000step_number: 0/29 cost:  0.4728925908233417 accuracy:  0.8906292563334242\n",
      "Epoch number: 926/10000step_number: 0/29 cost:  0.4724624050292958 accuracy:  0.8906292563334242\n",
      "Epoch number: 927/10000step_number: 0/29 cost:  0.4720339584590213 accuracy:  0.8906292563334242\n",
      "Epoch number: 928/10000step_number: 0/29 cost:  0.47160601417617126 accuracy:  0.8906292563334242\n",
      "Epoch number: 929/10000step_number: 0/29 cost:  0.4711801444810792 accuracy:  0.8906292563334242\n",
      "Epoch number: 930/10000step_number: 0/29 cost:  0.47076052234574334 accuracy:  0.8906292563334242\n",
      "Epoch number: 931/10000step_number: 0/29 cost:  0.47034404830731125 accuracy:  0.8906292563334242\n",
      "Epoch number: 932/10000step_number: 0/29 cost:  0.4699300446978649 accuracy:  0.8906292563334242\n",
      "Epoch number: 933/10000step_number: 0/29 cost:  0.4695193165403209 accuracy:  0.891037864342141\n",
      "Epoch number: 934/10000step_number: 0/29 cost:  0.469113360616014 accuracy:  0.8909016616725688\n",
      "Epoch number: 935/10000step_number: 0/29 cost:  0.46871273162167304 accuracy:  0.8909016616725688\n",
      "Epoch number: 936/10000step_number: 0/29 cost:  0.4683173439928628 accuracy:  0.8909016616725688\n",
      "Epoch number: 937/10000step_number: 0/29 cost:  0.46792682942019304 accuracy:  0.8909016616725688\n",
      "Epoch number: 938/10000step_number: 0/29 cost:  0.4675406299652631 accuracy:  0.8907654590029964\n",
      "Epoch number: 939/10000step_number: 0/29 cost:  0.4671580981458044 accuracy:  0.8907654590029964\n",
      "Epoch number: 940/10000step_number: 0/29 cost:  0.46677860075825567 accuracy:  0.8906292563334242\n",
      "Epoch number: 941/10000step_number: 0/29 cost:  0.466401555781662 accuracy:  0.8907654590029964\n",
      "Epoch number: 942/10000step_number: 0/29 cost:  0.466026470268457 accuracy:  0.8906292563334242\n",
      "Epoch number: 943/10000step_number: 0/29 cost:  0.4656529825111616 accuracy:  0.8906292563334242\n",
      "Epoch number: 944/10000step_number: 0/29 cost:  0.465280870870236 accuracy:  0.8907654590029964\n",
      "Epoch number: 945/10000step_number: 0/29 cost:  0.4649100102353682 accuracy:  0.8907654590029964\n",
      "Epoch number: 946/10000step_number: 0/29 cost:  0.4645403221188701 accuracy:  0.891037864342141\n",
      "Epoch number: 947/10000step_number: 0/29 cost:  0.4641717519162963 accuracy:  0.891037864342141\n",
      "Epoch number: 948/10000step_number: 0/29 cost:  0.4638042603070004 accuracy:  0.8909016616725688\n",
      "Epoch number: 949/10000step_number: 0/29 cost:  0.4634378157407427 accuracy:  0.8907654590029964\n",
      "Epoch number: 950/10000step_number: 0/29 cost:  0.4630723855376934 accuracy:  0.8907654590029964\n",
      "Epoch number: 951/10000step_number: 0/29 cost:  0.462707925927112 accuracy:  0.8907654590029964\n",
      "Epoch number: 952/10000step_number: 0/29 cost:  0.4623443721601561 accuracy:  0.8907654590029964\n",
      "Epoch number: 953/10000step_number: 0/29 cost:  0.46198163099394424 accuracy:  0.8907654590029964\n",
      "Epoch number: 954/10000step_number: 0/29 cost:  0.46161957872345555 accuracy:  0.8909016616725688\n",
      "Epoch number: 955/10000step_number: 0/29 cost:  0.46125806752961784 accuracy:  0.8907654590029964\n",
      "Epoch number: 956/10000step_number: 0/29 cost:  0.46089694061119063 accuracy:  0.8907654590029964\n",
      "Epoch number: 957/10000step_number: 0/29 cost:  0.46053605281543736 accuracy:  0.8909016616725688\n",
      "Epoch number: 958/10000step_number: 0/29 cost:  0.46017529038949834 accuracy:  0.891037864342141\n",
      "Epoch number: 959/10000step_number: 0/29 cost:  0.4598145836190209 accuracy:  0.8911740670117134\n",
      "Epoch number: 960/10000step_number: 0/29 cost:  0.45945390979899225 accuracy:  0.891037864342141\n",
      "Epoch number: 961/10000step_number: 0/29 cost:  0.4590932883672647 accuracy:  0.891037864342141\n",
      "Epoch number: 962/10000step_number: 0/29 cost:  0.45873277203957297 accuracy:  0.8913102696812858\n",
      "Epoch number: 963/10000step_number: 0/29 cost:  0.4583724370815356 accuracy:  0.8913102696812858\n",
      "Epoch number: 964/10000step_number: 0/29 cost:  0.458012374255717 accuracy:  0.8913102696812858\n",
      "Epoch number: 965/10000step_number: 0/29 cost:  0.45765268095043155 accuracy:  0.8913102696812858\n",
      "Epoch number: 966/10000step_number: 0/29 cost:  0.457293454672323 accuracy:  0.891446472350858\n",
      "Epoch number: 967/10000step_number: 0/29 cost:  0.4569347880270831 accuracy:  0.8915826750204304\n",
      "Epoch number: 968/10000step_number: 0/29 cost:  0.45657676523697366 accuracy:  0.8915826750204304\n",
      "Epoch number: 969/10000step_number: 0/29 cost:  0.4562194601178931 accuracy:  0.8917188776900027\n",
      "Epoch number: 970/10000step_number: 0/29 cost:  0.45586293531829836 accuracy:  0.8919912830291473\n",
      "Epoch number: 971/10000step_number: 0/29 cost:  0.4555072425458075 accuracy:  0.8922636883682921\n",
      "Epoch number: 972/10000step_number: 0/29 cost:  0.45515242348037926 accuracy:  0.8923998910378643\n",
      "Epoch number: 973/10000step_number: 0/29 cost:  0.45479851108465597 accuracy:  0.8925360937074367\n",
      "Epoch number: 974/10000step_number: 0/29 cost:  0.4544455310589441 accuracy:  0.892672296377009\n",
      "Epoch number: 975/10000step_number: 0/29 cost:  0.45409350323973774 accuracy:  0.8928084990465813\n",
      "Epoch number: 976/10000step_number: 0/29 cost:  0.45374244279861564 accuracy:  0.893080904385726\n",
      "Epoch number: 977/10000step_number: 0/29 cost:  0.4533923611552109 accuracy:  0.893080904385726\n",
      "Epoch number: 978/10000step_number: 0/29 cost:  0.4530432665668564 accuracy:  0.8932171070552983\n",
      "Epoch number: 979/10000step_number: 0/29 cost:  0.45269516439345514 accuracy:  0.8933533097248706\n",
      "Epoch number: 980/10000step_number: 0/29 cost:  0.4523480570581 accuracy:  0.8933533097248706\n",
      "Epoch number: 981/10000step_number: 0/29 cost:  0.4520019437342211 accuracy:  0.893489512394443\n",
      "Epoch number: 982/10000step_number: 0/29 cost:  0.4516568197922312 accuracy:  0.8933533097248706\n",
      "Epoch number: 983/10000step_number: 0/29 cost:  0.45131267603533765 accuracy:  0.893489512394443\n",
      "Epoch number: 984/10000step_number: 0/29 cost:  0.4509694977458355 accuracy:  0.893489512394443\n",
      "Epoch number: 985/10000step_number: 0/29 cost:  0.450627263548251 accuracy:  0.8937619177335876\n",
      "Epoch number: 986/10000step_number: 0/29 cost:  0.45028594407205197 accuracy:  0.8940343230727322\n",
      "Epoch number: 987/10000step_number: 0/29 cost:  0.4499455003630891 accuracy:  0.8940343230727322\n",
      "Epoch number: 988/10000step_number: 0/29 cost:  0.4496058819515495 accuracy:  0.8943067284118769\n",
      "Epoch number: 989/10000step_number: 0/29 cost:  0.44926702444314087 accuracy:  0.8943067284118769\n",
      "Epoch number: 990/10000step_number: 0/29 cost:  0.4489288464788141 accuracy:  0.8944429310814492\n",
      "Epoch number: 991/10000step_number: 0/29 cost:  0.4485912459495897 accuracy:  0.8943067284118769\n",
      "Epoch number: 992/10000step_number: 0/29 cost:  0.44825409556049045 accuracy:  0.8943067284118769\n",
      "Epoch number: 993/10000step_number: 0/29 cost:  0.4479172384866033 accuracy:  0.8944429310814492\n",
      "Epoch number: 994/10000step_number: 0/29 cost:  0.44758048669702655 accuracy:  0.8945791337510215\n",
      "Epoch number: 995/10000step_number: 0/29 cost:  0.44724362929646133 accuracy:  0.8949877417597385\n",
      "Epoch number: 996/10000step_number: 0/29 cost:  0.4469064685085738 accuracy:  0.8949877417597385\n",
      "Epoch number: 997/10000step_number: 0/29 cost:  0.4465689128785068 accuracy:  0.8948515390901661\n",
      "Epoch number: 998/10000step_number: 0/29 cost:  0.44623113408838777 accuracy:  0.8948515390901661\n",
      "Epoch number: 999/10000step_number: 0/29 cost:  0.44589366127904734 accuracy:  0.8948515390901661\n",
      "Epoch number: 1000/10000step_number: 0/29 cost:  0.4455571551991489 accuracy:  0.8948515390901661\n",
      "Epoch number: 1001/10000step_number: 0/29 cost:  0.4452219374872414 accuracy:  0.8948515390901661\n",
      "Epoch number: 1002/10000step_number: 0/29 cost:  0.4448878593963505 accuracy:  0.8948515390901661\n",
      "Epoch number: 1003/10000step_number: 0/29 cost:  0.44455464575276626 accuracy:  0.8948515390901661\n",
      "Epoch number: 1004/10000step_number: 0/29 cost:  0.4442221669889965 accuracy:  0.8947153364205939\n",
      "Epoch number: 1005/10000step_number: 0/29 cost:  0.443890405944195 accuracy:  0.8948515390901661\n",
      "Epoch number: 1006/10000step_number: 0/29 cost:  0.4435593641282556 accuracy:  0.8951239444293109\n",
      "Epoch number: 1007/10000step_number: 0/29 cost:  0.4432290312785285 accuracy:  0.8951239444293109\n",
      "Epoch number: 1008/10000step_number: 0/29 cost:  0.4428993809668853 accuracy:  0.8953963497684555\n",
      "Epoch number: 1009/10000step_number: 0/29 cost:  0.44257037538815636 accuracy:  0.8953963497684555\n",
      "Epoch number: 1010/10000step_number: 0/29 cost:  0.4422419737698641 accuracy:  0.8953963497684555\n",
      "Epoch number: 1011/10000step_number: 0/29 cost:  0.44191414085748876 accuracy:  0.8953963497684555\n",
      "Epoch number: 1012/10000step_number: 0/29 cost:  0.44158685339646353 accuracy:  0.8953963497684555\n",
      "Epoch number: 1013/10000step_number: 0/29 cost:  0.44126010137948574 accuracy:  0.8953963497684555\n",
      "Epoch number: 1014/10000step_number: 0/29 cost:  0.4409338844669224 accuracy:  0.8956687551076001\n",
      "Epoch number: 1015/10000step_number: 0/29 cost:  0.4406082064047128 accuracy:  0.8956687551076001\n",
      "Epoch number: 1016/10000step_number: 0/29 cost:  0.44028306957630303 accuracy:  0.8956687551076001\n",
      "Epoch number: 1017/10000step_number: 0/29 cost:  0.43995847091109647 accuracy:  0.8958049577771724\n",
      "Epoch number: 1018/10000step_number: 0/29 cost:  0.4396343996014723 accuracy:  0.8959411604467448\n",
      "Epoch number: 1019/10000step_number: 0/29 cost:  0.43931083650233216 accuracy:  0.896077363116317\n",
      "Epoch number: 1020/10000step_number: 0/29 cost:  0.43898775485146974 accuracy:  0.896077363116317\n",
      "Epoch number: 1021/10000step_number: 0/29 cost:  0.4386651218437207 accuracy:  0.896077363116317\n",
      "Epoch number: 1022/10000step_number: 0/29 cost:  0.4383429005904665 accuracy:  0.896077363116317\n",
      "Epoch number: 1023/10000step_number: 0/29 cost:  0.43802105209475817 accuracy:  0.8962135657858894\n",
      "Epoch number: 1024/10000step_number: 0/29 cost:  0.4376995369985706 accuracy:  0.8962135657858894\n",
      "Epoch number: 1025/10000step_number: 0/29 cost:  0.43737831698854657 accuracy:  0.8962135657858894\n",
      "Epoch number: 1026/10000step_number: 0/29 cost:  0.43705735585695693 accuracy:  0.8963497684554618\n",
      "Epoch number: 1027/10000step_number: 0/29 cost:  0.43673662028973803 accuracy:  0.8966221737946064\n",
      "Epoch number: 1028/10000step_number: 0/29 cost:  0.4364160805027209 accuracy:  0.8966221737946064\n",
      "Epoch number: 1029/10000step_number: 0/29 cost:  0.4360957108813548 accuracy:  0.8966221737946064\n",
      "Epoch number: 1030/10000step_number: 0/29 cost:  0.43577549080608446 accuracy:  0.896485971125034\n",
      "Epoch number: 1031/10000step_number: 0/29 cost:  0.4354554058658334 accuracy:  0.896485971125034\n",
      "Epoch number: 1032/10000step_number: 0/29 cost:  0.43513544966319606 accuracy:  0.8966221737946064\n",
      "Epoch number: 1033/10000step_number: 0/29 cost:  0.43481562637190874 accuracy:  0.8966221737946064\n",
      "Epoch number: 1034/10000step_number: 0/29 cost:  0.4344959540865739 accuracy:  0.8992100245164806\n",
      "Epoch number: 1035/10000step_number: 0/29 cost:  0.4341764687755541 accuracy:  0.8992100245164806\n",
      "Epoch number: 1036/10000step_number: 0/29 cost:  0.4338572283044658 accuracy:  0.8993462271860528\n",
      "Epoch number: 1037/10000step_number: 0/29 cost:  0.4335383155903659 accuracy:  0.8993462271860528\n",
      "Epoch number: 1038/10000step_number: 0/29 cost:  0.43321983961258576 accuracy:  0.8993462271860528\n",
      "Epoch number: 1039/10000step_number: 0/29 cost:  0.4329019329651725 accuracy:  0.8993462271860528\n",
      "Epoch number: 1040/10000step_number: 0/29 cost:  0.43258474511049366 accuracy:  0.8993462271860528\n",
      "Epoch number: 1041/10000step_number: 0/29 cost:  0.43226843153990024 accuracy:  0.8994824298556252\n",
      "Epoch number: 1042/10000step_number: 0/29 cost:  0.43195314038828303 accuracy:  0.8994824298556252\n",
      "Epoch number: 1043/10000step_number: 0/29 cost:  0.4316389990970348 accuracy:  0.8994824298556252\n",
      "Epoch number: 1044/10000step_number: 0/29 cost:  0.43132610389681464 accuracy:  0.8993462271860528\n",
      "Epoch number: 1045/10000step_number: 0/29 cost:  0.4310145140471714 accuracy:  0.8993462271860528\n",
      "Epoch number: 1046/10000step_number: 0/29 cost:  0.4307042513516562 accuracy:  0.8994824298556252\n",
      "Epoch number: 1047/10000step_number: 0/29 cost:  0.43039530413893773 accuracy:  0.8994824298556252\n",
      "Epoch number: 1048/10000step_number: 0/29 cost:  0.4300876341298471 accuracy:  0.8990738218469082\n",
      "Epoch number: 1049/10000step_number: 0/29 cost:  0.42978118447265207 accuracy:  0.8990738218469082\n",
      "Epoch number: 1050/10000step_number: 0/29 cost:  0.4294758875341304 accuracy:  0.8993462271860528\n",
      "Epoch number: 1051/10000step_number: 0/29 cost:  0.4291716715329981 accuracy:  0.8993462271860528\n",
      "Epoch number: 1052/10000step_number: 0/29 cost:  0.4288684656037783 accuracy:  0.8993462271860528\n",
      "Epoch number: 1053/10000step_number: 0/29 cost:  0.42856620327592065 accuracy:  0.8992100245164806\n",
      "Epoch number: 1054/10000step_number: 0/29 cost:  0.42826482460911836 accuracy:  0.8993462271860528\n",
      "Epoch number: 1055/10000step_number: 0/29 cost:  0.427964277355801 accuracy:  0.8993462271860528\n",
      "Epoch number: 1056/10000step_number: 0/29 cost:  0.42766451756506785 accuracy:  0.8993462271860528\n",
      "Epoch number: 1057/10000step_number: 0/29 cost:  0.42736551002763506 accuracy:  0.8993462271860528\n",
      "Epoch number: 1058/10000step_number: 0/29 cost:  0.42706722882161896 accuracy:  0.8994824298556252\n",
      "Epoch number: 1059/10000step_number: 0/29 cost:  0.4267696581066547 accuracy:  0.8994824298556252\n",
      "Epoch number: 1060/10000step_number: 0/29 cost:  0.4264729200499661 accuracy:  0.8994824298556252\n",
      "Epoch number: 1061/10000step_number: 0/29 cost:  0.4261795228296477 accuracy:  0.8996186325251975\n",
      "Epoch number: 1062/10000step_number: 0/29 cost:  0.4258416488981211 accuracy:  0.8994824298556252\n",
      "Epoch number: 1063/10000step_number: 0/29 cost:  0.42558339096571335 accuracy:  0.8996186325251975\n",
      "Epoch number: 1064/10000step_number: 0/29 cost:  0.4252405556528854 accuracy:  0.8994824298556252\n",
      "Epoch number: 1065/10000step_number: 0/29 cost:  0.4249692149939534 accuracy:  0.8996186325251975\n",
      "Epoch number: 1066/10000step_number: 0/29 cost:  0.4246668538697217 accuracy:  0.8997548351947698\n",
      "Epoch number: 1067/10000step_number: 0/29 cost:  0.4243780239591672 accuracy:  0.8997548351947698\n",
      "Epoch number: 1068/10000step_number: 0/29 cost:  0.42408511091345746 accuracy:  0.8997548351947698\n",
      "Epoch number: 1069/10000step_number: 0/29 cost:  0.4237938844459929 accuracy:  0.8998910378643421\n",
      "Epoch number: 1070/10000step_number: 0/29 cost:  0.4235020633351098 accuracy:  0.8998910378643421\n",
      "Epoch number: 1071/10000step_number: 0/29 cost:  0.42321133858482907 accuracy:  0.8998910378643421\n",
      "Epoch number: 1072/10000step_number: 0/29 cost:  0.4229206709033299 accuracy:  0.8998910378643421\n",
      "Epoch number: 1073/10000step_number: 0/29 cost:  0.4226305429947901 accuracy:  0.8998910378643421\n",
      "Epoch number: 1074/10000step_number: 0/29 cost:  0.42234074585341247 accuracy:  0.8998910378643421\n",
      "Epoch number: 1075/10000step_number: 0/29 cost:  0.42205132685290925 accuracy:  0.8998910378643421\n",
      "Epoch number: 1076/10000step_number: 0/29 cost:  0.42176222407245023 accuracy:  0.8998910378643421\n",
      "Epoch number: 1077/10000step_number: 0/29 cost:  0.4214734735480448 accuracy:  0.8998910378643421\n",
      "Epoch number: 1078/10000step_number: 0/29 cost:  0.42118499747760874 accuracy:  0.8998910378643421\n",
      "Epoch number: 1079/10000step_number: 0/29 cost:  0.4208968138736939 accuracy:  0.8998910378643421\n",
      "Epoch number: 1080/10000step_number: 0/29 cost:  0.42060887478460096 accuracy:  0.9000272405339145\n",
      "Epoch number: 1081/10000step_number: 0/29 cost:  0.4203211713985132 accuracy:  0.8998910378643421\n",
      "Epoch number: 1082/10000step_number: 0/29 cost:  0.42003367411343795 accuracy:  0.8998910378643421\n",
      "Epoch number: 1083/10000step_number: 0/29 cost:  0.4197463707102599 accuracy:  0.8998910378643421\n",
      "Epoch number: 1084/10000step_number: 0/29 cost:  0.4194592394072357 accuracy:  0.8998910378643421\n",
      "Epoch number: 1085/10000step_number: 0/29 cost:  0.41917227156174575 accuracy:  0.9000272405339145\n",
      "Epoch number: 1086/10000step_number: 0/29 cost:  0.4188854553288007 accuracy:  0.9000272405339145\n",
      "Epoch number: 1087/10000step_number: 0/29 cost:  0.4185987877793871 accuracy:  0.9007082538817761\n",
      "Epoch number: 1088/10000step_number: 0/29 cost:  0.4183122679154543 accuracy:  0.9007082538817761\n",
      "Epoch number: 1089/10000step_number: 0/29 cost:  0.4180259010833698 accuracy:  0.9007082538817761\n",
      "Epoch number: 1090/10000step_number: 0/29 cost:  0.4177396962282819 accuracy:  0.9007082538817761\n",
      "Epoch number: 1091/10000step_number: 0/29 cost:  0.4174536670087217 accuracy:  0.9008444565513484\n",
      "Epoch number: 1092/10000step_number: 0/29 cost:  0.41716782985819445 accuracy:  0.9008444565513484\n",
      "Epoch number: 1093/10000step_number: 0/29 cost:  0.41688220327145226 accuracy:  0.9008444565513484\n",
      "Epoch number: 1094/10000step_number: 0/29 cost:  0.41659680557149786 accuracy:  0.9009806592209207\n",
      "Epoch number: 1095/10000step_number: 0/29 cost:  0.41631165293502936 accuracy:  0.9009806592209207\n",
      "Epoch number: 1096/10000step_number: 0/29 cost:  0.4160267572309166 accuracy:  0.9009806592209207\n",
      "Epoch number: 1097/10000step_number: 0/29 cost:  0.4157421248959535 accuracy:  0.9007082538817761\n",
      "Epoch number: 1098/10000step_number: 0/29 cost:  0.41545775759060416 accuracy:  0.9007082538817761\n",
      "Epoch number: 1099/10000step_number: 0/29 cost:  0.4151736555608573 accuracy:  0.9007082538817761\n",
      "Epoch number: 1100/10000step_number: 0/29 cost:  0.41488982401867897 accuracy:  0.9007082538817761\n",
      "Epoch number: 1101/10000step_number: 0/29 cost:  0.41460628271325284 accuracy:  0.9008444565513484\n",
      "Epoch number: 1102/10000step_number: 0/29 cost:  0.4143230799203432 accuracy:  0.9007082538817761\n",
      "Epoch number: 1103/10000step_number: 0/29 cost:  0.4140403165680815 accuracy:  0.9007082538817761\n",
      "Epoch number: 1104/10000step_number: 0/29 cost:  0.41375819878465026 accuracy:  0.9009806592209207\n",
      "Epoch number: 1105/10000step_number: 0/29 cost:  0.4134771681859986 accuracy:  0.901116861890493\n",
      "Epoch number: 1106/10000step_number: 0/29 cost:  0.41319816383657226 accuracy:  0.901116861890493\n",
      "Epoch number: 1107/10000step_number: 0/29 cost:  0.4129219889398999 accuracy:  0.9013892672296377\n",
      "Epoch number: 1108/10000step_number: 0/29 cost:  0.4126435367262911 accuracy:  0.901934077907927\n",
      "Epoch number: 1109/10000step_number: 0/29 cost:  0.4123615491687719 accuracy:  0.9022064832470716\n",
      "Epoch number: 1110/10000step_number: 0/29 cost:  0.4120820920877288 accuracy:  0.9024788885862163\n",
      "Epoch number: 1111/10000step_number: 0/29 cost:  0.41179565106549365 accuracy:  0.9024788885862163\n",
      "Epoch number: 1112/10000step_number: 0/29 cost:  0.41148178006902847 accuracy:  0.9027512939253609\n",
      "Epoch number: 1113/10000step_number: 0/29 cost:  0.4112126957594301 accuracy:  0.9028874965949333\n",
      "Epoch number: 1114/10000step_number: 0/29 cost:  0.4109158856800749 accuracy:  0.9028874965949333\n",
      "Epoch number: 1115/10000step_number: 0/29 cost:  0.41064003527019416 accuracy:  0.9028874965949333\n",
      "Epoch number: 1116/10000step_number: 0/29 cost:  0.41035845819290445 accuracy:  0.9030236992645055\n",
      "Epoch number: 1117/10000step_number: 0/29 cost:  0.41007832913243475 accuracy:  0.9030236992645055\n",
      "Epoch number: 1118/10000step_number: 0/29 cost:  0.4098014268382645 accuracy:  0.9030236992645055\n",
      "Epoch number: 1119/10000step_number: 0/29 cost:  0.40952210179667575 accuracy:  0.9030236992645055\n",
      "Epoch number: 1120/10000step_number: 0/29 cost:  0.4092460572869024 accuracy:  0.9030236992645055\n",
      "Epoch number: 1121/10000step_number: 0/29 cost:  0.40896905259217525 accuracy:  0.9030236992645055\n",
      "Epoch number: 1122/10000step_number: 0/29 cost:  0.4086937174048768 accuracy:  0.9030236992645055\n",
      "Epoch number: 1123/10000step_number: 0/29 cost:  0.40841874498808545 accuracy:  0.9030236992645055\n",
      "Epoch number: 1124/10000step_number: 0/29 cost:  0.40814462304171906 accuracy:  0.9028874965949333\n",
      "Epoch number: 1125/10000step_number: 0/29 cost:  0.40787130414038114 accuracy:  0.9028874965949333\n",
      "Epoch number: 1126/10000step_number: 0/29 cost:  0.40759868104303226 accuracy:  0.9028874965949333\n",
      "Epoch number: 1127/10000step_number: 0/29 cost:  0.40732688308979637 accuracy:  0.9028874965949333\n",
      "Epoch number: 1128/10000step_number: 0/29 cost:  0.4070558160759941 accuracy:  0.9030236992645055\n",
      "Epoch number: 1129/10000step_number: 0/29 cost:  0.40678552563072357 accuracy:  0.9030236992645055\n",
      "Epoch number: 1130/10000step_number: 0/29 cost:  0.4065159897841322 accuracy:  0.9031599019340779\n",
      "Epoch number: 1131/10000step_number: 0/29 cost:  0.40624720481008697 accuracy:  0.9032961046036503\n",
      "Epoch number: 1132/10000step_number: 0/29 cost:  0.4059791717316515 accuracy:  0.9032961046036503\n",
      "Epoch number: 1133/10000step_number: 0/29 cost:  0.4057118820782523 accuracy:  0.9034323072732225\n",
      "Epoch number: 1134/10000step_number: 0/29 cost:  0.40544533702701335 accuracy:  0.9032961046036503\n",
      "Epoch number: 1135/10000step_number: 0/29 cost:  0.40517953200418755 accuracy:  0.9032961046036503\n",
      "Epoch number: 1136/10000step_number: 0/29 cost:  0.40491446258956937 accuracy:  0.9034323072732225\n",
      "Epoch number: 1137/10000step_number: 0/29 cost:  0.40465012059018146 accuracy:  0.9034323072732225\n",
      "Epoch number: 1138/10000step_number: 0/29 cost:  0.4043864939182225 accuracy:  0.9034323072732225\n",
      "Epoch number: 1139/10000step_number: 0/29 cost:  0.4041235682417688 accuracy:  0.9035685099427949\n",
      "Epoch number: 1140/10000step_number: 0/29 cost:  0.403861327371022 accuracy:  0.9037047126123672\n",
      "Epoch number: 1141/10000step_number: 0/29 cost:  0.4035997547129755 accuracy:  0.9038409152819395\n",
      "Epoch number: 1142/10000step_number: 0/29 cost:  0.4033388335231283 accuracy:  0.9035685099427949\n",
      "Epoch number: 1143/10000step_number: 0/29 cost:  0.40307854717491887 accuracy:  0.9035685099427949\n",
      "Epoch number: 1144/10000step_number: 0/29 cost:  0.40281887926459004 accuracy:  0.9035685099427949\n",
      "Epoch number: 1145/10000step_number: 0/29 cost:  0.4025598136755059 accuracy:  0.9035685099427949\n",
      "Epoch number: 1146/10000step_number: 0/29 cost:  0.40230133470797236 accuracy:  0.9035685099427949\n",
      "Epoch number: 1147/10000step_number: 0/29 cost:  0.4020434271774893 accuracy:  0.9035685099427949\n",
      "Epoch number: 1148/10000step_number: 0/29 cost:  0.4017860765107678 accuracy:  0.9035685099427949\n",
      "Epoch number: 1149/10000step_number: 0/29 cost:  0.401529268815121 accuracy:  0.9037047126123672\n",
      "Epoch number: 1150/10000step_number: 0/29 cost:  0.40127299092164637 accuracy:  0.9038409152819395\n",
      "Epoch number: 1151/10000step_number: 0/29 cost:  0.40101723041113135 accuracy:  0.9038409152819395\n",
      "Epoch number: 1152/10000step_number: 0/29 cost:  0.4007619756233964 accuracy:  0.9038409152819395\n",
      "Epoch number: 1153/10000step_number: 0/29 cost:  0.4005072156574373 accuracy:  0.9038409152819395\n",
      "Epoch number: 1154/10000step_number: 0/29 cost:  0.4002529403652795 accuracy:  0.9037047126123672\n",
      "Epoch number: 1155/10000step_number: 0/29 cost:  0.39999914034259565 accuracy:  0.9037047126123672\n",
      "Epoch number: 1156/10000step_number: 0/29 cost:  0.3997458069182552 accuracy:  0.9035685099427949\n",
      "Epoch number: 1157/10000step_number: 0/29 cost:  0.3994929321437276 accuracy:  0.9035685099427949\n",
      "Epoch number: 1158/10000step_number: 0/29 cost:  0.3992405087828899 accuracy:  0.9035685099427949\n",
      "Epoch number: 1159/10000step_number: 0/29 cost:  0.39898853030209874 accuracy:  0.9035685099427949\n",
      "Epoch number: 1160/10000step_number: 0/29 cost:  0.39873699086017167 accuracy:  0.9035685099427949\n",
      "Epoch number: 1161/10000step_number: 0/29 cost:  0.398485885297772 accuracy:  0.9037047126123672\n",
      "Epoch number: 1162/10000step_number: 0/29 cost:  0.3982352091256896 accuracy:  0.9037047126123672\n",
      "Epoch number: 1163/10000step_number: 0/29 cost:  0.397984958511598 accuracy:  0.9038409152819395\n",
      "Epoch number: 1164/10000step_number: 0/29 cost:  0.39773513026498325 accuracy:  0.9038409152819395\n",
      "Epoch number: 1165/10000step_number: 0/29 cost:  0.39748572182009023 accuracy:  0.9039771179515118\n",
      "Epoch number: 1166/10000step_number: 0/29 cost:  0.397236731216895 accuracy:  0.9039771179515118\n",
      "Epoch number: 1167/10000step_number: 0/29 cost:  0.39698815708026347 accuracy:  0.9041133206210842\n",
      "Epoch number: 1168/10000step_number: 0/29 cost:  0.39673999859764025 accuracy:  0.9041133206210842\n",
      "Epoch number: 1169/10000step_number: 0/29 cost:  0.39649225549576267 accuracy:  0.9041133206210842\n",
      "Epoch number: 1170/10000step_number: 0/29 cost:  0.3962449280170776 accuracy:  0.9041133206210842\n",
      "Epoch number: 1171/10000step_number: 0/29 cost:  0.39599801689668196 accuracy:  0.9042495232906564\n",
      "Epoch number: 1172/10000step_number: 0/29 cost:  0.3957515233407464 accuracy:  0.9043857259602288\n",
      "Epoch number: 1173/10000step_number: 0/29 cost:  0.39550544900746626 accuracy:  0.9042495232906564\n",
      "Epoch number: 1174/10000step_number: 0/29 cost:  0.3952597959916094 accuracy:  0.9042495232906564\n",
      "Epoch number: 1175/10000step_number: 0/29 cost:  0.39501456681367064 accuracy:  0.9045219286298012\n",
      "Epoch number: 1176/10000step_number: 0/29 cost:  0.3947697644144843 accuracy:  0.9046581312993734\n",
      "Epoch number: 1177/10000step_number: 0/29 cost:  0.3945253921558806 accuracy:  0.9046581312993734\n",
      "Epoch number: 1178/10000step_number: 0/29 cost:  0.39428145382761015 accuracy:  0.9046581312993734\n",
      "Epoch number: 1179/10000step_number: 0/29 cost:  0.3940379536603038 accuracy:  0.9046581312993734\n",
      "Epoch number: 1180/10000step_number: 0/29 cost:  0.3937948963437425 accuracy:  0.9047943339689458\n",
      "Epoch number: 1181/10000step_number: 0/29 cost:  0.3935522870491858 accuracy:  0.9047943339689458\n",
      "Epoch number: 1182/10000step_number: 0/29 cost:  0.3933101314539846 accuracy:  0.9049305366385181\n",
      "Epoch number: 1183/10000step_number: 0/29 cost:  0.3930684357662568 accuracy:  0.9050667393080905\n",
      "Epoch number: 1184/10000step_number: 0/29 cost:  0.39282720674698685 accuracy:  0.9050667393080905\n",
      "Epoch number: 1185/10000step_number: 0/29 cost:  0.3925864517266076 accuracy:  0.9052029419776627\n",
      "Epoch number: 1186/10000step_number: 0/29 cost:  0.392346178612908 accuracy:  0.9052029419776627\n",
      "Epoch number: 1187/10000step_number: 0/29 cost:  0.39210639588705987 accuracy:  0.9053391446472351\n",
      "Epoch number: 1188/10000step_number: 0/29 cost:  0.3918671125846712 accuracy:  0.9054753473168075\n",
      "Epoch number: 1189/10000step_number: 0/29 cost:  0.3916283382591623 accuracy:  0.9056115499863797\n",
      "Epoch number: 1190/10000step_number: 0/29 cost:  0.39139008292547733 accuracy:  0.9057477526559521\n",
      "Epoch number: 1191/10000step_number: 0/29 cost:  0.3911523569832588 accuracy:  0.9057477526559521\n",
      "Epoch number: 1192/10000step_number: 0/29 cost:  0.3909151711201701 accuracy:  0.906156360664669\n",
      "Epoch number: 1193/10000step_number: 0/29 cost:  0.3906785361979912 accuracy:  0.9064287660038137\n",
      "Epoch number: 1194/10000step_number: 0/29 cost:  0.3904424631263039 accuracy:  0.9064287660038137\n",
      "Epoch number: 1195/10000step_number: 0/29 cost:  0.39020696273072675 accuracy:  0.9064287660038137\n",
      "Epoch number: 1196/10000step_number: 0/29 cost:  0.38997204562441073 accuracy:  0.9064287660038137\n",
      "Epoch number: 1197/10000step_number: 0/29 cost:  0.389737722092337 accuracy:  0.906564968673386\n",
      "Epoch number: 1198/10000step_number: 0/29 cost:  0.3895040019975055 accuracy:  0.9067011713429584\n",
      "Epoch number: 1199/10000step_number: 0/29 cost:  0.38927089471599285 accuracy:  0.9067011713429584\n",
      "Epoch number: 1200/10000step_number: 0/29 cost:  0.3890384091040422 accuracy:  0.9067011713429584\n",
      "Epoch number: 1201/10000step_number: 0/29 cost:  0.38880655349502036 accuracy:  0.9067011713429584\n",
      "Epoch number: 1202/10000step_number: 0/29 cost:  0.3885753357177618 accuracy:  0.9075183873603923\n",
      "Epoch number: 1203/10000step_number: 0/29 cost:  0.38834476312120036 accuracy:  0.9075183873603923\n",
      "Epoch number: 1204/10000step_number: 0/29 cost:  0.3881148425840529 accuracy:  0.9076545900299646\n",
      "Epoch number: 1205/10000step_number: 0/29 cost:  0.38788558048338745 accuracy:  0.9076545900299646\n",
      "Epoch number: 1206/10000step_number: 0/29 cost:  0.3876569825926743 accuracy:  0.9076545900299646\n",
      "Epoch number: 1207/10000step_number: 0/29 cost:  0.38742905387878035 accuracy:  0.9077907926995369\n",
      "Epoch number: 1208/10000step_number: 0/29 cost:  0.38720179816855155 accuracy:  0.9077907926995369\n",
      "Epoch number: 1209/10000step_number: 0/29 cost:  0.3869752176594601 accuracy:  0.9077907926995369\n",
      "Epoch number: 1210/10000step_number: 0/29 cost:  0.3867493122558253 accuracy:  0.9077907926995369\n",
      "Epoch number: 1211/10000step_number: 0/29 cost:  0.3865240787232095 accuracy:  0.9077907926995369\n",
      "Epoch number: 1212/10000step_number: 0/29 cost:  0.3862995096700166 accuracy:  0.9077907926995369\n",
      "Epoch number: 1213/10000step_number: 0/29 cost:  0.3860755923885035 accuracy:  0.9077907926995369\n",
      "Epoch number: 1214/10000step_number: 0/29 cost:  0.38585230761851746 accuracy:  0.9077907926995369\n",
      "Epoch number: 1215/10000step_number: 0/29 cost:  0.3856296283363793 accuracy:  0.9077907926995369\n",
      "Epoch number: 1216/10000step_number: 0/29 cost:  0.3854075187162525 accuracy:  0.9077907926995369\n",
      "Epoch number: 1217/10000step_number: 0/29 cost:  0.3851859334561053 accuracy:  0.9077907926995369\n",
      "Epoch number: 1218/10000step_number: 0/29 cost:  0.38496481769410634 accuracy:  0.9077907926995369\n",
      "Epoch number: 1219/10000step_number: 0/29 cost:  0.3847441077479239 accuracy:  0.9079269953691093\n",
      "Epoch number: 1220/10000step_number: 0/29 cost:  0.38452373287007036 accuracy:  0.9079269953691093\n",
      "Epoch number: 1221/10000step_number: 0/29 cost:  0.3843036181108902 accuracy:  0.9080631980386815\n",
      "Epoch number: 1222/10000step_number: 0/29 cost:  0.38408368821256944 accuracy:  0.9080631980386815\n",
      "Epoch number: 1223/10000step_number: 0/29 cost:  0.3838638722395656 accuracy:  0.9080631980386815\n",
      "Epoch number: 1224/10000step_number: 0/29 cost:  0.38364410842690244 accuracy:  0.9081994007082539\n",
      "Epoch number: 1225/10000step_number: 0/29 cost:  0.38342434856323054 accuracy:  0.9083356033778262\n",
      "Epoch number: 1226/10000step_number: 0/29 cost:  0.38320456118833257 accuracy:  0.9081994007082539\n",
      "Epoch number: 1227/10000step_number: 0/29 cost:  0.3829847330166343 accuracy:  0.9083356033778262\n",
      "Epoch number: 1228/10000step_number: 0/29 cost:  0.3827648682899511 accuracy:  0.9084718060473985\n",
      "Epoch number: 1229/10000step_number: 0/29 cost:  0.38254498614737437 accuracy:  0.9084718060473985\n",
      "Epoch number: 1230/10000step_number: 0/29 cost:  0.3823251164737403 accuracy:  0.9084718060473985\n",
      "Epoch number: 1231/10000step_number: 0/29 cost:  0.3821052949479383 accuracy:  0.9086080087169709\n",
      "Epoch number: 1232/10000step_number: 0/29 cost:  0.38188555809606695 accuracy:  0.9087442113865432\n",
      "Epoch number: 1233/10000step_number: 0/29 cost:  0.38166593905901586 accuracy:  0.9088804140561155\n",
      "Epoch number: 1234/10000step_number: 0/29 cost:  0.3814464645588026 accuracy:  0.9088804140561155\n",
      "Epoch number: 1235/10000step_number: 0/29 cost:  0.3812271532686963 accuracy:  0.9088804140561155\n",
      "Epoch number: 1236/10000step_number: 0/29 cost:  0.38100801553203256 accuracy:  0.9087442113865432\n",
      "Epoch number: 1237/10000step_number: 0/29 cost:  0.38078905418339576 accuracy:  0.9087442113865432\n",
      "Epoch number: 1238/10000step_number: 0/29 cost:  0.3805702661232092 accuracy:  0.9086080087169709\n",
      "Epoch number: 1239/10000step_number: 0/29 cost:  0.3803516442765085 accuracy:  0.9084718060473985\n",
      "Epoch number: 1240/10000step_number: 0/29 cost:  0.3801331796073329 accuracy:  0.9084718060473985\n",
      "Epoch number: 1241/10000step_number: 0/29 cost:  0.3799148629357997 accuracy:  0.9087442113865432\n",
      "Epoch number: 1242/10000step_number: 0/29 cost:  0.37969668639301224 accuracy:  0.9087442113865432\n",
      "Epoch number: 1243/10000step_number: 0/29 cost:  0.3794786444335079 accuracy:  0.9088804140561155\n",
      "Epoch number: 1244/10000step_number: 0/29 cost:  0.37926073439646585 accuracy:  0.9088804140561155\n",
      "Epoch number: 1245/10000step_number: 0/29 cost:  0.3790429566605528 accuracy:  0.9088804140561155\n",
      "Epoch number: 1246/10000step_number: 0/29 cost:  0.3788253144716665 accuracy:  0.9088804140561155\n",
      "Epoch number: 1247/10000step_number: 0/29 cost:  0.3786078135395666 accuracy:  0.9088804140561155\n",
      "Epoch number: 1248/10000step_number: 0/29 cost:  0.378390461502163 accuracy:  0.9088804140561155\n",
      "Epoch number: 1249/10000step_number: 0/29 cost:  0.37817326734950735 accuracy:  0.9088804140561155\n",
      "Epoch number: 1250/10000step_number: 0/29 cost:  0.3779562408856795 accuracy:  0.9090166167256878\n",
      "Epoch number: 1251/10000step_number: 0/29 cost:  0.37773939228586667 accuracy:  0.9090166167256878\n",
      "Epoch number: 1252/10000step_number: 0/29 cost:  0.3775227317779144 accuracy:  0.9088804140561155\n",
      "Epoch number: 1253/10000step_number: 0/29 cost:  0.3773062694462975 accuracy:  0.9088804140561155\n",
      "Epoch number: 1254/10000step_number: 0/29 cost:  0.37709001512992585 accuracy:  0.9090166167256878\n",
      "Epoch number: 1255/10000step_number: 0/29 cost:  0.3768739783718335 accuracy:  0.9090166167256878\n",
      "Epoch number: 1256/10000step_number: 0/29 cost:  0.37665816838170924 accuracy:  0.9091528193952602\n",
      "Epoch number: 1257/10000step_number: 0/29 cost:  0.3764425939870146 accuracy:  0.9091528193952602\n",
      "Epoch number: 1258/10000step_number: 0/29 cost:  0.37622726356623515 accuracy:  0.9091528193952602\n",
      "Epoch number: 1259/10000step_number: 0/29 cost:  0.3760121849706178 accuracy:  0.9091528193952602\n",
      "Epoch number: 1260/10000step_number: 0/29 cost:  0.37579736544547054 accuracy:  0.9091528193952602\n",
      "Epoch number: 1261/10000step_number: 0/29 cost:  0.3755828115602397 accuracy:  0.9091528193952602\n",
      "Epoch number: 1262/10000step_number: 0/29 cost:  0.37536852915176144 accuracy:  0.9091528193952602\n",
      "Epoch number: 1263/10000step_number: 0/29 cost:  0.37515452328030446 accuracy:  0.9092890220648324\n",
      "Epoch number: 1264/10000step_number: 0/29 cost:  0.3749407981947031 accuracy:  0.9092890220648324\n",
      "Epoch number: 1265/10000step_number: 0/29 cost:  0.37472735730106677 accuracy:  0.9091528193952602\n",
      "Epoch number: 1266/10000step_number: 0/29 cost:  0.37451420312871925 accuracy:  0.9091528193952602\n",
      "Epoch number: 1267/10000step_number: 0/29 cost:  0.37430133728643855 accuracy:  0.9090166167256878\n",
      "Epoch number: 1268/10000step_number: 0/29 cost:  0.3740887604010527 accuracy:  0.9091528193952602\n",
      "Epoch number: 1269/10000step_number: 0/29 cost:  0.37387647202833 accuracy:  0.9091528193952602\n",
      "Epoch number: 1270/10000step_number: 0/29 cost:  0.3736644705219181 accuracy:  0.9091528193952602\n",
      "Epoch number: 1271/10000step_number: 0/29 cost:  0.37345275283829027 accuracy:  0.9091528193952602\n",
      "Epoch number: 1272/10000step_number: 0/29 cost:  0.37324131424109885 accuracy:  0.9091528193952602\n",
      "Epoch number: 1273/10000step_number: 0/29 cost:  0.37303014784065863 accuracy:  0.9091528193952602\n",
      "Epoch number: 1274/10000step_number: 0/29 cost:  0.3728192438490953 accuracy:  0.9091528193952602\n",
      "Epoch number: 1275/10000step_number: 0/29 cost:  0.3726085883150698 accuracy:  0.9091528193952602\n",
      "Epoch number: 1276/10000step_number: 0/29 cost:  0.37239816083845745 accuracy:  0.9091528193952602\n",
      "Epoch number: 1277/10000step_number: 0/29 cost:  0.3721879301281291 accuracy:  0.9091528193952602\n",
      "Epoch number: 1278/10000step_number: 0/29 cost:  0.3719778446556296 accuracy:  0.9092890220648324\n",
      "Epoch number: 1279/10000step_number: 0/29 cost:  0.37176781194915953 accuracy:  0.9092890220648324\n",
      "Epoch number: 1280/10000step_number: 0/29 cost:  0.3715576599170858 accuracy:  0.9092890220648324\n",
      "Epoch number: 1281/10000step_number: 0/29 cost:  0.3713471790722679 accuracy:  0.9092890220648324\n",
      "Epoch number: 1282/10000step_number: 0/29 cost:  0.3711361017197964 accuracy:  0.9094252247344048\n",
      "Epoch number: 1283/10000step_number: 0/29 cost:  0.37092232813187614 accuracy:  0.9094252247344048\n",
      "Epoch number: 1284/10000step_number: 0/29 cost:  0.3707094710217701 accuracy:  0.9094252247344048\n",
      "Epoch number: 1285/10000step_number: 0/29 cost:  0.37049868310828543 accuracy:  0.9095614274039772\n",
      "Epoch number: 1286/10000step_number: 0/29 cost:  0.3702872860700763 accuracy:  0.9096976300735494\n",
      "Epoch number: 1287/10000step_number: 0/29 cost:  0.3700773893253608 accuracy:  0.9098338327431218\n",
      "Epoch number: 1288/10000step_number: 0/29 cost:  0.3698678275391807 accuracy:  0.9098338327431218\n",
      "Epoch number: 1289/10000step_number: 0/29 cost:  0.3696574107708908 accuracy:  0.9098338327431218\n",
      "Epoch number: 1290/10000step_number: 0/29 cost:  0.3694480848543998 accuracy:  0.9098338327431218\n",
      "Epoch number: 1291/10000step_number: 0/29 cost:  0.36923866275138034 accuracy:  0.9099700354126941\n",
      "Epoch number: 1292/10000step_number: 0/29 cost:  0.36902877073704 accuracy:  0.9099700354126941\n",
      "Epoch number: 1293/10000step_number: 0/29 cost:  0.3688196957701697 accuracy:  0.9099700354126941\n",
      "Epoch number: 1294/10000step_number: 0/29 cost:  0.36861035480380067 accuracy:  0.9099700354126941\n",
      "Epoch number: 1295/10000step_number: 0/29 cost:  0.36840075971631153 accuracy:  0.9101062380822664\n",
      "Epoch number: 1296/10000step_number: 0/29 cost:  0.3681918016176686 accuracy:  0.9101062380822664\n",
      "Epoch number: 1297/10000step_number: 0/29 cost:  0.3679824252051193 accuracy:  0.9101062380822664\n",
      "Epoch number: 1298/10000step_number: 0/29 cost:  0.3677730094306844 accuracy:  0.9101062380822664\n",
      "Epoch number: 1299/10000step_number: 0/29 cost:  0.3675639263382819 accuracy:  0.9101062380822664\n",
      "Epoch number: 1300/10000step_number: 0/29 cost:  0.36735440831971533 accuracy:  0.9101062380822664\n",
      "Epoch number: 1301/10000step_number: 0/29 cost:  0.367144864232002 accuracy:  0.9103786434214111\n",
      "Epoch number: 1302/10000step_number: 0/29 cost:  0.36693541679605846 accuracy:  0.9102424407518387\n",
      "Epoch number: 1303/10000step_number: 0/29 cost:  0.3667254610396863 accuracy:  0.9105148460909834\n",
      "Epoch number: 1304/10000step_number: 0/29 cost:  0.3665154719525971 accuracy:  0.9103786434214111\n",
      "Epoch number: 1305/10000step_number: 0/29 cost:  0.36630531634809954 accuracy:  0.9103786434214111\n",
      "Epoch number: 1306/10000step_number: 0/29 cost:  0.3660946809670852 accuracy:  0.9105148460909834\n",
      "Epoch number: 1307/10000step_number: 0/29 cost:  0.3658839853704084 accuracy:  0.9107872514301281\n",
      "Epoch number: 1308/10000step_number: 0/29 cost:  0.3656731010764814 accuracy:  0.9109234540997003\n",
      "Epoch number: 1309/10000step_number: 0/29 cost:  0.36546203209957867 accuracy:  0.9109234540997003\n",
      "Epoch number: 1310/10000step_number: 0/29 cost:  0.3652513790533837 accuracy:  0.9107872514301281\n",
      "Epoch number: 1311/10000step_number: 0/29 cost:  0.36504135503058877 accuracy:  0.9107872514301281\n",
      "Epoch number: 1312/10000step_number: 0/29 cost:  0.36483272227311264 accuracy:  0.9107872514301281\n",
      "Epoch number: 1313/10000step_number: 0/29 cost:  0.3646267154315724 accuracy:  0.9107872514301281\n",
      "Epoch number: 1314/10000step_number: 0/29 cost:  0.3644243577129594 accuracy:  0.9107872514301281\n",
      "Epoch number: 1315/10000step_number: 0/29 cost:  0.364226875823442 accuracy:  0.9107872514301281\n",
      "Epoch number: 1316/10000step_number: 0/29 cost:  0.3640347039886015 accuracy:  0.9109234540997003\n",
      "Epoch number: 1317/10000step_number: 0/29 cost:  0.36384672392252027 accuracy:  0.9109234540997003\n",
      "Epoch number: 1318/10000step_number: 0/29 cost:  0.36366113360783153 accuracy:  0.9109234540997003\n",
      "Epoch number: 1319/10000step_number: 0/29 cost:  0.363475900264442 accuracy:  0.9109234540997003\n",
      "Epoch number: 1320/10000step_number: 0/29 cost:  0.3632897752425992 accuracy:  0.911195859438845\n",
      "Epoch number: 1321/10000step_number: 0/29 cost:  0.36310254429728955 accuracy:  0.9113320621084173\n",
      "Epoch number: 1322/10000step_number: 0/29 cost:  0.3629139494514634 accuracy:  0.9113320621084173\n",
      "Epoch number: 1323/10000step_number: 0/29 cost:  0.3627238726928327 accuracy:  0.9113320621084173\n",
      "Epoch number: 1324/10000step_number: 0/29 cost:  0.36253224089509867 accuracy:  0.911604467447562\n",
      "Epoch number: 1325/10000step_number: 0/29 cost:  0.362338759303045 accuracy:  0.9124216834649959\n",
      "Epoch number: 1326/10000step_number: 0/29 cost:  0.3621435726677983 accuracy:  0.9124216834649959\n",
      "Epoch number: 1327/10000step_number: 0/29 cost:  0.3619467631123794 accuracy:  0.9124216834649959\n",
      "Epoch number: 1328/10000step_number: 0/29 cost:  0.36174842339923585 accuracy:  0.9122854807954236\n",
      "Epoch number: 1329/10000step_number: 0/29 cost:  0.36154894664603165 accuracy:  0.9122854807954236\n",
      "Epoch number: 1330/10000step_number: 0/29 cost:  0.3613484569746872 accuracy:  0.9124216834649959\n",
      "Epoch number: 1331/10000step_number: 0/29 cost:  0.361147215321969 accuracy:  0.9122854807954236\n",
      "Epoch number: 1332/10000step_number: 0/29 cost:  0.3609455418141772 accuracy:  0.9121492781258512\n",
      "Epoch number: 1333/10000step_number: 0/29 cost:  0.36074352924914904 accuracy:  0.9121492781258512\n",
      "Epoch number: 1334/10000step_number: 0/29 cost:  0.3605415184665307 accuracy:  0.9121492781258512\n",
      "Epoch number: 1335/10000step_number: 0/29 cost:  0.3603398904548766 accuracy:  0.9121492781258512\n",
      "Epoch number: 1336/10000step_number: 0/29 cost:  0.3601400941230796 accuracy:  0.9121492781258512\n",
      "Epoch number: 1337/10000step_number: 0/29 cost:  0.3599490159346757 accuracy:  0.912013075456279\n",
      "Epoch number: 1338/10000step_number: 0/29 cost:  0.35972091584251453 accuracy:  0.912013075456279\n",
      "Epoch number: 1339/10000step_number: 0/29 cost:  0.35951745182765393 accuracy:  0.912013075456279\n",
      "Epoch number: 1340/10000step_number: 0/29 cost:  0.35932440316620523 accuracy:  0.912013075456279\n",
      "Epoch number: 1341/10000step_number: 0/29 cost:  0.35912378630199837 accuracy:  0.9121492781258512\n",
      "Epoch number: 1342/10000step_number: 0/29 cost:  0.35892053159424764 accuracy:  0.9121492781258512\n",
      "Epoch number: 1343/10000step_number: 0/29 cost:  0.35873859139028724 accuracy:  0.9121492781258512\n",
      "Epoch number: 1344/10000step_number: 0/29 cost:  0.3585291854671525 accuracy:  0.9121492781258512\n",
      "Epoch number: 1345/10000step_number: 0/29 cost:  0.35834001927959275 accuracy:  0.9121492781258512\n",
      "Epoch number: 1346/10000step_number: 0/29 cost:  0.3581446489583394 accuracy:  0.9124216834649959\n",
      "Epoch number: 1347/10000step_number: 0/29 cost:  0.3579423654192286 accuracy:  0.9124216834649959\n",
      "Epoch number: 1348/10000step_number: 0/29 cost:  0.3577519464272682 accuracy:  0.9124216834649959\n",
      "Epoch number: 1349/10000step_number: 0/29 cost:  0.35755412710862877 accuracy:  0.9124216834649959\n",
      "Epoch number: 1350/10000step_number: 0/29 cost:  0.3573538261084854 accuracy:  0.9125578861345682\n",
      "Epoch number: 1351/10000step_number: 0/29 cost:  0.3571647058376864 accuracy:  0.9125578861345682\n",
      "Epoch number: 1352/10000step_number: 0/29 cost:  0.3569623087580778 accuracy:  0.9125578861345682\n",
      "Epoch number: 1353/10000step_number: 0/29 cost:  0.3567693576669069 accuracy:  0.9125578861345682\n",
      "Epoch number: 1354/10000step_number: 0/29 cost:  0.3565744980464166 accuracy:  0.9125578861345682\n",
      "Epoch number: 1355/10000step_number: 0/29 cost:  0.3563763420401336 accuracy:  0.9126940888041406\n",
      "Epoch number: 1356/10000step_number: 0/29 cost:  0.35618336311983056 accuracy:  0.9126940888041406\n",
      "Epoch number: 1357/10000step_number: 0/29 cost:  0.3559885961898368 accuracy:  0.9128302914737129\n",
      "Epoch number: 1358/10000step_number: 0/29 cost:  0.35579169944390826 accuracy:  0.9128302914737129\n",
      "Epoch number: 1359/10000step_number: 0/29 cost:  0.3556006813364649 accuracy:  0.9128302914737129\n",
      "Epoch number: 1360/10000step_number: 0/29 cost:  0.3554041730756627 accuracy:  0.9128302914737129\n",
      "Epoch number: 1361/10000step_number: 0/29 cost:  0.35521127544107506 accuracy:  0.9129664941432852\n",
      "Epoch number: 1362/10000step_number: 0/29 cost:  0.3550183956619703 accuracy:  0.9131026968128575\n",
      "Epoch number: 1363/10000step_number: 0/29 cost:  0.3548238829212279 accuracy:  0.9129664941432852\n",
      "Epoch number: 1364/10000step_number: 0/29 cost:  0.35463139322751375 accuracy:  0.9129664941432852\n",
      "Epoch number: 1365/10000step_number: 0/29 cost:  0.3544386936907663 accuracy:  0.9129664941432852\n",
      "Epoch number: 1366/10000step_number: 0/29 cost:  0.354244557295725 accuracy:  0.9129664941432852\n",
      "Epoch number: 1367/10000step_number: 0/29 cost:  0.3540530445779165 accuracy:  0.9129664941432852\n",
      "Epoch number: 1368/10000step_number: 0/29 cost:  0.3538592443407451 accuracy:  0.9129664941432852\n",
      "Epoch number: 1369/10000step_number: 0/29 cost:  0.3536665830399246 accuracy:  0.9129664941432852\n",
      "Epoch number: 1370/10000step_number: 0/29 cost:  0.35347400109887545 accuracy:  0.9129664941432852\n",
      "Epoch number: 1371/10000step_number: 0/29 cost:  0.3532805685424409 accuracy:  0.9129664941432852\n",
      "Epoch number: 1372/10000step_number: 0/29 cost:  0.353087654727545 accuracy:  0.9129664941432852\n",
      "Epoch number: 1373/10000step_number: 0/29 cost:  0.3528946836343831 accuracy:  0.9128302914737129\n",
      "Epoch number: 1374/10000step_number: 0/29 cost:  0.3527007595648303 accuracy:  0.9128302914737129\n",
      "Epoch number: 1375/10000step_number: 0/29 cost:  0.3525077404568435 accuracy:  0.9128302914737129\n",
      "Epoch number: 1376/10000step_number: 0/29 cost:  0.35231358246771416 accuracy:  0.9128302914737129\n",
      "Epoch number: 1377/10000step_number: 0/29 cost:  0.3521195786382342 accuracy:  0.9128302914737129\n",
      "Epoch number: 1378/10000step_number: 0/29 cost:  0.3519253364756882 accuracy:  0.9128302914737129\n",
      "Epoch number: 1379/10000step_number: 0/29 cost:  0.3517305002205897 accuracy:  0.9129664941432852\n",
      "Epoch number: 1380/10000step_number: 0/29 cost:  0.3515354633371708 accuracy:  0.9129664941432852\n",
      "Epoch number: 1381/10000step_number: 0/29 cost:  0.3513401432965561 accuracy:  0.9129664941432852\n",
      "Epoch number: 1382/10000step_number: 0/29 cost:  0.3511440207974213 accuracy:  0.9129664941432852\n",
      "Epoch number: 1383/10000step_number: 0/29 cost:  0.3509479007660605 accuracy:  0.9129664941432852\n",
      "Epoch number: 1384/10000step_number: 0/29 cost:  0.35075091401803066 accuracy:  0.9129664941432852\n",
      "Epoch number: 1385/10000step_number: 0/29 cost:  0.3505536017753784 accuracy:  0.9129664941432852\n",
      "Epoch number: 1386/10000step_number: 0/29 cost:  0.3503557366893225 accuracy:  0.9129664941432852\n",
      "Epoch number: 1387/10000step_number: 0/29 cost:  0.3501572770807249 accuracy:  0.9129664941432852\n",
      "Epoch number: 1388/10000step_number: 0/29 cost:  0.34995826909922323 accuracy:  0.9129664941432852\n",
      "Epoch number: 1389/10000step_number: 0/29 cost:  0.3497587867818838 accuracy:  0.9129664941432852\n",
      "Epoch number: 1390/10000step_number: 0/29 cost:  0.34955855123690915 accuracy:  0.9129664941432852\n",
      "Epoch number: 1391/10000step_number: 0/29 cost:  0.3493579358597377 accuracy:  0.9128302914737129\n",
      "Epoch number: 1392/10000step_number: 0/29 cost:  0.34915653464942603 accuracy:  0.9128302914737129\n",
      "Epoch number: 1393/10000step_number: 0/29 cost:  0.3489546143803105 accuracy:  0.9128302914737129\n",
      "Epoch number: 1394/10000step_number: 0/29 cost:  0.34875197358070703 accuracy:  0.9128302914737129\n",
      "Epoch number: 1395/10000step_number: 0/29 cost:  0.3485486674797319 accuracy:  0.9126940888041406\n",
      "Epoch number: 1396/10000step_number: 0/29 cost:  0.34834458179561323 accuracy:  0.9126940888041406\n",
      "Epoch number: 1397/10000step_number: 0/29 cost:  0.348139797340289 accuracy:  0.9128302914737129\n",
      "Epoch number: 1398/10000step_number: 0/29 cost:  0.3479340971513067 accuracy:  0.9131026968128575\n",
      "Epoch number: 1399/10000step_number: 0/29 cost:  0.3477276622318401 accuracy:  0.9131026968128575\n",
      "Epoch number: 1400/10000step_number: 0/29 cost:  0.34752023762661366 accuracy:  0.9131026968128575\n",
      "Epoch number: 1401/10000step_number: 0/29 cost:  0.3473119867562559 accuracy:  0.9132388994824299\n",
      "Epoch number: 1402/10000step_number: 0/29 cost:  0.34710272821570765 accuracy:  0.9132388994824299\n",
      "Epoch number: 1403/10000step_number: 0/29 cost:  0.34689257563858 accuracy:  0.9132388994824299\n",
      "Epoch number: 1404/10000step_number: 0/29 cost:  0.34668139499670086 accuracy:  0.9133751021520021\n",
      "Epoch number: 1405/10000step_number: 0/29 cost:  0.34646932557050103 accuracy:  0.9133751021520021\n",
      "Epoch number: 1406/10000step_number: 0/29 cost:  0.3462562253027379 accuracy:  0.9133751021520021\n",
      "Epoch number: 1407/10000step_number: 0/29 cost:  0.3460422894640432 accuracy:  0.9135113048215745\n",
      "Epoch number: 1408/10000step_number: 0/29 cost:  0.34582738301653154 accuracy:  0.9135113048215745\n",
      "Epoch number: 1409/10000step_number: 0/29 cost:  0.3456117202666864 accuracy:  0.9135113048215745\n",
      "Epoch number: 1410/10000step_number: 0/29 cost:  0.34539519561355675 accuracy:  0.9133751021520021\n",
      "Epoch number: 1411/10000step_number: 0/29 cost:  0.3451780111104514 accuracy:  0.9133751021520021\n",
      "Epoch number: 1412/10000step_number: 0/29 cost:  0.34496005601329727 accuracy:  0.9133751021520021\n",
      "Epoch number: 1413/10000step_number: 0/29 cost:  0.34474150343670296 accuracy:  0.9133751021520021\n",
      "Epoch number: 1414/10000step_number: 0/29 cost:  0.3445221774865186 accuracy:  0.9135113048215745\n",
      "Epoch number: 1415/10000step_number: 0/29 cost:  0.3443021891249481 accuracy:  0.9135113048215745\n",
      "Epoch number: 1416/10000step_number: 0/29 cost:  0.344081263741655 accuracy:  0.9133751021520021\n",
      "Epoch number: 1417/10000step_number: 0/29 cost:  0.3438594174727304 accuracy:  0.9133751021520021\n",
      "Epoch number: 1418/10000step_number: 0/29 cost:  0.34363627943397296 accuracy:  0.9133751021520021\n",
      "Epoch number: 1419/10000step_number: 0/29 cost:  0.3434117780746558 accuracy:  0.9133751021520021\n",
      "Epoch number: 1420/10000step_number: 0/29 cost:  0.3431854704044462 accuracy:  0.9133751021520021\n",
      "Epoch number: 1421/10000step_number: 0/29 cost:  0.34295723926579375 accuracy:  0.9135113048215745\n",
      "Epoch number: 1422/10000step_number: 0/29 cost:  0.3427266021075508 accuracy:  0.9136475074911469\n",
      "Epoch number: 1423/10000step_number: 0/29 cost:  0.34249343651397235 accuracy:  0.9137837101607191\n",
      "Epoch number: 1424/10000step_number: 0/29 cost:  0.3422572483013845 accuracy:  0.9137837101607191\n",
      "Epoch number: 1425/10000step_number: 0/29 cost:  0.34201792899166866 accuracy:  0.9137837101607191\n",
      "Epoch number: 1426/10000step_number: 0/29 cost:  0.3417749840676556 accuracy:  0.9136475074911469\n",
      "Epoch number: 1427/10000step_number: 0/29 cost:  0.34152832228311514 accuracy:  0.9137837101607191\n",
      "Epoch number: 1428/10000step_number: 0/29 cost:  0.3412774424051745 accuracy:  0.9137837101607191\n",
      "Epoch number: 1429/10000step_number: 0/29 cost:  0.34102226751003134 accuracy:  0.9137837101607191\n",
      "Epoch number: 1430/10000step_number: 0/29 cost:  0.34076227682353016 accuracy:  0.9139199128302915\n",
      "Epoch number: 1431/10000step_number: 0/29 cost:  0.34049740536974366 accuracy:  0.9144647235085808\n",
      "Epoch number: 1432/10000step_number: 0/29 cost:  0.34022710624323893 accuracy:  0.9143285208390084\n",
      "Epoch number: 1433/10000step_number: 0/29 cost:  0.33995133226176033 accuracy:  0.9143285208390084\n",
      "Epoch number: 1434/10000step_number: 0/29 cost:  0.33966951671852236 accuracy:  0.9143285208390084\n",
      "Epoch number: 1435/10000step_number: 0/29 cost:  0.33938165269538595 accuracy:  0.9143285208390084\n",
      "Epoch number: 1436/10000step_number: 0/29 cost:  0.33908717696199403 accuracy:  0.9155543448651594\n",
      "Epoch number: 1437/10000step_number: 0/29 cost:  0.33878616847753723 accuracy:  0.9155543448651594\n",
      "Epoch number: 1438/10000step_number: 0/29 cost:  0.33847811366450786 accuracy:  0.9155543448651594\n",
      "Epoch number: 1439/10000step_number: 0/29 cost:  0.3381632503821125 accuracy:  0.9162353582130209\n",
      "Epoch number: 1440/10000step_number: 0/29 cost:  0.3378411882693325 accuracy:  0.9162353582130209\n",
      "Epoch number: 1441/10000step_number: 0/29 cost:  0.33751242428080047 accuracy:  0.9162353582130209\n",
      "Epoch number: 1442/10000step_number: 0/29 cost:  0.33717678625796976 accuracy:  0.9162353582130209\n",
      "Epoch number: 1443/10000step_number: 0/29 cost:  0.3368351440650338 accuracy:  0.9162353582130209\n",
      "Epoch number: 1444/10000step_number: 0/29 cost:  0.3364876333549718 accuracy:  0.9162353582130209\n",
      "Epoch number: 1445/10000step_number: 0/29 cost:  0.33613558530575255 accuracy:  0.9162353582130209\n",
      "Epoch number: 1446/10000step_number: 0/29 cost:  0.3357794725079967 accuracy:  0.9166439662217379\n",
      "Epoch number: 1447/10000step_number: 0/29 cost:  0.3354210820637108 accuracy:  0.9174611822391718\n",
      "Epoch number: 1448/10000step_number: 0/29 cost:  0.3350611016993569 accuracy:  0.9174611822391718\n",
      "Epoch number: 1449/10000step_number: 0/29 cost:  0.33470151528551445 accuracy:  0.9174611822391718\n",
      "Epoch number: 1450/10000step_number: 0/29 cost:  0.3343423651101531 accuracy:  0.9174611822391718\n",
      "Epoch number: 1451/10000step_number: 0/29 cost:  0.3339826979314441 accuracy:  0.9174611822391718\n",
      "Epoch number: 1452/10000step_number: 0/29 cost:  0.3336252074460127 accuracy:  0.9174611822391718\n",
      "Epoch number: 1453/10000step_number: 0/29 cost:  0.3332812736456838 accuracy:  0.9174611822391718\n",
      "Epoch number: 1454/10000step_number: 0/29 cost:  0.3329460926746184 accuracy:  0.9174611822391718\n",
      "Epoch number: 1455/10000step_number: 0/29 cost:  0.33261655721615646 accuracy:  0.9175973849087442\n",
      "Epoch number: 1456/10000step_number: 0/29 cost:  0.33229524901106783 accuracy:  0.9175973849087442\n",
      "Epoch number: 1457/10000step_number: 0/29 cost:  0.3319811362135074 accuracy:  0.9175973849087442\n",
      "Epoch number: 1458/10000step_number: 0/29 cost:  0.33167486777479555 accuracy:  0.9175973849087442\n",
      "Epoch number: 1459/10000step_number: 0/29 cost:  0.33137497725663173 accuracy:  0.9175973849087442\n",
      "Epoch number: 1460/10000step_number: 0/29 cost:  0.3310827942453679 accuracy:  0.9177335875783166\n",
      "Epoch number: 1461/10000step_number: 0/29 cost:  0.3307958926170777 accuracy:  0.9177335875783166\n",
      "Epoch number: 1462/10000step_number: 0/29 cost:  0.33051624221019105 accuracy:  0.9178697902478888\n",
      "Epoch number: 1463/10000step_number: 0/29 cost:  0.33024063508218626 accuracy:  0.9178697902478888\n",
      "Epoch number: 1464/10000step_number: 0/29 cost:  0.3299719625457923 accuracy:  0.9180059929174612\n",
      "Epoch number: 1465/10000step_number: 0/29 cost:  0.32970583642504486 accuracy:  0.9178697902478888\n",
      "Epoch number: 1466/10000step_number: 0/29 cost:  0.3294468069132526 accuracy:  0.9180059929174612\n",
      "Epoch number: 1467/10000step_number: 0/29 cost:  0.329188419297536 accuracy:  0.9181421955870335\n",
      "Epoch number: 1468/10000step_number: 0/29 cost:  0.3289380097272873 accuracy:  0.9181421955870335\n",
      "Epoch number: 1469/10000step_number: 0/29 cost:  0.32868568548280885 accuracy:  0.9181421955870335\n",
      "Epoch number: 1470/10000step_number: 0/29 cost:  0.3284432676726808 accuracy:  0.9181421955870335\n",
      "Epoch number: 1471/10000step_number: 0/29 cost:  0.3281952045192443 accuracy:  0.9181421955870335\n",
      "Epoch number: 1472/10000step_number: 0/29 cost:  0.3279606492794438 accuracy:  0.9181421955870335\n",
      "Epoch number: 1473/10000step_number: 0/29 cost:  0.32771457405621485 accuracy:  0.9181421955870335\n",
      "Epoch number: 1474/10000step_number: 0/29 cost:  0.32748837656591956 accuracy:  0.9181421955870335\n",
      "Epoch number: 1475/10000step_number: 0/29 cost:  0.32724099638108395 accuracy:  0.9181421955870335\n",
      "Epoch number: 1476/10000step_number: 0/29 cost:  0.32702447693593933 accuracy:  0.9182783982566058\n",
      "Epoch number: 1477/10000step_number: 0/29 cost:  0.3267705649684968 accuracy:  0.9182783982566058\n",
      "Epoch number: 1478/10000step_number: 0/29 cost:  0.3265662916875737 accuracy:  0.9182783982566058\n",
      "Epoch number: 1479/10000step_number: 0/29 cost:  0.32629752892671227 accuracy:  0.9180059929174612\n",
      "Epoch number: 1480/10000step_number: 0/29 cost:  0.32611050081210463 accuracy:  0.9181421955870335\n",
      "Epoch number: 1481/10000step_number: 0/29 cost:  0.32581657929463664 accuracy:  0.9180059929174612\n",
      "Epoch number: 1482/10000step_number: 0/29 cost:  0.32565618682684055 accuracy:  0.9180059929174612\n",
      "Epoch number: 1483/10000step_number: 0/29 cost:  0.32533491805251163 accuracy:  0.9180059929174612\n",
      "Epoch number: 1484/10000step_number: 0/29 cost:  0.3252059988330977 accuracy:  0.9180059929174612\n",
      "Epoch number: 1485/10000step_number: 0/29 cost:  0.3248685465852757 accuracy:  0.9180059929174612\n",
      "Epoch number: 1486/10000step_number: 0/29 cost:  0.32475539630997435 accuracy:  0.9180059929174612\n",
      "Epoch number: 1487/10000step_number: 0/29 cost:  0.32440136898263666 accuracy:  0.9180059929174612\n",
      "Epoch number: 1488/10000step_number: 0/29 cost:  0.32430004327837797 accuracy:  0.9180059929174612\n",
      "Epoch number: 1489/10000step_number: 0/29 cost:  0.3239323472286199 accuracy:  0.9178697902478888\n",
      "Epoch number: 1490/10000step_number: 0/29 cost:  0.32383820368280963 accuracy:  0.9180059929174612\n",
      "Epoch number: 1491/10000step_number: 0/29 cost:  0.32347013984843975 accuracy:  0.9178697902478888\n",
      "Epoch number: 1492/10000step_number: 0/29 cost:  0.3233686837263845 accuracy:  0.9178697902478888\n",
      "Epoch number: 1493/10000step_number: 0/29 cost:  0.32299750215741974 accuracy:  0.9177335875783166\n",
      "Epoch number: 1494/10000step_number: 0/29 cost:  0.3228933751681858 accuracy:  0.9178697902478888\n",
      "Epoch number: 1495/10000step_number: 0/29 cost:  0.32251877123726314 accuracy:  0.9175973849087442\n",
      "Epoch number: 1496/10000step_number: 0/29 cost:  0.3224107334204908 accuracy:  0.9177335875783166\n",
      "Epoch number: 1497/10000step_number: 0/29 cost:  0.3220368530097383 accuracy:  0.9175973849087442\n",
      "Epoch number: 1498/10000step_number: 0/29 cost:  0.32192036222501247 accuracy:  0.9175973849087442\n",
      "Epoch number: 1499/10000step_number: 0/29 cost:  0.3215452822343109 accuracy:  0.9175973849087442\n",
      "Epoch number: 1500/10000step_number: 0/29 cost:  0.32142249080475466 accuracy:  0.9175973849087442\n",
      "Epoch number: 1501/10000step_number: 0/29 cost:  0.3210457197489538 accuracy:  0.9173249795695996\n",
      "Epoch number: 1502/10000step_number: 0/29 cost:  0.3209160773288414 accuracy:  0.9175973849087442\n",
      "Epoch number: 1503/10000step_number: 0/29 cost:  0.32053924822126034 accuracy:  0.9173249795695996\n",
      "Epoch number: 1504/10000step_number: 0/29 cost:  0.3204008584686938 accuracy:  0.9173249795695996\n",
      "Epoch number: 1505/10000step_number: 0/29 cost:  0.32002362589121647 accuracy:  0.9173249795695996\n",
      "Epoch number: 1506/10000step_number: 0/29 cost:  0.3198766623437427 accuracy:  0.9173249795695996\n",
      "Epoch number: 1507/10000step_number: 0/29 cost:  0.31949872135207413 accuracy:  0.9174611822391718\n",
      "Epoch number: 1508/10000step_number: 0/29 cost:  0.31934283216129866 accuracy:  0.9173249795695996\n",
      "Epoch number: 1509/10000step_number: 0/29 cost:  0.31896507272446134 accuracy:  0.9173249795695996\n",
      "Epoch number: 1510/10000step_number: 0/29 cost:  0.31879905927940516 accuracy:  0.9173249795695996\n",
      "Epoch number: 1511/10000step_number: 0/29 cost:  0.3184221001806888 accuracy:  0.9171887769000272\n",
      "Epoch number: 1512/10000step_number: 0/29 cost:  0.31824528509075845 accuracy:  0.9171887769000272\n",
      "Epoch number: 1513/10000step_number: 0/29 cost:  0.317869418575993 accuracy:  0.9171887769000272\n",
      "Epoch number: 1514/10000step_number: 0/29 cost:  0.3176813096477043 accuracy:  0.9171887769000272\n",
      "Epoch number: 1515/10000step_number: 0/29 cost:  0.3173072340185003 accuracy:  0.9171887769000272\n",
      "Epoch number: 1516/10000step_number: 0/29 cost:  0.3171070258781737 accuracy:  0.9171887769000272\n",
      "Epoch number: 1517/10000step_number: 0/29 cost:  0.31673557589809087 accuracy:  0.9171887769000272\n",
      "Epoch number: 1518/10000step_number: 0/29 cost:  0.316522586954303 accuracy:  0.9171887769000272\n",
      "Epoch number: 1519/10000step_number: 0/29 cost:  0.31615425036389605 accuracy:  0.9171887769000272\n",
      "Epoch number: 1520/10000step_number: 0/29 cost:  0.3159281766015699 accuracy:  0.9171887769000272\n",
      "Epoch number: 1521/10000step_number: 0/29 cost:  0.31556320859474274 accuracy:  0.9173249795695996\n",
      "Epoch number: 1522/10000step_number: 0/29 cost:  0.31532390485882367 accuracy:  0.9173249795695996\n",
      "Epoch number: 1523/10000step_number: 0/29 cost:  0.31496245155906444 accuracy:  0.9173249795695996\n",
      "Epoch number: 1524/10000step_number: 0/29 cost:  0.3147099601702471 accuracy:  0.9173249795695996\n",
      "Epoch number: 1525/10000step_number: 0/29 cost:  0.31435188308177536 accuracy:  0.9173249795695996\n",
      "Epoch number: 1526/10000step_number: 0/29 cost:  0.3140866078321698 accuracy:  0.9173249795695996\n",
      "Epoch number: 1527/10000step_number: 0/29 cost:  0.3137314952612807 accuracy:  0.9173249795695996\n",
      "Epoch number: 1528/10000step_number: 0/29 cost:  0.31345408999805024 accuracy:  0.9174611822391718\n",
      "Epoch number: 1529/10000step_number: 0/29 cost:  0.3131014566316367 accuracy:  0.9173249795695996\n",
      "Epoch number: 1530/10000step_number: 0/29 cost:  0.3128127460382089 accuracy:  0.9173249795695996\n",
      "Epoch number: 1531/10000step_number: 0/29 cost:  0.31246211175397415 accuracy:  0.9173249795695996\n",
      "Epoch number: 1532/10000step_number: 0/29 cost:  0.31216320762987537 accuracy:  0.9173249795695996\n",
      "Epoch number: 1533/10000step_number: 0/29 cost:  0.3118142213166599 accuracy:  0.9173249795695996\n",
      "Epoch number: 1534/10000step_number: 0/29 cost:  0.31150656202109556 accuracy:  0.9173249795695996\n",
      "Epoch number: 1535/10000step_number: 0/29 cost:  0.31115917850412567 accuracy:  0.9171887769000272\n",
      "Epoch number: 1536/10000step_number: 0/29 cost:  0.31084450707400085 accuracy:  0.9171887769000272\n",
      "Epoch number: 1537/10000step_number: 0/29 cost:  0.31049903497869596 accuracy:  0.9171887769000272\n",
      "Epoch number: 1538/10000step_number: 0/29 cost:  0.31017937213040314 accuracy:  0.9171887769000272\n",
      "Epoch number: 1539/10000step_number: 0/29 cost:  0.30983647728404073 accuracy:  0.9174611822391718\n",
      "Epoch number: 1540/10000step_number: 0/29 cost:  0.30951404922677606 accuracy:  0.9174611822391718\n",
      "Epoch number: 1541/10000step_number: 0/29 cost:  0.30917473793289263 accuracy:  0.9174611822391718\n",
      "Epoch number: 1542/10000step_number: 0/29 cost:  0.3088518880272333 accuracy:  0.9174611822391718\n",
      "Epoch number: 1543/10000step_number: 0/29 cost:  0.3085174203584948 accuracy:  0.9174611822391718\n",
      "Epoch number: 1544/10000step_number: 0/29 cost:  0.3081964861771891 accuracy:  0.9173249795695996\n",
      "Epoch number: 1545/10000step_number: 0/29 cost:  0.3078682293248863 accuracy:  0.9173249795695996\n",
      "Epoch number: 1546/10000step_number: 0/29 cost:  0.3075513780753065 accuracy:  0.9175973849087442\n",
      "Epoch number: 1547/10000step_number: 0/29 cost:  0.3072306155153726 accuracy:  0.9175973849087442\n",
      "Epoch number: 1548/10000step_number: 0/29 cost:  0.3069196670538986 accuracy:  0.9177335875783166\n",
      "Epoch number: 1549/10000step_number: 0/29 cost:  0.3066074026141582 accuracy:  0.9177335875783166\n",
      "Epoch number: 1550/10000step_number: 0/29 cost:  0.30630367220534627 accuracy:  0.9177335875783166\n",
      "Epoch number: 1551/10000step_number: 0/29 cost:  0.30600046917237794 accuracy:  0.9177335875783166\n",
      "Epoch number: 1552/10000step_number: 0/29 cost:  0.30570466019960507 accuracy:  0.9178697902478888\n",
      "Epoch number: 1553/10000step_number: 0/29 cost:  0.30541053705467464 accuracy:  0.9178697902478888\n",
      "Epoch number: 1554/10000step_number: 0/29 cost:  0.3051226871877951 accuracy:  0.9177335875783166\n",
      "Epoch number: 1555/10000step_number: 0/29 cost:  0.30483705935891797 accuracy:  0.9175973849087442\n",
      "Epoch number: 1556/10000step_number: 0/29 cost:  0.3045565068332976 accuracy:  0.9178697902478888\n",
      "Epoch number: 1557/10000step_number: 0/29 cost:  0.304278118322991 accuracy:  0.9178697902478888\n",
      "Epoch number: 1558/10000step_number: 0/29 cost:  0.30400340359637834 accuracy:  0.9178697902478888\n",
      "Epoch number: 1559/10000step_number: 0/29 cost:  0.3037301282483142 accuracy:  0.9178697902478888\n",
      "Epoch number: 1560/10000step_number: 0/29 cost:  0.303458665606388 accuracy:  0.9178697902478888\n",
      "Epoch number: 1561/10000step_number: 0/29 cost:  0.3031869647109016 accuracy:  0.9178697902478888\n",
      "Epoch number: 1562/10000step_number: 0/29 cost:  0.3029142757699111 accuracy:  0.9178697902478888\n",
      "Epoch number: 1563/10000step_number: 0/29 cost:  0.3026383753633761 accuracy:  0.9178697902478888\n",
      "Epoch number: 1564/10000step_number: 0/29 cost:  0.3023582203846137 accuracy:  0.9178697902478888\n",
      "Epoch number: 1565/10000step_number: 0/29 cost:  0.3020746308328142 accuracy:  0.9178697902478888\n",
      "Epoch number: 1566/10000step_number: 0/29 cost:  0.30179638327871716 accuracy:  0.9177335875783166\n",
      "Epoch number: 1567/10000step_number: 0/29 cost:  0.3015435066749911 accuracy:  0.9178697902478888\n",
      "Epoch number: 1568/10000step_number: 0/29 cost:  0.3013328351354261 accuracy:  0.9180059929174612\n",
      "Epoch number: 1569/10000step_number: 0/29 cost:  0.30115183339532187 accuracy:  0.9178697902478888\n",
      "Epoch number: 1570/10000step_number: 0/29 cost:  0.30097958706090616 accuracy:  0.9178697902478888\n",
      "Epoch number: 1571/10000step_number: 0/29 cost:  0.3008095794258045 accuracy:  0.9178697902478888\n",
      "Epoch number: 1572/10000step_number: 0/29 cost:  0.30063513993656876 accuracy:  0.9181421955870335\n",
      "Epoch number: 1573/10000step_number: 0/29 cost:  0.30045710788877295 accuracy:  0.9181421955870335\n",
      "Epoch number: 1574/10000step_number: 0/29 cost:  0.3002786318754647 accuracy:  0.9182783982566058\n",
      "Epoch number: 1575/10000step_number: 0/29 cost:  0.3000966425630042 accuracy:  0.9184146009261781\n",
      "Epoch number: 1576/10000step_number: 0/29 cost:  0.29991415857168424 accuracy:  0.9184146009261781\n",
      "Epoch number: 1577/10000step_number: 0/29 cost:  0.29973086546588595 accuracy:  0.9184146009261781\n",
      "Epoch number: 1578/10000step_number: 0/29 cost:  0.299545982170725 accuracy:  0.9184146009261781\n",
      "Epoch number: 1579/10000step_number: 0/29 cost:  0.29936189883747877 accuracy:  0.9184146009261781\n",
      "Epoch number: 1580/10000step_number: 0/29 cost:  0.29917677937708453 accuracy:  0.9184146009261781\n",
      "Epoch number: 1581/10000step_number: 0/29 cost:  0.2989917229924488 accuracy:  0.9185508035957505\n",
      "Epoch number: 1582/10000step_number: 0/29 cost:  0.29880711575996344 accuracy:  0.9186870062653228\n",
      "Epoch number: 1583/10000step_number: 0/29 cost:  0.29862183520058977 accuracy:  0.9186870062653228\n",
      "Epoch number: 1584/10000step_number: 0/29 cost:  0.2984372415317832 accuracy:  0.9186870062653228\n",
      "Epoch number: 1585/10000step_number: 0/29 cost:  0.2982525335677357 accuracy:  0.9186870062653228\n",
      "Epoch number: 1586/10000step_number: 0/29 cost:  0.2980677621140444 accuracy:  0.9186870062653228\n",
      "Epoch number: 1587/10000step_number: 0/29 cost:  0.29788351460425166 accuracy:  0.9185508035957505\n",
      "Epoch number: 1588/10000step_number: 0/29 cost:  0.2976989949893158 accuracy:  0.9185508035957505\n",
      "Epoch number: 1589/10000step_number: 0/29 cost:  0.29751476864965104 accuracy:  0.9185508035957505\n",
      "Epoch number: 1590/10000step_number: 0/29 cost:  0.2973306934125989 accuracy:  0.9185508035957505\n",
      "Epoch number: 1591/10000step_number: 0/29 cost:  0.29714649643499497 accuracy:  0.9185508035957505\n",
      "Epoch number: 1592/10000step_number: 0/29 cost:  0.2969625882347801 accuracy:  0.920049032961046\n",
      "Epoch number: 1593/10000step_number: 0/29 cost:  0.2967786248549243 accuracy:  0.9199128302914737\n",
      "Epoch number: 1594/10000step_number: 0/29 cost:  0.2965946858489833 accuracy:  0.9199128302914737\n",
      "Epoch number: 1595/10000step_number: 0/29 cost:  0.2964108846623642 accuracy:  0.920049032961046\n",
      "Epoch number: 1596/10000step_number: 0/29 cost:  0.2962269791110045 accuracy:  0.9203214383001906\n",
      "Epoch number: 1597/10000step_number: 0/29 cost:  0.2960431332791913 accuracy:  0.9203214383001906\n",
      "Epoch number: 1598/10000step_number: 0/29 cost:  0.29585926871399626 accuracy:  0.92086624897848\n",
      "Epoch number: 1599/10000step_number: 0/29 cost:  0.2956753054931355 accuracy:  0.92086624897848\n",
      "Epoch number: 1600/10000step_number: 0/29 cost:  0.29549132241948195 accuracy:  0.92086624897848\n",
      "Epoch number: 1601/10000step_number: 0/29 cost:  0.2953072072467275 accuracy:  0.92086624897848\n",
      "Epoch number: 1602/10000step_number: 0/29 cost:  0.2951229439293965 accuracy:  0.9210024516480523\n",
      "Epoch number: 1603/10000step_number: 0/29 cost:  0.29493852555659456 accuracy:  0.9210024516480523\n",
      "Epoch number: 1604/10000step_number: 0/29 cost:  0.29475385355279576 accuracy:  0.9211386543176246\n",
      "Epoch number: 1605/10000step_number: 0/29 cost:  0.29456891455658096 accuracy:  0.9211386543176246\n",
      "Epoch number: 1606/10000step_number: 0/29 cost:  0.2943836453875732 accuracy:  0.9210024516480523\n",
      "Epoch number: 1607/10000step_number: 0/29 cost:  0.2941979719683789 accuracy:  0.9210024516480523\n",
      "Epoch number: 1608/10000step_number: 0/29 cost:  0.2940118509610236 accuracy:  0.9210024516480523\n",
      "Epoch number: 1609/10000step_number: 0/29 cost:  0.2938252042512799 accuracy:  0.9210024516480523\n",
      "Epoch number: 1610/10000step_number: 0/29 cost:  0.29363795947717564 accuracy:  0.9211386543176246\n",
      "Epoch number: 1611/10000step_number: 0/29 cost:  0.2934500501794073 accuracy:  0.9211386543176246\n",
      "Epoch number: 1612/10000step_number: 0/29 cost:  0.29326138577247096 accuracy:  0.9211386543176246\n",
      "Epoch number: 1613/10000step_number: 0/29 cost:  0.29307188088164543 accuracy:  0.9211386543176246\n",
      "Epoch number: 1614/10000step_number: 0/29 cost:  0.2928814354869622 accuracy:  0.9212748569871969\n",
      "Epoch number: 1615/10000step_number: 0/29 cost:  0.29268993057193077 accuracy:  0.9212748569871969\n",
      "Epoch number: 1616/10000step_number: 0/29 cost:  0.292497230760161 accuracy:  0.9212748569871969\n",
      "Epoch number: 1617/10000step_number: 0/29 cost:  0.29230316970935677 accuracy:  0.9212748569871969\n",
      "Epoch number: 1618/10000step_number: 0/29 cost:  0.29210754038283543 accuracy:  0.9212748569871969\n",
      "Epoch number: 1619/10000step_number: 0/29 cost:  0.2919100856131102 accuracy:  0.9212748569871969\n",
      "Epoch number: 1620/10000step_number: 0/29 cost:  0.29171047396585537 accuracy:  0.9212748569871969\n",
      "Epoch number: 1621/10000step_number: 0/29 cost:  0.291508277023397 accuracy:  0.9212748569871969\n",
      "Epoch number: 1622/10000step_number: 0/29 cost:  0.2913029320367043 accuracy:  0.9212748569871969\n",
      "Epoch number: 1623/10000step_number: 0/29 cost:  0.2910936877400693 accuracy:  0.9212748569871969\n",
      "Epoch number: 1624/10000step_number: 0/29 cost:  0.29087952485444757 accuracy:  0.9211386543176246\n",
      "Epoch number: 1625/10000step_number: 0/29 cost:  0.290659031924228 accuracy:  0.9212748569871969\n",
      "Epoch number: 1626/10000step_number: 0/29 cost:  0.29043020382433965 accuracy:  0.9212748569871969\n",
      "Epoch number: 1627/10000step_number: 0/29 cost:  0.2901901035177624 accuracy:  0.9219558703350585\n",
      "Epoch number: 1628/10000step_number: 0/29 cost:  0.2899342583378584 accuracy:  0.9219558703350585\n",
      "Epoch number: 1629/10000step_number: 0/29 cost:  0.28965551577388066 accuracy:  0.9219558703350585\n",
      "Epoch number: 1630/10000step_number: 0/29 cost:  0.2893416950613563 accuracy:  0.9219558703350585\n",
      "Epoch number: 1631/10000step_number: 0/29 cost:  0.288970242720868 accuracy:  0.9220920730046309\n",
      "Epoch number: 1632/10000step_number: 0/29 cost:  0.2884942057625682 accuracy:  0.9222282756742032\n",
      "Epoch number: 1633/10000step_number: 0/29 cost:  0.28779792076829525 accuracy:  0.9222282756742032\n",
      "Epoch number: 1634/10000step_number: 0/29 cost:  0.286589720282558 accuracy:  0.9220920730046309\n",
      "Epoch number: 1635/10000step_number: 0/29 cost:  0.2853582823454399 accuracy:  0.9223644783437756\n",
      "Epoch number: 1636/10000step_number: 0/29 cost:  0.28369859059605634 accuracy:  0.9242713157177881\n",
      "Epoch number: 1637/10000step_number: 0/29 cost:  0.28377169927713136 accuracy:  0.9245437210569327\n",
      "Epoch number: 1638/10000step_number: 0/29 cost:  0.2827368052843723 accuracy:  0.9241351130482157\n",
      "Epoch number: 1639/10000step_number: 0/29 cost:  0.28339600583129393 accuracy:  0.9244075183873603\n",
      "Epoch number: 1640/10000step_number: 0/29 cost:  0.2829361457895548 accuracy:  0.9235903023699265\n",
      "Epoch number: 1641/10000step_number: 0/29 cost:  0.2826116852944146 accuracy:  0.9241351130482157\n",
      "Epoch number: 1642/10000step_number: 0/29 cost:  0.28230450947003327 accuracy:  0.9242713157177881\n",
      "Epoch number: 1643/10000step_number: 0/29 cost:  0.28244333960852985 accuracy:  0.9242713157177881\n",
      "Epoch number: 1644/10000step_number: 0/29 cost:  0.2824659126112436 accuracy:  0.9242713157177881\n",
      "Epoch number: 1645/10000step_number: 0/29 cost:  0.2821701018699711 accuracy:  0.9245437210569327\n",
      "Epoch number: 1646/10000step_number: 0/29 cost:  0.2819414150112147 accuracy:  0.9245437210569327\n",
      "Epoch number: 1647/10000step_number: 0/29 cost:  0.2817671348588912 accuracy:  0.9245437210569327\n",
      "Epoch number: 1648/10000step_number: 0/29 cost:  0.2816043635756832 accuracy:  0.9244075183873603\n",
      "Epoch number: 1649/10000step_number: 0/29 cost:  0.2815341321941579 accuracy:  0.9244075183873603\n",
      "Epoch number: 1650/10000step_number: 0/29 cost:  0.2812294431065722 accuracy:  0.9244075183873603\n",
      "Epoch number: 1651/10000step_number: 0/29 cost:  0.28116886439520933 accuracy:  0.9246799237265051\n",
      "Epoch number: 1652/10000step_number: 0/29 cost:  0.28090750133713743 accuracy:  0.9244075183873603\n",
      "Epoch number: 1653/10000step_number: 0/29 cost:  0.2807805288195848 accuracy:  0.9242713157177881\n",
      "Epoch number: 1654/10000step_number: 0/29 cost:  0.2805927306792952 accuracy:  0.9242713157177881\n",
      "Epoch number: 1655/10000step_number: 0/29 cost:  0.28047902705585065 accuracy:  0.9242713157177881\n",
      "Epoch number: 1656/10000step_number: 0/29 cost:  0.2802765909236089 accuracy:  0.9242713157177881\n",
      "Epoch number: 1657/10000step_number: 0/29 cost:  0.2801661536150959 accuracy:  0.9244075183873603\n",
      "Epoch number: 1658/10000step_number: 0/29 cost:  0.27997331266263 accuracy:  0.9244075183873603\n",
      "Epoch number: 1659/10000step_number: 0/29 cost:  0.2798726732738735 accuracy:  0.9244075183873603\n",
      "Epoch number: 1660/10000step_number: 0/29 cost:  0.27967626307902216 accuracy:  0.9245437210569327\n",
      "Epoch number: 1661/10000step_number: 0/29 cost:  0.2795840067325975 accuracy:  0.9245437210569327\n",
      "Epoch number: 1662/10000step_number: 0/29 cost:  0.27938832557809096 accuracy:  0.9244075183873603\n",
      "Epoch number: 1663/10000step_number: 0/29 cost:  0.2793020069952437 accuracy:  0.9244075183873603\n",
      "Epoch number: 1664/10000step_number: 0/29 cost:  0.2791073396475563 accuracy:  0.9245437210569327\n",
      "Epoch number: 1665/10000step_number: 0/29 cost:  0.2790252912471019 accuracy:  0.9244075183873603\n",
      "Epoch number: 1666/10000step_number: 0/29 cost:  0.2788327178180099 accuracy:  0.9245437210569327\n",
      "Epoch number: 1667/10000step_number: 0/29 cost:  0.2787531029761813 accuracy:  0.9245437210569327\n",
      "Epoch number: 1668/10000step_number: 0/29 cost:  0.2785634997700847 accuracy:  0.9245437210569327\n",
      "Epoch number: 1669/10000step_number: 0/29 cost:  0.2784848104269982 accuracy:  0.9245437210569327\n",
      "Epoch number: 1670/10000step_number: 0/29 cost:  0.27829881632678105 accuracy:  0.9245437210569327\n",
      "Epoch number: 1671/10000step_number: 0/29 cost:  0.2782202928205662 accuracy:  0.9245437210569327\n",
      "Epoch number: 1672/10000step_number: 0/29 cost:  0.278038964816054 accuracy:  0.9245437210569327\n",
      "Epoch number: 1673/10000step_number: 0/29 cost:  0.2779599959274178 accuracy:  0.9245437210569327\n",
      "Epoch number: 1674/10000step_number: 0/29 cost:  0.27778266803313323 accuracy:  0.9245437210569327\n",
      "Epoch number: 1675/10000step_number: 0/29 cost:  0.27770263668225414 accuracy:  0.9245437210569327\n",
      "Epoch number: 1676/10000step_number: 0/29 cost:  0.277529409407362 accuracy:  0.9246799237265051\n",
      "Epoch number: 1677/10000step_number: 0/29 cost:  0.27744823720026696 accuracy:  0.9244075183873603\n",
      "Epoch number: 1678/10000step_number: 0/29 cost:  0.2772787940084351 accuracy:  0.9244075183873603\n",
      "Epoch number: 1679/10000step_number: 0/29 cost:  0.2771965454053904 accuracy:  0.9245437210569327\n",
      "Epoch number: 1680/10000step_number: 0/29 cost:  0.27703041988250177 accuracy:  0.9244075183873603\n",
      "Epoch number: 1681/10000step_number: 0/29 cost:  0.2769473059522169 accuracy:  0.9246799237265051\n",
      "Epoch number: 1682/10000step_number: 0/29 cost:  0.2767840747244926 accuracy:  0.9245437210569327\n",
      "Epoch number: 1683/10000step_number: 0/29 cost:  0.2767006412336411 accuracy:  0.9245437210569327\n",
      "Epoch number: 1684/10000step_number: 0/29 cost:  0.2765400288624113 accuracy:  0.9244075183873603\n",
      "Epoch number: 1685/10000step_number: 0/29 cost:  0.2764565471602792 accuracy:  0.9244075183873603\n",
      "Epoch number: 1686/10000step_number: 0/29 cost:  0.2762978782018309 accuracy:  0.9244075183873603\n",
      "Epoch number: 1687/10000step_number: 0/29 cost:  0.2762145162660724 accuracy:  0.9244075183873603\n",
      "Epoch number: 1688/10000step_number: 0/29 cost:  0.2760573959993416 accuracy:  0.9244075183873603\n",
      "Epoch number: 1689/10000step_number: 0/29 cost:  0.2759744376070732 accuracy:  0.9244075183873603\n",
      "Epoch number: 1690/10000step_number: 0/29 cost:  0.27581850585732914 accuracy:  0.9244075183873603\n",
      "Epoch number: 1691/10000step_number: 0/29 cost:  0.27573619090612944 accuracy:  0.9245437210569327\n",
      "Epoch number: 1692/10000step_number: 0/29 cost:  0.2755811444256529 accuracy:  0.9246799237265051\n",
      "Epoch number: 1693/10000step_number: 0/29 cost:  0.2754996661386433 accuracy:  0.9245437210569327\n",
      "Epoch number: 1694/10000step_number: 0/29 cost:  0.27534526592262215 accuracy:  0.9245437210569327\n",
      "Epoch number: 1695/10000step_number: 0/29 cost:  0.2752647749303508 accuracy:  0.9245437210569327\n",
      "Epoch number: 1696/10000step_number: 0/29 cost:  0.27511083437853145 accuracy:  0.9245437210569327\n",
      "Epoch number: 1697/10000step_number: 0/29 cost:  0.2750314474816381 accuracy:  0.9246799237265051\n",
      "Epoch number: 1698/10000step_number: 0/29 cost:  0.274877832189249 accuracy:  0.9246799237265051\n",
      "Epoch number: 1699/10000step_number: 0/29 cost:  0.27479961905719824 accuracy:  0.9246799237265051\n",
      "Epoch number: 1700/10000step_number: 0/29 cost:  0.27464627477964637 accuracy:  0.9246799237265051\n",
      "Epoch number: 1701/10000step_number: 0/29 cost:  0.27456922443803566 accuracy:  0.9246799237265051\n",
      "Epoch number: 1702/10000step_number: 0/29 cost:  0.2744161846950222 accuracy:  0.9248161263960774\n",
      "Epoch number: 1703/10000step_number: 0/29 cost:  0.2743402356487606 accuracy:  0.9248161263960774\n",
      "Epoch number: 1704/10000step_number: 0/29 cost:  0.27418752919863326 accuracy:  0.9248161263960774\n",
      "Epoch number: 1705/10000step_number: 0/29 cost:  0.27411265404803814 accuracy:  0.9248161263960774\n",
      "Epoch number: 1706/10000step_number: 0/29 cost:  0.2739602650829278 accuracy:  0.9248161263960774\n",
      "Epoch number: 1707/10000step_number: 0/29 cost:  0.2738864563998284 accuracy:  0.9249523290656497\n",
      "Epoch number: 1708/10000step_number: 0/29 cost:  0.2737343851614002 accuracy:  0.9248161263960774\n",
      "Epoch number: 1709/10000step_number: 0/29 cost:  0.2736616153923485 accuracy:  0.925088531735222\n",
      "Epoch number: 1710/10000step_number: 0/29 cost:  0.27350989878908255 accuracy:  0.9249523290656497\n",
      "Epoch number: 1711/10000step_number: 0/29 cost:  0.27343811538010077 accuracy:  0.925088531735222\n",
      "Epoch number: 1712/10000step_number: 0/29 cost:  0.2732868116708849 accuracy:  0.925088531735222\n",
      "Epoch number: 1713/10000step_number: 0/29 cost:  0.2732159457759735 accuracy:  0.9252247344047944\n",
      "Epoch number: 1714/10000step_number: 0/29 cost:  0.27306512075106637 accuracy:  0.925088531735222\n",
      "Epoch number: 1715/10000step_number: 0/29 cost:  0.2729950986330209 accuracy:  0.9252247344047944\n",
      "Epoch number: 1716/10000step_number: 0/29 cost:  0.2728448150260454 accuracy:  0.925088531735222\n",
      "Epoch number: 1717/10000step_number: 0/29 cost:  0.2727755695133113 accuracy:  0.9252247344047944\n",
      "Epoch number: 1718/10000step_number: 0/29 cost:  0.2726258766240888 accuracy:  0.925088531735222\n",
      "Epoch number: 1719/10000step_number: 0/29 cost:  0.2725573579986966 accuracy:  0.9252247344047944\n",
      "Epoch number: 1720/10000step_number: 0/29 cost:  0.2724082811753353 accuracy:  0.9252247344047944\n",
      "Epoch number: 1721/10000step_number: 0/29 cost:  0.27234046756604563 accuracy:  0.9252247344047944\n",
      "Epoch number: 1722/10000step_number: 0/29 cost:  0.27219199849041514 accuracy:  0.9252247344047944\n",
      "Epoch number: 1723/10000step_number: 0/29 cost:  0.27212490408695855 accuracy:  0.9252247344047944\n",
      "Epoch number: 1724/10000step_number: 0/29 cost:  0.2719769945424257 accuracy:  0.9252247344047944\n",
      "Epoch number: 1725/10000step_number: 0/29 cost:  0.2719106725095525 accuracy:  0.925088531735222\n",
      "Epoch number: 1726/10000step_number: 0/29 cost:  0.271763235093836 accuracy:  0.9252247344047944\n",
      "Epoch number: 1727/10000step_number: 0/29 cost:  0.2716977714121398 accuracy:  0.925088531735222\n",
      "Epoch number: 1728/10000step_number: 0/29 cost:  0.271550690384237 accuracy:  0.9252247344047944\n",
      "Epoch number: 1729/10000step_number: 0/29 cost:  0.2714861855524443 accuracy:  0.925088531735222\n",
      "Epoch number: 1730/10000step_number: 0/29 cost:  0.27133933934457444 accuracy:  0.9253609370743666\n",
      "Epoch number: 1731/10000step_number: 0/29 cost:  0.2712758771819027 accuracy:  0.9252247344047944\n",
      "Epoch number: 1732/10000step_number: 0/29 cost:  0.27112917125728 accuracy:  0.9253609370743666\n",
      "Epoch number: 1733/10000step_number: 0/29 cost:  0.271066777450137 accuracy:  0.9253609370743666\n",
      "Epoch number: 1734/10000step_number: 0/29 cost:  0.2709201832335595 accuracy:  0.925497139743939\n",
      "Epoch number: 1735/10000step_number: 0/29 cost:  0.27085877982674883 accuracy:  0.9253609370743666\n",
      "Epoch number: 1736/10000step_number: 0/29 cost:  0.27071237367451645 accuracy:  0.925497139743939\n",
      "Epoch number: 1737/10000step_number: 0/29 cost:  0.2706517389863531 accuracy:  0.9253609370743666\n",
      "Epoch number: 1738/10000step_number: 0/29 cost:  0.27050573473025247 accuracy:  0.925497139743939\n",
      "Epoch number: 1739/10000step_number: 0/29 cost:  0.27044548222375725 accuracy:  0.9253609370743666\n",
      "Epoch number: 1740/10000step_number: 0/29 cost:  0.27030024978648987 accuracy:  0.9260419504222283\n",
      "Epoch number: 1741/10000step_number: 0/29 cost:  0.270239844525458 accuracy:  0.925905747752656\n",
      "Epoch number: 1742/10000step_number: 0/29 cost:  0.27009590332698474 accuracy:  0.925905747752656\n",
      "Epoch number: 1743/10000step_number: 0/29 cost:  0.27003473338156586 accuracy:  0.9260419504222283\n",
      "Epoch number: 1744/10000step_number: 0/29 cost:  0.26989270554008205 accuracy:  0.9261781530918006\n",
      "Epoch number: 1745/10000step_number: 0/29 cost:  0.26983020183263984 accuracy:  0.9261781530918006\n",
      "Epoch number: 1746/10000step_number: 0/29 cost:  0.26969071843144293 accuracy:  0.9261781530918006\n",
      "Epoch number: 1747/10000step_number: 0/29 cost:  0.2696264710231852 accuracy:  0.9263143557613729\n",
      "Epoch number: 1748/10000step_number: 0/29 cost:  0.26949005574474505 accuracy:  0.9264505584309453\n",
      "Epoch number: 1749/10000step_number: 0/29 cost:  0.2694238581561644 accuracy:  0.9264505584309453\n",
      "Epoch number: 1750/10000step_number: 0/29 cost:  0.269290844490001 accuracy:  0.9265867611005175\n",
      "Epoch number: 1751/10000step_number: 0/29 cost:  0.2692226544152181 accuracy:  0.9264505584309453\n",
      "Epoch number: 1752/10000step_number: 0/29 cost:  0.2690931753400056 accuracy:  0.9267229637700899\n",
      "Epoch number: 1753/10000step_number: 0/29 cost:  0.269023047805488 accuracy:  0.9267229637700899\n",
      "Epoch number: 1754/10000step_number: 0/29 cost:  0.26889707804460167 accuracy:  0.9267229637700899\n",
      "Epoch number: 1755/10000step_number: 0/29 cost:  0.2688251214887166 accuracy:  0.9267229637700899\n",
      "Epoch number: 1756/10000step_number: 0/29 cost:  0.26870252653068216 accuracy:  0.9267229637700899\n",
      "Epoch number: 1757/10000step_number: 0/29 cost:  0.26862888558825915 accuracy:  0.9267229637700899\n",
      "Epoch number: 1758/10000step_number: 0/29 cost:  0.2685094559767343 accuracy:  0.9267229637700899\n",
      "Epoch number: 1759/10000step_number: 0/29 cost:  0.26843430377013694 accuracy:  0.9267229637700899\n",
      "Epoch number: 1760/10000step_number: 0/29 cost:  0.26831777830894443 accuracy:  0.9267229637700899\n",
      "Epoch number: 1761/10000step_number: 0/29 cost:  0.2682413078530674 accuracy:  0.9267229637700899\n",
      "Epoch number: 1762/10000step_number: 0/29 cost:  0.268127392881035 accuracy:  0.9267229637700899\n",
      "Epoch number: 1763/10000step_number: 0/29 cost:  0.2680498067924768 accuracy:  0.9267229637700899\n",
      "Epoch number: 1764/10000step_number: 0/29 cost:  0.26793819375165223 accuracy:  0.9267229637700899\n",
      "Epoch number: 1765/10000step_number: 0/29 cost:  0.2678596943932691 accuracy:  0.9267229637700899\n",
      "Epoch number: 1766/10000step_number: 0/29 cost:  0.2677500749786062 accuracy:  0.9267229637700899\n",
      "Epoch number: 1767/10000step_number: 0/29 cost:  0.2676708561018337 accuracy:  0.9267229637700899\n",
      "Epoch number: 1768/10000step_number: 0/29 cost:  0.267562933212434 accuracy:  0.9267229637700899\n",
      "Epoch number: 1769/10000step_number: 0/29 cost:  0.26748317184035075 accuracy:  0.9267229637700899\n",
      "Epoch number: 1770/10000step_number: 0/29 cost:  0.26737666312409214 accuracy:  0.9267229637700899\n",
      "Epoch number: 1771/10000step_number: 0/29 cost:  0.26729650793833315 accuracy:  0.9267229637700899\n",
      "Epoch number: 1772/10000step_number: 0/29 cost:  0.26719113831124913 accuracy:  0.9267229637700899\n",
      "Epoch number: 1773/10000step_number: 0/29 cost:  0.2671106935063768 accuracy:  0.9267229637700899\n",
      "Epoch number: 1774/10000step_number: 0/29 cost:  0.26700618313615865 accuracy:  0.9268591664396623\n",
      "Epoch number: 1775/10000step_number: 0/29 cost:  0.2669255042185198 accuracy:  0.9268591664396623\n",
      "Epoch number: 1776/10000step_number: 0/29 cost:  0.2668215800487513 accuracy:  0.9268591664396623\n",
      "Epoch number: 1777/10000step_number: 0/29 cost:  0.2667407075464315 accuracy:  0.9268591664396623\n",
      "Epoch number: 1778/10000step_number: 0/29 cost:  0.2666371496138287 accuracy:  0.9268591664396623\n",
      "Epoch number: 1779/10000step_number: 0/29 cost:  0.26655615650392284 accuracy:  0.9268591664396623\n",
      "Epoch number: 1780/10000step_number: 0/29 cost:  0.2664528275140147 accuracy:  0.9268591664396623\n",
      "Epoch number: 1781/10000step_number: 0/29 cost:  0.2663718227841451 accuracy:  0.9267229637700899\n",
      "Epoch number: 1782/10000step_number: 0/29 cost:  0.266268647641173 accuracy:  0.9267229637700899\n",
      "Epoch number: 1783/10000step_number: 0/29 cost:  0.26618774540360995 accuracy:  0.9267229637700899\n",
      "Epoch number: 1784/10000step_number: 0/29 cost:  0.2660846773439581 accuracy:  0.9268591664396623\n",
      "Epoch number: 1785/10000step_number: 0/29 cost:  0.2660039754455534 accuracy:  0.9268591664396623\n",
      "Epoch number: 1786/10000step_number: 0/29 cost:  0.2659009781183618 accuracy:  0.9268591664396623\n",
      "Epoch number: 1787/10000step_number: 0/29 cost:  0.26582055469412674 accuracy:  0.9268591664396623\n",
      "Epoch number: 1788/10000step_number: 0/29 cost:  0.2657175965101002 accuracy:  0.9268591664396623\n",
      "Epoch number: 1789/10000step_number: 0/29 cost:  0.2656375133376714 accuracy:  0.9268591664396623\n",
      "Epoch number: 1790/10000step_number: 0/29 cost:  0.26553456580344004 accuracy:  0.9268591664396623\n",
      "Epoch number: 1791/10000step_number: 0/29 cost:  0.2654548718995694 accuracy:  0.9268591664396623\n",
      "Epoch number: 1792/10000step_number: 0/29 cost:  0.2653519091177089 accuracy:  0.9268591664396623\n",
      "Epoch number: 1793/10000step_number: 0/29 cost:  0.2652726433526242 accuracy:  0.9268591664396623\n",
      "Epoch number: 1794/10000step_number: 0/29 cost:  0.26516964215355815 accuracy:  0.9268591664396623\n",
      "Epoch number: 1795/10000step_number: 0/29 cost:  0.2650908350738598 accuracy:  0.9268591664396623\n",
      "Epoch number: 1796/10000step_number: 0/29 cost:  0.26498777549655894 accuracy:  0.9269953691092345\n",
      "Epoch number: 1797/10000step_number: 0/29 cost:  0.26490945045984327 accuracy:  0.9269953691092345\n",
      "Epoch number: 1798/10000step_number: 0/29 cost:  0.26480631645884817 accuracy:  0.9269953691092345\n",
      "Epoch number: 1799/10000step_number: 0/29 cost:  0.26472848990796355 accuracy:  0.9269953691092345\n",
      "Epoch number: 1800/10000step_number: 0/29 cost:  0.26462527055786106 accuracy:  0.9269953691092345\n",
      "Epoch number: 1801/10000step_number: 0/29 cost:  0.2645479510260893 accuracy:  0.9271315717788069\n",
      "Epoch number: 1802/10000step_number: 0/29 cost:  0.2644446428457553 accuracy:  0.9271315717788069\n",
      "Epoch number: 1803/10000step_number: 0/29 cost:  0.26436782821482707 accuracy:  0.9271315717788069\n",
      "Epoch number: 1804/10000step_number: 0/29 cost:  0.264264439142809 accuracy:  0.9271315717788069\n",
      "Epoch number: 1805/10000step_number: 0/29 cost:  0.2641881122035516 accuracy:  0.9271315717788069\n",
      "Epoch number: 1806/10000step_number: 0/29 cost:  0.26408466670406733 accuracy:  0.9271315717788069\n",
      "Epoch number: 1807/10000step_number: 0/29 cost:  0.26400879068890154 accuracy:  0.9272677744483792\n",
      "Epoch number: 1808/10000step_number: 0/29 cost:  0.26390533334535077 accuracy:  0.9272677744483792\n",
      "Epoch number: 1809/10000step_number: 0/29 cost:  0.2638298512351237 accuracy:  0.9272677744483792\n",
      "Epoch number: 1810/10000step_number: 0/29 cost:  0.26372644465851103 accuracy:  0.9272677744483792\n",
      "Epoch number: 1811/10000step_number: 0/29 cost:  0.2636512859345723 accuracy:  0.9272677744483792\n",
      "Epoch number: 1812/10000step_number: 0/29 cost:  0.26354800106696497 accuracy:  0.9272677744483792\n",
      "Epoch number: 1813/10000step_number: 0/29 cost:  0.2634730947802718 accuracy:  0.9272677744483792\n",
      "Epoch number: 1814/10000step_number: 0/29 cost:  0.2633699975976348 accuracy:  0.9272677744483792\n",
      "Epoch number: 1815/10000step_number: 0/29 cost:  0.2632952848349256 accuracy:  0.9272677744483792\n",
      "Epoch number: 1816/10000step_number: 0/29 cost:  0.2631924268010729 accuracy:  0.9272677744483792\n",
      "Epoch number: 1817/10000step_number: 0/29 cost:  0.2631178659730408 accuracy:  0.9271315717788069\n",
      "Epoch number: 1818/10000step_number: 0/29 cost:  0.2630152821027981 accuracy:  0.9271315717788069\n",
      "Epoch number: 1819/10000step_number: 0/29 cost:  0.26294084657923283 accuracy:  0.9269953691092345\n",
      "Epoch number: 1820/10000step_number: 0/29 cost:  0.2628385591497259 accuracy:  0.9269953691092345\n",
      "Epoch number: 1821/10000step_number: 0/29 cost:  0.2627642313568966 accuracy:  0.9269953691092345\n",
      "Epoch number: 1822/10000step_number: 0/29 cost:  0.2626622551242056 accuracy:  0.9269953691092345\n",
      "Epoch number: 1823/10000step_number: 0/29 cost:  0.2625880210261391 accuracy:  0.9269953691092345\n",
      "Epoch number: 1824/10000step_number: 0/29 cost:  0.2624863672731886 accuracy:  0.9269953691092345\n",
      "Epoch number: 1825/10000step_number: 0/29 cost:  0.2624122127694891 accuracy:  0.9269953691092345\n",
      "Epoch number: 1826/10000step_number: 0/29 cost:  0.2623108915826134 accuracy:  0.9269953691092345\n",
      "Epoch number: 1827/10000step_number: 0/29 cost:  0.2622368005937975 accuracy:  0.9269953691092345\n",
      "Epoch number: 1828/10000step_number: 0/29 cost:  0.2621358218235696 accuracy:  0.9268591664396623\n",
      "Epoch number: 1829/10000step_number: 0/29 cost:  0.26206177528713054 accuracy:  0.9268591664396623\n",
      "Epoch number: 1830/10000step_number: 0/29 cost:  0.26196114880865373 accuracy:  0.9268591664396623\n",
      "Epoch number: 1831/10000step_number: 0/29 cost:  0.26188712394024205 accuracy:  0.9268591664396623\n",
      "Epoch number: 1832/10000step_number: 0/29 cost:  0.26178685961822057 accuracy:  0.9268591664396623\n",
      "Epoch number: 1833/10000step_number: 0/29 cost:  0.26171282911015276 accuracy:  0.9269953691092345\n",
      "Epoch number: 1834/10000step_number: 0/29 cost:  0.26161293661300006 accuracy:  0.9271315717788069\n",
      "Epoch number: 1835/10000step_number: 0/29 cost:  0.26153886774112844 accuracy:  0.9272677744483792\n",
      "Epoch number: 1836/10000step_number: 0/29 cost:  0.2614393561521362 accuracy:  0.9272677744483792\n",
      "Epoch number: 1837/10000step_number: 0/29 cost:  0.2613652099795728 accuracy:  0.9272677744483792\n",
      "Epoch number: 1838/10000step_number: 0/29 cost:  0.261266087067931 accuracy:  0.9272677744483792\n",
      "Epoch number: 1839/10000step_number: 0/29 cost:  0.26119181802874397 accuracy:  0.9274039771179515\n",
      "Epoch number: 1840/10000step_number: 0/29 cost:  0.2610930891009672 accuracy:  0.9274039771179515\n",
      "Epoch number: 1841/10000step_number: 0/29 cost:  0.2610186451845368 accuracy:  0.9274039771179515\n",
      "Epoch number: 1842/10000step_number: 0/29 cost:  0.26092031162916807 accuracy:  0.9274039771179515\n",
      "Epoch number: 1843/10000step_number: 0/29 cost:  0.26084563519457216 accuracy:  0.9274039771179515\n",
      "Epoch number: 1844/10000step_number: 0/29 cost:  0.2607476930697781 accuracy:  0.9274039771179515\n",
      "Epoch number: 1845/10000step_number: 0/29 cost:  0.26067272212438786 accuracy:  0.9274039771179515\n",
      "Epoch number: 1846/10000step_number: 0/29 cost:  0.2605751612801419 accuracy:  0.9274039771179515\n",
      "Epoch number: 1847/10000step_number: 0/29 cost:  0.26049983101959734 accuracy:  0.9274039771179515\n",
      "Epoch number: 1848/10000step_number: 0/29 cost:  0.2604026352247786 accuracy:  0.9274039771179515\n",
      "Epoch number: 1849/10000step_number: 0/29 cost:  0.26032687982048536 accuracy:  0.9274039771179515\n",
      "Epoch number: 1850/10000step_number: 0/29 cost:  0.2602300282506411 accuracy:  0.9275401797875238\n",
      "Epoch number: 1851/10000step_number: 0/29 cost:  0.26015378314654575 accuracy:  0.9275401797875238\n",
      "Epoch number: 1852/10000step_number: 0/29 cost:  0.260057253427515 accuracy:  0.9276763824570962\n",
      "Epoch number: 1853/10000step_number: 0/29 cost:  0.25998045836691774 accuracy:  0.9276763824570962\n",
      "Epoch number: 1854/10000step_number: 0/29 cost:  0.25988423085925727 accuracy:  0.9276763824570962\n",
      "Epoch number: 1855/10000step_number: 0/29 cost:  0.259806833003946 accuracy:  0.9278125851266685\n",
      "Epoch number: 1856/10000step_number: 0/29 cost:  0.2597108946972402 accuracy:  0.9278125851266685\n",
      "Epoch number: 1857/10000step_number: 0/29 cost:  0.2596328498684911 accuracy:  0.9276763824570962\n",
      "Epoch number: 1858/10000step_number: 0/29 cost:  0.2595371950301231 accuracy:  0.9276763824570962\n",
      "Epoch number: 1859/10000step_number: 0/29 cost:  0.2594584655239304 accuracy:  0.9276763824570962\n",
      "Epoch number: 1860/10000step_number: 0/29 cost:  0.2593630918289242 accuracy:  0.9278125851266685\n",
      "Epoch number: 1861/10000step_number: 0/29 cost:  0.25928364298701534 accuracy:  0.9278125851266685\n",
      "Epoch number: 1862/10000step_number: 0/29 cost:  0.2591885463024593 accuracy:  0.9278125851266685\n",
      "Epoch number: 1863/10000step_number: 0/29 cost:  0.2591083474818414 accuracy:  0.9278125851266685\n",
      "Epoch number: 1864/10000step_number: 0/29 cost:  0.25901352076132866 accuracy:  0.9278125851266685\n",
      "Epoch number: 1865/10000step_number: 0/29 cost:  0.25893255370375134 accuracy:  0.9278125851266685\n",
      "Epoch number: 1866/10000step_number: 0/29 cost:  0.25883798955600335 accuracy:  0.9278125851266685\n",
      "Epoch number: 1867/10000step_number: 0/29 cost:  0.2587562520305313 accuracy:  0.9278125851266685\n",
      "Epoch number: 1868/10000step_number: 0/29 cost:  0.25866192678798244 accuracy:  0.9278125851266685\n",
      "Epoch number: 1869/10000step_number: 0/29 cost:  0.25857938792645885 accuracy:  0.9278125851266685\n",
      "Epoch number: 1870/10000step_number: 0/29 cost:  0.2584851625715402 accuracy:  0.9278125851266685\n",
      "Epoch number: 1871/10000step_number: 0/29 cost:  0.2584015499199505 accuracy:  0.9278125851266685\n",
      "Epoch number: 1872/10000step_number: 0/29 cost:  0.25830669824206787 accuracy:  0.9278125851266685\n",
      "Epoch number: 1873/10000step_number: 0/29 cost:  0.25822031326120637 accuracy:  0.9278125851266685\n",
      "Epoch number: 1874/10000step_number: 0/29 cost:  0.2581208261104986 accuracy:  0.9278125851266685\n",
      "Epoch number: 1875/10000step_number: 0/29 cost:  0.2580266099593627 accuracy:  0.9278125851266685\n",
      "Epoch number: 1876/10000step_number: 0/29 cost:  0.257925292240173 accuracy:  0.9278125851266685\n",
      "Epoch number: 1877/10000step_number: 0/29 cost:  0.25783622713691523 accuracy:  0.9278125851266685\n",
      "Epoch number: 1878/10000step_number: 0/29 cost:  0.2577415854621449 accuracy:  0.9278125851266685\n",
      "Epoch number: 1879/10000step_number: 0/29 cost:  0.2576542057899393 accuracy:  0.9278125851266685\n",
      "Epoch number: 1880/10000step_number: 0/29 cost:  0.2575590779241826 accuracy:  0.9278125851266685\n",
      "Epoch number: 1881/10000step_number: 0/29 cost:  0.25747011486493937 accuracy:  0.9279487877962408\n",
      "Epoch number: 1882/10000step_number: 0/29 cost:  0.25737507763028133 accuracy:  0.9279487877962408\n",
      "Epoch number: 1883/10000step_number: 0/29 cost:  0.2572864015134404 accuracy:  0.9279487877962408\n",
      "Epoch number: 1884/10000step_number: 0/29 cost:  0.2571920897533871 accuracy:  0.9279487877962408\n",
      "Epoch number: 1885/10000step_number: 0/29 cost:  0.2571035152061403 accuracy:  0.9284935984745301\n",
      "Epoch number: 1886/10000step_number: 0/29 cost:  0.2570099162232633 accuracy:  0.9287660038136748\n",
      "Epoch number: 1887/10000step_number: 0/29 cost:  0.2569215343414564 accuracy:  0.9287660038136748\n",
      "Epoch number: 1888/10000step_number: 0/29 cost:  0.25682843013258083 accuracy:  0.9289022064832471\n",
      "Epoch number: 1889/10000step_number: 0/29 cost:  0.2567401545165611 accuracy:  0.9289022064832471\n",
      "Epoch number: 1890/10000step_number: 0/29 cost:  0.25664743412788804 accuracy:  0.9289022064832471\n",
      "Epoch number: 1891/10000step_number: 0/29 cost:  0.25655917694525704 accuracy:  0.9289022064832471\n",
      "Epoch number: 1892/10000step_number: 0/29 cost:  0.2564666817348727 accuracy:  0.9289022064832471\n",
      "Epoch number: 1893/10000step_number: 0/29 cost:  0.25637838768473775 accuracy:  0.9289022064832471\n",
      "Epoch number: 1894/10000step_number: 0/29 cost:  0.25628599512482697 accuracy:  0.9289022064832471\n",
      "Epoch number: 1895/10000step_number: 0/29 cost:  0.25619759662994773 accuracy:  0.9289022064832471\n",
      "Epoch number: 1896/10000step_number: 0/29 cost:  0.25610521180929835 accuracy:  0.9287660038136748\n",
      "Epoch number: 1897/10000step_number: 0/29 cost:  0.2560166582163249 accuracy:  0.9287660038136748\n",
      "Epoch number: 1898/10000step_number: 0/29 cost:  0.2559242072075009 accuracy:  0.9289022064832471\n",
      "Epoch number: 1899/10000step_number: 0/29 cost:  0.25583545685092074 accuracy:  0.9287660038136748\n",
      "Epoch number: 1900/10000step_number: 0/29 cost:  0.2557428942986842 accuracy:  0.9287660038136748\n",
      "Epoch number: 1901/10000step_number: 0/29 cost:  0.25565391659710246 accuracy:  0.9287660038136748\n",
      "Epoch number: 1902/10000step_number: 0/29 cost:  0.2555612188269145 accuracy:  0.9287660038136748\n",
      "Epoch number: 1903/10000step_number: 0/29 cost:  0.25547199862619513 accuracy:  0.9287660038136748\n",
      "Epoch number: 1904/10000step_number: 0/29 cost:  0.25537916070744643 accuracy:  0.9287660038136748\n",
      "Epoch number: 1905/10000step_number: 0/29 cost:  0.2552896992010378 accuracy:  0.9287660038136748\n",
      "Epoch number: 1906/10000step_number: 0/29 cost:  0.25519673145504823 accuracy:  0.9287660038136748\n",
      "Epoch number: 1907/10000step_number: 0/29 cost:  0.25510704840565684 accuracy:  0.9289022064832471\n",
      "Epoch number: 1908/10000step_number: 0/29 cost:  0.25501397344043725 accuracy:  0.9289022064832471\n",
      "Epoch number: 1909/10000step_number: 0/29 cost:  0.25492410796154974 accuracy:  0.9290384091528194\n",
      "Epoch number: 1910/10000step_number: 0/29 cost:  0.2548309601361051 accuracy:  0.9290384091528194\n",
      "Epoch number: 1911/10000step_number: 0/29 cost:  0.25474097096267884 accuracy:  0.9290384091528194\n",
      "Epoch number: 1912/10000step_number: 0/29 cost:  0.25464779775523666 accuracy:  0.9290384091528194\n",
      "Epoch number: 1913/10000step_number: 0/29 cost:  0.25455776444057693 accuracy:  0.9290384091528194\n",
      "Epoch number: 1914/10000step_number: 0/29 cost:  0.2544646312193158 accuracy:  0.9290384091528194\n",
      "Epoch number: 1915/10000step_number: 0/29 cost:  0.25437465898113676 accuracy:  0.9290384091528194\n",
      "Epoch number: 1916/10000step_number: 0/29 cost:  0.2542816607213668 accuracy:  0.9291746118223917\n",
      "Epoch number: 1917/10000step_number: 0/29 cost:  0.254191894456242 accuracy:  0.9291746118223917\n",
      "Epoch number: 1918/10000step_number: 0/29 cost:  0.2540991792345107 accuracy:  0.9291746118223917\n",
      "Epoch number: 1919/10000step_number: 0/29 cost:  0.25400982983288367 accuracy:  0.9291746118223917\n",
      "Epoch number: 1920/10000step_number: 0/29 cost:  0.2539176315227768 accuracy:  0.9291746118223917\n",
      "Epoch number: 1921/10000step_number: 0/29 cost:  0.25382900160891475 accuracy:  0.9293108144919641\n",
      "Epoch number: 1922/10000step_number: 0/29 cost:  0.2537376451326242 accuracy:  0.9293108144919641\n",
      "Epoch number: 1923/10000step_number: 0/29 cost:  0.25365005683985603 accuracy:  0.9293108144919641\n",
      "Epoch number: 1924/10000step_number: 0/29 cost:  0.25355968597985623 accuracy:  0.9293108144919641\n",
      "Epoch number: 1925/10000step_number: 0/29 cost:  0.2534727841833635 accuracy:  0.9293108144919641\n",
      "Epoch number: 1926/10000step_number: 0/29 cost:  0.25338213193995374 accuracy:  0.9293108144919641\n",
      "Epoch number: 1927/10000step_number: 0/29 cost:  0.2532937984035924 accuracy:  0.9294470171615363\n",
      "Epoch number: 1928/10000step_number: 0/29 cost:  0.2532010505572823 accuracy:  0.9295832198311087\n",
      "Epoch number: 1929/10000step_number: 0/29 cost:  0.25311123416836157 accuracy:  0.9295832198311087\n",
      "Epoch number: 1930/10000step_number: 0/29 cost:  0.253018360466656 accuracy:  0.9295832198311087\n",
      "Epoch number: 1931/10000step_number: 0/29 cost:  0.2529296652104644 accuracy:  0.9295832198311087\n",
      "Epoch number: 1932/10000step_number: 0/29 cost:  0.25283845706589475 accuracy:  0.9295832198311087\n",
      "Epoch number: 1933/10000step_number: 0/29 cost:  0.25275141142105684 accuracy:  0.9295832198311087\n",
      "Epoch number: 1934/10000step_number: 0/29 cost:  0.25266175504794336 accuracy:  0.9295832198311087\n",
      "Epoch number: 1935/10000step_number: 0/29 cost:  0.2525760479889769 accuracy:  0.929719422500681\n",
      "Epoch number: 1936/10000step_number: 0/29 cost:  0.25248754632895365 accuracy:  0.929719422500681\n",
      "Epoch number: 1937/10000step_number: 0/29 cost:  0.2524026554999827 accuracy:  0.929719422500681\n",
      "Epoch number: 1938/10000step_number: 0/29 cost:  0.2523146789742376 accuracy:  0.929719422500681\n",
      "Epoch number: 1939/10000step_number: 0/29 cost:  0.2522298209865407 accuracy:  0.9298556251702533\n",
      "Epoch number: 1940/10000step_number: 0/29 cost:  0.2521413452861742 accuracy:  0.9298556251702533\n",
      "Epoch number: 1941/10000step_number: 0/29 cost:  0.2520550122125868 accuracy:  0.9299918278398257\n",
      "Epoch number: 1942/10000step_number: 0/29 cost:  0.2519639499837874 accuracy:  0.9299918278398257\n",
      "Epoch number: 1943/10000step_number: 0/29 cost:  0.2518737682754415 accuracy:  0.9299918278398257\n",
      "Epoch number: 1944/10000step_number: 0/29 cost:  0.251778274875514 accuracy:  0.9299918278398257\n",
      "Epoch number: 1945/10000step_number: 0/29 cost:  0.2516848870214765 accuracy:  0.9299918278398257\n",
      "Epoch number: 1946/10000step_number: 0/29 cost:  0.2515923015540341 accuracy:  0.9299918278398257\n",
      "Epoch number: 1947/10000step_number: 0/29 cost:  0.251510401120434 accuracy:  0.9299918278398257\n",
      "Epoch number: 1948/10000step_number: 0/29 cost:  0.25142690892346875 accuracy:  0.9299918278398257\n",
      "Epoch number: 1949/10000step_number: 0/29 cost:  0.25134180117876104 accuracy:  0.9299918278398257\n",
      "Epoch number: 1950/10000step_number: 0/29 cost:  0.2512596443337897 accuracy:  0.9299918278398257\n",
      "Epoch number: 1951/10000step_number: 0/29 cost:  0.25118010291408704 accuracy:  0.9299918278398257\n",
      "Epoch number: 1952/10000step_number: 0/29 cost:  0.2510971843241106 accuracy:  0.930128030509398\n",
      "Epoch number: 1953/10000step_number: 0/29 cost:  0.25101445830392505 accuracy:  0.9302642331789703\n",
      "Epoch number: 1954/10000step_number: 0/29 cost:  0.2509312312580286 accuracy:  0.9302642331789703\n",
      "Epoch number: 1955/10000step_number: 0/29 cost:  0.2508473230540211 accuracy:  0.9302642331789703\n",
      "Epoch number: 1956/10000step_number: 0/29 cost:  0.25073555261535674 accuracy:  0.9302642331789703\n",
      "Epoch number: 1957/10000step_number: 0/29 cost:  0.25066365419968306 accuracy:  0.9304004358485426\n",
      "Epoch number: 1958/10000step_number: 0/29 cost:  0.2505866627424063 accuracy:  0.9304004358485426\n",
      "Epoch number: 1959/10000step_number: 0/29 cost:  0.2505154041897093 accuracy:  0.9304004358485426\n",
      "Epoch number: 1960/10000step_number: 0/29 cost:  0.2503885105984027 accuracy:  0.9302642331789703\n",
      "Epoch number: 1961/10000step_number: 0/29 cost:  0.25034106929403116 accuracy:  0.9304004358485426\n",
      "Epoch number: 1962/10000step_number: 0/29 cost:  0.2502052362945729 accuracy:  0.930536638518115\n",
      "Epoch number: 1963/10000step_number: 0/29 cost:  0.2501640585997266 accuracy:  0.9304004358485426\n",
      "Epoch number: 1964/10000step_number: 0/29 cost:  0.2500547767532034 accuracy:  0.9302642331789703\n",
      "Epoch number: 1965/10000step_number: 0/29 cost:  0.2500087851301341 accuracy:  0.930536638518115\n",
      "Epoch number: 1966/10000step_number: 0/29 cost:  0.2498728321617257 accuracy:  0.9304004358485426\n",
      "Epoch number: 1967/10000step_number: 0/29 cost:  0.24983623616822337 accuracy:  0.9304004358485426\n",
      "Epoch number: 1968/10000step_number: 0/29 cost:  0.24970304153373307 accuracy:  0.9304004358485426\n",
      "Epoch number: 1969/10000step_number: 0/29 cost:  0.24966700062030653 accuracy:  0.930536638518115\n",
      "Epoch number: 1970/10000step_number: 0/29 cost:  0.24952261369722056 accuracy:  0.930536638518115\n",
      "Epoch number: 1971/10000step_number: 0/29 cost:  0.24949827173617004 accuracy:  0.930536638518115\n",
      "Epoch number: 1972/10000step_number: 0/29 cost:  0.24934808159420357 accuracy:  0.930536638518115\n",
      "Epoch number: 1973/10000step_number: 0/29 cost:  0.24933372263195552 accuracy:  0.930536638518115\n",
      "Epoch number: 1974/10000step_number: 0/29 cost:  0.24917553883324653 accuracy:  0.930536638518115\n",
      "Epoch number: 1975/10000step_number: 0/29 cost:  0.24916811813533124 accuracy:  0.930536638518115\n",
      "Epoch number: 1976/10000step_number: 0/29 cost:  0.24900420507236623 accuracy:  0.930536638518115\n",
      "Epoch number: 1977/10000step_number: 0/29 cost:  0.2490011202202424 accuracy:  0.930536638518115\n",
      "Epoch number: 1978/10000step_number: 0/29 cost:  0.24883571321113107 accuracy:  0.930536638518115\n",
      "Epoch number: 1979/10000step_number: 0/29 cost:  0.24883374525326551 accuracy:  0.9306728411876872\n",
      "Epoch number: 1980/10000step_number: 0/29 cost:  0.24866814624870373 accuracy:  0.9308090438572596\n",
      "Epoch number: 1981/10000step_number: 0/29 cost:  0.2486650902398125 accuracy:  0.9306728411876872\n",
      "Epoch number: 1982/10000step_number: 0/29 cost:  0.24850244023567067 accuracy:  0.9308090438572596\n",
      "Epoch number: 1983/10000step_number: 0/29 cost:  0.24849493668476055 accuracy:  0.9306728411876872\n",
      "Epoch number: 1984/10000step_number: 0/29 cost:  0.24833933107800205 accuracy:  0.9308090438572596\n",
      "Epoch number: 1985/10000step_number: 0/29 cost:  0.2483209761257777 accuracy:  0.9306728411876872\n",
      "Epoch number: 1986/10000step_number: 0/29 cost:  0.2481813135953167 accuracy:  0.9308090438572596\n",
      "Epoch number: 1987/10000step_number: 0/29 cost:  0.24813264253549394 accuracy:  0.930536638518115\n",
      "Epoch number: 1988/10000step_number: 0/29 cost:  0.24802971942681973 accuracy:  0.9308090438572596\n",
      "Epoch number: 1989/10000step_number: 0/29 cost:  0.24793877938133901 accuracy:  0.9308090438572596\n",
      "Epoch number: 1990/10000step_number: 0/29 cost:  0.24787013955390005 accuracy:  0.9308090438572596\n",
      "Epoch number: 1991/10000step_number: 0/29 cost:  0.24777755701286655 accuracy:  0.9308090438572596\n",
      "Epoch number: 1992/10000step_number: 0/29 cost:  0.24770643189956165 accuracy:  0.930945246526832\n",
      "Epoch number: 1993/10000step_number: 0/29 cost:  0.24760831513415849 accuracy:  0.930945246526832\n",
      "Epoch number: 1994/10000step_number: 0/29 cost:  0.24755441225417832 accuracy:  0.930945246526832\n",
      "Epoch number: 1995/10000step_number: 0/29 cost:  0.24741768368766195 accuracy:  0.930945246526832\n",
      "Epoch number: 1996/10000step_number: 0/29 cost:  0.24739282469595306 accuracy:  0.930945246526832\n",
      "Epoch number: 1997/10000step_number: 0/29 cost:  0.2472423184139922 accuracy:  0.930945246526832\n",
      "Epoch number: 1998/10000step_number: 0/29 cost:  0.24722997579848444 accuracy:  0.930945246526832\n",
      "Epoch number: 1999/10000step_number: 0/29 cost:  0.24706948813596388 accuracy:  0.930945246526832\n",
      "Epoch number: 2000/10000step_number: 0/29 cost:  0.24706810565559165 accuracy:  0.930945246526832\n",
      "Epoch number: 2001/10000step_number: 0/29 cost:  0.24690345382763013 accuracy:  0.930945246526832\n",
      "Epoch number: 2002/10000step_number: 0/29 cost:  0.24690214330907617 accuracy:  0.930945246526832\n",
      "Epoch number: 2003/10000step_number: 0/29 cost:  0.24674782842106618 accuracy:  0.930945246526832\n",
      "Epoch number: 2004/10000step_number: 0/29 cost:  0.24671992208357096 accuracy:  0.930945246526832\n",
      "Epoch number: 2005/10000step_number: 0/29 cost:  0.24660525871254257 accuracy:  0.9308090438572596\n",
      "Epoch number: 2006/10000step_number: 0/29 cost:  0.24650936004108273 accuracy:  0.9310814491964042\n",
      "Epoch number: 2007/10000step_number: 0/29 cost:  0.2464507616324259 accuracy:  0.9308090438572596\n",
      "Epoch number: 2008/10000step_number: 0/29 cost:  0.2463916778233902 accuracy:  0.9308090438572596\n",
      "Epoch number: 2009/10000step_number: 0/29 cost:  0.24630270118551012 accuracy:  0.9306728411876872\n",
      "Epoch number: 2010/10000step_number: 0/29 cost:  0.2462404487748765 accuracy:  0.930536638518115\n",
      "Epoch number: 2011/10000step_number: 0/29 cost:  0.24615345102205885 accuracy:  0.930536638518115\n",
      "Epoch number: 2012/10000step_number: 0/29 cost:  0.24607019768565963 accuracy:  0.930536638518115\n",
      "Epoch number: 2013/10000step_number: 0/29 cost:  0.24600606556232996 accuracy:  0.930536638518115\n",
      "Epoch number: 2014/10000step_number: 0/29 cost:  0.24592795418044433 accuracy:  0.930536638518115\n",
      "Epoch number: 2015/10000step_number: 0/29 cost:  0.24585525021565272 accuracy:  0.9306728411876872\n",
      "Epoch number: 2016/10000step_number: 0/29 cost:  0.24578308700093282 accuracy:  0.9306728411876872\n",
      "Epoch number: 2017/10000step_number: 0/29 cost:  0.2457173483488532 accuracy:  0.9306728411876872\n",
      "Epoch number: 2018/10000step_number: 0/29 cost:  0.24564639457376508 accuracy:  0.9306728411876872\n",
      "Epoch number: 2019/10000step_number: 0/29 cost:  0.24558124331976716 accuracy:  0.930945246526832\n",
      "Epoch number: 2020/10000step_number: 0/29 cost:  0.24552405317264947 accuracy:  0.930945246526832\n",
      "Epoch number: 2021/10000step_number: 0/29 cost:  0.2454525748982782 accuracy:  0.930945246526832\n",
      "Epoch number: 2022/10000step_number: 0/29 cost:  0.24540971267083464 accuracy:  0.930945246526832\n",
      "Epoch number: 2023/10000step_number: 0/29 cost:  0.24532307737579107 accuracy:  0.930945246526832\n",
      "Epoch number: 2024/10000step_number: 0/29 cost:  0.24527049471008983 accuracy:  0.9310814491964042\n",
      "Epoch number: 2025/10000step_number: 0/29 cost:  0.24516586886733324 accuracy:  0.9310814491964042\n",
      "Epoch number: 2026/10000step_number: 0/29 cost:  0.24510888615102494 accuracy:  0.9310814491964042\n",
      "Epoch number: 2027/10000step_number: 0/29 cost:  0.24499310620664505 accuracy:  0.930945246526832\n",
      "Epoch number: 2028/10000step_number: 0/29 cost:  0.2449423400943481 accuracy:  0.930945246526832\n",
      "Epoch number: 2029/10000step_number: 0/29 cost:  0.2448231193924162 accuracy:  0.930945246526832\n",
      "Epoch number: 2030/10000step_number: 0/29 cost:  0.24477342460824192 accuracy:  0.9308090438572596\n",
      "Epoch number: 2031/10000step_number: 0/29 cost:  0.24465331271916102 accuracy:  0.9308090438572596\n",
      "Epoch number: 2032/10000step_number: 0/29 cost:  0.24460212625145533 accuracy:  0.930945246526832\n",
      "Epoch number: 2033/10000step_number: 0/29 cost:  0.24448549926145088 accuracy:  0.930945246526832\n",
      "Epoch number: 2034/10000step_number: 0/29 cost:  0.24442740612154626 accuracy:  0.930945246526832\n",
      "Epoch number: 2035/10000step_number: 0/29 cost:  0.24431756947047104 accuracy:  0.9310814491964042\n",
      "Epoch number: 2036/10000step_number: 0/29 cost:  0.24424865521757805 accuracy:  0.9310814491964042\n",
      "Epoch number: 2037/10000step_number: 0/29 cost:  0.24414878889604194 accuracy:  0.9310814491964042\n",
      "Epoch number: 2038/10000step_number: 0/29 cost:  0.24406763000925846 accuracy:  0.9310814491964042\n",
      "Epoch number: 2039/10000step_number: 0/29 cost:  0.24397624118259767 accuracy:  0.9310814491964042\n",
      "Epoch number: 2040/10000step_number: 0/29 cost:  0.24388773154467522 accuracy:  0.9312176518659766\n",
      "Epoch number: 2041/10000step_number: 0/29 cost:  0.24379915392993257 accuracy:  0.9312176518659766\n",
      "Epoch number: 2042/10000step_number: 0/29 cost:  0.24370957152521136 accuracy:  0.9312176518659766\n",
      "Epoch number: 2043/10000step_number: 0/29 cost:  0.24362011805364145 accuracy:  0.9312176518659766\n",
      "Epoch number: 2044/10000step_number: 0/29 cost:  0.24353128171394936 accuracy:  0.9312176518659766\n",
      "Epoch number: 2045/10000step_number: 0/29 cost:  0.24344145286309685 accuracy:  0.9312176518659766\n",
      "Epoch number: 2046/10000step_number: 0/29 cost:  0.24335199833517365 accuracy:  0.9313538545355489\n",
      "Epoch number: 2047/10000step_number: 0/29 cost:  0.24326343018493993 accuracy:  0.9313538545355489\n",
      "Epoch number: 2048/10000step_number: 0/29 cost:  0.2431727097892249 accuracy:  0.9313538545355489\n",
      "Epoch number: 2049/10000step_number: 0/29 cost:  0.24308496189813744 accuracy:  0.9314900572051212\n",
      "Epoch number: 2050/10000step_number: 0/29 cost:  0.24299437826234774 accuracy:  0.9316262598746935\n",
      "Epoch number: 2051/10000step_number: 0/29 cost:  0.24290616929039135 accuracy:  0.9316262598746935\n",
      "Epoch number: 2052/10000step_number: 0/29 cost:  0.2428163285462448 accuracy:  0.9316262598746935\n",
      "Epoch number: 2053/10000step_number: 0/29 cost:  0.24272834822458086 accuracy:  0.9316262598746935\n",
      "Epoch number: 2054/10000step_number: 0/29 cost:  0.2426378916520389 accuracy:  0.9316262598746935\n",
      "Epoch number: 2055/10000step_number: 0/29 cost:  0.2425517439370695 accuracy:  0.9316262598746935\n",
      "Epoch number: 2056/10000step_number: 0/29 cost:  0.24245987245704662 accuracy:  0.9314900572051212\n",
      "Epoch number: 2057/10000step_number: 0/29 cost:  0.2423756217256438 accuracy:  0.9314900572051212\n",
      "Epoch number: 2058/10000step_number: 0/29 cost:  0.24228321375099107 accuracy:  0.9316262598746935\n",
      "Epoch number: 2059/10000step_number: 0/29 cost:  0.24219975360600296 accuracy:  0.9318986652138382\n",
      "Epoch number: 2060/10000step_number: 0/29 cost:  0.24210808511025791 accuracy:  0.9320348678834105\n",
      "Epoch number: 2061/10000step_number: 0/29 cost:  0.24202452569244642 accuracy:  0.9320348678834105\n",
      "Epoch number: 2062/10000step_number: 0/29 cost:  0.241934197366563 accuracy:  0.9323072732225551\n",
      "Epoch number: 2063/10000step_number: 0/29 cost:  0.24185042873251467 accuracy:  0.9323072732225551\n",
      "Epoch number: 2064/10000step_number: 0/29 cost:  0.24176141544355748 accuracy:  0.9323072732225551\n",
      "Epoch number: 2065/10000step_number: 0/29 cost:  0.2416782555104057 accuracy:  0.9323072732225551\n",
      "Epoch number: 2066/10000step_number: 0/29 cost:  0.2415928434235258 accuracy:  0.9323072732225551\n",
      "Epoch number: 2067/10000step_number: 0/29 cost:  0.24151578553936573 accuracy:  0.9323072732225551\n",
      "Epoch number: 2068/10000step_number: 0/29 cost:  0.24144471221446942 accuracy:  0.9324434758921275\n",
      "Epoch number: 2069/10000step_number: 0/29 cost:  0.24133762727170177 accuracy:  0.9324434758921275\n",
      "Epoch number: 2070/10000step_number: 0/29 cost:  0.24128195044178638 accuracy:  0.9324434758921275\n",
      "Epoch number: 2071/10000step_number: 0/29 cost:  0.24114623544915548 accuracy:  0.9324434758921275\n",
      "Epoch number: 2072/10000step_number: 0/29 cost:  0.2411176168119092 accuracy:  0.9324434758921275\n",
      "Epoch number: 2073/10000step_number: 0/29 cost:  0.24093361679164066 accuracy:  0.9324434758921275\n",
      "Epoch number: 2074/10000step_number: 0/29 cost:  0.24096321488897302 accuracy:  0.9324434758921275\n",
      "Epoch number: 2075/10000step_number: 0/29 cost:  0.24069998478133375 accuracy:  0.9324434758921275\n",
      "Epoch number: 2076/10000step_number: 0/29 cost:  0.24081366957819342 accuracy:  0.9329882865704168\n",
      "Epoch number: 2077/10000step_number: 0/29 cost:  0.24050110241205055 accuracy:  0.9329882865704168\n",
      "Epoch number: 2078/10000step_number: 0/29 cost:  0.24068140089905057 accuracy:  0.9329882865704168\n",
      "Epoch number: 2079/10000step_number: 0/29 cost:  0.24036969531305358 accuracy:  0.9331244892399891\n",
      "Epoch number: 2080/10000step_number: 0/29 cost:  0.24052648067660723 accuracy:  0.9328520839008445\n",
      "Epoch number: 2081/10000step_number: 0/29 cost:  0.2402802587733919 accuracy:  0.9331244892399891\n",
      "Epoch number: 2082/10000step_number: 0/29 cost:  0.24040910972208598 accuracy:  0.9329882865704168\n",
      "Epoch number: 2083/10000step_number: 0/29 cost:  0.2401757529555343 accuracy:  0.9331244892399891\n",
      "Epoch number: 2084/10000step_number: 0/29 cost:  0.2402525317672399 accuracy:  0.9331244892399891\n",
      "Epoch number: 2085/10000step_number: 0/29 cost:  0.2400677483903115 accuracy:  0.9331244892399891\n",
      "Epoch number: 2086/10000step_number: 0/29 cost:  0.24015509644468988 accuracy:  0.9329882865704168\n",
      "Epoch number: 2087/10000step_number: 0/29 cost:  0.23993777870570102 accuracy:  0.9331244892399891\n",
      "Epoch number: 2088/10000step_number: 0/29 cost:  0.23999103840382321 accuracy:  0.9329882865704168\n",
      "Epoch number: 2089/10000step_number: 0/29 cost:  0.23982695098406226 accuracy:  0.9331244892399891\n",
      "Epoch number: 2090/10000step_number: 0/29 cost:  0.23993243285968274 accuracy:  0.9331244892399891\n",
      "Epoch number: 2091/10000step_number: 0/29 cost:  0.23967969443151127 accuracy:  0.9329882865704168\n",
      "Epoch number: 2092/10000step_number: 0/29 cost:  0.23971793701478133 accuracy:  0.9331244892399891\n",
      "Epoch number: 2093/10000step_number: 0/29 cost:  0.23957558609207658 accuracy:  0.9329882865704168\n",
      "Epoch number: 2094/10000step_number: 0/29 cost:  0.239723233252676 accuracy:  0.9331244892399891\n",
      "Epoch number: 2095/10000step_number: 0/29 cost:  0.23939122580114686 accuracy:  0.9331244892399891\n",
      "Epoch number: 2096/10000step_number: 0/29 cost:  0.23938869861092485 accuracy:  0.9329882865704168\n",
      "Epoch number: 2097/10000step_number: 0/29 cost:  0.23929705964970543 accuracy:  0.9333968945791338\n",
      "Epoch number: 2098/10000step_number: 0/29 cost:  0.23949196921703528 accuracy:  0.9328520839008445\n",
      "Epoch number: 2099/10000step_number: 0/29 cost:  0.23905361106223616 accuracy:  0.9333968945791338\n",
      "Epoch number: 2100/10000step_number: 0/29 cost:  0.23902632495863743 accuracy:  0.9340779079269954\n",
      "Epoch number: 2101/10000step_number: 0/29 cost:  0.23897418406578616 accuracy:  0.9333968945791338\n",
      "Epoch number: 2102/10000step_number: 0/29 cost:  0.23918132001355907 accuracy:  0.933941705257423\n",
      "Epoch number: 2103/10000step_number: 0/29 cost:  0.23870800347974766 accuracy:  0.93435031326614\n",
      "Epoch number: 2104/10000step_number: 0/29 cost:  0.23872170937159398 accuracy:  0.9340779079269954\n",
      "Epoch number: 2105/10000step_number: 0/29 cost:  0.238620311930237 accuracy:  0.9342141105965677\n",
      "Epoch number: 2106/10000step_number: 0/29 cost:  0.23880967442279305 accuracy:  0.933941705257423\n",
      "Epoch number: 2107/10000step_number: 0/29 cost:  0.23839031949927433 accuracy:  0.9342141105965677\n",
      "Epoch number: 2108/10000step_number: 0/29 cost:  0.2383567154249506 accuracy:  0.933941705257423\n",
      "Epoch number: 2109/10000step_number: 0/29 cost:  0.23829796887532798 accuracy:  0.933941705257423\n",
      "Epoch number: 2110/10000step_number: 0/29 cost:  0.23850188599819547 accuracy:  0.9338055025878507\n",
      "Epoch number: 2111/10000step_number: 0/29 cost:  0.23803618818443492 accuracy:  0.9342141105965677\n",
      "Epoch number: 2112/10000step_number: 0/29 cost:  0.23802578629250049 accuracy:  0.9340779079269954\n",
      "Epoch number: 2113/10000step_number: 0/29 cost:  0.23794292183992313 accuracy:  0.9342141105965677\n",
      "Epoch number: 2114/10000step_number: 0/29 cost:  0.23813238993963654 accuracy:  0.9340779079269954\n",
      "Epoch number: 2115/10000step_number: 0/29 cost:  0.23771019048298045 accuracy:  0.9342141105965677\n",
      "Epoch number: 2116/10000step_number: 0/29 cost:  0.23766222540958262 accuracy:  0.9342141105965677\n",
      "Epoch number: 2117/10000step_number: 0/29 cost:  0.23761868412415144 accuracy:  0.9342141105965677\n",
      "Epoch number: 2118/10000step_number: 0/29 cost:  0.23782577794735574 accuracy:  0.9342141105965677\n",
      "Epoch number: 2119/10000step_number: 0/29 cost:  0.2373642218909509 accuracy:  0.9342141105965677\n",
      "Epoch number: 2120/10000step_number: 0/29 cost:  0.23734475530720364 accuracy:  0.9342141105965677\n",
      "Epoch number: 2121/10000step_number: 0/29 cost:  0.23727221315479405 accuracy:  0.93435031326614\n",
      "Epoch number: 2122/10000step_number: 0/29 cost:  0.2374626170259175 accuracy:  0.9342141105965677\n",
      "Epoch number: 2123/10000step_number: 0/29 cost:  0.23704894201017182 accuracy:  0.93435031326614\n",
      "Epoch number: 2124/10000step_number: 0/29 cost:  0.23698749697525603 accuracy:  0.9342141105965677\n",
      "Epoch number: 2125/10000step_number: 0/29 cost:  0.2369598471466231 accuracy:  0.9344865159357123\n",
      "Epoch number: 2126/10000step_number: 0/29 cost:  0.23717129950491933 accuracy:  0.9344865159357123\n",
      "Epoch number: 2127/10000step_number: 0/29 cost:  0.2367090096297439 accuracy:  0.9344865159357123\n",
      "Epoch number: 2128/10000step_number: 0/29 cost:  0.2366856517926283 accuracy:  0.9346227186052847\n",
      "Epoch number: 2129/10000step_number: 0/29 cost:  0.23661762085466204 accuracy:  0.9344865159357123\n",
      "Epoch number: 2130/10000step_number: 0/29 cost:  0.23680338690391484 accuracy:  0.9346227186052847\n",
      "Epoch number: 2131/10000step_number: 0/29 cost:  0.23640165323681425 accuracy:  0.9344865159357123\n",
      "Epoch number: 2132/10000step_number: 0/29 cost:  0.23632738097009598 accuracy:  0.9348951239444293\n",
      "Epoch number: 2133/10000step_number: 0/29 cost:  0.2363130219363847 accuracy:  0.9350313266140017\n",
      "Epoch number: 2134/10000step_number: 0/29 cost:  0.2365265046798187 accuracy:  0.9348951239444293\n",
      "Epoch number: 2135/10000step_number: 0/29 cost:  0.2360613082929163 accuracy:  0.9350313266140017\n",
      "Epoch number: 2136/10000step_number: 0/29 cost:  0.2360362673028337 accuracy:  0.9350313266140017\n",
      "Epoch number: 2137/10000step_number: 0/29 cost:  0.23596939208141504 accuracy:  0.9350313266140017\n",
      "Epoch number: 2138/10000step_number: 0/29 cost:  0.23614570572644208 accuracy:  0.9351675292835739\n",
      "Epoch number: 2139/10000step_number: 0/29 cost:  0.23575741813914614 accuracy:  0.9350313266140017\n",
      "Epoch number: 2140/10000step_number: 0/29 cost:  0.2356738801632099 accuracy:  0.9351675292835739\n",
      "Epoch number: 2141/10000step_number: 0/29 cost:  0.23566848474410534 accuracy:  0.9351675292835739\n",
      "Epoch number: 2142/10000step_number: 0/29 cost:  0.23588121425337807 accuracy:  0.9351675292835739\n",
      "Epoch number: 2143/10000step_number: 0/29 cost:  0.23541639842417234 accuracy:  0.9351675292835739\n",
      "Epoch number: 2144/10000step_number: 0/29 cost:  0.23538210122224723 accuracy:  0.9351675292835739\n",
      "Epoch number: 2145/10000step_number: 0/29 cost:  0.23532513363137922 accuracy:  0.9351675292835739\n",
      "Epoch number: 2146/10000step_number: 0/29 cost:  0.2354955110580418 accuracy:  0.9351675292835739\n",
      "Epoch number: 2147/10000step_number: 0/29 cost:  0.2351115958885043 accuracy:  0.9351675292835739\n",
      "Epoch number: 2148/10000step_number: 0/29 cost:  0.23501833073287384 accuracy:  0.9351675292835739\n",
      "Epoch number: 2149/10000step_number: 0/29 cost:  0.23502362192996076 accuracy:  0.9351675292835739\n",
      "Epoch number: 2150/10000step_number: 0/29 cost:  0.23523481027626117 accuracy:  0.9351675292835739\n",
      "Epoch number: 2151/10000step_number: 0/29 cost:  0.2347710440747402 accuracy:  0.9350313266140017\n",
      "Epoch number: 2152/10000step_number: 0/29 cost:  0.23472955997365938 accuracy:  0.9350313266140017\n",
      "Epoch number: 2153/10000step_number: 0/29 cost:  0.23468007540964655 accuracy:  0.9350313266140017\n",
      "Epoch number: 2154/10000step_number: 0/29 cost:  0.2348414717139315 accuracy:  0.9353037319531463\n",
      "Epoch number: 2155/10000step_number: 0/29 cost:  0.23446631822494862 accuracy:  0.9350313266140017\n",
      "Epoch number: 2156/10000step_number: 0/29 cost:  0.23436466854714513 accuracy:  0.9350313266140017\n",
      "Epoch number: 2157/10000step_number: 0/29 cost:  0.23437896148766912 accuracy:  0.9348951239444293\n",
      "Epoch number: 2158/10000step_number: 0/29 cost:  0.2345866792642392 accuracy:  0.9348951239444293\n",
      "Epoch number: 2159/10000step_number: 0/29 cost:  0.23412901650087634 accuracy:  0.9348951239444293\n",
      "Epoch number: 2160/10000step_number: 0/29 cost:  0.23407050191015283 accuracy:  0.9350313266140017\n",
      "Epoch number: 2161/10000step_number: 0/29 cost:  0.2340392673601831 accuracy:  0.9350313266140017\n",
      "Epoch number: 2162/10000step_number: 0/29 cost:  0.2341966627226182 accuracy:  0.9348951239444293\n",
      "Epoch number: 2163/10000step_number: 0/29 cost:  0.23382407160353377 accuracy:  0.9351675292835739\n",
      "Epoch number: 2164/10000step_number: 0/29 cost:  0.23371421645758633 accuracy:  0.9348951239444293\n",
      "Epoch number: 2165/10000step_number: 0/29 cost:  0.23374019063169266 accuracy:  0.9351675292835739\n",
      "Epoch number: 2166/10000step_number: 0/29 cost:  0.23394313976382727 accuracy:  0.9348951239444293\n",
      "Epoch number: 2167/10000step_number: 0/29 cost:  0.23349503114296763 accuracy:  0.9353037319531463\n",
      "Epoch number: 2168/10000step_number: 0/29 cost:  0.23342286514467903 accuracy:  0.9350313266140017\n",
      "Epoch number: 2169/10000step_number: 0/29 cost:  0.2334067991766554 accuracy:  0.9350313266140017\n",
      "Epoch number: 2170/10000step_number: 0/29 cost:  0.23354602346202302 accuracy:  0.9350313266140017\n",
      "Epoch number: 2171/10000step_number: 0/29 cost:  0.23319345148853302 accuracy:  0.9353037319531463\n",
      "Epoch number: 2172/10000step_number: 0/29 cost:  0.23305881561034794 accuracy:  0.9350313266140017\n",
      "Epoch number: 2173/10000step_number: 0/29 cost:  0.23310874444398785 accuracy:  0.9353037319531463\n",
      "Epoch number: 2174/10000step_number: 0/29 cost:  0.23327934429640176 accuracy:  0.9351675292835739\n",
      "Epoch number: 2175/10000step_number: 0/29 cost:  0.23287960117881903 accuracy:  0.9353037319531463\n",
      "Epoch number: 2176/10000step_number: 0/29 cost:  0.23274060195535481 accuracy:  0.9351675292835739\n",
      "Epoch number: 2177/10000step_number: 0/29 cost:  0.23279574586634075 accuracy:  0.9353037319531463\n",
      "Epoch number: 2178/10000step_number: 0/29 cost:  0.232862482462755 accuracy:  0.9353037319531463\n",
      "Epoch number: 2179/10000step_number: 0/29 cost:  0.2325807351396811 accuracy:  0.9353037319531463\n",
      "Epoch number: 2180/10000step_number: 0/29 cost:  0.2323814664082875 accuracy:  0.9353037319531463\n",
      "Epoch number: 2181/10000step_number: 0/29 cost:  0.2325376298556948 accuracy:  0.9353037319531463\n",
      "Epoch number: 2182/10000step_number: 0/29 cost:  0.23247590809448282 accuracy:  0.9353037319531463\n",
      "Epoch number: 2183/10000step_number: 0/29 cost:  0.23230610794934178 accuracy:  0.9353037319531463\n",
      "Epoch number: 2184/10000step_number: 0/29 cost:  0.23202351432369295 accuracy:  0.9353037319531463\n",
      "Epoch number: 2185/10000step_number: 0/29 cost:  0.23231132252518022 accuracy:  0.9353037319531463\n",
      "Epoch number: 2186/10000step_number: 0/29 cost:  0.23196544497026556 accuracy:  0.9354399346227186\n",
      "Epoch number: 2187/10000step_number: 0/29 cost:  0.23185950375910788 accuracy:  0.9351675292835739\n",
      "Epoch number: 2188/10000step_number: 0/29 cost:  0.23186388704199765 accuracy:  0.9354399346227186\n",
      "Epoch number: 2189/10000step_number: 0/29 cost:  0.23207324490979586 accuracy:  0.9353037319531463\n",
      "Epoch number: 2190/10000step_number: 0/29 cost:  0.23162317400703614 accuracy:  0.9355761372922909\n",
      "Epoch number: 2191/10000step_number: 0/29 cost:  0.23150156667783675 accuracy:  0.9353037319531463\n",
      "Epoch number: 2192/10000step_number: 0/29 cost:  0.23152711409712223 accuracy:  0.9354399346227186\n",
      "Epoch number: 2193/10000step_number: 0/29 cost:  0.2317393442783448 accuracy:  0.9353037319531463\n",
      "Epoch number: 2194/10000step_number: 0/29 cost:  0.231283864107052 accuracy:  0.9354399346227186\n",
      "Epoch number: 2195/10000step_number: 0/29 cost:  0.23117341705379782 accuracy:  0.9353037319531463\n",
      "Epoch number: 2196/10000step_number: 0/29 cost:  0.23120148844350277 accuracy:  0.9353037319531463\n",
      "Epoch number: 2197/10000step_number: 0/29 cost:  0.23140151990524374 accuracy:  0.9353037319531463\n",
      "Epoch number: 2198/10000step_number: 0/29 cost:  0.23097898669250855 accuracy:  0.9353037319531463\n",
      "Epoch number: 2199/10000step_number: 0/29 cost:  0.23087230368628894 accuracy:  0.9353037319531463\n",
      "Epoch number: 2200/10000step_number: 0/29 cost:  0.23087059154874298 accuracy:  0.9355761372922909\n",
      "Epoch number: 2201/10000step_number: 0/29 cost:  0.23104245333751788 accuracy:  0.9353037319531463\n",
      "Epoch number: 2202/10000step_number: 0/29 cost:  0.23065599274187248 accuracy:  0.9354399346227186\n",
      "Epoch number: 2203/10000step_number: 0/29 cost:  0.2305421685300064 accuracy:  0.9351675292835739\n",
      "Epoch number: 2204/10000step_number: 0/29 cost:  0.23056547583382186 accuracy:  0.9357123399618632\n",
      "Epoch number: 2205/10000step_number: 0/29 cost:  0.23076210682676118 accuracy:  0.9354399346227186\n",
      "Epoch number: 2206/10000step_number: 0/29 cost:  0.23033520116808143 accuracy:  0.9355761372922909\n",
      "Epoch number: 2207/10000step_number: 0/29 cost:  0.23022577650672374 accuracy:  0.9354399346227186\n",
      "Epoch number: 2208/10000step_number: 0/29 cost:  0.23024863886390612 accuracy:  0.9355761372922909\n",
      "Epoch number: 2209/10000step_number: 0/29 cost:  0.23043106524139786 accuracy:  0.9353037319531463\n",
      "Epoch number: 2210/10000step_number: 0/29 cost:  0.23007822878820997 accuracy:  0.9354399346227186\n",
      "Epoch number: 2211/10000step_number: 0/29 cost:  0.2299301766400192 accuracy:  0.9354399346227186\n",
      "Epoch number: 2212/10000step_number: 0/29 cost:  0.22997395374128066 accuracy:  0.9357123399618632\n",
      "Epoch number: 2213/10000step_number: 0/29 cost:  0.2301736727707917 accuracy:  0.9351675292835739\n",
      "Epoch number: 2214/10000step_number: 0/29 cost:  0.22969676590166643 accuracy:  0.9355761372922909\n",
      "Epoch number: 2215/10000step_number: 0/29 cost:  0.22959574255050627 accuracy:  0.9353037319531463\n",
      "Epoch number: 2216/10000step_number: 0/29 cost:  0.22965941430942105 accuracy:  0.9357123399618632\n",
      "Epoch number: 2217/10000step_number: 0/29 cost:  0.22989498705973185 accuracy:  0.9353037319531463\n",
      "Epoch number: 2218/10000step_number: 0/29 cost:  0.22942152663045384 accuracy:  0.9355761372922909\n",
      "Epoch number: 2219/10000step_number: 0/29 cost:  0.22937723556843095 accuracy:  0.9353037319531463\n",
      "Epoch number: 2220/10000step_number: 0/29 cost:  0.22931350051328664 accuracy:  0.9355761372922909\n",
      "Epoch number: 2221/10000step_number: 0/29 cost:  0.22945556842548304 accuracy:  0.9354399346227186\n",
      "Epoch number: 2222/10000step_number: 0/29 cost:  0.2291693785005715 accuracy:  0.9354399346227186\n",
      "Epoch number: 2223/10000step_number: 0/29 cost:  0.22897025162245857 accuracy:  0.9354399346227186\n",
      "Epoch number: 2224/10000step_number: 0/29 cost:  0.2291037450763086 accuracy:  0.9355761372922909\n",
      "Epoch number: 2225/10000step_number: 0/29 cost:  0.22920014366848604 accuracy:  0.9357123399618632\n",
      "Epoch number: 2226/10000step_number: 0/29 cost:  0.2288710905724739 accuracy:  0.9355761372922909\n",
      "Epoch number: 2227/10000step_number: 0/29 cost:  0.22849603570804825 accuracy:  0.9355761372922909\n",
      "Epoch number: 2228/10000step_number: 0/29 cost:  0.22878377111846324 accuracy:  0.9357123399618632\n",
      "Epoch number: 2229/10000step_number: 0/29 cost:  0.2287231671421241 accuracy:  0.9357123399618632\n",
      "Epoch number: 2230/10000step_number: 0/29 cost:  0.2284882747387073 accuracy:  0.9355761372922909\n",
      "Epoch number: 2231/10000step_number: 0/29 cost:  0.22837999672852727 accuracy:  0.9358485426314356\n",
      "Epoch number: 2232/10000step_number: 0/29 cost:  0.22851398804827341 accuracy:  0.9357123399618632\n",
      "Epoch number: 2233/10000step_number: 0/29 cost:  0.22808434821273063 accuracy:  0.9357123399618632\n",
      "Epoch number: 2234/10000step_number: 0/29 cost:  0.22821227598431762 accuracy:  0.9357123399618632\n",
      "Epoch number: 2235/10000step_number: 0/29 cost:  0.22816685756174102 accuracy:  0.9355761372922909\n",
      "Epoch number: 2236/10000step_number: 0/29 cost:  0.228152164403299 accuracy:  0.9357123399618632\n",
      "Epoch number: 2237/10000step_number: 0/29 cost:  0.22809021126634244 accuracy:  0.9358485426314356\n",
      "Epoch number: 2238/10000step_number: 0/29 cost:  0.22779454853434214 accuracy:  0.9358485426314356\n",
      "Epoch number: 2239/10000step_number: 0/29 cost:  0.2281607144899868 accuracy:  0.935984745301008\n",
      "Epoch number: 2240/10000step_number: 0/29 cost:  0.228019222538227 accuracy:  0.935984745301008\n",
      "Epoch number: 2241/10000step_number: 0/29 cost:  0.2277961618941871 accuracy:  0.9361209479705802\n",
      "Epoch number: 2242/10000step_number: 0/29 cost:  0.22786318760172247 accuracy:  0.9361209479705802\n",
      "Epoch number: 2243/10000step_number: 0/29 cost:  0.22763915295030052 accuracy:  0.935984745301008\n",
      "Epoch number: 2244/10000step_number: 0/29 cost:  0.22790479463954502 accuracy:  0.9361209479705802\n",
      "Epoch number: 2245/10000step_number: 0/29 cost:  0.22770153829916 accuracy:  0.9361209479705802\n",
      "Epoch number: 2246/10000step_number: 0/29 cost:  0.22737853236025046 accuracy:  0.9362571506401526\n",
      "Epoch number: 2247/10000step_number: 0/29 cost:  0.2276999550567206 accuracy:  0.935984745301008\n",
      "Epoch number: 2248/10000step_number: 0/29 cost:  0.22773603160884903 accuracy:  0.9358485426314356\n",
      "Epoch number: 2249/10000step_number: 0/29 cost:  0.22750388758956797 accuracy:  0.9361209479705802\n",
      "Epoch number: 2250/10000step_number: 0/29 cost:  0.22760481150345657 accuracy:  0.9361209479705802\n",
      "Epoch number: 2251/10000step_number: 0/29 cost:  0.22729333939726284 accuracy:  0.9362571506401526\n",
      "Epoch number: 2252/10000step_number: 0/29 cost:  0.22724194337769774 accuracy:  0.9365295559792972\n",
      "Epoch number: 2253/10000step_number: 0/29 cost:  0.22741653419844488 accuracy:  0.9362571506401526\n",
      "Epoch number: 2254/10000step_number: 0/29 cost:  0.22737980788207848 accuracy:  0.9362571506401526\n",
      "Epoch number: 2255/10000step_number: 0/29 cost:  0.2270628919747807 accuracy:  0.9362571506401526\n",
      "Epoch number: 2256/10000step_number: 0/29 cost:  0.22721756743703822 accuracy:  0.9363933533097248\n",
      "Epoch number: 2257/10000step_number: 0/29 cost:  0.22719063798465494 accuracy:  0.9362571506401526\n",
      "Epoch number: 2258/10000step_number: 0/29 cost:  0.22702902156485716 accuracy:  0.9362571506401526\n",
      "Epoch number: 2259/10000step_number: 0/29 cost:  0.22697116720729218 accuracy:  0.9362571506401526\n",
      "Epoch number: 2260/10000step_number: 0/29 cost:  0.22707104694535923 accuracy:  0.9361209479705802\n",
      "Epoch number: 2261/10000step_number: 0/29 cost:  0.2269486325381323 accuracy:  0.9362571506401526\n",
      "Epoch number: 2262/10000step_number: 0/29 cost:  0.22676157679897604 accuracy:  0.9361209479705802\n",
      "Epoch number: 2263/10000step_number: 0/29 cost:  0.22694762340136135 accuracy:  0.9362571506401526\n",
      "Epoch number: 2264/10000step_number: 0/29 cost:  0.22697174223048094 accuracy:  0.9363933533097248\n",
      "Epoch number: 2265/10000step_number: 0/29 cost:  0.22674447510052761 accuracy:  0.9362571506401526\n",
      "Epoch number: 2266/10000step_number: 0/29 cost:  0.226394739727777 accuracy:  0.9363933533097248\n",
      "Epoch number: 2267/10000step_number: 0/29 cost:  0.2270277670907077 accuracy:  0.9361209479705802\n",
      "Epoch number: 2268/10000step_number: 0/29 cost:  0.22648302059327444 accuracy:  0.9362571506401526\n",
      "Epoch number: 2269/10000step_number: 0/29 cost:  0.22660257699607778 accuracy:  0.9361209479705802\n",
      "Epoch number: 2270/10000step_number: 0/29 cost:  0.2264873731132392 accuracy:  0.9363933533097248\n",
      "Epoch number: 2271/10000step_number: 0/29 cost:  0.2264915324932522 accuracy:  0.9362571506401526\n",
      "Epoch number: 2272/10000step_number: 0/29 cost:  0.22639357438311675 accuracy:  0.9361209479705802\n",
      "Epoch number: 2273/10000step_number: 0/29 cost:  0.22639911464620496 accuracy:  0.9362571506401526\n",
      "Epoch number: 2274/10000step_number: 0/29 cost:  0.22624035758868719 accuracy:  0.935984745301008\n",
      "Epoch number: 2275/10000step_number: 0/29 cost:  0.2261182327841607 accuracy:  0.935984745301008\n",
      "Epoch number: 2276/10000step_number: 0/29 cost:  0.2264081691336668 accuracy:  0.9362571506401526\n",
      "Epoch number: 2277/10000step_number: 0/29 cost:  0.226299689126693 accuracy:  0.9362571506401526\n",
      "Epoch number: 2278/10000step_number: 0/29 cost:  0.22605139439330202 accuracy:  0.935984745301008\n",
      "Epoch number: 2279/10000step_number: 0/29 cost:  0.2261335192923943 accuracy:  0.9362571506401526\n",
      "Epoch number: 2280/10000step_number: 0/29 cost:  0.22612311466072652 accuracy:  0.9361209479705802\n",
      "Epoch number: 2281/10000step_number: 0/29 cost:  0.22595837055638804 accuracy:  0.9362571506401526\n",
      "Epoch number: 2282/10000step_number: 0/29 cost:  0.22602631821813632 accuracy:  0.935984745301008\n",
      "Epoch number: 2283/10000step_number: 0/29 cost:  0.22592380518930813 accuracy:  0.9362571506401526\n",
      "Epoch number: 2284/10000step_number: 0/29 cost:  0.2258812970879949 accuracy:  0.9361209479705802\n",
      "Epoch number: 2285/10000step_number: 0/29 cost:  0.22585146056192032 accuracy:  0.935984745301008\n",
      "Epoch number: 2286/10000step_number: 0/29 cost:  0.2257674988271063 accuracy:  0.9361209479705802\n",
      "Epoch number: 2287/10000step_number: 0/29 cost:  0.22576195378190447 accuracy:  0.9361209479705802\n",
      "Epoch number: 2288/10000step_number: 0/29 cost:  0.22563375381801992 accuracy:  0.9361209479705802\n",
      "Epoch number: 2289/10000step_number: 0/29 cost:  0.22563528765161583 accuracy:  0.9361209479705802\n",
      "Epoch number: 2290/10000step_number: 0/29 cost:  0.2255501321174677 accuracy:  0.9361209479705802\n",
      "Epoch number: 2291/10000step_number: 0/29 cost:  0.22540814788558494 accuracy:  0.9362571506401526\n",
      "Epoch number: 2292/10000step_number: 0/29 cost:  0.225495408475548 accuracy:  0.9361209479705802\n",
      "Epoch number: 2293/10000step_number: 0/29 cost:  0.22532267477478654 accuracy:  0.9361209479705802\n",
      "Epoch number: 2294/10000step_number: 0/29 cost:  0.22527342399633862 accuracy:  0.9361209479705802\n",
      "Epoch number: 2295/10000step_number: 0/29 cost:  0.2252812950111835 accuracy:  0.9361209479705802\n",
      "Epoch number: 2296/10000step_number: 0/29 cost:  0.22517194382273653 accuracy:  0.9361209479705802\n",
      "Epoch number: 2297/10000step_number: 0/29 cost:  0.22498855061115097 accuracy:  0.9362571506401526\n",
      "Epoch number: 2298/10000step_number: 0/29 cost:  0.2251409071931546 accuracy:  0.9361209479705802\n",
      "Epoch number: 2299/10000step_number: 0/29 cost:  0.22495385670121618 accuracy:  0.9362571506401526\n",
      "Epoch number: 2300/10000step_number: 0/29 cost:  0.22483400361841802 accuracy:  0.9361209479705802\n",
      "Epoch number: 2301/10000step_number: 0/29 cost:  0.2249234125705578 accuracy:  0.9362571506401526\n",
      "Epoch number: 2302/10000step_number: 0/29 cost:  0.22471062695063676 accuracy:  0.9362571506401526\n",
      "Epoch number: 2303/10000step_number: 0/29 cost:  0.22450126310199034 accuracy:  0.9363933533097248\n",
      "Epoch number: 2304/10000step_number: 0/29 cost:  0.22468932389584695 accuracy:  0.9361209479705802\n",
      "Epoch number: 2305/10000step_number: 0/29 cost:  0.2246899574342908 accuracy:  0.9361209479705802\n",
      "Epoch number: 2306/10000step_number: 0/29 cost:  0.2243431182887524 accuracy:  0.9365295559792972\n",
      "Epoch number: 2307/10000step_number: 0/29 cost:  0.22422019021959066 accuracy:  0.9365295559792972\n",
      "Epoch number: 2308/10000step_number: 0/29 cost:  0.22439745905648606 accuracy:  0.9363933533097248\n",
      "Epoch number: 2309/10000step_number: 0/29 cost:  0.2243729827618535 accuracy:  0.9363933533097248\n",
      "Epoch number: 2310/10000step_number: 0/29 cost:  0.22404478351010898 accuracy:  0.9363933533097248\n",
      "Epoch number: 2311/10000step_number: 0/29 cost:  0.22391418922941816 accuracy:  0.9365295559792972\n",
      "Epoch number: 2312/10000step_number: 0/29 cost:  0.22408625276671829 accuracy:  0.9363933533097248\n",
      "Epoch number: 2313/10000step_number: 0/29 cost:  0.2240354622356568 accuracy:  0.9363933533097248\n",
      "Epoch number: 2314/10000step_number: 0/29 cost:  0.22371981731275667 accuracy:  0.9365295559792972\n",
      "Epoch number: 2315/10000step_number: 0/29 cost:  0.22363926818156055 accuracy:  0.9365295559792972\n",
      "Epoch number: 2316/10000step_number: 0/29 cost:  0.22380455514760722 accuracy:  0.9363933533097248\n",
      "Epoch number: 2317/10000step_number: 0/29 cost:  0.22364988563768398 accuracy:  0.9363933533097248\n",
      "Epoch number: 2318/10000step_number: 0/29 cost:  0.2234288324686519 accuracy:  0.9365295559792972\n",
      "Epoch number: 2319/10000step_number: 0/29 cost:  0.22350502895907512 accuracy:  0.9365295559792972\n",
      "Epoch number: 2320/10000step_number: 0/29 cost:  0.22334180519815272 accuracy:  0.9365295559792972\n",
      "Epoch number: 2321/10000step_number: 0/29 cost:  0.22316967497468654 accuracy:  0.9365295559792972\n",
      "Epoch number: 2322/10000step_number: 0/29 cost:  0.2233232666774532 accuracy:  0.9365295559792972\n",
      "Epoch number: 2323/10000step_number: 0/29 cost:  0.22329369887878825 accuracy:  0.9365295559792972\n",
      "Epoch number: 2324/10000step_number: 0/29 cost:  0.22296460031281676 accuracy:  0.9365295559792972\n",
      "Epoch number: 2325/10000step_number: 0/29 cost:  0.22294463216637367 accuracy:  0.9365295559792972\n",
      "Epoch number: 2326/10000step_number: 0/29 cost:  0.22304144497923412 accuracy:  0.9368019613184418\n",
      "Epoch number: 2327/10000step_number: 0/29 cost:  0.22286125830038864 accuracy:  0.9366657586488695\n",
      "Epoch number: 2328/10000step_number: 0/29 cost:  0.22274714134980064 accuracy:  0.9365295559792972\n",
      "Epoch number: 2329/10000step_number: 0/29 cost:  0.22287545510419154 accuracy:  0.9363933533097248\n",
      "Epoch number: 2330/10000step_number: 0/29 cost:  0.22259710928660975 accuracy:  0.9363933533097248\n",
      "Epoch number: 2331/10000step_number: 0/29 cost:  0.22249635422361705 accuracy:  0.9365295559792972\n",
      "Epoch number: 2332/10000step_number: 0/29 cost:  0.22257918151600078 accuracy:  0.9365295559792972\n",
      "Epoch number: 2333/10000step_number: 0/29 cost:  0.22270468712961958 accuracy:  0.9363933533097248\n",
      "Epoch number: 2334/10000step_number: 0/29 cost:  0.22230816643386034 accuracy:  0.9363933533097248\n",
      "Epoch number: 2335/10000step_number: 0/29 cost:  0.22225021637651568 accuracy:  0.9365295559792972\n",
      "Epoch number: 2336/10000step_number: 0/29 cost:  0.2223767579279443 accuracy:  0.9365295559792972\n",
      "Epoch number: 2337/10000step_number: 0/29 cost:  0.222475118431995 accuracy:  0.9362571506401526\n",
      "Epoch number: 2338/10000step_number: 0/29 cost:  0.2220105886257037 accuracy:  0.9363933533097248\n",
      "Epoch number: 2339/10000step_number: 0/29 cost:  0.22198166159684418 accuracy:  0.9366657586488695\n",
      "Epoch number: 2340/10000step_number: 0/29 cost:  0.22204983623592545 accuracy:  0.9366657586488695\n",
      "Epoch number: 2341/10000step_number: 0/29 cost:  0.22221506535280627 accuracy:  0.9363933533097248\n",
      "Epoch number: 2342/10000step_number: 0/29 cost:  0.22188058676501432 accuracy:  0.9368019613184418\n",
      "Epoch number: 2343/10000step_number: 0/29 cost:  0.2218067311436012 accuracy:  0.9365295559792972\n",
      "Epoch number: 2344/10000step_number: 0/29 cost:  0.22189246350515288 accuracy:  0.9366657586488695\n",
      "Epoch number: 2345/10000step_number: 0/29 cost:  0.2217763378510572 accuracy:  0.9368019613184418\n",
      "Epoch number: 2346/10000step_number: 0/29 cost:  0.22164057490585656 accuracy:  0.9368019613184418\n",
      "Epoch number: 2347/10000step_number: 0/29 cost:  0.2216765892711541 accuracy:  0.9368019613184418\n",
      "Epoch number: 2348/10000step_number: 0/29 cost:  0.2215625951267428 accuracy:  0.9368019613184418\n",
      "Epoch number: 2349/10000step_number: 0/29 cost:  0.22145854049627217 accuracy:  0.9369381639880142\n",
      "Epoch number: 2350/10000step_number: 0/29 cost:  0.22154048954119882 accuracy:  0.9368019613184418\n",
      "Epoch number: 2351/10000step_number: 0/29 cost:  0.22144439748572223 accuracy:  0.9368019613184418\n",
      "Epoch number: 2352/10000step_number: 0/29 cost:  0.2212878716671269 accuracy:  0.9368019613184418\n",
      "Epoch number: 2353/10000step_number: 0/29 cost:  0.22133654744152167 accuracy:  0.9369381639880142\n",
      "Epoch number: 2354/10000step_number: 0/29 cost:  0.2212133373613455 accuracy:  0.9368019613184418\n",
      "Epoch number: 2355/10000step_number: 0/29 cost:  0.22110964185223905 accuracy:  0.9370743666575865\n",
      "Epoch number: 2356/10000step_number: 0/29 cost:  0.22117646697856433 accuracy:  0.9368019613184418\n",
      "Epoch number: 2357/10000step_number: 0/29 cost:  0.22109880583094235 accuracy:  0.9370743666575865\n",
      "Epoch number: 2358/10000step_number: 0/29 cost:  0.22092304087393 accuracy:  0.9370743666575865\n",
      "Epoch number: 2359/10000step_number: 0/29 cost:  0.22096194994936239 accuracy:  0.9372105693271588\n",
      "Epoch number: 2360/10000step_number: 0/29 cost:  0.22086381745117342 accuracy:  0.9372105693271588\n",
      "Epoch number: 2361/10000step_number: 0/29 cost:  0.22075576794757762 accuracy:  0.9372105693271588\n",
      "Epoch number: 2362/10000step_number: 0/29 cost:  0.22078277323968756 accuracy:  0.9372105693271588\n",
      "Epoch number: 2363/10000step_number: 0/29 cost:  0.22069476615135444 accuracy:  0.9374829746663035\n",
      "Epoch number: 2364/10000step_number: 0/29 cost:  0.22056121945889595 accuracy:  0.9373467719967311\n",
      "Epoch number: 2365/10000step_number: 0/29 cost:  0.2205768865769917 accuracy:  0.9376191773358757\n",
      "Epoch number: 2366/10000step_number: 0/29 cost:  0.22046855771319898 accuracy:  0.9372105693271588\n",
      "Epoch number: 2367/10000step_number: 0/29 cost:  0.2203799788870773 accuracy:  0.9376191773358757\n",
      "Epoch number: 2368/10000step_number: 0/29 cost:  0.2203592728486471 accuracy:  0.9372105693271588\n",
      "Epoch number: 2369/10000step_number: 0/29 cost:  0.22028566390422044 accuracy:  0.9376191773358757\n",
      "Epoch number: 2370/10000step_number: 0/29 cost:  0.22016669996878627 accuracy:  0.9373467719967311\n",
      "Epoch number: 2371/10000step_number: 0/29 cost:  0.22014356280387956 accuracy:  0.9377553800054481\n",
      "Epoch number: 2372/10000step_number: 0/29 cost:  0.22006502939624895 accuracy:  0.9373467719967311\n",
      "Epoch number: 2373/10000step_number: 0/29 cost:  0.2199857631579103 accuracy:  0.9377553800054481\n",
      "Epoch number: 2374/10000step_number: 0/29 cost:  0.21989056356019993 accuracy:  0.9374829746663035\n",
      "Epoch number: 2375/10000step_number: 0/29 cost:  0.21984753827821288 accuracy:  0.9377553800054481\n",
      "Epoch number: 2376/10000step_number: 0/29 cost:  0.2197732046328747 accuracy:  0.9374829746663035\n",
      "Epoch number: 2377/10000step_number: 0/29 cost:  0.21970332020708241 accuracy:  0.9377553800054481\n",
      "Epoch number: 2378/10000step_number: 0/29 cost:  0.21958390019465032 accuracy:  0.9376191773358757\n",
      "Epoch number: 2379/10000step_number: 0/29 cost:  0.21954385092191753 accuracy:  0.9377553800054481\n",
      "Epoch number: 2380/10000step_number: 0/29 cost:  0.21947230145675528 accuracy:  0.9374829746663035\n",
      "Epoch number: 2381/10000step_number: 0/29 cost:  0.21941216854778478 accuracy:  0.9377553800054481\n",
      "Epoch number: 2382/10000step_number: 0/29 cost:  0.21925141008367627 accuracy:  0.9376191773358757\n",
      "Epoch number: 2383/10000step_number: 0/29 cost:  0.21923178580215738 accuracy:  0.9376191773358757\n",
      "Epoch number: 2384/10000step_number: 0/29 cost:  0.21917332118405394 accuracy:  0.9377553800054481\n",
      "Epoch number: 2385/10000step_number: 0/29 cost:  0.21914645881666264 accuracy:  0.9377553800054481\n",
      "Epoch number: 2386/10000step_number: 0/29 cost:  0.21886616904818426 accuracy:  0.9376191773358757\n",
      "Epoch number: 2387/10000step_number: 0/29 cost:  0.2188972169915533 accuracy:  0.9376191773358757\n",
      "Epoch number: 2388/10000step_number: 0/29 cost:  0.21886404285640332 accuracy:  0.9377553800054481\n",
      "Epoch number: 2389/10000step_number: 0/29 cost:  0.21903732199058557 accuracy:  0.9376191773358757\n",
      "Epoch number: 2390/10000step_number: 0/29 cost:  0.21829196860038355 accuracy:  0.9380277853445927\n",
      "Epoch number: 2391/10000step_number: 0/29 cost:  0.21861332036734782 accuracy:  0.9374829746663035\n",
      "Epoch number: 2392/10000step_number: 0/29 cost:  0.218377676527215 accuracy:  0.9373467719967311\n",
      "Epoch number: 2393/10000step_number: 0/29 cost:  0.21842687076245393 accuracy:  0.9376191773358757\n",
      "Epoch number: 2394/10000step_number: 0/29 cost:  0.21832347437831295 accuracy:  0.9380277853445927\n",
      "Epoch number: 2395/10000step_number: 0/29 cost:  0.21840219350326828 accuracy:  0.9374829746663035\n",
      "Epoch number: 2396/10000step_number: 0/29 cost:  0.21820436786091796 accuracy:  0.9381639880141651\n",
      "Epoch number: 2397/10000step_number: 0/29 cost:  0.21840975235273152 accuracy:  0.9374829746663035\n",
      "Epoch number: 2398/10000step_number: 0/29 cost:  0.21789303484389427 accuracy:  0.9381639880141651\n",
      "Epoch number: 2399/10000step_number: 0/29 cost:  0.21805077978023935 accuracy:  0.9374829746663035\n",
      "Epoch number: 2400/10000step_number: 0/29 cost:  0.21756779347741148 accuracy:  0.9384363933533098\n",
      "Epoch number: 2401/10000step_number: 0/29 cost:  0.21764236907562237 accuracy:  0.9373467719967311\n",
      "Epoch number: 2402/10000step_number: 0/29 cost:  0.21761530614235153 accuracy:  0.9383001906837374\n",
      "Epoch number: 2403/10000step_number: 0/29 cost:  0.2178561058836625 accuracy:  0.9373467719967311\n",
      "Epoch number: 2404/10000step_number: 0/29 cost:  0.21731663119525405 accuracy:  0.9384363933533098\n",
      "Epoch number: 2405/10000step_number: 0/29 cost:  0.21766011758382878 accuracy:  0.9373467719967311\n",
      "Epoch number: 2406/10000step_number: 0/29 cost:  0.21699101111665745 accuracy:  0.9383001906837374\n",
      "Epoch number: 2407/10000step_number: 0/29 cost:  0.21711390827948743 accuracy:  0.9370743666575865\n",
      "Epoch number: 2408/10000step_number: 0/29 cost:  0.21705979515495874 accuracy:  0.9384363933533098\n",
      "Epoch number: 2409/10000step_number: 0/29 cost:  0.21719503709047344 accuracy:  0.9370743666575865\n",
      "Epoch number: 2410/10000step_number: 0/29 cost:  0.21684902034179254 accuracy:  0.9381639880141651\n",
      "Epoch number: 2411/10000step_number: 0/29 cost:  0.2170552926372952 accuracy:  0.9376191773358757\n",
      "Epoch number: 2412/10000step_number: 0/29 cost:  0.2166161904585078 accuracy:  0.9380277853445927\n",
      "Epoch number: 2413/10000step_number: 0/29 cost:  0.21623410293125223 accuracy:  0.9376191773358757\n",
      "Epoch number: 2414/10000step_number: 0/29 cost:  0.21558073281766552 accuracy:  0.9383001906837374\n",
      "Epoch number: 2415/10000step_number: 0/29 cost:  0.21547711033050013 accuracy:  0.9374829746663035\n",
      "Epoch number: 2416/10000step_number: 0/29 cost:  0.21531615753945196 accuracy:  0.9378915826750205\n",
      "Epoch number: 2417/10000step_number: 0/29 cost:  0.21535881250652814 accuracy:  0.9374829746663035\n",
      "Epoch number: 2418/10000step_number: 0/29 cost:  0.2155845766465139 accuracy:  0.9377553800054481\n",
      "Epoch number: 2419/10000step_number: 0/29 cost:  0.21543944762904327 accuracy:  0.9378915826750205\n",
      "Epoch number: 2420/10000step_number: 0/29 cost:  0.21534313118286555 accuracy:  0.9378915826750205\n",
      "Epoch number: 2421/10000step_number: 0/29 cost:  0.21509814880268718 accuracy:  0.9380277853445927\n",
      "Epoch number: 2422/10000step_number: 0/29 cost:  0.21529425747333927 accuracy:  0.9378915826750205\n",
      "Epoch number: 2423/10000step_number: 0/29 cost:  0.21500359549835837 accuracy:  0.9383001906837374\n",
      "Epoch number: 2424/10000step_number: 0/29 cost:  0.215141919791704 accuracy:  0.9377553800054481\n",
      "Epoch number: 2425/10000step_number: 0/29 cost:  0.2150964901904713 accuracy:  0.9384363933533098\n",
      "Epoch number: 2426/10000step_number: 0/29 cost:  0.21563171129768927 accuracy:  0.9380277853445927\n",
      "Epoch number: 2427/10000step_number: 0/29 cost:  0.21450650292348064 accuracy:  0.9384363933533098\n",
      "Epoch number: 2428/10000step_number: 0/29 cost:  0.21501740262818642 accuracy:  0.9378915826750205\n",
      "Epoch number: 2429/10000step_number: 0/29 cost:  0.2146688750352535 accuracy:  0.9387087986924544\n",
      "Epoch number: 2430/10000step_number: 0/29 cost:  0.21522523564144105 accuracy:  0.9381639880141651\n",
      "Epoch number: 2431/10000step_number: 0/29 cost:  0.21473431887477432 accuracy:  0.9384363933533098\n",
      "Epoch number: 2432/10000step_number: 0/29 cost:  0.21489834703542085 accuracy:  0.9387087986924544\n",
      "Epoch number: 2433/10000step_number: 0/29 cost:  0.2147730607154643 accuracy:  0.9384363933533098\n",
      "Epoch number: 2434/10000step_number: 0/29 cost:  0.21472338306554287 accuracy:  0.938981204031599\n",
      "Epoch number: 2435/10000step_number: 0/29 cost:  0.21492659205452763 accuracy:  0.9383001906837374\n",
      "Epoch number: 2436/10000step_number: 0/29 cost:  0.21458142147268808 accuracy:  0.9387087986924544\n",
      "Epoch number: 2437/10000step_number: 0/29 cost:  0.21477302730504613 accuracy:  0.9384363933533098\n",
      "Epoch number: 2438/10000step_number: 0/29 cost:  0.21458235982237836 accuracy:  0.938981204031599\n",
      "Epoch number: 2439/10000step_number: 0/29 cost:  0.21484375169445935 accuracy:  0.9380277853445927\n",
      "Epoch number: 2440/10000step_number: 0/29 cost:  0.21416752502445213 accuracy:  0.9387087986924544\n",
      "Epoch number: 2441/10000step_number: 0/29 cost:  0.21431133049020326 accuracy:  0.9380277853445927\n",
      "Epoch number: 2442/10000step_number: 0/29 cost:  0.21434523425998595 accuracy:  0.9388450013620266\n",
      "Epoch number: 2443/10000step_number: 0/29 cost:  0.21466355481720886 accuracy:  0.9384363933533098\n",
      "Epoch number: 2444/10000step_number: 0/29 cost:  0.21420477820555509 accuracy:  0.938572596022882\n",
      "Epoch number: 2445/10000step_number: 0/29 cost:  0.21442537774176915 accuracy:  0.9387087986924544\n",
      "Epoch number: 2446/10000step_number: 0/29 cost:  0.21449593971631628 accuracy:  0.938981204031599\n",
      "Epoch number: 2447/10000step_number: 0/29 cost:  0.21399634092722272 accuracy:  0.938981204031599\n",
      "Epoch number: 2448/10000step_number: 0/29 cost:  0.21402484974748978 accuracy:  0.938981204031599\n",
      "Epoch number: 2449/10000step_number: 0/29 cost:  0.21404540944482311 accuracy:  0.9391174067011714\n",
      "Epoch number: 2450/10000step_number: 0/29 cost:  0.21402701499503832 accuracy:  0.9391174067011714\n",
      "Epoch number: 2451/10000step_number: 0/29 cost:  0.21375554790314316 accuracy:  0.938981204031599\n",
      "Epoch number: 2452/10000step_number: 0/29 cost:  0.2137299404217424 accuracy:  0.9392536093707436\n",
      "Epoch number: 2453/10000step_number: 0/29 cost:  0.21410983427052277 accuracy:  0.9388450013620266\n",
      "Epoch number: 2454/10000step_number: 0/29 cost:  0.21328856823413236 accuracy:  0.9387087986924544\n",
      "Epoch number: 2455/10000step_number: 0/29 cost:  0.21350719826221978 accuracy:  0.938572596022882\n",
      "Epoch number: 2456/10000step_number: 0/29 cost:  0.2133631738604364 accuracy:  0.9388450013620266\n",
      "Epoch number: 2457/10000step_number: 0/29 cost:  0.21361051038506737 accuracy:  0.9391174067011714\n",
      "Epoch number: 2458/10000step_number: 0/29 cost:  0.21325883736216394 accuracy:  0.939389812040316\n",
      "Epoch number: 2459/10000step_number: 0/29 cost:  0.2133937273778211 accuracy:  0.9391174067011714\n",
      "Epoch number: 2460/10000step_number: 0/29 cost:  0.21324332416535166 accuracy:  0.938981204031599\n",
      "Epoch number: 2461/10000step_number: 0/29 cost:  0.21294725503389395 accuracy:  0.938981204031599\n",
      "Epoch number: 2462/10000step_number: 0/29 cost:  0.21294652167028424 accuracy:  0.938981204031599\n",
      "Epoch number: 2463/10000step_number: 0/29 cost:  0.21252428364422413 accuracy:  0.938981204031599\n",
      "Epoch number: 2464/10000step_number: 0/29 cost:  0.21217308302491503 accuracy:  0.9388450013620266\n",
      "Epoch number: 2465/10000step_number: 0/29 cost:  0.21230688505366027 accuracy:  0.9387087986924544\n",
      "Epoch number: 2466/10000step_number: 0/29 cost:  0.21260609563541144 accuracy:  0.9388450013620266\n",
      "Epoch number: 2467/10000step_number: 0/29 cost:  0.21285243474711996 accuracy:  0.9387087986924544\n",
      "Epoch number: 2468/10000step_number: 0/29 cost:  0.21252764841854138 accuracy:  0.9387087986924544\n",
      "Epoch number: 2469/10000step_number: 0/29 cost:  0.21184861781234599 accuracy:  0.9388450013620266\n",
      "Epoch number: 2470/10000step_number: 0/29 cost:  0.21199674046387276 accuracy:  0.9387087986924544\n",
      "Epoch number: 2471/10000step_number: 0/29 cost:  0.2123285978776678 accuracy:  0.9384363933533098\n",
      "Epoch number: 2472/10000step_number: 0/29 cost:  0.21244752059785305 accuracy:  0.938981204031599\n",
      "Epoch number: 2473/10000step_number: 0/29 cost:  0.21266854984712813 accuracy:  0.9387087986924544\n",
      "Epoch number: 2474/10000step_number: 0/29 cost:  0.2115036065782709 accuracy:  0.9391174067011714\n",
      "Epoch number: 2475/10000step_number: 0/29 cost:  0.21222550403356488 accuracy:  0.9380277853445927\n",
      "Epoch number: 2476/10000step_number: 0/29 cost:  0.21196332706725685 accuracy:  0.9387087986924544\n",
      "Epoch number: 2477/10000step_number: 0/29 cost:  0.21234358816805182 accuracy:  0.9388450013620266\n",
      "Epoch number: 2478/10000step_number: 0/29 cost:  0.21224174771421547 accuracy:  0.9388450013620266\n",
      "Epoch number: 2479/10000step_number: 0/29 cost:  0.21208965963085066 accuracy:  0.9388450013620266\n",
      "Epoch number: 2480/10000step_number: 0/29 cost:  0.21223543884677548 accuracy:  0.938981204031599\n",
      "Epoch number: 2481/10000step_number: 0/29 cost:  0.2121114460468611 accuracy:  0.9388450013620266\n",
      "Epoch number: 2482/10000step_number: 0/29 cost:  0.21232735049246257 accuracy:  0.9391174067011714\n",
      "Epoch number: 2483/10000step_number: 0/29 cost:  0.21205062553200618 accuracy:  0.9388450013620266\n",
      "Epoch number: 2484/10000step_number: 0/29 cost:  0.2123216042132965 accuracy:  0.938981204031599\n",
      "Epoch number: 2485/10000step_number: 0/29 cost:  0.21172922152020265 accuracy:  0.939389812040316\n",
      "Epoch number: 2486/10000step_number: 0/29 cost:  0.21168514262006707 accuracy:  0.9388450013620266\n",
      "Epoch number: 2487/10000step_number: 0/29 cost:  0.2117866103570544 accuracy:  0.9391174067011714\n",
      "Epoch number: 2488/10000step_number: 0/29 cost:  0.21241228905323162 accuracy:  0.938981204031599\n",
      "Epoch number: 2489/10000step_number: 0/29 cost:  0.21139907065575642 accuracy:  0.939389812040316\n",
      "Epoch number: 2490/10000step_number: 0/29 cost:  0.21143280383639454 accuracy:  0.9388450013620266\n",
      "Epoch number: 2491/10000step_number: 0/29 cost:  0.21157389623871894 accuracy:  0.9392536093707436\n",
      "Epoch number: 2492/10000step_number: 0/29 cost:  0.21190782109370918 accuracy:  0.9392536093707436\n",
      "Epoch number: 2493/10000step_number: 0/29 cost:  0.21162046138532764 accuracy:  0.939389812040316\n",
      "Epoch number: 2494/10000step_number: 0/29 cost:  0.2115448162079866 accuracy:  0.9391174067011714\n",
      "Epoch number: 2495/10000step_number: 0/29 cost:  0.21152544874872212 accuracy:  0.9392536093707436\n",
      "Epoch number: 2496/10000step_number: 0/29 cost:  0.21129310277440266 accuracy:  0.9391174067011714\n",
      "Epoch number: 2497/10000step_number: 0/29 cost:  0.21108951866037795 accuracy:  0.9395260147098883\n",
      "Epoch number: 2498/10000step_number: 0/29 cost:  0.21144070760740227 accuracy:  0.9392536093707436\n",
      "Epoch number: 2499/10000step_number: 0/29 cost:  0.21088485436376342 accuracy:  0.9392536093707436\n",
      "Epoch number: 2500/10000step_number: 0/29 cost:  0.21066620186396898 accuracy:  0.9391174067011714\n",
      "Epoch number: 2501/10000step_number: 0/29 cost:  0.21104749010204804 accuracy:  0.9391174067011714\n",
      "Epoch number: 2502/10000step_number: 0/29 cost:  0.21113538664318363 accuracy:  0.9391174067011714\n",
      "Epoch number: 2503/10000step_number: 0/29 cost:  0.21139340344785654 accuracy:  0.9392536093707436\n",
      "Epoch number: 2504/10000step_number: 0/29 cost:  0.21072270015411917 accuracy:  0.9396622173794607\n",
      "Epoch number: 2505/10000step_number: 0/29 cost:  0.2105003022281196 accuracy:  0.9391174067011714\n",
      "Epoch number: 2506/10000step_number: 0/29 cost:  0.2103960325272696 accuracy:  0.9395260147098883\n",
      "Epoch number: 2507/10000step_number: 0/29 cost:  0.21055073223348797 accuracy:  0.9392536093707436\n",
      "Epoch number: 2508/10000step_number: 0/29 cost:  0.21076840556822704 accuracy:  0.938981204031599\n",
      "Epoch number: 2509/10000step_number: 0/29 cost:  0.21108205696829738 accuracy:  0.9391174067011714\n",
      "Epoch number: 2510/10000step_number: 0/29 cost:  0.2102478536642001 accuracy:  0.9396622173794607\n",
      "Epoch number: 2511/10000step_number: 0/29 cost:  0.2099353754498012 accuracy:  0.939389812040316\n",
      "Epoch number: 2512/10000step_number: 0/29 cost:  0.21025032488584128 accuracy:  0.9391174067011714\n",
      "Epoch number: 2513/10000step_number: 0/29 cost:  0.21076792168498054 accuracy:  0.9395260147098883\n",
      "Epoch number: 2514/10000step_number: 0/29 cost:  0.21005330732902633 accuracy:  0.9396622173794607\n",
      "Epoch number: 2515/10000step_number: 0/29 cost:  0.20985320373707 accuracy:  0.9392536093707436\n",
      "Epoch number: 2516/10000step_number: 0/29 cost:  0.20999932805445576 accuracy:  0.939389812040316\n",
      "Epoch number: 2517/10000step_number: 0/29 cost:  0.21028133774495691 accuracy:  0.9395260147098883\n",
      "Epoch number: 2518/10000step_number: 0/29 cost:  0.20973161340136795 accuracy:  0.9396622173794607\n",
      "Epoch number: 2519/10000step_number: 0/29 cost:  0.2094407433679401 accuracy:  0.9392536093707436\n",
      "Epoch number: 2520/10000step_number: 0/29 cost:  0.20974480056472203 accuracy:  0.939389812040316\n",
      "Epoch number: 2521/10000step_number: 0/29 cost:  0.21015062050241018 accuracy:  0.939389812040316\n",
      "Epoch number: 2522/10000step_number: 0/29 cost:  0.20915437759098343 accuracy:  0.9396622173794607\n",
      "Epoch number: 2523/10000step_number: 0/29 cost:  0.20901005227521016 accuracy:  0.939389812040316\n",
      "Epoch number: 2524/10000step_number: 0/29 cost:  0.20931205561858554 accuracy:  0.939389812040316\n",
      "Epoch number: 2525/10000step_number: 0/29 cost:  0.20947282774277554 accuracy:  0.9396622173794607\n",
      "Epoch number: 2526/10000step_number: 0/29 cost:  0.20923679665390962 accuracy:  0.9396622173794607\n",
      "Epoch number: 2527/10000step_number: 0/29 cost:  0.20911610116429324 accuracy:  0.9395260147098883\n",
      "Epoch number: 2528/10000step_number: 0/29 cost:  0.20903248618819306 accuracy:  0.9396622173794607\n",
      "Epoch number: 2529/10000step_number: 0/29 cost:  0.20909829479891492 accuracy:  0.9395260147098883\n",
      "Epoch number: 2530/10000step_number: 0/29 cost:  0.20879258351664118 accuracy:  0.9397984200490329\n",
      "Epoch number: 2531/10000step_number: 0/29 cost:  0.20891544203265025 accuracy:  0.9396622173794607\n",
      "Epoch number: 2532/10000step_number: 0/29 cost:  0.2088531166866481 accuracy:  0.9397984200490329\n",
      "Epoch number: 2533/10000step_number: 0/29 cost:  0.20909152181746 accuracy:  0.9396622173794607\n",
      "Epoch number: 2534/10000step_number: 0/29 cost:  0.20830945516427762 accuracy:  0.9397984200490329\n",
      "Epoch number: 2535/10000step_number: 0/29 cost:  0.20798358457034885 accuracy:  0.9397984200490329\n",
      "Epoch number: 2536/10000step_number: 0/29 cost:  0.20825579646726736 accuracy:  0.9396622173794607\n",
      "Epoch number: 2537/10000step_number: 0/29 cost:  0.20838729936362427 accuracy:  0.9397984200490329\n",
      "Epoch number: 2538/10000step_number: 0/29 cost:  0.2088701631972243 accuracy:  0.9399346227186053\n",
      "Epoch number: 2539/10000step_number: 0/29 cost:  0.2081269935600815 accuracy:  0.9397984200490329\n",
      "Epoch number: 2540/10000step_number: 0/29 cost:  0.20826936555321443 accuracy:  0.9397984200490329\n",
      "Epoch number: 2541/10000step_number: 0/29 cost:  0.2075332274051524 accuracy:  0.9397984200490329\n",
      "Epoch number: 2542/10000step_number: 0/29 cost:  0.2075162477228457 accuracy:  0.9397984200490329\n",
      "Epoch number: 2543/10000step_number: 0/29 cost:  0.20768739311064804 accuracy:  0.9396622173794607\n",
      "Epoch number: 2544/10000step_number: 0/29 cost:  0.20804127532982336 accuracy:  0.9397984200490329\n",
      "Epoch number: 2545/10000step_number: 0/29 cost:  0.20750736755083193 accuracy:  0.9399346227186053\n",
      "Epoch number: 2546/10000step_number: 0/29 cost:  0.20772548515646705 accuracy:  0.9397984200490329\n",
      "Epoch number: 2547/10000step_number: 0/29 cost:  0.20738511687410663 accuracy:  0.9397984200490329\n",
      "Epoch number: 2548/10000step_number: 0/29 cost:  0.20741079404216267 accuracy:  0.9396622173794607\n",
      "Epoch number: 2549/10000step_number: 0/29 cost:  0.20733624584402777 accuracy:  0.9396622173794607\n",
      "Epoch number: 2550/10000step_number: 0/29 cost:  0.20713627327258685 accuracy:  0.9396622173794607\n",
      "Epoch number: 2551/10000step_number: 0/29 cost:  0.2072352723118298 accuracy:  0.9396622173794607\n",
      "Epoch number: 2552/10000step_number: 0/29 cost:  0.20709858892379032 accuracy:  0.9396622173794607\n",
      "Epoch number: 2553/10000step_number: 0/29 cost:  0.20706641967624914 accuracy:  0.9396622173794607\n",
      "Epoch number: 2554/10000step_number: 0/29 cost:  0.20685045383424455 accuracy:  0.9397984200490329\n",
      "Epoch number: 2555/10000step_number: 0/29 cost:  0.20721421592413888 accuracy:  0.9397984200490329\n",
      "Epoch number: 2556/10000step_number: 0/29 cost:  0.2066836605555716 accuracy:  0.9399346227186053\n",
      "Epoch number: 2557/10000step_number: 0/29 cost:  0.20694620845188103 accuracy:  0.9397984200490329\n",
      "Epoch number: 2558/10000step_number: 0/29 cost:  0.20608226729837775 accuracy:  0.9397984200490329\n",
      "Epoch number: 2559/10000step_number: 0/29 cost:  0.2059732378226031 accuracy:  0.9400708253881777\n",
      "Epoch number: 2560/10000step_number: 0/29 cost:  0.20612186616421094 accuracy:  0.9396622173794607\n",
      "Epoch number: 2561/10000step_number: 0/29 cost:  0.20660558076329663 accuracy:  0.9397984200490329\n",
      "Epoch number: 2562/10000step_number: 0/29 cost:  0.20607836687280934 accuracy:  0.9400708253881777\n",
      "Epoch number: 2563/10000step_number: 0/29 cost:  0.20625166602667475 accuracy:  0.9399346227186053\n",
      "Epoch number: 2564/10000step_number: 0/29 cost:  0.20586530967143302 accuracy:  0.9402070280577499\n",
      "Epoch number: 2565/10000step_number: 0/29 cost:  0.20625714072933954 accuracy:  0.9399346227186053\n",
      "Epoch number: 2566/10000step_number: 0/29 cost:  0.20566009840920255 accuracy:  0.9399346227186053\n",
      "Epoch number: 2567/10000step_number: 0/29 cost:  0.2056925551614595 accuracy:  0.9399346227186053\n",
      "Epoch number: 2568/10000step_number: 0/29 cost:  0.20554414641683066 accuracy:  0.9399346227186053\n",
      "Epoch number: 2569/10000step_number: 0/29 cost:  0.20549590150269237 accuracy:  0.9399346227186053\n",
      "Epoch number: 2570/10000step_number: 0/29 cost:  0.20567399189449542 accuracy:  0.9399346227186053\n",
      "Epoch number: 2571/10000step_number: 0/29 cost:  0.20530011810047613 accuracy:  0.9404794333968945\n",
      "Epoch number: 2572/10000step_number: 0/29 cost:  0.20553345654733102 accuracy:  0.9400708253881777\n",
      "Epoch number: 2573/10000step_number: 0/29 cost:  0.20512108010589203 accuracy:  0.9402070280577499\n",
      "Epoch number: 2574/10000step_number: 0/29 cost:  0.20524342532039844 accuracy:  0.9399346227186053\n",
      "Epoch number: 2575/10000step_number: 0/29 cost:  0.20500747538670067 accuracy:  0.9403432307273223\n",
      "Epoch number: 2576/10000step_number: 0/29 cost:  0.20519532707396387 accuracy:  0.9402070280577499\n",
      "Epoch number: 2577/10000step_number: 0/29 cost:  0.20489212894238068 accuracy:  0.9403432307273223\n",
      "Epoch number: 2578/10000step_number: 0/29 cost:  0.20504093376496732 accuracy:  0.9402070280577499\n",
      "Epoch number: 2579/10000step_number: 0/29 cost:  0.20474047657968672 accuracy:  0.9406156360664669\n",
      "Epoch number: 2580/10000step_number: 0/29 cost:  0.20480800179780767 accuracy:  0.9406156360664669\n",
      "Epoch number: 2581/10000step_number: 0/29 cost:  0.2045424758504367 accuracy:  0.9406156360664669\n",
      "Epoch number: 2582/10000step_number: 0/29 cost:  0.20496240906688365 accuracy:  0.9402070280577499\n",
      "Epoch number: 2583/10000step_number: 0/29 cost:  0.20439431608483585 accuracy:  0.9407518387360392\n",
      "Epoch number: 2584/10000step_number: 0/29 cost:  0.20443207457361906 accuracy:  0.9407518387360392\n",
      "Epoch number: 2585/10000step_number: 0/29 cost:  0.2042424920583615 accuracy:  0.9406156360664669\n",
      "Epoch number: 2586/10000step_number: 0/29 cost:  0.20456218126104567 accuracy:  0.9404794333968945\n",
      "Epoch number: 2587/10000step_number: 0/29 cost:  0.20417230008227077 accuracy:  0.9407518387360392\n",
      "Epoch number: 2588/10000step_number: 0/29 cost:  0.20422590799018298 accuracy:  0.9407518387360392\n",
      "Epoch number: 2589/10000step_number: 0/29 cost:  0.2040597776904815 accuracy:  0.9407518387360392\n",
      "Epoch number: 2590/10000step_number: 0/29 cost:  0.20397444926121125 accuracy:  0.9407518387360392\n",
      "Epoch number: 2591/10000step_number: 0/29 cost:  0.2039911909001189 accuracy:  0.9407518387360392\n",
      "Epoch number: 2592/10000step_number: 0/29 cost:  0.20399485581081395 accuracy:  0.9407518387360392\n",
      "Epoch number: 2593/10000step_number: 0/29 cost:  0.2036657324896042 accuracy:  0.9407518387360392\n",
      "Epoch number: 2594/10000step_number: 0/29 cost:  0.20398162994464958 accuracy:  0.9407518387360392\n",
      "Epoch number: 2595/10000step_number: 0/29 cost:  0.20356587572857257 accuracy:  0.9406156360664669\n",
      "Epoch number: 2596/10000step_number: 0/29 cost:  0.20352955591301689 accuracy:  0.9408880414056116\n",
      "Epoch number: 2597/10000step_number: 0/29 cost:  0.20356157518717835 accuracy:  0.9406156360664669\n",
      "Epoch number: 2598/10000step_number: 0/29 cost:  0.20322915371851247 accuracy:  0.9408880414056116\n",
      "Epoch number: 2599/10000step_number: 0/29 cost:  0.20384442431154498 accuracy:  0.9403432307273223\n",
      "Epoch number: 2600/10000step_number: 0/29 cost:  0.203172102493059 accuracy:  0.9407518387360392\n",
      "Epoch number: 2601/10000step_number: 0/29 cost:  0.2031061654280593 accuracy:  0.9407518387360392\n",
      "Epoch number: 2602/10000step_number: 0/29 cost:  0.20305688459395793 accuracy:  0.9407518387360392\n",
      "Epoch number: 2603/10000step_number: 0/29 cost:  0.20305953499725155 accuracy:  0.9407518387360392\n",
      "Epoch number: 2604/10000step_number: 0/29 cost:  0.20328615638805078 accuracy:  0.9407518387360392\n",
      "Epoch number: 2605/10000step_number: 0/29 cost:  0.20279562189329414 accuracy:  0.9407518387360392\n",
      "Epoch number: 2606/10000step_number: 0/29 cost:  0.20305791726737465 accuracy:  0.9406156360664669\n",
      "Epoch number: 2607/10000step_number: 0/29 cost:  0.20263840312402154 accuracy:  0.9408880414056116\n",
      "Epoch number: 2608/10000step_number: 0/29 cost:  0.20278771005880186 accuracy:  0.9407518387360392\n",
      "Epoch number: 2609/10000step_number: 0/29 cost:  0.20257350779126465 accuracy:  0.9406156360664669\n",
      "Epoch number: 2610/10000step_number: 0/29 cost:  0.2026593190864466 accuracy:  0.9407518387360392\n",
      "Epoch number: 2611/10000step_number: 0/29 cost:  0.20239809032441952 accuracy:  0.9407518387360392\n",
      "Epoch number: 2612/10000step_number: 0/29 cost:  0.20285555638998745 accuracy:  0.9404794333968945\n",
      "Epoch number: 2613/10000step_number: 0/29 cost:  0.2022857925417552 accuracy:  0.9407518387360392\n",
      "Epoch number: 2614/10000step_number: 0/29 cost:  0.20219572985716858 accuracy:  0.9407518387360392\n",
      "Epoch number: 2615/10000step_number: 0/29 cost:  0.20222645760803196 accuracy:  0.9406156360664669\n",
      "Epoch number: 2616/10000step_number: 0/29 cost:  0.20205335783574338 accuracy:  0.9407518387360392\n",
      "Epoch number: 2617/10000step_number: 0/29 cost:  0.2025493477498418 accuracy:  0.9404794333968945\n",
      "Epoch number: 2618/10000step_number: 0/29 cost:  0.20198761926222683 accuracy:  0.9407518387360392\n",
      "Epoch number: 2619/10000step_number: 0/29 cost:  0.201837145280551 accuracy:  0.9407518387360392\n",
      "Epoch number: 2620/10000step_number: 0/29 cost:  0.20195068672172256 accuracy:  0.9407518387360392\n",
      "Epoch number: 2621/10000step_number: 0/29 cost:  0.2017345026610444 accuracy:  0.9407518387360392\n",
      "Epoch number: 2622/10000step_number: 0/29 cost:  0.2021588110853776 accuracy:  0.9407518387360392\n",
      "Epoch number: 2623/10000step_number: 0/29 cost:  0.20164440705820744 accuracy:  0.9407518387360392\n",
      "Epoch number: 2624/10000step_number: 0/29 cost:  0.20154218531863605 accuracy:  0.9407518387360392\n",
      "Epoch number: 2625/10000step_number: 0/29 cost:  0.20165561964667408 accuracy:  0.9407518387360392\n",
      "Epoch number: 2626/10000step_number: 0/29 cost:  0.20137566168808177 accuracy:  0.9407518387360392\n",
      "Epoch number: 2627/10000step_number: 0/29 cost:  0.20185238873277048 accuracy:  0.9406156360664669\n",
      "Epoch number: 2628/10000step_number: 0/29 cost:  0.20130852047298023 accuracy:  0.9407518387360392\n",
      "Epoch number: 2629/10000step_number: 0/29 cost:  0.20122750534495812 accuracy:  0.9407518387360392\n",
      "Epoch number: 2630/10000step_number: 0/29 cost:  0.20130918449768487 accuracy:  0.9407518387360392\n",
      "Epoch number: 2631/10000step_number: 0/29 cost:  0.20109051673814454 accuracy:  0.9406156360664669\n",
      "Epoch number: 2632/10000step_number: 0/29 cost:  0.20150099855107217 accuracy:  0.9404794333968945\n",
      "Epoch number: 2633/10000step_number: 0/29 cost:  0.20100513534539738 accuracy:  0.9404794333968945\n",
      "Epoch number: 2634/10000step_number: 0/29 cost:  0.20091899025436197 accuracy:  0.9406156360664669\n",
      "Epoch number: 2635/10000step_number: 0/29 cost:  0.2010319718564547 accuracy:  0.9406156360664669\n",
      "Epoch number: 2636/10000step_number: 0/29 cost:  0.200742849283654 accuracy:  0.9406156360664669\n",
      "Epoch number: 2637/10000step_number: 0/29 cost:  0.20116217377307158 accuracy:  0.9404794333968945\n",
      "Epoch number: 2638/10000step_number: 0/29 cost:  0.20066242726501157 accuracy:  0.9404794333968945\n",
      "Epoch number: 2639/10000step_number: 0/29 cost:  0.20061547534569468 accuracy:  0.9402070280577499\n",
      "Epoch number: 2640/10000step_number: 0/29 cost:  0.2006920174230332 accuracy:  0.9406156360664669\n",
      "Epoch number: 2641/10000step_number: 0/29 cost:  0.20041903025056274 accuracy:  0.9400708253881777\n",
      "Epoch number: 2642/10000step_number: 0/29 cost:  0.20079671181826655 accuracy:  0.9403432307273223\n",
      "Epoch number: 2643/10000step_number: 0/29 cost:  0.2003241348141774 accuracy:  0.9404794333968945\n",
      "Epoch number: 2644/10000step_number: 0/29 cost:  0.20025757405686573 accuracy:  0.9402070280577499\n",
      "Epoch number: 2645/10000step_number: 0/29 cost:  0.20032752414379865 accuracy:  0.9403432307273223\n",
      "Epoch number: 2646/10000step_number: 0/29 cost:  0.20000148373252644 accuracy:  0.9403432307273223\n",
      "Epoch number: 2647/10000step_number: 0/29 cost:  0.20031373531429672 accuracy:  0.9402070280577499\n",
      "Epoch number: 2648/10000step_number: 0/29 cost:  0.19983965615411153 accuracy:  0.9403432307273223\n",
      "Epoch number: 2649/10000step_number: 0/29 cost:  0.1997204045990073 accuracy:  0.9403432307273223\n",
      "Epoch number: 2650/10000step_number: 0/29 cost:  0.19966476229861888 accuracy:  0.9404794333968945\n",
      "Epoch number: 2651/10000step_number: 0/29 cost:  0.19932609867717505 accuracy:  0.9404794333968945\n",
      "Epoch number: 2652/10000step_number: 0/29 cost:  0.19958540994227292 accuracy:  0.9404794333968945\n",
      "Epoch number: 2653/10000step_number: 0/29 cost:  0.19937614514067084 accuracy:  0.9403432307273223\n",
      "Epoch number: 2654/10000step_number: 0/29 cost:  0.19935638121511942 accuracy:  0.9404794333968945\n",
      "Epoch number: 2655/10000step_number: 0/29 cost:  0.19930489362805132 accuracy:  0.9406156360664669\n",
      "Epoch number: 2656/10000step_number: 0/29 cost:  0.19909084316322131 accuracy:  0.9404794333968945\n",
      "Epoch number: 2657/10000step_number: 0/29 cost:  0.19922153941290296 accuracy:  0.9404794333968945\n",
      "Epoch number: 2658/10000step_number: 0/29 cost:  0.19888118940847027 accuracy:  0.9404794333968945\n",
      "Epoch number: 2659/10000step_number: 0/29 cost:  0.19912630465409717 accuracy:  0.9406156360664669\n",
      "Epoch number: 2660/10000step_number: 0/29 cost:  0.19879535272595175 accuracy:  0.9406156360664669\n",
      "Epoch number: 2661/10000step_number: 0/29 cost:  0.19890533019206705 accuracy:  0.9406156360664669\n",
      "Epoch number: 2662/10000step_number: 0/29 cost:  0.19862140941798798 accuracy:  0.9407518387360392\n",
      "Epoch number: 2663/10000step_number: 0/29 cost:  0.19880006943115833 accuracy:  0.9408880414056116\n",
      "Epoch number: 2664/10000step_number: 0/29 cost:  0.19848521683006567 accuracy:  0.9408880414056116\n",
      "Epoch number: 2665/10000step_number: 0/29 cost:  0.19860522800923822 accuracy:  0.9407518387360392\n",
      "Epoch number: 2666/10000step_number: 0/29 cost:  0.19831213163092218 accuracy:  0.9407518387360392\n",
      "Epoch number: 2667/10000step_number: 0/29 cost:  0.1985147904315108 accuracy:  0.9408880414056116\n",
      "Epoch number: 2668/10000step_number: 0/29 cost:  0.19822156374936475 accuracy:  0.9408880414056116\n",
      "Epoch number: 2669/10000step_number: 0/29 cost:  0.19826717198801566 accuracy:  0.9407518387360392\n",
      "Epoch number: 2670/10000step_number: 0/29 cost:  0.19814195395502282 accuracy:  0.9410242440751839\n",
      "Epoch number: 2671/10000step_number: 0/29 cost:  0.19808251826754872 accuracy:  0.9407518387360392\n",
      "Epoch number: 2672/10000step_number: 0/29 cost:  0.19808513099138844 accuracy:  0.9408880414056116\n",
      "Epoch number: 2673/10000step_number: 0/29 cost:  0.19781444691774538 accuracy:  0.9407518387360392\n",
      "Epoch number: 2674/10000step_number: 0/29 cost:  0.1980027012634286 accuracy:  0.9408880414056116\n",
      "Epoch number: 2675/10000step_number: 0/29 cost:  0.1977436217215003 accuracy:  0.9410242440751839\n",
      "Epoch number: 2676/10000step_number: 0/29 cost:  0.1977349192419041 accuracy:  0.9408880414056116\n",
      "Epoch number: 2677/10000step_number: 0/29 cost:  0.19770473025932142 accuracy:  0.9410242440751839\n",
      "Epoch number: 2678/10000step_number: 0/29 cost:  0.1974656143415511 accuracy:  0.9408880414056116\n",
      "Epoch number: 2679/10000step_number: 0/29 cost:  0.1976093562288341 accuracy:  0.9410242440751839\n",
      "Epoch number: 2680/10000step_number: 0/29 cost:  0.19734801275531652 accuracy:  0.9410242440751839\n",
      "Epoch number: 2681/10000step_number: 0/29 cost:  0.19737730837986248 accuracy:  0.9408880414056116\n",
      "Epoch number: 2682/10000step_number: 0/29 cost:  0.19733569476309742 accuracy:  0.9410242440751839\n",
      "Epoch number: 2683/10000step_number: 0/29 cost:  0.19710165539250352 accuracy:  0.9408880414056116\n",
      "Epoch number: 2684/10000step_number: 0/29 cost:  0.19719209620093017 accuracy:  0.9410242440751839\n",
      "Epoch number: 2685/10000step_number: 0/29 cost:  0.1969785604157995 accuracy:  0.9410242440751839\n",
      "Epoch number: 2686/10000step_number: 0/29 cost:  0.196968861275481 accuracy:  0.9408880414056116\n",
      "Epoch number: 2687/10000step_number: 0/29 cost:  0.19692109689889492 accuracy:  0.9410242440751839\n",
      "Epoch number: 2688/10000step_number: 0/29 cost:  0.19673489991209495 accuracy:  0.9408880414056116\n",
      "Epoch number: 2689/10000step_number: 0/29 cost:  0.19673465059629958 accuracy:  0.9410242440751839\n",
      "Epoch number: 2690/10000step_number: 0/29 cost:  0.19660531113448446 accuracy:  0.9410242440751839\n",
      "Epoch number: 2691/10000step_number: 0/29 cost:  0.19652888295441973 accuracy:  0.9410242440751839\n",
      "Epoch number: 2692/10000step_number: 0/29 cost:  0.19650663797447265 accuracy:  0.9410242440751839\n",
      "Epoch number: 2693/10000step_number: 0/29 cost:  0.19631484840556299 accuracy:  0.9408880414056116\n",
      "Epoch number: 2694/10000step_number: 0/29 cost:  0.19626816892767784 accuracy:  0.9410242440751839\n",
      "Epoch number: 2695/10000step_number: 0/29 cost:  0.19624445495867157 accuracy:  0.9410242440751839\n",
      "Epoch number: 2696/10000step_number: 0/29 cost:  0.195994615412416 accuracy:  0.9410242440751839\n",
      "Epoch number: 2697/10000step_number: 0/29 cost:  0.1961246845384047 accuracy:  0.9410242440751839\n",
      "Epoch number: 2698/10000step_number: 0/29 cost:  0.1958268864049536 accuracy:  0.9410242440751839\n",
      "Epoch number: 2699/10000step_number: 0/29 cost:  0.19575697035620493 accuracy:  0.9411604467447562\n",
      "Epoch number: 2700/10000step_number: 0/29 cost:  0.19582158685651183 accuracy:  0.9408880414056116\n",
      "Epoch number: 2701/10000step_number: 0/29 cost:  0.19540325767277875 accuracy:  0.9410242440751839\n",
      "Epoch number: 2702/10000step_number: 0/29 cost:  0.19569085252418242 accuracy:  0.9411604467447562\n",
      "Epoch number: 2703/10000step_number: 0/29 cost:  0.19527360806851113 accuracy:  0.9410242440751839\n",
      "Epoch number: 2704/10000step_number: 0/29 cost:  0.1953807197693884 accuracy:  0.9411604467447562\n",
      "Epoch number: 2705/10000step_number: 0/29 cost:  0.1951838672040701 accuracy:  0.9410242440751839\n",
      "Epoch number: 2706/10000step_number: 0/29 cost:  0.19493534156622194 accuracy:  0.9412966494143286\n",
      "Epoch number: 2707/10000step_number: 0/29 cost:  0.19430905921848068 accuracy:  0.9414328520839008\n",
      "Epoch number: 2708/10000step_number: 0/29 cost:  0.19381221219241976 accuracy:  0.9412966494143286\n",
      "Epoch number: 2709/10000step_number: 0/29 cost:  0.19340059172881535 accuracy:  0.9412966494143286\n",
      "Epoch number: 2710/10000step_number: 0/29 cost:  0.19366366360340226 accuracy:  0.9414328520839008\n",
      "Epoch number: 2711/10000step_number: 0/29 cost:  0.1986045352093201 accuracy:  0.9408880414056116\n",
      "Epoch number: 2712/10000step_number: 0/29 cost:  0.22877431450155733 accuracy:  0.9354399346227186\n",
      "Epoch number: 2713/10000step_number: 0/29 cost:  0.22689507346971396 accuracy:  0.9422500681013348\n",
      "Epoch number: 2714/10000step_number: 0/29 cost:  0.19644063372983386 accuracy:  0.9456551348406429\n",
      "Epoch number: 2715/10000step_number: 0/29 cost:  0.18429131979493363 accuracy:  0.9456551348406429\n",
      "Epoch number: 2716/10000step_number: 0/29 cost:  0.18987157305715352 accuracy:  0.9432034867883411\n",
      "Epoch number: 2717/10000step_number: 0/29 cost:  0.18544820968106684 accuracy:  0.9445655134840643\n",
      "Epoch number: 2718/10000step_number: 0/29 cost:  0.18650204954962743 accuracy:  0.9441569054753474\n",
      "Epoch number: 2719/10000step_number: 0/29 cost:  0.18576671918338722 accuracy:  0.9437482974666304\n",
      "Epoch number: 2720/10000step_number: 0/29 cost:  0.18525546275007418 accuracy:  0.944020702805775\n",
      "Epoch number: 2721/10000step_number: 0/29 cost:  0.18492339649288295 accuracy:  0.9442931081449196\n",
      "Epoch number: 2722/10000step_number: 0/29 cost:  0.18460841037794815 accuracy:  0.9437482974666304\n",
      "Epoch number: 2723/10000step_number: 0/29 cost:  0.1843098564031509 accuracy:  0.9438845001362026\n",
      "Epoch number: 2724/10000step_number: 0/29 cost:  0.18404606349269198 accuracy:  0.9433396894579134\n",
      "Epoch number: 2725/10000step_number: 0/29 cost:  0.18381785525018116 accuracy:  0.9433396894579134\n",
      "Epoch number: 2726/10000step_number: 0/29 cost:  0.1836392505599762 accuracy:  0.9438845001362026\n",
      "Epoch number: 2727/10000step_number: 0/29 cost:  0.18349082562585445 accuracy:  0.9438845001362026\n",
      "Epoch number: 2728/10000step_number: 0/29 cost:  0.18338434165184891 accuracy:  0.944020702805775\n",
      "Epoch number: 2729/10000step_number: 0/29 cost:  0.18330180458850584 accuracy:  0.9438845001362026\n",
      "Epoch number: 2730/10000step_number: 0/29 cost:  0.18325258459966018 accuracy:  0.9442931081449196\n",
      "Epoch number: 2731/10000step_number: 0/29 cost:  0.1832253601683819 accuracy:  0.9441569054753474\n",
      "Epoch number: 2732/10000step_number: 0/29 cost:  0.1832252738786309 accuracy:  0.9442931081449196\n",
      "Epoch number: 2733/10000step_number: 0/29 cost:  0.18324474798341447 accuracy:  0.9442931081449196\n",
      "Epoch number: 2734/10000step_number: 0/29 cost:  0.18328255769078725 accuracy:  0.9441569054753474\n",
      "Epoch number: 2735/10000step_number: 0/29 cost:  0.1833323183603156 accuracy:  0.944020702805775\n",
      "Epoch number: 2736/10000step_number: 0/29 cost:  0.18339045797872125 accuracy:  0.9438845001362026\n",
      "Epoch number: 2737/10000step_number: 0/29 cost:  0.18345222853564686 accuracy:  0.944020702805775\n",
      "Epoch number: 2738/10000step_number: 0/29 cost:  0.1835134959644418 accuracy:  0.9438845001362026\n",
      "Epoch number: 2739/10000step_number: 0/29 cost:  0.18357004276018138 accuracy:  0.9438845001362026\n",
      "Epoch number: 2740/10000step_number: 0/29 cost:  0.1836188853529886 accuracy:  0.9437482974666304\n",
      "Epoch number: 2741/10000step_number: 0/29 cost:  0.18365877660475136 accuracy:  0.9437482974666304\n",
      "Epoch number: 2742/10000step_number: 0/29 cost:  0.183689916774331 accuracy:  0.9437482974666304\n",
      "Epoch number: 2743/10000step_number: 0/29 cost:  0.18371310577860248 accuracy:  0.9437482974666304\n",
      "Epoch number: 2744/10000step_number: 0/29 cost:  0.1837292775435241 accuracy:  0.943612094797058\n",
      "Epoch number: 2745/10000step_number: 0/29 cost:  0.18373935353088294 accuracy:  0.943612094797058\n",
      "Epoch number: 2746/10000step_number: 0/29 cost:  0.18374402524270322 accuracy:  0.943612094797058\n",
      "Epoch number: 2747/10000step_number: 0/29 cost:  0.18374365949873778 accuracy:  0.9434758921274857\n",
      "Epoch number: 2748/10000step_number: 0/29 cost:  0.18373833853357063 accuracy:  0.9434758921274857\n",
      "Epoch number: 2749/10000step_number: 0/29 cost:  0.1837279926373757 accuracy:  0.9433396894579134\n",
      "Epoch number: 2750/10000step_number: 0/29 cost:  0.1837124753574479 accuracy:  0.9433396894579134\n",
      "Epoch number: 2751/10000step_number: 0/29 cost:  0.18369162754376187 accuracy:  0.9433396894579134\n",
      "Epoch number: 2752/10000step_number: 0/29 cost:  0.18366529599008477 accuracy:  0.9432034867883411\n",
      "Epoch number: 2753/10000step_number: 0/29 cost:  0.18363335940197772 accuracy:  0.9432034867883411\n",
      "Epoch number: 2754/10000step_number: 0/29 cost:  0.1835957332189824 accuracy:  0.9432034867883411\n",
      "Epoch number: 2755/10000step_number: 0/29 cost:  0.18355238482227684 accuracy:  0.9432034867883411\n",
      "Epoch number: 2756/10000step_number: 0/29 cost:  0.18350333842174557 accuracy:  0.9430672841187687\n",
      "Epoch number: 2757/10000step_number: 0/29 cost:  0.18344868901447783 accuracy:  0.9429310814491964\n",
      "Epoch number: 2758/10000step_number: 0/29 cost:  0.18338860991783706 accuracy:  0.9426586761100517\n",
      "Epoch number: 2759/10000step_number: 0/29 cost:  0.1833233593380927 accuracy:  0.9426586761100517\n",
      "Epoch number: 2760/10000step_number: 0/29 cost:  0.1832532699083639 accuracy:  0.9426586761100517\n",
      "Epoch number: 2761/10000step_number: 0/29 cost:  0.18317872427924567 accuracy:  0.9426586761100517\n",
      "Epoch number: 2762/10000step_number: 0/29 cost:  0.18310012270047352 accuracy:  0.9426586761100517\n",
      "Epoch number: 2763/10000step_number: 0/29 cost:  0.18301786391315567 accuracy:  0.9425224734404795\n",
      "Epoch number: 2764/10000step_number: 0/29 cost:  0.1829323440370476 accuracy:  0.9425224734404795\n",
      "Epoch number: 2765/10000step_number: 0/29 cost:  0.18284396231039024 accuracy:  0.9425224734404795\n",
      "Epoch number: 2766/10000step_number: 0/29 cost:  0.1827531161890713 accuracy:  0.9425224734404795\n",
      "Epoch number: 2767/10000step_number: 0/29 cost:  0.1826601836377446 accuracy:  0.9425224734404795\n",
      "Epoch number: 2768/10000step_number: 0/29 cost:  0.18256550074723674 accuracy:  0.9426586761100517\n",
      "Epoch number: 2769/10000step_number: 0/29 cost:  0.18246934395427217 accuracy:  0.9425224734404795\n",
      "Epoch number: 2770/10000step_number: 0/29 cost:  0.18237192005723132 accuracy:  0.9425224734404795\n",
      "Epoch number: 2771/10000step_number: 0/29 cost:  0.1822733632629321 accuracy:  0.9422500681013348\n",
      "Epoch number: 2772/10000step_number: 0/29 cost:  0.1821737366792476 accuracy:  0.9422500681013348\n",
      "Epoch number: 2773/10000step_number: 0/29 cost:  0.18207303610618747 accuracy:  0.9422500681013348\n",
      "Epoch number: 2774/10000step_number: 0/29 cost:  0.18197119470202722 accuracy:  0.9419776627621902\n",
      "Epoch number: 2775/10000step_number: 0/29 cost:  0.1818680879334283 accuracy:  0.9419776627621902\n",
      "Epoch number: 2776/10000step_number: 0/29 cost:  0.1817635385761987 accuracy:  0.9418414600926178\n",
      "Epoch number: 2777/10000step_number: 0/29 cost:  0.18165732171514617 accuracy:  0.9418414600926178\n",
      "Epoch number: 2778/10000step_number: 0/29 cost:  0.1815491698173833 accuracy:  0.9419776627621902\n",
      "Epoch number: 2779/10000step_number: 0/29 cost:  0.18143877826777802 accuracy:  0.9418414600926178\n",
      "Epoch number: 2780/10000step_number: 0/29 cost:  0.18132581220009303 accuracy:  0.9418414600926178\n",
      "Epoch number: 2781/10000step_number: 0/29 cost:  0.1812099160148823 accuracy:  0.9419776627621902\n",
      "Epoch number: 2782/10000step_number: 0/29 cost:  0.18109072766175688 accuracy:  0.9419776627621902\n",
      "Epoch number: 2783/10000step_number: 0/29 cost:  0.18096790058876622 accuracy:  0.9421138654317625\n",
      "Epoch number: 2784/10000step_number: 0/29 cost:  0.18084113701000332 accuracy:  0.9422500681013348\n",
      "Epoch number: 2785/10000step_number: 0/29 cost:  0.18071023632344543 accuracy:  0.9422500681013348\n",
      "Epoch number: 2786/10000step_number: 0/29 cost:  0.18057516141837562 accuracy:  0.9422500681013348\n",
      "Epoch number: 2787/10000step_number: 0/29 cost:  0.18043612234596337 accuracy:  0.9419776627621902\n",
      "Epoch number: 2788/10000step_number: 0/29 cost:  0.18029367033981578 accuracy:  0.9421138654317625\n",
      "Epoch number: 2789/10000step_number: 0/29 cost:  0.180148784917218 accuracy:  0.9421138654317625\n",
      "Epoch number: 2790/10000step_number: 0/29 cost:  0.18000292459193545 accuracy:  0.9421138654317625\n",
      "Epoch number: 2791/10000step_number: 0/29 cost:  0.1798580039988711 accuracy:  0.9421138654317625\n",
      "Epoch number: 2792/10000step_number: 0/29 cost:  0.17971626732384055 accuracy:  0.9419776627621902\n",
      "Epoch number: 2793/10000step_number: 0/29 cost:  0.17958005704840418 accuracy:  0.9419776627621902\n",
      "Epoch number: 2794/10000step_number: 0/29 cost:  0.17945152091211697 accuracy:  0.9421138654317625\n",
      "Epoch number: 2795/10000step_number: 0/29 cost:  0.1793323341268617 accuracy:  0.9421138654317625\n",
      "Epoch number: 2796/10000step_number: 0/29 cost:  0.17922351323009783 accuracy:  0.9421138654317625\n",
      "Epoch number: 2797/10000step_number: 0/29 cost:  0.17912536052909397 accuracy:  0.9421138654317625\n",
      "Epoch number: 2798/10000step_number: 0/29 cost:  0.1790375268155861 accuracy:  0.9421138654317625\n",
      "Epoch number: 2799/10000step_number: 0/29 cost:  0.1789591435579161 accuracy:  0.9421138654317625\n",
      "Epoch number: 2800/10000step_number: 0/29 cost:  0.17888900982829825 accuracy:  0.9419776627621902\n",
      "Epoch number: 2801/10000step_number: 0/29 cost:  0.17882626927692183 accuracy:  0.9419776627621902\n",
      "Epoch number: 2802/10000step_number: 0/29 cost:  0.17877246248746978 accuracy:  0.9419776627621902\n",
      "Epoch number: 2803/10000step_number: 0/29 cost:  0.1787265112029855 accuracy:  0.9419776627621902\n",
      "Epoch number: 2804/10000step_number: 0/29 cost:  0.17868072538281474 accuracy:  0.9419776627621902\n",
      "Epoch number: 2805/10000step_number: 0/29 cost:  0.17863815696247845 accuracy:  0.9419776627621902\n",
      "Epoch number: 2806/10000step_number: 0/29 cost:  0.17859713005514452 accuracy:  0.9421138654317625\n",
      "Epoch number: 2807/10000step_number: 0/29 cost:  0.17855678916355028 accuracy:  0.9421138654317625\n",
      "Epoch number: 2808/10000step_number: 0/29 cost:  0.17851653876119525 accuracy:  0.9421138654317625\n",
      "Epoch number: 2809/10000step_number: 0/29 cost:  0.17847590093650537 accuracy:  0.9421138654317625\n",
      "Epoch number: 2810/10000step_number: 0/29 cost:  0.1784343998932024 accuracy:  0.9421138654317625\n",
      "Epoch number: 2811/10000step_number: 0/29 cost:  0.1783917412364062 accuracy:  0.9421138654317625\n",
      "Epoch number: 2812/10000step_number: 0/29 cost:  0.1783477512035081 accuracy:  0.9421138654317625\n",
      "Epoch number: 2813/10000step_number: 0/29 cost:  0.17830236154054785 accuracy:  0.9421138654317625\n",
      "Epoch number: 2814/10000step_number: 0/29 cost:  0.1782555867160178 accuracy:  0.9423862707709071\n",
      "Epoch number: 2815/10000step_number: 0/29 cost:  0.17820749978515563 accuracy:  0.9425224734404795\n",
      "Epoch number: 2816/10000step_number: 0/29 cost:  0.1781582065934064 accuracy:  0.9425224734404795\n",
      "Epoch number: 2817/10000step_number: 0/29 cost:  0.17810782814383372 accuracy:  0.9425224734404795\n",
      "Epoch number: 2818/10000step_number: 0/29 cost:  0.17805648724220385 accuracy:  0.9426586761100517\n",
      "Epoch number: 2819/10000step_number: 0/29 cost:  0.17800430028916994 accuracy:  0.9426586761100517\n",
      "Epoch number: 2820/10000step_number: 0/29 cost:  0.17795137267465236 accuracy:  0.9426586761100517\n",
      "Epoch number: 2821/10000step_number: 0/29 cost:  0.17789779677675852 accuracy:  0.9426586761100517\n",
      "Epoch number: 2822/10000step_number: 0/29 cost:  0.1778436515811136 accuracy:  0.9426586761100517\n",
      "Epoch number: 2823/10000step_number: 0/29 cost:  0.17778900324144017 accuracy:  0.9427948787796241\n",
      "Epoch number: 2824/10000step_number: 0/29 cost:  0.1777339061413041 accuracy:  0.9427948787796241\n",
      "Epoch number: 2825/10000step_number: 0/29 cost:  0.17767840413867697 accuracy:  0.9427948787796241\n",
      "Epoch number: 2826/10000step_number: 0/29 cost:  0.1776225318586517 accuracy:  0.9427948787796241\n",
      "Epoch number: 2827/10000step_number: 0/29 cost:  0.17756631592182992 accuracy:  0.9429310814491964\n",
      "Epoch number: 2828/10000step_number: 0/29 cost:  0.17750977610932814 accuracy:  0.9429310814491964\n",
      "Epoch number: 2829/10000step_number: 0/29 cost:  0.17745292640866336 accuracy:  0.9429310814491964\n",
      "Epoch number: 2830/10000step_number: 0/29 cost:  0.17739577599963116 accuracy:  0.9429310814491964\n",
      "Epoch number: 2831/10000step_number: 0/29 cost:  0.17733833009791983 accuracy:  0.9429310814491964\n",
      "Epoch number: 2832/10000step_number: 0/29 cost:  0.17728059077689728 accuracy:  0.9429310814491964\n",
      "Epoch number: 2833/10000step_number: 0/29 cost:  0.1772225575867325 accuracy:  0.9429310814491964\n",
      "Epoch number: 2834/10000step_number: 0/29 cost:  0.17716422825294967 accuracy:  0.9429310814491964\n",
      "Epoch number: 2835/10000step_number: 0/29 cost:  0.1771055990010579 accuracy:  0.9427948787796241\n",
      "Epoch number: 2836/10000step_number: 0/29 cost:  0.17704666527310858 accuracy:  0.9429310814491964\n",
      "Epoch number: 2837/10000step_number: 0/29 cost:  0.176987421528079 accuracy:  0.9429310814491964\n",
      "Epoch number: 2838/10000step_number: 0/29 cost:  0.17692786247468348 accuracy:  0.9429310814491964\n",
      "Epoch number: 2839/10000step_number: 0/29 cost:  0.1768679814564848 accuracy:  0.9429310814491964\n",
      "Epoch number: 2840/10000step_number: 0/29 cost:  0.17680777408372841 accuracy:  0.9429310814491964\n",
      "Epoch number: 2841/10000step_number: 0/29 cost:  0.17674723146935792 accuracy:  0.9429310814491964\n",
      "Epoch number: 2842/10000step_number: 0/29 cost:  0.17668635416673373 accuracy:  0.9429310814491964\n",
      "Epoch number: 2843/10000step_number: 0/29 cost:  0.17662512352156914 accuracy:  0.9429310814491964\n",
      "Epoch number: 2844/10000step_number: 0/29 cost:  0.17656356239918933 accuracy:  0.9429310814491964\n",
      "Epoch number: 2845/10000step_number: 0/29 cost:  0.17650160383760796 accuracy:  0.9429310814491964\n",
      "Epoch number: 2846/10000step_number: 0/29 cost:  0.1764393812920356 accuracy:  0.9429310814491964\n",
      "Epoch number: 2847/10000step_number: 0/29 cost:  0.17637657398558912 accuracy:  0.9429310814491964\n",
      "Epoch number: 2848/10000step_number: 0/29 cost:  0.17631390958028284 accuracy:  0.9429310814491964\n",
      "Epoch number: 2849/10000step_number: 0/29 cost:  0.17624968288866907 accuracy:  0.9429310814491964\n",
      "Epoch number: 2850/10000step_number: 0/29 cost:  0.17618761265064883 accuracy:  0.9427948787796241\n",
      "Epoch number: 2851/10000step_number: 0/29 cost:  0.17612080422767512 accuracy:  0.9427948787796241\n",
      "Epoch number: 2852/10000step_number: 0/29 cost:  0.17605889558745816 accuracy:  0.9430672841187687\n",
      "Epoch number: 2853/10000step_number: 0/29 cost:  0.1759921241547786 accuracy:  0.9430672841187687\n",
      "Epoch number: 2854/10000step_number: 0/29 cost:  0.1759277102784551 accuracy:  0.9430672841187687\n",
      "Epoch number: 2855/10000step_number: 0/29 cost:  0.17586161999341282 accuracy:  0.9430672841187687\n",
      "Epoch number: 2856/10000step_number: 0/29 cost:  0.1757956594380358 accuracy:  0.9430672841187687\n",
      "Epoch number: 2857/10000step_number: 0/29 cost:  0.1757289611195525 accuracy:  0.9430672841187687\n",
      "Epoch number: 2858/10000step_number: 0/29 cost:  0.17566200163309753 accuracy:  0.9432034867883411\n",
      "Epoch number: 2859/10000step_number: 0/29 cost:  0.17559448054277432 accuracy:  0.9432034867883411\n",
      "Epoch number: 2860/10000step_number: 0/29 cost:  0.17552654355687042 accuracy:  0.9432034867883411\n",
      "Epoch number: 2861/10000step_number: 0/29 cost:  0.17545806471793005 accuracy:  0.9432034867883411\n",
      "Epoch number: 2862/10000step_number: 0/29 cost:  0.17538908945489595 accuracy:  0.9432034867883411\n",
      "Epoch number: 2863/10000step_number: 0/29 cost:  0.17531953785669457 accuracy:  0.9432034867883411\n",
      "Epoch number: 2864/10000step_number: 0/29 cost:  0.17524941837121671 accuracy:  0.9432034867883411\n",
      "Epoch number: 2865/10000step_number: 0/29 cost:  0.17517868670233094 accuracy:  0.9432034867883411\n",
      "Epoch number: 2866/10000step_number: 0/29 cost:  0.17510736579413486 accuracy:  0.9433396894579134\n",
      "Epoch number: 2867/10000step_number: 0/29 cost:  0.17503547692665064 accuracy:  0.9433396894579134\n",
      "Epoch number: 2868/10000step_number: 0/29 cost:  0.17496310674339266 accuracy:  0.9433396894579134\n",
      "Epoch number: 2869/10000step_number: 0/29 cost:  0.17489034960651806 accuracy:  0.9434758921274857\n",
      "Epoch number: 2870/10000step_number: 0/29 cost:  0.17481732288556168 accuracy:  0.9434758921274857\n",
      "Epoch number: 2871/10000step_number: 0/29 cost:  0.17474411410796012 accuracy:  0.9434758921274857\n",
      "Epoch number: 2872/10000step_number: 0/29 cost:  0.17467079612686925 accuracy:  0.9434758921274857\n",
      "Epoch number: 2873/10000step_number: 0/29 cost:  0.17459740772051527 accuracy:  0.9434758921274857\n",
      "Epoch number: 2874/10000step_number: 0/29 cost:  0.17452397721746246 accuracy:  0.9434758921274857\n",
      "Epoch number: 2875/10000step_number: 0/29 cost:  0.17445051221875305 accuracy:  0.9434758921274857\n",
      "Epoch number: 2876/10000step_number: 0/29 cost:  0.1743770181976061 accuracy:  0.9434758921274857\n",
      "Epoch number: 2877/10000step_number: 0/29 cost:  0.17430348966338502 accuracy:  0.9434758921274857\n",
      "Epoch number: 2878/10000step_number: 0/29 cost:  0.17422992465395967 accuracy:  0.9434758921274857\n",
      "Epoch number: 2879/10000step_number: 0/29 cost:  0.17415631592036457 accuracy:  0.9434758921274857\n",
      "Epoch number: 2880/10000step_number: 0/29 cost:  0.17408266257666688 accuracy:  0.9434758921274857\n",
      "Epoch number: 2881/10000step_number: 0/29 cost:  0.17400896105147837 accuracy:  0.9434758921274857\n",
      "Epoch number: 2882/10000step_number: 0/29 cost:  0.1739352151751436 accuracy:  0.9434758921274857\n",
      "Epoch number: 2883/10000step_number: 0/29 cost:  0.1738614268386354 accuracy:  0.9434758921274857\n",
      "Epoch number: 2884/10000step_number: 0/29 cost:  0.17378760542988325 accuracy:  0.943612094797058\n",
      "Epoch number: 2885/10000step_number: 0/29 cost:  0.17371375807762138 accuracy:  0.943612094797058\n",
      "Epoch number: 2886/10000step_number: 0/29 cost:  0.17363989912941724 accuracy:  0.943612094797058\n",
      "Epoch number: 2887/10000step_number: 0/29 cost:  0.17356603976644885 accuracy:  0.943612094797058\n",
      "Epoch number: 2888/10000step_number: 0/29 cost:  0.17349219809703334 accuracy:  0.9434758921274857\n",
      "Epoch number: 2889/10000step_number: 0/29 cost:  0.1734183878055734 accuracy:  0.9433396894579134\n",
      "Epoch number: 2890/10000step_number: 0/29 cost:  0.17334462939735606 accuracy:  0.9433396894579134\n",
      "Epoch number: 2891/10000step_number: 0/29 cost:  0.17327093739774682 accuracy:  0.9433396894579134\n",
      "Epoch number: 2892/10000step_number: 0/29 cost:  0.17319733334001677 accuracy:  0.9433396894579134\n",
      "Epoch number: 2893/10000step_number: 0/29 cost:  0.17312383086159117 accuracy:  0.9433396894579134\n",
      "Epoch number: 2894/10000step_number: 0/29 cost:  0.1730504511935186 accuracy:  0.9433396894579134\n",
      "Epoch number: 2895/10000step_number: 0/29 cost:  0.17297720528375998 accuracy:  0.9434758921274857\n",
      "Epoch number: 2896/10000step_number: 0/29 cost:  0.17290411284351634 accuracy:  0.9434758921274857\n",
      "Epoch number: 2897/10000step_number: 0/29 cost:  0.17283118031156222 accuracy:  0.9434758921274857\n",
      "Epoch number: 2898/10000step_number: 0/29 cost:  0.1727584249695309 accuracy:  0.9434758921274857\n",
      "Epoch number: 2899/10000step_number: 0/29 cost:  0.17268584706003823 accuracy:  0.9434758921274857\n",
      "Epoch number: 2900/10000step_number: 0/29 cost:  0.17261346115628845 accuracy:  0.9434758921274857\n",
      "Epoch number: 2901/10000step_number: 0/29 cost:  0.17254125992697614 accuracy:  0.9434758921274857\n",
      "Epoch number: 2902/10000step_number: 0/29 cost:  0.17246925594730544 accuracy:  0.9434758921274857\n",
      "Epoch number: 2903/10000step_number: 0/29 cost:  0.17239743326886492 accuracy:  0.9433396894579134\n",
      "Epoch number: 2904/10000step_number: 0/29 cost:  0.1723258044174799 accuracy:  0.9434758921274857\n",
      "Epoch number: 2905/10000step_number: 0/29 cost:  0.1722543437842186 accuracy:  0.9434758921274857\n",
      "Epoch number: 2906/10000step_number: 0/29 cost:  0.17218306710589645 accuracy:  0.9433396894579134\n",
      "Epoch number: 2907/10000step_number: 0/29 cost:  0.17211193726294705 accuracy:  0.9433396894579134\n",
      "Epoch number: 2908/10000step_number: 0/29 cost:  0.17204097784858727 accuracy:  0.9432034867883411\n",
      "Epoch number: 2909/10000step_number: 0/29 cost:  0.17197013635112748 accuracy:  0.9433396894579134\n",
      "Epoch number: 2910/10000step_number: 0/29 cost:  0.17189945079726923 accuracy:  0.9433396894579134\n",
      "Epoch number: 2911/10000step_number: 0/29 cost:  0.1718288457997661 accuracy:  0.9433396894579134\n",
      "Epoch number: 2912/10000step_number: 0/29 cost:  0.1717583840135558 accuracy:  0.9433396894579134\n",
      "Epoch number: 2913/10000step_number: 0/29 cost:  0.17168795388837624 accuracy:  0.9433396894579134\n",
      "Epoch number: 2914/10000step_number: 0/29 cost:  0.17161766010008733 accuracy:  0.9433396894579134\n",
      "Epoch number: 2915/10000step_number: 0/29 cost:  0.17154733190868068 accuracy:  0.9434758921274857\n",
      "Epoch number: 2916/10000step_number: 0/29 cost:  0.17147714716339815 accuracy:  0.9434758921274857\n",
      "Epoch number: 2917/10000step_number: 0/29 cost:  0.17140683514583321 accuracy:  0.9434758921274857\n",
      "Epoch number: 2918/10000step_number: 0/29 cost:  0.17133670365321826 accuracy:  0.9433396894579134\n",
      "Epoch number: 2919/10000step_number: 0/29 cost:  0.1712663071110489 accuracy:  0.9433396894579134\n",
      "Epoch number: 2920/10000step_number: 0/29 cost:  0.17119618796689834 accuracy:  0.9432034867883411\n",
      "Epoch number: 2921/10000step_number: 0/29 cost:  0.17112558511250983 accuracy:  0.9430672841187687\n",
      "Epoch number: 2922/10000step_number: 0/29 cost:  0.17105547003682167 accuracy:  0.9430672841187687\n",
      "Epoch number: 2923/10000step_number: 0/29 cost:  0.1709845042540053 accuracy:  0.9430672841187687\n",
      "Epoch number: 2924/10000step_number: 0/29 cost:  0.17091443665937847 accuracy:  0.9430672841187687\n",
      "Epoch number: 2925/10000step_number: 0/29 cost:  0.170842909965946 accuracy:  0.9429310814491964\n",
      "Epoch number: 2926/10000step_number: 0/29 cost:  0.17077295932855033 accuracy:  0.9429310814491964\n",
      "Epoch number: 2927/10000step_number: 0/29 cost:  0.17070072875390843 accuracy:  0.9429310814491964\n",
      "Epoch number: 2928/10000step_number: 0/29 cost:  0.17063078304600884 accuracy:  0.9430672841187687\n",
      "Epoch number: 2929/10000step_number: 0/29 cost:  0.17055803181087742 accuracy:  0.9430672841187687\n",
      "Epoch number: 2930/10000step_number: 0/29 cost:  0.1704876278955154 accuracy:  0.9430672841187687\n",
      "Epoch number: 2931/10000step_number: 0/29 cost:  0.17041474097531728 accuracy:  0.9430672841187687\n",
      "Epoch number: 2932/10000step_number: 0/29 cost:  0.1703435536762728 accuracy:  0.9430672841187687\n",
      "Epoch number: 2933/10000step_number: 0/29 cost:  0.1702705849551458 accuracy:  0.9430672841187687\n",
      "Epoch number: 2934/10000step_number: 0/29 cost:  0.17019861689403826 accuracy:  0.9430672841187687\n",
      "Epoch number: 2935/10000step_number: 0/29 cost:  0.1701254183321005 accuracy:  0.9432034867883411\n",
      "Epoch number: 2936/10000step_number: 0/29 cost:  0.17005275385488597 accuracy:  0.9432034867883411\n",
      "Epoch number: 2937/10000step_number: 0/29 cost:  0.16997919519106877 accuracy:  0.9432034867883411\n",
      "Epoch number: 2938/10000step_number: 0/29 cost:  0.16990588336545442 accuracy:  0.9432034867883411\n",
      "Epoch number: 2939/10000step_number: 0/29 cost:  0.1698318742712863 accuracy:  0.9432034867883411\n",
      "Epoch number: 2940/10000step_number: 0/29 cost:  0.16975793123767147 accuracy:  0.9432034867883411\n",
      "Epoch number: 2941/10000step_number: 0/29 cost:  0.16968341071549334 accuracy:  0.9433396894579134\n",
      "Epoch number: 2942/10000step_number: 0/29 cost:  0.169608843778024 accuracy:  0.9433396894579134\n",
      "Epoch number: 2943/10000step_number: 0/29 cost:  0.16953377236802641 accuracy:  0.9433396894579134\n",
      "Epoch number: 2944/10000step_number: 0/29 cost:  0.16945858478337256 accuracy:  0.9433396894579134\n",
      "Epoch number: 2945/10000step_number: 0/29 cost:  0.16938293420298953 accuracy:  0.9434758921274857\n",
      "Epoch number: 2946/10000step_number: 0/29 cost:  0.16930712123500585 accuracy:  0.9434758921274857\n",
      "Epoch number: 2947/10000step_number: 0/29 cost:  0.16923086373428192 accuracy:  0.9434758921274857\n",
      "Epoch number: 2948/10000step_number: 0/29 cost:  0.16915440931377293 accuracy:  0.9434758921274857\n",
      "Epoch number: 2949/10000step_number: 0/29 cost:  0.16907751174875257 accuracy:  0.9434758921274857\n",
      "Epoch number: 2950/10000step_number: 0/29 cost:  0.16900038914008253 accuracy:  0.9434758921274857\n",
      "Epoch number: 2951/10000step_number: 0/29 cost:  0.1689228122959557 accuracy:  0.9434758921274857\n",
      "Epoch number: 2952/10000step_number: 0/29 cost:  0.16884498720725633 accuracy:  0.9434758921274857\n",
      "Epoch number: 2953/10000step_number: 0/29 cost:  0.16876668659793678 accuracy:  0.9434758921274857\n",
      "Epoch number: 2954/10000step_number: 0/29 cost:  0.16868811845095497 accuracy:  0.9434758921274857\n",
      "Epoch number: 2955/10000step_number: 0/29 cost:  0.1686090417511563 accuracy:  0.9434758921274857\n",
      "Epoch number: 2956/10000step_number: 0/29 cost:  0.1685296798619763 accuracy:  0.9434758921274857\n",
      "Epoch number: 2957/10000step_number: 0/29 cost:  0.16844975894028633 accuracy:  0.9434758921274857\n",
      "Epoch number: 2958/10000step_number: 0/29 cost:  0.16836953413158137 accuracy:  0.9434758921274857\n",
      "Epoch number: 2959/10000step_number: 0/29 cost:  0.168288673431983 accuracy:  0.9434758921274857\n",
      "Epoch number: 2960/10000step_number: 0/29 cost:  0.1682074884882073 accuracy:  0.943612094797058\n",
      "Epoch number: 2961/10000step_number: 0/29 cost:  0.16812555258060832 accuracy:  0.943612094797058\n",
      "Epoch number: 2962/10000step_number: 0/29 cost:  0.1680432744525524 accuracy:  0.943612094797058\n",
      "Epoch number: 2963/10000step_number: 0/29 cost:  0.16796007491946863 accuracy:  0.943612094797058\n",
      "Epoch number: 2964/10000step_number: 0/29 cost:  0.16787652847706652 accuracy:  0.943612094797058\n",
      "Epoch number: 2965/10000step_number: 0/29 cost:  0.1677918061415791 accuracy:  0.943612094797058\n",
      "Epoch number: 2966/10000step_number: 0/29 cost:  0.16770676645735788 accuracy:  0.943612094797058\n",
      "Epoch number: 2967/10000step_number: 0/29 cost:  0.1676201631886457 accuracy:  0.943612094797058\n",
      "Epoch number: 2968/10000step_number: 0/29 cost:  0.1675333418187271 accuracy:  0.943612094797058\n",
      "Epoch number: 2969/10000step_number: 0/29 cost:  0.1674443626702585 accuracy:  0.943612094797058\n",
      "Epoch number: 2970/10000step_number: 0/29 cost:  0.1673553745349035 accuracy:  0.943612094797058\n",
      "Epoch number: 2971/10000step_number: 0/29 cost:  0.1672633702523902 accuracy:  0.943612094797058\n",
      "Epoch number: 2972/10000step_number: 0/29 cost:  0.1671716305735098 accuracy:  0.943612094797058\n",
      "Epoch number: 2973/10000step_number: 0/29 cost:  0.16707587605600588 accuracy:  0.9437482974666304\n",
      "Epoch number: 2974/10000step_number: 0/29 cost:  0.16698040071061584 accuracy:  0.9437482974666304\n",
      "Epoch number: 2975/10000step_number: 0/29 cost:  0.1668801925159799 accuracy:  0.9437482974666304\n",
      "Epoch number: 2976/10000step_number: 0/29 cost:  0.16677962730032175 accuracy:  0.9441569054753474\n",
      "Epoch number: 2977/10000step_number: 0/29 cost:  0.16667408853315172 accuracy:  0.9441569054753474\n",
      "Epoch number: 2978/10000step_number: 0/29 cost:  0.16656709451989413 accuracy:  0.9441569054753474\n",
      "Epoch number: 2979/10000step_number: 0/29 cost:  0.16645507211258365 accuracy:  0.9441569054753474\n",
      "Epoch number: 2980/10000step_number: 0/29 cost:  0.1663405668258685 accuracy:  0.9441569054753474\n",
      "Epoch number: 2981/10000step_number: 0/29 cost:  0.16622107224968782 accuracy:  0.9441569054753474\n",
      "Epoch number: 2982/10000step_number: 0/29 cost:  0.16609855105531676 accuracy:  0.9441569054753474\n",
      "Epoch number: 2983/10000step_number: 0/29 cost:  0.16597145501836505 accuracy:  0.9441569054753474\n",
      "Epoch number: 2984/10000step_number: 0/29 cost:  0.16584165409920013 accuracy:  0.9442931081449196\n",
      "Epoch number: 2985/10000step_number: 0/29 cost:  0.16570851165204897 accuracy:  0.9442931081449196\n",
      "Epoch number: 2986/10000step_number: 0/29 cost:  0.16557402112345868 accuracy:  0.9442931081449196\n",
      "Epoch number: 2987/10000step_number: 0/29 cost:  0.16543808294582066 accuracy:  0.9442931081449196\n",
      "Epoch number: 2988/10000step_number: 0/29 cost:  0.16530252089402853 accuracy:  0.9442931081449196\n",
      "Epoch number: 2989/10000step_number: 0/29 cost:  0.16516729278303036 accuracy:  0.9442931081449196\n",
      "Epoch number: 2990/10000step_number: 0/29 cost:  0.1650339405285364 accuracy:  0.9442931081449196\n",
      "Epoch number: 2991/10000step_number: 0/29 cost:  0.16490240643887105 accuracy:  0.9442931081449196\n",
      "Epoch number: 2992/10000step_number: 0/29 cost:  0.1647741265149143 accuracy:  0.9442931081449196\n",
      "Epoch number: 2993/10000step_number: 0/29 cost:  0.16464908400760087 accuracy:  0.9442931081449196\n",
      "Epoch number: 2994/10000step_number: 0/29 cost:  0.1645286558011308 accuracy:  0.9442931081449196\n",
      "Epoch number: 2995/10000step_number: 0/29 cost:  0.1644127828883002 accuracy:  0.9442931081449196\n",
      "Epoch number: 2996/10000step_number: 0/29 cost:  0.1643027269793118 accuracy:  0.944020702805775\n",
      "Epoch number: 2997/10000step_number: 0/29 cost:  0.16419835343674197 accuracy:  0.944020702805775\n",
      "Epoch number: 2998/10000step_number: 0/29 cost:  0.1641007616989557 accuracy:  0.944020702805775\n",
      "Epoch number: 2999/10000step_number: 0/29 cost:  0.16400966330140804 accuracy:  0.9441569054753474\n",
      "Epoch number: 3000/10000step_number: 0/29 cost:  0.16392581841424528 accuracy:  0.9441569054753474\n",
      "Epoch number: 3001/10000step_number: 0/29 cost:  0.16384861925530134 accuracy:  0.9442931081449196\n",
      "Epoch number: 3002/10000step_number: 0/29 cost:  0.16377838603599135 accuracy:  0.9442931081449196\n",
      "Epoch number: 3003/10000step_number: 0/29 cost:  0.16371422871863867 accuracy:  0.9442931081449196\n",
      "Epoch number: 3004/10000step_number: 0/29 cost:  0.1636562029779475 accuracy:  0.9442931081449196\n",
      "Epoch number: 3005/10000step_number: 0/29 cost:  0.16360329898820644 accuracy:  0.9442931081449196\n",
      "Epoch number: 3006/10000step_number: 0/29 cost:  0.1635555125678929 accuracy:  0.9442931081449196\n",
      "Epoch number: 3007/10000step_number: 0/29 cost:  0.16351173305313207 accuracy:  0.9441569054753474\n",
      "Epoch number: 3008/10000step_number: 0/29 cost:  0.16347201526163735 accuracy:  0.9442931081449196\n",
      "Epoch number: 3009/10000step_number: 0/29 cost:  0.16343501441419347 accuracy:  0.9441569054753474\n",
      "Epoch number: 3010/10000step_number: 0/29 cost:  0.16340105124197685 accuracy:  0.9441569054753474\n",
      "Epoch number: 3011/10000step_number: 0/29 cost:  0.1633683692805629 accuracy:  0.9441569054753474\n",
      "Epoch number: 3012/10000step_number: 0/29 cost:  0.163338109188761 accuracy:  0.9441569054753474\n",
      "Epoch number: 3013/10000step_number: 0/29 cost:  0.16330775878565548 accuracy:  0.9441569054753474\n",
      "Epoch number: 3014/10000step_number: 0/29 cost:  0.1632802086042939 accuracy:  0.9442931081449196\n",
      "Epoch number: 3015/10000step_number: 0/29 cost:  0.16325136468330254 accuracy:  0.9442931081449196\n",
      "Epoch number: 3016/10000step_number: 0/29 cost:  0.1632265338836118 accuracy:  0.944429310814492\n",
      "Epoch number: 3017/10000step_number: 0/29 cost:  0.16319976208279455 accuracy:  0.9445655134840643\n",
      "Epoch number: 3018/10000step_number: 0/29 cost:  0.16317735252093132 accuracy:  0.9445655134840643\n",
      "Epoch number: 3019/10000step_number: 0/29 cost:  0.16315372496808778 accuracy:  0.9445655134840643\n",
      "Epoch number: 3020/10000step_number: 0/29 cost:  0.16313311469287092 accuracy:  0.9445655134840643\n",
      "Epoch number: 3021/10000step_number: 0/29 cost:  0.16311246959709685 accuracy:  0.9447017161536366\n",
      "Epoch number: 3022/10000step_number: 0/29 cost:  0.16309324490540741 accuracy:  0.9448379188232089\n",
      "Epoch number: 3023/10000step_number: 0/29 cost:  0.16307474203425404 accuracy:  0.9448379188232089\n",
      "Epoch number: 3024/10000step_number: 0/29 cost:  0.16305668496168846 accuracy:  0.9449741214927813\n",
      "Epoch number: 3025/10000step_number: 0/29 cost:  0.16303995600309407 accuracy:  0.9448379188232089\n",
      "Epoch number: 3026/10000step_number: 0/29 cost:  0.16302322216494583 accuracy:  0.9449741214927813\n",
      "Epoch number: 3027/10000step_number: 0/29 cost:  0.16300875412493462 accuracy:  0.9449741214927813\n",
      "Epoch number: 3028/10000step_number: 0/29 cost:  0.1629941171673687 accuracy:  0.9449741214927813\n",
      "Epoch number: 3029/10000step_number: 0/29 cost:  0.16298322342426302 accuracy:  0.9447017161536366\n",
      "Epoch number: 3030/10000step_number: 0/29 cost:  0.16297066898255805 accuracy:  0.9445655134840643\n",
      "Epoch number: 3031/10000step_number: 0/29 cost:  0.16296304698231137 accuracy:  0.944429310814492\n",
      "Epoch number: 3032/10000step_number: 0/29 cost:  0.1629514083489595 accuracy:  0.9445655134840643\n",
      "Epoch number: 3033/10000step_number: 0/29 cost:  0.1629444602908169 accuracy:  0.9445655134840643\n",
      "Epoch number: 3034/10000step_number: 0/29 cost:  0.1629323870873313 accuracy:  0.9445655134840643\n",
      "Epoch number: 3035/10000step_number: 0/29 cost:  0.16292102413026407 accuracy:  0.9445655134840643\n",
      "Epoch number: 3036/10000step_number: 0/29 cost:  0.16291826551791472 accuracy:  0.9448379188232089\n",
      "Epoch number: 3037/10000step_number: 0/29 cost:  0.1628671582911661 accuracy:  0.9451103241623536\n",
      "Epoch number: 3038/10000step_number: 0/29 cost:  0.16295334414282212 accuracy:  0.9448379188232089\n",
      "Epoch number: 3039/10000step_number: 0/29 cost:  0.16282226436272113 accuracy:  0.9449741214927813\n",
      "Epoch number: 3040/10000step_number: 0/29 cost:  0.16288407814100567 accuracy:  0.9449741214927813\n",
      "Epoch number: 3041/10000step_number: 0/29 cost:  0.16281096167248182 accuracy:  0.9449741214927813\n",
      "Epoch number: 3042/10000step_number: 0/29 cost:  0.16287290753025746 accuracy:  0.9451103241623536\n",
      "Epoch number: 3043/10000step_number: 0/29 cost:  0.1626865481187612 accuracy:  0.9449741214927813\n",
      "Epoch number: 3044/10000step_number: 0/29 cost:  0.16286747981263056 accuracy:  0.9448379188232089\n",
      "Epoch number: 3045/10000step_number: 0/29 cost:  0.16267424408074016 accuracy:  0.9449741214927813\n",
      "Epoch number: 3046/10000step_number: 0/29 cost:  0.16276974691288099 accuracy:  0.9448379188232089\n",
      "Epoch number: 3047/10000step_number: 0/29 cost:  0.16261929908282513 accuracy:  0.9453827295014983\n",
      "Epoch number: 3048/10000step_number: 0/29 cost:  0.1626519046582917 accuracy:  0.9455189321710705\n",
      "Epoch number: 3049/10000step_number: 0/29 cost:  0.16251656181583582 accuracy:  0.9455189321710705\n",
      "Epoch number: 3050/10000step_number: 0/29 cost:  0.16237259361335882 accuracy:  0.9453827295014983\n",
      "Epoch number: 3051/10000step_number: 0/29 cost:  0.17267590782746883 accuracy:  0.9452465268319259\n",
      "Epoch number: 3052/10000step_number: 0/29 cost:  0.20939038456031722 accuracy:  0.9408880414056116\n",
      "Epoch number: 3053/10000step_number: 0/29 cost:  0.19298134029246916 accuracy:  0.9442931081449196\n",
      "Epoch number: 3054/10000step_number: 0/29 cost:  0.19745928879483568 accuracy:  0.9434758921274857\n",
      "Epoch number: 3055/10000step_number: 0/29 cost:  0.1655098583665165 accuracy:  0.9437482974666304\n",
      "Epoch number: 3056/10000step_number: 0/29 cost:  0.1638081941937711 accuracy:  0.9463361481885045\n",
      "Epoch number: 3057/10000step_number: 0/29 cost:  0.1595704478017498 accuracy:  0.9457913375102152\n",
      "Epoch number: 3058/10000step_number: 0/29 cost:  0.15797910221583703 accuracy:  0.9457913375102152\n",
      "Epoch number: 3059/10000step_number: 0/29 cost:  0.15741753771492778 accuracy:  0.9456551348406429\n",
      "Epoch number: 3060/10000step_number: 0/29 cost:  0.15733519971632975 accuracy:  0.9457913375102152\n",
      "Epoch number: 3061/10000step_number: 0/29 cost:  0.15716847816727034 accuracy:  0.9460637428493599\n",
      "Epoch number: 3062/10000step_number: 0/29 cost:  0.15711951161245674 accuracy:  0.9459275401797875\n",
      "Epoch number: 3063/10000step_number: 0/29 cost:  0.1571199430250625 accuracy:  0.9459275401797875\n",
      "Epoch number: 3064/10000step_number: 0/29 cost:  0.15715047736699522 accuracy:  0.9455189321710705\n",
      "Epoch number: 3065/10000step_number: 0/29 cost:  0.15719640975921242 accuracy:  0.9456551348406429\n",
      "Epoch number: 3066/10000step_number: 0/29 cost:  0.15724867190759295 accuracy:  0.9456551348406429\n",
      "Epoch number: 3067/10000step_number: 0/29 cost:  0.15730321154843108 accuracy:  0.9456551348406429\n",
      "Epoch number: 3068/10000step_number: 0/29 cost:  0.15735605915993114 accuracy:  0.9457913375102152\n",
      "Epoch number: 3069/10000step_number: 0/29 cost:  0.15740497254577465 accuracy:  0.9457913375102152\n",
      "Epoch number: 3070/10000step_number: 0/29 cost:  0.15744876320932294 accuracy:  0.9457913375102152\n",
      "Epoch number: 3071/10000step_number: 0/29 cost:  0.15748707561150227 accuracy:  0.9455189321710705\n",
      "Epoch number: 3072/10000step_number: 0/29 cost:  0.15752006279683228 accuracy:  0.9455189321710705\n",
      "Epoch number: 3073/10000step_number: 0/29 cost:  0.15754804043151388 accuracy:  0.9453827295014983\n",
      "Epoch number: 3074/10000step_number: 0/29 cost:  0.15757130009919126 accuracy:  0.9455189321710705\n",
      "Epoch number: 3075/10000step_number: 0/29 cost:  0.15758991140745274 accuracy:  0.9455189321710705\n",
      "Epoch number: 3076/10000step_number: 0/29 cost:  0.15760359120030795 accuracy:  0.9453827295014983\n",
      "Epoch number: 3077/10000step_number: 0/29 cost:  0.1576126827214507 accuracy:  0.9453827295014983\n",
      "Epoch number: 3078/10000step_number: 0/29 cost:  0.1576230586907743 accuracy:  0.9455189321710705\n",
      "Epoch number: 3079/10000step_number: 0/29 cost:  0.1576459048053655 accuracy:  0.9455189321710705\n",
      "Epoch number: 3080/10000step_number: 0/29 cost:  0.15768076326466268 accuracy:  0.9455189321710705\n",
      "Epoch number: 3081/10000step_number: 0/29 cost:  0.15772358827594787 accuracy:  0.9455189321710705\n",
      "Epoch number: 3082/10000step_number: 0/29 cost:  0.1577687760100013 accuracy:  0.9455189321710705\n",
      "Epoch number: 3083/10000step_number: 0/29 cost:  0.15781053728547365 accuracy:  0.9455189321710705\n",
      "Epoch number: 3084/10000step_number: 0/29 cost:  0.15784912379095112 accuracy:  0.9456551348406429\n",
      "Epoch number: 3085/10000step_number: 0/29 cost:  0.15788367136639472 accuracy:  0.9456551348406429\n",
      "Epoch number: 3086/10000step_number: 0/29 cost:  0.1579149654310298 accuracy:  0.9455189321710705\n",
      "Epoch number: 3087/10000step_number: 0/29 cost:  0.15794360321165538 accuracy:  0.9455189321710705\n",
      "Epoch number: 3088/10000step_number: 0/29 cost:  0.1579701876737088 accuracy:  0.9455189321710705\n",
      "Epoch number: 3089/10000step_number: 0/29 cost:  0.15799518935418277 accuracy:  0.9456551348406429\n",
      "Epoch number: 3090/10000step_number: 0/29 cost:  0.15801891288917363 accuracy:  0.9456551348406429\n",
      "Epoch number: 3091/10000step_number: 0/29 cost:  0.15804151760505333 accuracy:  0.9456551348406429\n",
      "Epoch number: 3092/10000step_number: 0/29 cost:  0.15806311657349573 accuracy:  0.9457913375102152\n",
      "Epoch number: 3093/10000step_number: 0/29 cost:  0.15808386047683126 accuracy:  0.9457913375102152\n",
      "Epoch number: 3094/10000step_number: 0/29 cost:  0.15810393441504061 accuracy:  0.9457913375102152\n",
      "Epoch number: 3095/10000step_number: 0/29 cost:  0.15812350990941304 accuracy:  0.9457913375102152\n",
      "Epoch number: 3096/10000step_number: 0/29 cost:  0.15814270207143707 accuracy:  0.9452465268319259\n",
      "Epoch number: 3097/10000step_number: 0/29 cost:  0.15816155374652785 accuracy:  0.9453827295014983\n",
      "Epoch number: 3098/10000step_number: 0/29 cost:  0.15818003939004366 accuracy:  0.9456551348406429\n",
      "Epoch number: 3099/10000step_number: 0/29 cost:  0.15819807731411492 accuracy:  0.9456551348406429\n",
      "Epoch number: 3100/10000step_number: 0/29 cost:  0.15821554348540973 accuracy:  0.9456551348406429\n",
      "Epoch number: 3101/10000step_number: 0/29 cost:  0.15823228631028974 accuracy:  0.9457913375102152\n",
      "Epoch number: 3102/10000step_number: 0/29 cost:  0.15824814437867996 accuracy:  0.9457913375102152\n",
      "Epoch number: 3103/10000step_number: 0/29 cost:  0.1582629646213644 accuracy:  0.9460637428493599\n",
      "Epoch number: 3104/10000step_number: 0/29 cost:  0.15827661275405017 accuracy:  0.9460637428493599\n",
      "Epoch number: 3105/10000step_number: 0/29 cost:  0.15828896982123378 accuracy:  0.9461999455189322\n",
      "Epoch number: 3106/10000step_number: 0/29 cost:  0.15829991588422376 accuracy:  0.9461999455189322\n",
      "Epoch number: 3107/10000step_number: 0/29 cost:  0.1583093054019726 accuracy:  0.9461999455189322\n",
      "Epoch number: 3108/10000step_number: 0/29 cost:  0.15831693893472568 accuracy:  0.9463361481885045\n",
      "Epoch number: 3109/10000step_number: 0/29 cost:  0.15832254395130452 accuracy:  0.9463361481885045\n",
      "Epoch number: 3110/10000step_number: 0/29 cost:  0.15832579979348316 accuracy:  0.9463361481885045\n",
      "Epoch number: 3111/10000step_number: 0/29 cost:  0.15832644118228542 accuracy:  0.9463361481885045\n",
      "Epoch number: 3112/10000step_number: 0/29 cost:  0.15832437222256981 accuracy:  0.9464723508580768\n",
      "Epoch number: 3113/10000step_number: 0/29 cost:  0.1583196476144239 accuracy:  0.9464723508580768\n",
      "Epoch number: 3114/10000step_number: 0/29 cost:  0.15831237382238675 accuracy:  0.9464723508580768\n",
      "Epoch number: 3115/10000step_number: 0/29 cost:  0.1583026708653714 accuracy:  0.9464723508580768\n",
      "Epoch number: 3116/10000step_number: 0/29 cost:  0.15829066466299277 accuracy:  0.9463361481885045\n",
      "Epoch number: 3117/10000step_number: 0/29 cost:  0.15827646679568141 accuracy:  0.9463361481885045\n",
      "Epoch number: 3118/10000step_number: 0/29 cost:  0.15826016219838432 accuracy:  0.9463361481885045\n",
      "Epoch number: 3119/10000step_number: 0/29 cost:  0.15824181869400689 accuracy:  0.9463361481885045\n",
      "Epoch number: 3120/10000step_number: 0/29 cost:  0.15822151113205393 accuracy:  0.9463361481885045\n",
      "Epoch number: 3121/10000step_number: 0/29 cost:  0.15819935294610404 accuracy:  0.9461999455189322\n",
      "Epoch number: 3122/10000step_number: 0/29 cost:  0.15817552099241253 accuracy:  0.9461999455189322\n",
      "Epoch number: 3123/10000step_number: 0/29 cost:  0.15815024934472724 accuracy:  0.9460637428493599\n",
      "Epoch number: 3124/10000step_number: 0/29 cost:  0.1581238556363598 accuracy:  0.9460637428493599\n",
      "Epoch number: 3125/10000step_number: 0/29 cost:  0.15809677154441654 accuracy:  0.9459275401797875\n",
      "Epoch number: 3126/10000step_number: 0/29 cost:  0.15806943964077244 accuracy:  0.9457913375102152\n",
      "Epoch number: 3127/10000step_number: 0/29 cost:  0.15804224995449068 accuracy:  0.9459275401797875\n",
      "Epoch number: 3128/10000step_number: 0/29 cost:  0.15801563896203055 accuracy:  0.9457913375102152\n",
      "Epoch number: 3129/10000step_number: 0/29 cost:  0.15799024295404196 accuracy:  0.9457913375102152\n",
      "Epoch number: 3130/10000step_number: 0/29 cost:  0.1579669734618007 accuracy:  0.9457913375102152\n",
      "Epoch number: 3131/10000step_number: 0/29 cost:  0.15794683756530323 accuracy:  0.9461999455189322\n",
      "Epoch number: 3132/10000step_number: 0/29 cost:  0.15793043506720197 accuracy:  0.9461999455189322\n",
      "Epoch number: 3133/10000step_number: 0/29 cost:  0.15791745031156137 accuracy:  0.9461999455189322\n",
      "Epoch number: 3134/10000step_number: 0/29 cost:  0.15790666549851728 accuracy:  0.9461999455189322\n",
      "Epoch number: 3135/10000step_number: 0/29 cost:  0.15789655212845713 accuracy:  0.9461999455189322\n",
      "Epoch number: 3136/10000step_number: 0/29 cost:  0.1578858789587568 accuracy:  0.9461999455189322\n",
      "Epoch number: 3137/10000step_number: 0/29 cost:  0.1578738916527011 accuracy:  0.9461999455189322\n",
      "Epoch number: 3138/10000step_number: 0/29 cost:  0.15786017784458994 accuracy:  0.9460637428493599\n",
      "Epoch number: 3139/10000step_number: 0/29 cost:  0.15784450561469945 accuracy:  0.9460637428493599\n",
      "Epoch number: 3140/10000step_number: 0/29 cost:  0.15782673707709688 accuracy:  0.9460637428493599\n",
      "Epoch number: 3141/10000step_number: 0/29 cost:  0.15780679155496236 accuracy:  0.9460637428493599\n",
      "Epoch number: 3142/10000step_number: 0/29 cost:  0.15778462880284116 accuracy:  0.9459275401797875\n",
      "Epoch number: 3143/10000step_number: 0/29 cost:  0.15776024025418411 accuracy:  0.9459275401797875\n",
      "Epoch number: 3144/10000step_number: 0/29 cost:  0.1577336435183663 accuracy:  0.9459275401797875\n",
      "Epoch number: 3145/10000step_number: 0/29 cost:  0.15770487830190807 accuracy:  0.9459275401797875\n",
      "Epoch number: 3146/10000step_number: 0/29 cost:  0.1576740032598857 accuracy:  0.9459275401797875\n",
      "Epoch number: 3147/10000step_number: 0/29 cost:  0.15764109345027952 accuracy:  0.9460637428493599\n",
      "Epoch number: 3148/10000step_number: 0/29 cost:  0.15760623794803047 accuracy:  0.9460637428493599\n",
      "Epoch number: 3149/10000step_number: 0/29 cost:  0.1575695372886803 accuracy:  0.9460637428493599\n",
      "Epoch number: 3150/10000step_number: 0/29 cost:  0.15753110069074128 accuracy:  0.9459275401797875\n",
      "Epoch number: 3151/10000step_number: 0/29 cost:  0.15749104324328114 accuracy:  0.9457913375102152\n",
      "Epoch number: 3152/10000step_number: 0/29 cost:  0.15744948333805786 accuracy:  0.9457913375102152\n",
      "Epoch number: 3153/10000step_number: 0/29 cost:  0.1574065405801438 accuracy:  0.9457913375102152\n",
      "Epoch number: 3154/10000step_number: 0/29 cost:  0.15736233428698843 accuracy:  0.9457913375102152\n",
      "Epoch number: 3155/10000step_number: 0/29 cost:  0.15731698254998736 accuracy:  0.9456551348406429\n",
      "Epoch number: 3156/10000step_number: 0/29 cost:  0.1572706017318767 accuracy:  0.9456551348406429\n",
      "Epoch number: 3157/10000step_number: 0/29 cost:  0.15722330622718103 accuracy:  0.9456551348406429\n",
      "Epoch number: 3158/10000step_number: 0/29 cost:  0.15717520831940274 accuracy:  0.9456551348406429\n",
      "Epoch number: 3159/10000step_number: 0/29 cost:  0.1571264180138004 accuracy:  0.9456551348406429\n",
      "Epoch number: 3160/10000step_number: 0/29 cost:  0.15707704279050172 accuracy:  0.9456551348406429\n",
      "Epoch number: 3161/10000step_number: 0/29 cost:  0.1570271872917822 accuracy:  0.9456551348406429\n",
      "Epoch number: 3162/10000step_number: 0/29 cost:  0.1569769530140021 accuracy:  0.9457913375102152\n",
      "Epoch number: 3163/10000step_number: 0/29 cost:  0.15692643810702334 accuracy:  0.9457913375102152\n",
      "Epoch number: 3164/10000step_number: 0/29 cost:  0.15687573738555552 accuracy:  0.9457913375102152\n",
      "Epoch number: 3165/10000step_number: 0/29 cost:  0.15682494262908223 accuracy:  0.9457913375102152\n",
      "Epoch number: 3166/10000step_number: 0/29 cost:  0.1567741432000214 accuracy:  0.9457913375102152\n",
      "Epoch number: 3167/10000step_number: 0/29 cost:  0.15672342696224129 accuracy:  0.9459275401797875\n",
      "Epoch number: 3168/10000step_number: 0/29 cost:  0.15667288145910363 accuracy:  0.9459275401797875\n",
      "Epoch number: 3169/10000step_number: 0/29 cost:  0.15662259534129291 accuracy:  0.9459275401797875\n",
      "Epoch number: 3170/10000step_number: 0/29 cost:  0.15657266015342827 accuracy:  0.9459275401797875\n",
      "Epoch number: 3171/10000step_number: 0/29 cost:  0.15652317283821696 accuracy:  0.9459275401797875\n",
      "Epoch number: 3172/10000step_number: 0/29 cost:  0.1564742397649849 accuracy:  0.9460637428493599\n",
      "Epoch number: 3173/10000step_number: 0/29 cost:  0.15642598385686113 accuracy:  0.9461999455189322\n",
      "Epoch number: 3174/10000step_number: 0/29 cost:  0.15637855770237122 accuracy:  0.9461999455189322\n",
      "Epoch number: 3175/10000step_number: 0/29 cost:  0.15633216777722836 accuracy:  0.9461999455189322\n",
      "Epoch number: 3176/10000step_number: 0/29 cost:  0.15628711852692784 accuracy:  0.9461999455189322\n",
      "Epoch number: 3177/10000step_number: 0/29 cost:  0.15624388952048748 accuracy:  0.9463361481885045\n",
      "Epoch number: 3178/10000step_number: 0/29 cost:  0.15620325639637864 accuracy:  0.9463361481885045\n",
      "Epoch number: 3179/10000step_number: 0/29 cost:  0.1561664119483138 accuracy:  0.9466085535276492\n",
      "Epoch number: 3180/10000step_number: 0/29 cost:  0.15613473614716025 accuracy:  0.9466085535276492\n",
      "Epoch number: 3181/10000step_number: 0/29 cost:  0.15610770337550897 accuracy:  0.9466085535276492\n",
      "Epoch number: 3182/10000step_number: 0/29 cost:  0.15607594583080447 accuracy:  0.9468809588667938\n",
      "Epoch number: 3183/10000step_number: 0/29 cost:  0.15601719726355254 accuracy:  0.9470171615363661\n",
      "Epoch number: 3184/10000step_number: 0/29 cost:  0.15592332519546562 accuracy:  0.9470171615363661\n",
      "Epoch number: 3185/10000step_number: 0/29 cost:  0.15582005475980223 accuracy:  0.9470171615363661\n",
      "Epoch number: 3186/10000step_number: 0/29 cost:  0.15573192538241193 accuracy:  0.9472895668755108\n",
      "Epoch number: 3187/10000step_number: 0/29 cost:  0.1556632435866692 accuracy:  0.9472895668755108\n",
      "Epoch number: 3188/10000step_number: 0/29 cost:  0.15560945725806336 accuracy:  0.9472895668755108\n",
      "Epoch number: 3189/10000step_number: 0/29 cost:  0.1555606149029353 accuracy:  0.9470171615363661\n",
      "Epoch number: 3190/10000step_number: 0/29 cost:  0.15550800091812134 accuracy:  0.9470171615363661\n",
      "Epoch number: 3191/10000step_number: 0/29 cost:  0.15545494130300447 accuracy:  0.9470171615363661\n",
      "Epoch number: 3192/10000step_number: 0/29 cost:  0.15540450897872773 accuracy:  0.9470171615363661\n",
      "Epoch number: 3193/10000step_number: 0/29 cost:  0.15535677114716567 accuracy:  0.9470171615363661\n",
      "Epoch number: 3194/10000step_number: 0/29 cost:  0.1553110336049101 accuracy:  0.9470171615363661\n",
      "Epoch number: 3195/10000step_number: 0/29 cost:  0.15526616111252642 accuracy:  0.9468809588667938\n",
      "Epoch number: 3196/10000step_number: 0/29 cost:  0.1552218324622048 accuracy:  0.9468809588667938\n",
      "Epoch number: 3197/10000step_number: 0/29 cost:  0.15517803228481325 accuracy:  0.9470171615363661\n",
      "Epoch number: 3198/10000step_number: 0/29 cost:  0.15513487464690792 accuracy:  0.9470171615363661\n",
      "Epoch number: 3199/10000step_number: 0/29 cost:  0.15509229153616996 accuracy:  0.9470171615363661\n",
      "Epoch number: 3200/10000step_number: 0/29 cost:  0.15505016048844236 accuracy:  0.9470171615363661\n",
      "Epoch number: 3201/10000step_number: 0/29 cost:  0.15500837368066006 accuracy:  0.9470171615363661\n",
      "Epoch number: 3202/10000step_number: 0/29 cost:  0.15496690018658393 accuracy:  0.9468809588667938\n",
      "Epoch number: 3203/10000step_number: 0/29 cost:  0.15492573069008772 accuracy:  0.9468809588667938\n",
      "Epoch number: 3204/10000step_number: 0/29 cost:  0.15488485353595804 accuracy:  0.9468809588667938\n",
      "Epoch number: 3205/10000step_number: 0/29 cost:  0.15484423024410646 accuracy:  0.9468809588667938\n",
      "Epoch number: 3206/10000step_number: 0/29 cost:  0.154803820052746 accuracy:  0.9470171615363661\n",
      "Epoch number: 3207/10000step_number: 0/29 cost:  0.15476358596626075 accuracy:  0.9470171615363661\n",
      "Epoch number: 3208/10000step_number: 0/29 cost:  0.15472350536518553 accuracy:  0.9470171615363661\n",
      "Epoch number: 3209/10000step_number: 0/29 cost:  0.154683555286695 accuracy:  0.9471533642059384\n",
      "Epoch number: 3210/10000step_number: 0/29 cost:  0.154643710442681 accuracy:  0.9471533642059384\n",
      "Epoch number: 3211/10000step_number: 0/29 cost:  0.15460393627494806 accuracy:  0.9472895668755108\n",
      "Epoch number: 3212/10000step_number: 0/29 cost:  0.15456419834210386 accuracy:  0.9472895668755108\n",
      "Epoch number: 3213/10000step_number: 0/29 cost:  0.1545244625356009 accuracy:  0.9474257695450831\n",
      "Epoch number: 3214/10000step_number: 0/29 cost:  0.15448470092606356 accuracy:  0.9475619722146554\n",
      "Epoch number: 3215/10000step_number: 0/29 cost:  0.1544448853565471 accuracy:  0.9475619722146554\n",
      "Epoch number: 3216/10000step_number: 0/29 cost:  0.1544049888916485 accuracy:  0.9475619722146554\n",
      "Epoch number: 3217/10000step_number: 0/29 cost:  0.15436498095400333 accuracy:  0.9475619722146554\n",
      "Epoch number: 3218/10000step_number: 0/29 cost:  0.1543248334296072 accuracy:  0.9475619722146554\n",
      "Epoch number: 3219/10000step_number: 0/29 cost:  0.15428451898187479 accuracy:  0.9474257695450831\n",
      "Epoch number: 3220/10000step_number: 0/29 cost:  0.15424401717359426 accuracy:  0.9474257695450831\n",
      "Epoch number: 3221/10000step_number: 0/29 cost:  0.1542033091576816 accuracy:  0.9474257695450831\n",
      "Epoch number: 3222/10000step_number: 0/29 cost:  0.15416238160535142 accuracy:  0.9472895668755108\n",
      "Epoch number: 3223/10000step_number: 0/29 cost:  0.15412121994556446 accuracy:  0.9472895668755108\n",
      "Epoch number: 3224/10000step_number: 0/29 cost:  0.1540798155572757 accuracy:  0.9472895668755108\n",
      "Epoch number: 3225/10000step_number: 0/29 cost:  0.15403815981227142 accuracy:  0.9471533642059384\n",
      "Epoch number: 3226/10000step_number: 0/29 cost:  0.15399625433816966 accuracy:  0.9471533642059384\n",
      "Epoch number: 3227/10000step_number: 0/29 cost:  0.15395410081149702 accuracy:  0.9471533642059384\n",
      "Epoch number: 3228/10000step_number: 0/29 cost:  0.15391171248048421 accuracy:  0.9472895668755108\n",
      "Epoch number: 3229/10000step_number: 0/29 cost:  0.15386909721915504 accuracy:  0.9472895668755108\n",
      "Epoch number: 3230/10000step_number: 0/29 cost:  0.1538262759309623 accuracy:  0.9472895668755108\n",
      "Epoch number: 3231/10000step_number: 0/29 cost:  0.1537832582238038 accuracy:  0.9472895668755108\n",
      "Epoch number: 3232/10000step_number: 0/29 cost:  0.15374007489491182 accuracy:  0.9472895668755108\n",
      "Epoch number: 3233/10000step_number: 0/29 cost:  0.15369673639555578 accuracy:  0.9472895668755108\n",
      "Epoch number: 3234/10000step_number: 0/29 cost:  0.15365328788683433 accuracy:  0.9472895668755108\n",
      "Epoch number: 3235/10000step_number: 0/29 cost:  0.15360973041458348 accuracy:  0.9472895668755108\n",
      "Epoch number: 3236/10000step_number: 0/29 cost:  0.15356612479173282 accuracy:  0.9472895668755108\n",
      "Epoch number: 3237/10000step_number: 0/29 cost:  0.15352243910057473 accuracy:  0.9472895668755108\n",
      "Epoch number: 3238/10000step_number: 0/29 cost:  0.15347876524322968 accuracy:  0.9472895668755108\n",
      "Epoch number: 3239/10000step_number: 0/29 cost:  0.15343500096328672 accuracy:  0.9472895668755108\n",
      "Epoch number: 3240/10000step_number: 0/29 cost:  0.15339132531192576 accuracy:  0.9471533642059384\n",
      "Epoch number: 3241/10000step_number: 0/29 cost:  0.15334747624256806 accuracy:  0.9471533642059384\n",
      "Epoch number: 3242/10000step_number: 0/29 cost:  0.15330386529360157 accuracy:  0.9471533642059384\n",
      "Epoch number: 3243/10000step_number: 0/29 cost:  0.15325982074172517 accuracy:  0.9471533642059384\n",
      "Epoch number: 3244/10000step_number: 0/29 cost:  0.1532163985860967 accuracy:  0.9471533642059384\n",
      "Epoch number: 3245/10000step_number: 0/29 cost:  0.15317180627120452 accuracy:  0.9471533642059384\n",
      "Epoch number: 3246/10000step_number: 0/29 cost:  0.15312899437278044 accuracy:  0.9471533642059384\n",
      "Epoch number: 3247/10000step_number: 0/29 cost:  0.15308286192519574 accuracy:  0.9471533642059384\n",
      "Epoch number: 3248/10000step_number: 0/29 cost:  0.1530422189803801 accuracy:  0.9471533642059384\n",
      "Epoch number: 3249/10000step_number: 0/29 cost:  0.15299144203391327 accuracy:  0.9471533642059384\n",
      "Epoch number: 3250/10000step_number: 0/29 cost:  0.15295858384692224 accuracy:  0.9471533642059384\n",
      "Epoch number: 3251/10000step_number: 0/29 cost:  0.152892432531529 accuracy:  0.9471533642059384\n",
      "Epoch number: 3252/10000step_number: 0/29 cost:  0.15288743091113002 accuracy:  0.9471533642059384\n",
      "Epoch number: 3253/10000step_number: 0/29 cost:  0.15277179481391137 accuracy:  0.9471533642059384\n",
      "Epoch number: 3254/10000step_number: 0/29 cost:  0.15284158165671927 accuracy:  0.9472895668755108\n",
      "Epoch number: 3255/10000step_number: 0/29 cost:  0.15269381461139228 accuracy:  0.9471533642059384\n",
      "Epoch number: 3256/10000step_number: 0/29 cost:  0.15270440837907784 accuracy:  0.9472895668755108\n",
      "Epoch number: 3257/10000step_number: 0/29 cost:  0.1525843235857027 accuracy:  0.9472895668755108\n",
      "Epoch number: 3258/10000step_number: 0/29 cost:  0.15267550179780717 accuracy:  0.9472895668755108\n",
      "Epoch number: 3259/10000step_number: 0/29 cost:  0.15255191214728822 accuracy:  0.9474257695450831\n",
      "Epoch number: 3260/10000step_number: 0/29 cost:  0.1524441688088045 accuracy:  0.9474257695450831\n",
      "Epoch number: 3261/10000step_number: 0/29 cost:  0.15249130035782432 accuracy:  0.9475619722146554\n",
      "Epoch number: 3262/10000step_number: 0/29 cost:  0.15232576259641137 accuracy:  0.9474257695450831\n",
      "Epoch number: 3263/10000step_number: 0/29 cost:  0.15246046053370382 accuracy:  0.9475619722146554\n",
      "Epoch number: 3264/10000step_number: 0/29 cost:  0.1523700959691181 accuracy:  0.9474257695450831\n",
      "Epoch number: 3265/10000step_number: 0/29 cost:  0.1522226330532842 accuracy:  0.9476981748842277\n",
      "Epoch number: 3266/10000step_number: 0/29 cost:  0.15215421853202776 accuracy:  0.9476981748842277\n",
      "Epoch number: 3267/10000step_number: 0/29 cost:  0.15221067123953674 accuracy:  0.9476981748842277\n",
      "Epoch number: 3268/10000step_number: 0/29 cost:  0.1521051994563669 accuracy:  0.9475619722146554\n",
      "Epoch number: 3269/10000step_number: 0/29 cost:  0.15215556805633712 accuracy:  0.9476981748842277\n",
      "Epoch number: 3270/10000step_number: 0/29 cost:  0.15196806096327578 accuracy:  0.9476981748842277\n",
      "Epoch number: 3271/10000step_number: 0/29 cost:  0.1519224660296818 accuracy:  0.9476981748842277\n",
      "Epoch number: 3272/10000step_number: 0/29 cost:  0.15181464607491296 accuracy:  0.9474257695450831\n",
      "Epoch number: 3273/10000step_number: 0/29 cost:  0.1520013610547738 accuracy:  0.9478343775538001\n",
      "Epoch number: 3274/10000step_number: 0/29 cost:  0.15198157328228334 accuracy:  0.9475619722146554\n",
      "Epoch number: 3275/10000step_number: 0/29 cost:  0.1518120474047259 accuracy:  0.9472895668755108\n",
      "Epoch number: 3276/10000step_number: 0/29 cost:  0.15159041897487374 accuracy:  0.9472895668755108\n",
      "Epoch number: 3277/10000step_number: 0/29 cost:  0.15173042926281743 accuracy:  0.9475619722146554\n",
      "Epoch number: 3278/10000step_number: 0/29 cost:  0.151704328700517 accuracy:  0.9476981748842277\n",
      "Epoch number: 3279/10000step_number: 0/29 cost:  0.15157213841382897 accuracy:  0.9476981748842277\n",
      "Epoch number: 3280/10000step_number: 0/29 cost:  0.1513861125165413 accuracy:  0.9474257695450831\n",
      "Epoch number: 3281/10000step_number: 0/29 cost:  0.1515967628074942 accuracy:  0.9474257695450831\n",
      "Epoch number: 3282/10000step_number: 0/29 cost:  0.15158159412051236 accuracy:  0.9474257695450831\n",
      "Epoch number: 3283/10000step_number: 0/29 cost:  0.15144010919882905 accuracy:  0.9472895668755108\n",
      "Epoch number: 3284/10000step_number: 0/29 cost:  0.15129854801212037 accuracy:  0.9474257695450831\n",
      "Epoch number: 3285/10000step_number: 0/29 cost:  0.1512544751448152 accuracy:  0.9475619722146554\n",
      "Epoch number: 3286/10000step_number: 0/29 cost:  0.151286344734425 accuracy:  0.9474257695450831\n",
      "Epoch number: 3287/10000step_number: 0/29 cost:  0.15129304797156895 accuracy:  0.9475619722146554\n",
      "Epoch number: 3288/10000step_number: 0/29 cost:  0.15120808277933612 accuracy:  0.9476981748842277\n",
      "Epoch number: 3289/10000step_number: 0/29 cost:  0.1511348499459977 accuracy:  0.9474257695450831\n",
      "Epoch number: 3290/10000step_number: 0/29 cost:  0.15111430759143332 accuracy:  0.9474257695450831\n",
      "Epoch number: 3291/10000step_number: 0/29 cost:  0.1510847505073923 accuracy:  0.9475619722146554\n",
      "Epoch number: 3292/10000step_number: 0/29 cost:  0.15102667567668757 accuracy:  0.9475619722146554\n",
      "Epoch number: 3293/10000step_number: 0/29 cost:  0.15098503009624398 accuracy:  0.9475619722146554\n",
      "Epoch number: 3294/10000step_number: 0/29 cost:  0.15096893133251021 accuracy:  0.9475619722146554\n",
      "Epoch number: 3295/10000step_number: 0/29 cost:  0.15090954636318582 accuracy:  0.9475619722146554\n",
      "Epoch number: 3296/10000step_number: 0/29 cost:  0.15080541979410936 accuracy:  0.9475619722146554\n",
      "Epoch number: 3297/10000step_number: 0/29 cost:  0.15072172632200978 accuracy:  0.9475619722146554\n",
      "Epoch number: 3298/10000step_number: 0/29 cost:  0.1506902413244465 accuracy:  0.9479705802233723\n",
      "Epoch number: 3299/10000step_number: 0/29 cost:  0.15067467407127605 accuracy:  0.9479705802233723\n",
      "Epoch number: 3300/10000step_number: 0/29 cost:  0.15063382784292734 accuracy:  0.9479705802233723\n",
      "Epoch number: 3301/10000step_number: 0/29 cost:  0.1505629296499488 accuracy:  0.9479705802233723\n",
      "Epoch number: 3302/10000step_number: 0/29 cost:  0.15048354834474195 accuracy:  0.9479705802233723\n",
      "Epoch number: 3303/10000step_number: 0/29 cost:  0.15041413091272762 accuracy:  0.9479705802233723\n",
      "Epoch number: 3304/10000step_number: 0/29 cost:  0.15035698979932352 accuracy:  0.9481067828929447\n",
      "Epoch number: 3305/10000step_number: 0/29 cost:  0.15030132465266718 accuracy:  0.9479705802233723\n",
      "Epoch number: 3306/10000step_number: 0/29 cost:  0.1502429826341806 accuracy:  0.9479705802233723\n",
      "Epoch number: 3307/10000step_number: 0/29 cost:  0.15018992738281445 accuracy:  0.9478343775538001\n",
      "Epoch number: 3308/10000step_number: 0/29 cost:  0.1501414107006926 accuracy:  0.9478343775538001\n",
      "Epoch number: 3309/10000step_number: 0/29 cost:  0.15008069950759317 accuracy:  0.9479705802233723\n",
      "Epoch number: 3310/10000step_number: 0/29 cost:  0.15000213705969492 accuracy:  0.9479705802233723\n",
      "Epoch number: 3311/10000step_number: 0/29 cost:  0.14992617797910374 accuracy:  0.9481067828929447\n",
      "Epoch number: 3312/10000step_number: 0/29 cost:  0.14987192051053344 accuracy:  0.9481067828929447\n",
      "Epoch number: 3313/10000step_number: 0/29 cost:  0.14983067857272733 accuracy:  0.9481067828929447\n",
      "Epoch number: 3314/10000step_number: 0/29 cost:  0.1497805475178458 accuracy:  0.9479705802233723\n",
      "Epoch number: 3315/10000step_number: 0/29 cost:  0.14971476150119878 accuracy:  0.9479705802233723\n",
      "Epoch number: 3316/10000step_number: 0/29 cost:  0.14964634702596735 accuracy:  0.9479705802233723\n",
      "Epoch number: 3317/10000step_number: 0/29 cost:  0.14958597483723804 accuracy:  0.9479705802233723\n",
      "Epoch number: 3318/10000step_number: 0/29 cost:  0.1495296352068926 accuracy:  0.9481067828929447\n",
      "Epoch number: 3319/10000step_number: 0/29 cost:  0.1494690000097243 accuracy:  0.9481067828929447\n",
      "Epoch number: 3320/10000step_number: 0/29 cost:  0.1494055674530997 accuracy:  0.9481067828929447\n",
      "Epoch number: 3321/10000step_number: 0/29 cost:  0.1493489868515686 accuracy:  0.9481067828929447\n",
      "Epoch number: 3322/10000step_number: 0/29 cost:  0.149301000042655 accuracy:  0.9481067828929447\n",
      "Epoch number: 3323/10000step_number: 0/29 cost:  0.14925026421705742 accuracy:  0.9481067828929447\n",
      "Epoch number: 3324/10000step_number: 0/29 cost:  0.14918643807767434 accuracy:  0.9481067828929447\n",
      "Epoch number: 3325/10000step_number: 0/29 cost:  0.14911517670937685 accuracy:  0.9479705802233723\n",
      "Epoch number: 3326/10000step_number: 0/29 cost:  0.14905175840978366 accuracy:  0.9479705802233723\n",
      "Epoch number: 3327/10000step_number: 0/29 cost:  0.14900048881442746 accuracy:  0.9479705802233723\n",
      "Epoch number: 3328/10000step_number: 0/29 cost:  0.1489511426031223 accuracy:  0.9479705802233723\n",
      "Epoch number: 3329/10000step_number: 0/29 cost:  0.1488948993983442 accuracy:  0.9478343775538001\n",
      "Epoch number: 3330/10000step_number: 0/29 cost:  0.14883598012362187 accuracy:  0.9478343775538001\n",
      "Epoch number: 3331/10000step_number: 0/29 cost:  0.14878252674131023 accuracy:  0.9478343775538001\n",
      "Epoch number: 3332/10000step_number: 0/29 cost:  0.14873217224887644 accuracy:  0.9478343775538001\n",
      "Epoch number: 3333/10000step_number: 0/29 cost:  0.14867509582926855 accuracy:  0.9478343775538001\n",
      "Epoch number: 3334/10000step_number: 0/29 cost:  0.14860752033494157 accuracy:  0.9476981748842277\n",
      "Epoch number: 3335/10000step_number: 0/29 cost:  0.148537523791322 accuracy:  0.9476981748842277\n",
      "Epoch number: 3336/10000step_number: 0/29 cost:  0.14847621703743935 accuracy:  0.9476981748842277\n",
      "Epoch number: 3337/10000step_number: 0/29 cost:  0.14842998355622342 accuracy:  0.9478343775538001\n",
      "Epoch number: 3338/10000step_number: 0/29 cost:  0.14839983250509226 accuracy:  0.9478343775538001\n",
      "Epoch number: 3339/10000step_number: 0/29 cost:  0.14837524844359873 accuracy:  0.9478343775538001\n",
      "Epoch number: 3340/10000step_number: 0/29 cost:  0.14833496345752623 accuracy:  0.9476981748842277\n",
      "Epoch number: 3341/10000step_number: 0/29 cost:  0.14826790262669004 accuracy:  0.9476981748842277\n",
      "Epoch number: 3342/10000step_number: 0/29 cost:  0.1481975738439228 accuracy:  0.9476981748842277\n",
      "Epoch number: 3343/10000step_number: 0/29 cost:  0.1481971438634026 accuracy:  0.9479705802233723\n",
      "Epoch number: 3344/10000step_number: 0/29 cost:  0.21593100192681677 accuracy:  0.9429310814491964\n",
      "Epoch number: 3345/10000step_number: 0/29 cost:  0.164393439974713 accuracy:  0.9481067828929447\n",
      "Epoch number: 3346/10000step_number: 0/29 cost:  0.15634577179426842 accuracy:  0.9493326069190956\n",
      "Epoch number: 3347/10000step_number: 0/29 cost:  0.147158849454142 accuracy:  0.9478343775538001\n",
      "Epoch number: 3348/10000step_number: 0/29 cost:  0.14811033919485872 accuracy:  0.9487877962408063\n",
      "Epoch number: 3349/10000step_number: 0/29 cost:  0.1435116952129384 accuracy:  0.9505584309452465\n",
      "Epoch number: 3350/10000step_number: 0/29 cost:  0.14765397794908364 accuracy:  0.9482429855625171\n",
      "Epoch number: 3351/10000step_number: 0/29 cost:  0.14558317729553172 accuracy:  0.9487877962408063\n",
      "Epoch number: 3352/10000step_number: 0/29 cost:  0.1461866214204336 accuracy:  0.9491964042495233\n",
      "Epoch number: 3353/10000step_number: 0/29 cost:  0.14418025759713532 accuracy:  0.9487877962408063\n",
      "Epoch number: 3354/10000step_number: 0/29 cost:  0.14426202741818386 accuracy:  0.9491964042495233\n",
      "Epoch number: 3355/10000step_number: 0/29 cost:  0.14352711096897758 accuracy:  0.9487877962408063\n",
      "Epoch number: 3356/10000step_number: 0/29 cost:  0.1431785275770909 accuracy:  0.9483791882320893\n",
      "Epoch number: 3357/10000step_number: 0/29 cost:  0.1429192698891039 accuracy:  0.9482429855625171\n",
      "Epoch number: 3358/10000step_number: 0/29 cost:  0.14262771812892033 accuracy:  0.9485153909016617\n",
      "Epoch number: 3359/10000step_number: 0/29 cost:  0.14247141354324208 accuracy:  0.948651593571234\n",
      "Epoch number: 3360/10000step_number: 0/29 cost:  0.1423122890470069 accuracy:  0.9485153909016617\n",
      "Epoch number: 3361/10000step_number: 0/29 cost:  0.14219797027723485 accuracy:  0.9482429855625171\n",
      "Epoch number: 3362/10000step_number: 0/29 cost:  0.14211567938877018 accuracy:  0.9482429855625171\n",
      "Epoch number: 3363/10000step_number: 0/29 cost:  0.1420549101299957 accuracy:  0.9482429855625171\n",
      "Epoch number: 3364/10000step_number: 0/29 cost:  0.1420232961877464 accuracy:  0.9481067828929447\n",
      "Epoch number: 3365/10000step_number: 0/29 cost:  0.14201060622949235 accuracy:  0.9485153909016617\n",
      "Epoch number: 3366/10000step_number: 0/29 cost:  0.14201622403532024 accuracy:  0.9489239989103786\n",
      "Epoch number: 3367/10000step_number: 0/29 cost:  0.14203737437975603 accuracy:  0.9487877962408063\n",
      "Epoch number: 3368/10000step_number: 0/29 cost:  0.14207239079178988 accuracy:  0.949060201579951\n",
      "Epoch number: 3369/10000step_number: 0/29 cost:  0.14212056783320803 accuracy:  0.949060201579951\n",
      "Epoch number: 3370/10000step_number: 0/29 cost:  0.14218047207896564 accuracy:  0.949060201579951\n",
      "Epoch number: 3371/10000step_number: 0/29 cost:  0.14224881875875162 accuracy:  0.9491964042495233\n",
      "Epoch number: 3372/10000step_number: 0/29 cost:  0.14231773210459095 accuracy:  0.9491964042495233\n",
      "Epoch number: 3373/10000step_number: 0/29 cost:  0.1423774603018415 accuracy:  0.949060201579951\n",
      "Epoch number: 3374/10000step_number: 0/29 cost:  0.14242673082353688 accuracy:  0.949060201579951\n",
      "Epoch number: 3375/10000step_number: 0/29 cost:  0.14247316549209438 accuracy:  0.949060201579951\n",
      "Epoch number: 3376/10000step_number: 0/29 cost:  0.14252179649399618 accuracy:  0.9487877962408063\n",
      "Epoch number: 3377/10000step_number: 0/29 cost:  0.14257478727677952 accuracy:  0.9487877962408063\n",
      "Epoch number: 3378/10000step_number: 0/29 cost:  0.14263307449299145 accuracy:  0.9491964042495233\n",
      "Epoch number: 3379/10000step_number: 0/29 cost:  0.14269604868357347 accuracy:  0.9496050122582402\n",
      "Epoch number: 3380/10000step_number: 0/29 cost:  0.14276355183237935 accuracy:  0.949468809588668\n",
      "Epoch number: 3381/10000step_number: 0/29 cost:  0.14283556149912974 accuracy:  0.949468809588668\n",
      "Epoch number: 3382/10000step_number: 0/29 cost:  0.14291202462260558 accuracy:  0.9493326069190956\n",
      "Epoch number: 3383/10000step_number: 0/29 cost:  0.14299283367436 accuracy:  0.9493326069190956\n",
      "Epoch number: 3384/10000step_number: 0/29 cost:  0.14307774396511036 accuracy:  0.9493326069190956\n",
      "Epoch number: 3385/10000step_number: 0/29 cost:  0.14316632962533424 accuracy:  0.949060201579951\n",
      "Epoch number: 3386/10000step_number: 0/29 cost:  0.14325793146052188 accuracy:  0.949060201579951\n",
      "Epoch number: 3387/10000step_number: 0/29 cost:  0.14335162321069686 accuracy:  0.9491964042495233\n",
      "Epoch number: 3388/10000step_number: 0/29 cost:  0.1434461983135816 accuracy:  0.9487877962408063\n",
      "Epoch number: 3389/10000step_number: 0/29 cost:  0.14354018171614735 accuracy:  0.948651593571234\n",
      "Epoch number: 3390/10000step_number: 0/29 cost:  0.14363187024099278 accuracy:  0.948651593571234\n",
      "Epoch number: 3391/10000step_number: 0/29 cost:  0.1437194011965834 accuracy:  0.948651593571234\n",
      "Epoch number: 3392/10000step_number: 0/29 cost:  0.1438008446874955 accuracy:  0.9487877962408063\n",
      "Epoch number: 3393/10000step_number: 0/29 cost:  0.14387431029381 accuracy:  0.9487877962408063\n",
      "Epoch number: 3394/10000step_number: 0/29 cost:  0.14393805480967342 accuracy:  0.9487877962408063\n",
      "Epoch number: 3395/10000step_number: 0/29 cost:  0.14399057632425952 accuracy:  0.949060201579951\n",
      "Epoch number: 3396/10000step_number: 0/29 cost:  0.14403068193932778 accuracy:  0.949060201579951\n",
      "Epoch number: 3397/10000step_number: 0/29 cost:  0.14405752211592374 accuracy:  0.949060201579951\n",
      "Epoch number: 3398/10000step_number: 0/29 cost:  0.14407059263204472 accuracy:  0.9493326069190956\n",
      "Epoch number: 3399/10000step_number: 0/29 cost:  0.14406971283762976 accuracy:  0.9491964042495233\n",
      "Epoch number: 3400/10000step_number: 0/29 cost:  0.14405499318379328 accuracy:  0.9491964042495233\n",
      "Epoch number: 3401/10000step_number: 0/29 cost:  0.1440268038580162 accuracy:  0.949060201579951\n",
      "Epoch number: 3402/10000step_number: 0/29 cost:  0.143985750174633 accuracy:  0.949060201579951\n",
      "Epoch number: 3403/10000step_number: 0/29 cost:  0.14393265232155972 accuracy:  0.9489239989103786\n",
      "Epoch number: 3404/10000step_number: 0/29 cost:  0.1438685215193356 accuracy:  0.9489239989103786\n",
      "Epoch number: 3405/10000step_number: 0/29 cost:  0.1437945245940388 accuracy:  0.9489239989103786\n",
      "Epoch number: 3406/10000step_number: 0/29 cost:  0.14371193406936042 accuracy:  0.9489239989103786\n",
      "Epoch number: 3407/10000step_number: 0/29 cost:  0.1436220678700033 accuracy:  0.9489239989103786\n",
      "Epoch number: 3408/10000step_number: 0/29 cost:  0.1435262276787385 accuracy:  0.9489239989103786\n",
      "Epoch number: 3409/10000step_number: 0/29 cost:  0.14342564575974892 accuracy:  0.949060201579951\n",
      "Epoch number: 3410/10000step_number: 0/29 cost:  0.14332144707123945 accuracy:  0.9489239989103786\n",
      "Epoch number: 3411/10000step_number: 0/29 cost:  0.14321462879441996 accuracy:  0.9487877962408063\n",
      "Epoch number: 3412/10000step_number: 0/29 cost:  0.14310605515120822 accuracy:  0.9489239989103786\n",
      "Epoch number: 3413/10000step_number: 0/29 cost:  0.1429964628222549 accuracy:  0.9487877962408063\n",
      "Epoch number: 3414/10000step_number: 0/29 cost:  0.14288647163508356 accuracy:  0.9489239989103786\n",
      "Epoch number: 3415/10000step_number: 0/29 cost:  0.142776596056259 accuracy:  0.9489239989103786\n",
      "Epoch number: 3416/10000step_number: 0/29 cost:  0.14266725476684605 accuracy:  0.9489239989103786\n",
      "Epoch number: 3417/10000step_number: 0/29 cost:  0.14255877761959881 accuracy:  0.9487877962408063\n",
      "Epoch number: 3418/10000step_number: 0/29 cost:  0.14245141102848913 accuracy:  0.9487877962408063\n",
      "Epoch number: 3419/10000step_number: 0/29 cost:  0.14234532386853238 accuracy:  0.9487877962408063\n",
      "Epoch number: 3420/10000step_number: 0/29 cost:  0.14224061598309784 accuracy:  0.9489239989103786\n",
      "Epoch number: 3421/10000step_number: 0/29 cost:  0.14213733044229065 accuracy:  0.9489239989103786\n",
      "Epoch number: 3422/10000step_number: 0/29 cost:  0.14203546918463003 accuracy:  0.9489239989103786\n",
      "Epoch number: 3423/10000step_number: 0/29 cost:  0.14193501025982228 accuracy:  0.9489239989103786\n",
      "Epoch number: 3424/10000step_number: 0/29 cost:  0.1418359241577877 accuracy:  0.9489239989103786\n",
      "Epoch number: 3425/10000step_number: 0/29 cost:  0.14173818688909026 accuracy:  0.9489239989103786\n",
      "Epoch number: 3426/10000step_number: 0/29 cost:  0.14164178838148148 accuracy:  0.9489239989103786\n",
      "Epoch number: 3427/10000step_number: 0/29 cost:  0.14154673592862999 accuracy:  0.9491964042495233\n",
      "Epoch number: 3428/10000step_number: 0/29 cost:  0.1414530534277908 accuracy:  0.9491964042495233\n",
      "Epoch number: 3429/10000step_number: 0/29 cost:  0.1413607777188978 accuracy:  0.949060201579951\n",
      "Epoch number: 3430/10000step_number: 0/29 cost:  0.14126995345737778 accuracy:  0.949060201579951\n",
      "Epoch number: 3431/10000step_number: 0/29 cost:  0.14118062773841736 accuracy:  0.949060201579951\n",
      "Epoch number: 3432/10000step_number: 0/29 cost:  0.14109284531335556 accuracy:  0.9491964042495233\n",
      "Epoch number: 3433/10000step_number: 0/29 cost:  0.14100664484651174 accuracy:  0.9491964042495233\n",
      "Epoch number: 3434/10000step_number: 0/29 cost:  0.14092205634211072 accuracy:  0.9491964042495233\n",
      "Epoch number: 3435/10000step_number: 0/29 cost:  0.14083909965880687 accuracy:  0.9487877962408063\n",
      "Epoch number: 3436/10000step_number: 0/29 cost:  0.14075778391752364 accuracy:  0.9487877962408063\n",
      "Epoch number: 3437/10000step_number: 0/29 cost:  0.140678107572494 accuracy:  0.9487877962408063\n",
      "Epoch number: 3438/10000step_number: 0/29 cost:  0.14060005892730332 accuracy:  0.9487877962408063\n",
      "Epoch number: 3439/10000step_number: 0/29 cost:  0.1405236169135536 accuracy:  0.949060201579951\n",
      "Epoch number: 3440/10000step_number: 0/29 cost:  0.14044875199289394 accuracy:  0.949060201579951\n",
      "Epoch number: 3441/10000step_number: 0/29 cost:  0.1403754270835313 accuracy:  0.949060201579951\n",
      "Epoch number: 3442/10000step_number: 0/29 cost:  0.1403035984453559 accuracy:  0.949060201579951\n",
      "Epoch number: 3443/10000step_number: 0/29 cost:  0.14023321648211254 accuracy:  0.949060201579951\n",
      "Epoch number: 3444/10000step_number: 0/29 cost:  0.1401642264353425 accuracy:  0.949060201579951\n",
      "Epoch number: 3445/10000step_number: 0/29 cost:  0.14009656895455555 accuracy:  0.949060201579951\n",
      "Epoch number: 3446/10000step_number: 0/29 cost:  0.14003018053286861 accuracy:  0.9496050122582402\n",
      "Epoch number: 3447/10000step_number: 0/29 cost:  0.13996499379830726 accuracy:  0.9496050122582402\n",
      "Epoch number: 3448/10000step_number: 0/29 cost:  0.13990093764872114 accuracy:  0.9496050122582402\n",
      "Epoch number: 3449/10000step_number: 0/29 cost:  0.1398379372127194 accuracy:  0.9496050122582402\n",
      "Epoch number: 3450/10000step_number: 0/29 cost:  0.13977591360969682 accuracy:  0.9497412149278126\n",
      "Epoch number: 3451/10000step_number: 0/29 cost:  0.13971478346852997 accuracy:  0.9498774175973849\n",
      "Epoch number: 3452/10000step_number: 0/29 cost:  0.13965445814743666 accuracy:  0.9498774175973849\n",
      "Epoch number: 3453/10000step_number: 0/29 cost:  0.13959484257989954 accuracy:  0.9498774175973849\n",
      "Epoch number: 3454/10000step_number: 0/29 cost:  0.13953583366151634 accuracy:  0.9498774175973849\n",
      "Epoch number: 3455/10000step_number: 0/29 cost:  0.1394773181065088 accuracy:  0.9497412149278126\n",
      "Epoch number: 3456/10000step_number: 0/29 cost:  0.1394191697695961 accuracy:  0.9498774175973849\n",
      "Epoch number: 3457/10000step_number: 0/29 cost:  0.1393612465942467 accuracy:  0.9498774175973849\n",
      "Epoch number: 3458/10000step_number: 0/29 cost:  0.13930338767007158 accuracy:  0.9498774175973849\n",
      "Epoch number: 3459/10000step_number: 0/29 cost:  0.13924541140837682 accuracy:  0.9498774175973849\n",
      "Epoch number: 3460/10000step_number: 0/29 cost:  0.13918711655207233 accuracy:  0.9498774175973849\n",
      "Epoch number: 3461/10000step_number: 0/29 cost:  0.13912828841169933 accuracy:  0.9497412149278126\n",
      "Epoch number: 3462/10000step_number: 0/29 cost:  0.13906871282423247 accuracy:  0.9497412149278126\n",
      "Epoch number: 3463/10000step_number: 0/29 cost:  0.13900819899957345 accuracy:  0.9497412149278126\n",
      "Epoch number: 3464/10000step_number: 0/29 cost:  0.13894660890572494 accuracy:  0.9497412149278126\n",
      "Epoch number: 3465/10000step_number: 0/29 cost:  0.13888388560050707 accuracy:  0.9497412149278126\n",
      "Epoch number: 3466/10000step_number: 0/29 cost:  0.13882006867823185 accuracy:  0.9497412149278126\n",
      "Epoch number: 3467/10000step_number: 0/29 cost:  0.13875528609384358 accuracy:  0.9497412149278126\n",
      "Epoch number: 3468/10000step_number: 0/29 cost:  0.13868972035361612 accuracy:  0.9497412149278126\n",
      "Epoch number: 3469/10000step_number: 0/29 cost:  0.13862355971195714 accuracy:  0.9498774175973849\n",
      "Epoch number: 3470/10000step_number: 0/29 cost:  0.13855695307051794 accuracy:  0.9498774175973849\n",
      "Epoch number: 3471/10000step_number: 0/29 cost:  0.13848998470562757 accuracy:  0.9498774175973849\n",
      "Epoch number: 3472/10000step_number: 0/29 cost:  0.13842267401491576 accuracy:  0.9498774175973849\n",
      "Epoch number: 3473/10000step_number: 0/29 cost:  0.1383549941835399 accuracy:  0.9498774175973849\n",
      "Epoch number: 3474/10000step_number: 0/29 cost:  0.1382868983511343 accuracy:  0.9497412149278126\n",
      "Epoch number: 3475/10000step_number: 0/29 cost:  0.1382183431477916 accuracy:  0.9497412149278126\n",
      "Epoch number: 3476/10000step_number: 0/29 cost:  0.138149304103221 accuracy:  0.9497412149278126\n",
      "Epoch number: 3477/10000step_number: 0/29 cost:  0.13807978196312717 accuracy:  0.9497412149278126\n",
      "Epoch number: 3478/10000step_number: 0/29 cost:  0.13800980166237037 accuracy:  0.9498774175973849\n",
      "Epoch number: 3479/10000step_number: 0/29 cost:  0.137939406550993 accuracy:  0.9498774175973849\n",
      "Epoch number: 3480/10000step_number: 0/29 cost:  0.13786865021835853 accuracy:  0.9498774175973849\n",
      "Epoch number: 3481/10000step_number: 0/29 cost:  0.13779758774638043 accuracy:  0.9500136202669572\n",
      "Epoch number: 3482/10000step_number: 0/29 cost:  0.13772626787076409 accuracy:  0.9502860256061019\n",
      "Epoch number: 3483/10000step_number: 0/29 cost:  0.13765472728699862 accuracy:  0.9505584309452465\n",
      "Epoch number: 3484/10000step_number: 0/29 cost:  0.13758298794949528 accuracy:  0.9504222282756742\n",
      "Epoch number: 3485/10000step_number: 0/29 cost:  0.13751105755936516 accuracy:  0.9504222282756742\n",
      "Epoch number: 3486/10000step_number: 0/29 cost:  0.13743893267494878 accuracy:  0.9504222282756742\n",
      "Epoch number: 3487/10000step_number: 0/29 cost:  0.13736660331589484 accuracy:  0.9504222282756742\n",
      "Epoch number: 3488/10000step_number: 0/29 cost:  0.13729405778776835 accuracy:  0.9504222282756742\n",
      "Epoch number: 3489/10000step_number: 0/29 cost:  0.1372212867199409 accuracy:  0.9504222282756742\n",
      "Epoch number: 3490/10000step_number: 0/29 cost:  0.1371482857798327 accuracy:  0.9504222282756742\n",
      "Epoch number: 3491/10000step_number: 0/29 cost:  0.13707505695753974 accuracy:  0.9505584309452465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Burak\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py:59: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Burak\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\ipykernel_launcher.py:59: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 3492/10000step_number: 0/29 cost:  0.13700160856437252 accuracy:  0.9505584309452465\n",
      "Epoch number: 3493/10000step_number: 0/29 cost:  0.13692795415407744 accuracy:  0.9505584309452465\n",
      "Epoch number: 3494/10000step_number: 0/29 cost:  0.1368541105378845 accuracy:  0.9505584309452465\n",
      "Epoch number: 3495/10000step_number: 0/29 cost:  0.136780095012267 accuracy:  0.9504222282756742\n",
      "Epoch number: 3496/10000step_number: 0/29 cost:  0.13670592190678266 accuracy:  0.9504222282756742\n",
      "Epoch number: 3497/10000step_number: 0/29 cost:  0.13663159861790738 accuracy:  0.9504222282756742\n",
      "Epoch number: 3498/10000step_number: 0/29 cost:  0.13655712145173748 accuracy:  0.9504222282756742\n",
      "Epoch number: 3499/10000step_number: 0/29 cost:  0.13648247188722923 accuracy:  0.9505584309452465\n",
      "Epoch number: 3500/10000step_number: 0/29 cost:  0.13640761429882378 accuracy:  0.9505584309452465\n",
      "Epoch number: 3501/10000step_number: 0/29 cost:  0.13633249664660269 accuracy:  0.9506946336148189\n",
      "Epoch number: 3502/10000step_number: 0/29 cost:  0.13625705586360343 accuracy:  0.9508308362843911\n",
      "Epoch number: 3503/10000step_number: 0/29 cost:  0.13618122913685624 accuracy:  0.9508308362843911\n",
      "Epoch number: 3504/10000step_number: 0/29 cost:  0.1361049704914135 accuracy:  0.9508308362843911\n",
      "Epoch number: 3505/10000step_number: 0/29 cost:  0.13602826913378124 accuracy:  0.9508308362843911\n",
      "Epoch number: 3506/10000step_number: 0/29 cost:  0.13595116320987885 accuracy:  0.9508308362843911\n",
      "Epoch number: 3507/10000step_number: 0/29 cost:  0.13587374228615956 accuracy:  0.9508308362843911\n",
      "Epoch number: 3508/10000step_number: 0/29 cost:  0.13579613550480155 accuracy:  0.9508308362843911\n",
      "Epoch number: 3509/10000step_number: 0/29 cost:  0.13571848874467032 accuracy:  0.9506946336148189\n",
      "Epoch number: 3510/10000step_number: 0/29 cost:  0.13564093950717562 accuracy:  0.9506946336148189\n",
      "Epoch number: 3511/10000step_number: 0/29 cost:  0.13556359921393282 accuracy:  0.9505584309452465\n",
      "Epoch number: 3512/10000step_number: 0/29 cost:  0.13548654842364835 accuracy:  0.9505584309452465\n",
      "Epoch number: 3513/10000step_number: 0/29 cost:  0.13540984346991888 accuracy:  0.9505584309452465\n",
      "Epoch number: 3514/10000step_number: 0/29 cost:  0.13533352754671416 accuracy:  0.9505584309452465\n",
      "Epoch number: 3515/10000step_number: 0/29 cost:  0.1352576390257058 accuracy:  0.9506946336148189\n",
      "Epoch number: 3516/10000step_number: 0/29 cost:  0.1351822143695992 accuracy:  0.9506946336148189\n",
      "Epoch number: 3517/10000step_number: 0/29 cost:  0.13510728780524442 accuracy:  0.9506946336148189\n",
      "Epoch number: 3518/10000step_number: 0/29 cost:  0.135032890921143 accuracy:  0.9506946336148189\n",
      "Epoch number: 3519/10000step_number: 0/29 cost:  0.13495905313849849 accuracy:  0.9506946336148189\n",
      "Epoch number: 3520/10000step_number: 0/29 cost:  0.134885802159654 accuracy:  0.9508308362843911\n",
      "Epoch number: 3521/10000step_number: 0/29 cost:  0.13481316386945028 accuracy:  0.9508308362843911\n",
      "Epoch number: 3522/10000step_number: 0/29 cost:  0.13474116237285974 accuracy:  0.9506946336148189\n",
      "Epoch number: 3523/10000step_number: 0/29 cost:  0.13466982088036514 accuracy:  0.9506946336148189\n",
      "Epoch number: 3524/10000step_number: 0/29 cost:  0.13459916313322579 accuracy:  0.9505584309452465\n",
      "Epoch number: 3525/10000step_number: 0/29 cost:  0.13452921446831562 accuracy:  0.9505584309452465\n",
      "Epoch number: 3526/10000step_number: 0/29 cost:  0.13446000218666865 accuracy:  0.9505584309452465\n",
      "Epoch number: 3527/10000step_number: 0/29 cost:  0.13439155562974264 accuracy:  0.9505584309452465\n",
      "Epoch number: 3528/10000step_number: 0/29 cost:  0.13432390641762912 accuracy:  0.9505584309452465\n",
      "Epoch number: 3529/10000step_number: 0/29 cost:  0.13425708869068484 accuracy:  0.9505584309452465\n",
      "Epoch number: 3530/10000step_number: 0/29 cost:  0.1341911389930194 accuracy:  0.9505584309452465\n",
      "Epoch number: 3531/10000step_number: 0/29 cost:  0.1341260956555388 accuracy:  0.9505584309452465\n",
      "Epoch number: 3532/10000step_number: 0/29 cost:  0.1340619980077019 accuracy:  0.9505584309452465\n",
      "Epoch number: 3533/10000step_number: 0/29 cost:  0.1339988855022973 accuracy:  0.9505584309452465\n",
      "Epoch number: 3534/10000step_number: 0/29 cost:  0.13393679673140357 accuracy:  0.9505584309452465\n",
      "Epoch number: 3535/10000step_number: 0/29 cost:  0.13387576797355802 accuracy:  0.9505584309452465\n",
      "Epoch number: 3536/10000step_number: 0/29 cost:  0.13381583159213215 accuracy:  0.9504222282756742\n",
      "Epoch number: 3537/10000step_number: 0/29 cost:  0.13375701432659082 accuracy:  0.9504222282756742\n",
      "Epoch number: 3538/10000step_number: 0/29 cost:  0.13369933616846694 accuracy:  0.9504222282756742\n",
      "Epoch number: 3539/10000step_number: 0/29 cost:  0.13364280931720857 accuracy:  0.9504222282756742\n",
      "Epoch number: 3540/10000step_number: 0/29 cost:  0.1335874380149695 accuracy:  0.9505584309452465\n",
      "Epoch number: 3541/10000step_number: 0/29 cost:  0.13353321827087558 accuracy:  0.9505584309452465\n",
      "Epoch number: 3542/10000step_number: 0/29 cost:  0.1334801388693382 accuracy:  0.9505584309452465\n",
      "Epoch number: 3543/10000step_number: 0/29 cost:  0.13342817983798502 accuracy:  0.9506946336148189\n",
      "Epoch number: 3544/10000step_number: 0/29 cost:  0.13337730544650997 accuracy:  0.9506946336148189\n",
      "Epoch number: 3545/10000step_number: 0/29 cost:  0.13332744541258557 accuracy:  0.9506946336148189\n",
      "Epoch number: 3546/10000step_number: 0/29 cost:  0.1332785261539296 accuracy:  0.9506946336148189\n",
      "Epoch number: 3547/10000step_number: 0/29 cost:  0.13323055656778324 accuracy:  0.9505584309452465\n",
      "Epoch number: 3548/10000step_number: 0/29 cost:  0.13318350358678213 accuracy:  0.9504222282756742\n",
      "Epoch number: 3549/10000step_number: 0/29 cost:  0.13313731109935079 accuracy:  0.9504222282756742\n",
      "Epoch number: 3550/10000step_number: 0/29 cost:  0.1330919041414457 accuracy:  0.9504222282756742\n",
      "Epoch number: 3551/10000step_number: 0/29 cost:  0.1330472403564202 accuracy:  0.9505584309452465\n",
      "Epoch number: 3552/10000step_number: 0/29 cost:  0.13300325895452517 accuracy:  0.9505584309452465\n",
      "Epoch number: 3553/10000step_number: 0/29 cost:  0.13295992293126654 accuracy:  0.9505584309452465\n",
      "Epoch number: 3554/10000step_number: 0/29 cost:  0.13291714369482446 accuracy:  0.9506946336148189\n",
      "Epoch number: 3555/10000step_number: 0/29 cost:  0.13287490232473725 accuracy:  0.9506946336148189\n",
      "Epoch number: 3556/10000step_number: 0/29 cost:  0.13283309965508083 accuracy:  0.9506946336148189\n",
      "Epoch number: 3557/10000step_number: 0/29 cost:  0.13279176317738547 accuracy:  0.9506946336148189\n",
      "Epoch number: 3558/10000step_number: 0/29 cost:  0.1327507167174868 accuracy:  0.9506946336148189\n",
      "Epoch number: 3559/10000step_number: 0/29 cost:  0.13271006440519534 accuracy:  0.9506946336148189\n",
      "Epoch number: 3560/10000step_number: 0/29 cost:  0.1326695107751636 accuracy:  0.9506946336148189\n",
      "Epoch number: 3561/10000step_number: 0/29 cost:  0.13262939322845402 accuracy:  0.9506946336148189\n",
      "Epoch number: 3562/10000step_number: 0/29 cost:  0.13258912414078508 accuracy:  0.9505584309452465\n",
      "Epoch number: 3563/10000step_number: 0/29 cost:  0.1325494932450663 accuracy:  0.9505584309452465\n",
      "Epoch number: 3564/10000step_number: 0/29 cost:  0.13250919893249474 accuracy:  0.9505584309452465\n",
      "Epoch number: 3565/10000step_number: 0/29 cost:  0.13247012834312105 accuracy:  0.9505584309452465\n",
      "Epoch number: 3566/10000step_number: 0/29 cost:  0.13242934840454745 accuracy:  0.9505584309452465\n",
      "Epoch number: 3567/10000step_number: 0/29 cost:  0.13239132443883467 accuracy:  0.9506946336148189\n",
      "Epoch number: 3568/10000step_number: 0/29 cost:  0.1323491359512625 accuracy:  0.9506946336148189\n",
      "Epoch number: 3569/10000step_number: 0/29 cost:  0.13231343719549626 accuracy:  0.9506946336148189\n",
      "Epoch number: 3570/10000step_number: 0/29 cost:  0.13226763698745903 accuracy:  0.9506946336148189\n",
      "Epoch number: 3571/10000step_number: 0/29 cost:  0.13223758023214338 accuracy:  0.9506946336148189\n",
      "Epoch number: 3572/10000step_number: 0/29 cost:  0.13218301406282895 accuracy:  0.9506946336148189\n",
      "Epoch number: 3573/10000step_number: 0/29 cost:  0.13216638791172824 accuracy:  0.9506946336148189\n",
      "Epoch number: 3574/10000step_number: 0/29 cost:  0.1320925244648811 accuracy:  0.9506946336148189\n",
      "Epoch number: 3575/10000step_number: 0/29 cost:  0.13210075121004525 accuracy:  0.9508308362843911\n",
      "Epoch number: 3576/10000step_number: 0/29 cost:  0.13199860630546442 accuracy:  0.9506946336148189\n",
      "Epoch number: 3577/10000step_number: 0/29 cost:  0.1320293165697281 accuracy:  0.9508308362843911\n",
      "Epoch number: 3578/10000step_number: 0/29 cost:  0.13191255286069392 accuracy:  0.9505584309452465\n",
      "Epoch number: 3579/10000step_number: 0/29 cost:  0.13195247011615283 accuracy:  0.9505584309452465\n",
      "Epoch number: 3580/10000step_number: 0/29 cost:  0.13183150614268133 accuracy:  0.9505584309452465\n",
      "Epoch number: 3581/10000step_number: 0/29 cost:  0.1318723919243684 accuracy:  0.9505584309452465\n",
      "Epoch number: 3582/10000step_number: 0/29 cost:  0.13175295619845673 accuracy:  0.9505584309452465\n",
      "Epoch number: 3583/10000step_number: 0/29 cost:  0.1317907471926221 accuracy:  0.9505584309452465\n",
      "Epoch number: 3584/10000step_number: 0/29 cost:  0.1316758353435994 accuracy:  0.9505584309452465\n",
      "Epoch number: 3585/10000step_number: 0/29 cost:  0.1317089148151419 accuracy:  0.9505584309452465\n",
      "Epoch number: 3586/10000step_number: 0/29 cost:  0.13159899628899052 accuracy:  0.9505584309452465\n",
      "Epoch number: 3587/10000step_number: 0/29 cost:  0.131627215007716 accuracy:  0.9505584309452465\n",
      "Epoch number: 3588/10000step_number: 0/29 cost:  0.13152211610951808 accuracy:  0.9505584309452465\n",
      "Epoch number: 3589/10000step_number: 0/29 cost:  0.13154579653922005 accuracy:  0.9505584309452465\n",
      "Epoch number: 3590/10000step_number: 0/29 cost:  0.13144500068257253 accuracy:  0.9505584309452465\n",
      "Epoch number: 3591/10000step_number: 0/29 cost:  0.13146467158834577 accuracy:  0.9505584309452465\n",
      "Epoch number: 3592/10000step_number: 0/29 cost:  0.13136760315112475 accuracy:  0.9506946336148189\n",
      "Epoch number: 3593/10000step_number: 0/29 cost:  0.13138418348977968 accuracy:  0.9506946336148189\n",
      "Epoch number: 3594/10000step_number: 0/29 cost:  0.1312908148668775 accuracy:  0.9506946336148189\n",
      "Epoch number: 3595/10000step_number: 0/29 cost:  0.13130668777464422 accuracy:  0.9506946336148189\n",
      "Epoch number: 3596/10000step_number: 0/29 cost:  0.13121864382037693 accuracy:  0.9508308362843911\n",
      "Epoch number: 3597/10000step_number: 0/29 cost:  0.13123169815304056 accuracy:  0.9508308362843911\n",
      "Epoch number: 3598/10000step_number: 0/29 cost:  0.1311322475842718 accuracy:  0.9509670389539635\n",
      "Epoch number: 3599/10000step_number: 0/29 cost:  0.1311306066844948 accuracy:  0.9508308362843911\n",
      "Epoch number: 3600/10000step_number: 0/29 cost:  0.13103652607143637 accuracy:  0.9509670389539635\n",
      "Epoch number: 3601/10000step_number: 0/29 cost:  0.13104722425070212 accuracy:  0.9509670389539635\n",
      "Epoch number: 3602/10000step_number: 0/29 cost:  0.13096082647626514 accuracy:  0.9509670389539635\n",
      "Epoch number: 3603/10000step_number: 0/29 cost:  0.13096576251624784 accuracy:  0.9509670389539635\n",
      "Epoch number: 3604/10000step_number: 0/29 cost:  0.13087487941538775 accuracy:  0.9509670389539635\n",
      "Epoch number: 3605/10000step_number: 0/29 cost:  0.1308723075619979 accuracy:  0.9511032416235358\n",
      "Epoch number: 3606/10000step_number: 0/29 cost:  0.1307667674705567 accuracy:  0.9511032416235358\n",
      "Epoch number: 3607/10000step_number: 0/29 cost:  0.13076926564920568 accuracy:  0.9512394442931081\n",
      "Epoch number: 3608/10000step_number: 0/29 cost:  0.13071227637940513 accuracy:  0.9511032416235358\n",
      "Epoch number: 3609/10000step_number: 0/29 cost:  0.13081467158762086 accuracy:  0.9509670389539635\n",
      "Epoch number: 3610/10000step_number: 0/29 cost:  0.13072189799466985 accuracy:  0.9508308362843911\n",
      "Epoch number: 3611/10000step_number: 0/29 cost:  0.1306965789351561 accuracy:  0.9508308362843911\n",
      "Epoch number: 3612/10000step_number: 0/29 cost:  0.1306216631510448 accuracy:  0.9509670389539635\n",
      "Epoch number: 3613/10000step_number: 0/29 cost:  0.1305182713821353 accuracy:  0.9511032416235358\n",
      "Epoch number: 3614/10000step_number: 0/29 cost:  0.13017949676543272 accuracy:  0.9512394442931081\n",
      "Epoch number: 3615/10000step_number: 0/29 cost:  0.13391138024949023 accuracy:  0.9476981748842277\n",
      "Epoch number: 3616/10000step_number: 0/29 cost:  0.16544984834402804 accuracy:  0.9432034867883411\n",
      "Epoch number: 3617/10000step_number: 0/29 cost:  0.23783905301375688 accuracy:  0.9459275401797875\n",
      "Epoch number: 3618/10000step_number: 0/29 cost:  0.1449497279316402 accuracy:  0.9519204576409698\n",
      "Epoch number: 3619/10000step_number: 0/29 cost:  0.13564456124034896 accuracy:  0.9500136202669572\n",
      "Epoch number: 3620/10000step_number: 0/29 cost:  0.1296228271309766 accuracy:  0.9527376736584037\n",
      "Epoch number: 3621/10000step_number: 0/29 cost:  0.13284954271647453 accuracy:  0.9536910923454099\n",
      "Epoch number: 3622/10000step_number: 0/29 cost:  0.1384671100455377 accuracy:  0.9543721056932716\n",
      "Epoch number: 3623/10000step_number: 0/29 cost:  0.13507658885797214 accuracy:  0.9543721056932716\n",
      "Epoch number: 3624/10000step_number: 0/29 cost:  0.13418537980742268 accuracy:  0.9539634976845546\n",
      "Epoch number: 3625/10000step_number: 0/29 cost:  0.13414467625863155 accuracy:  0.9539634976845546\n",
      "Epoch number: 3626/10000step_number: 0/29 cost:  0.13346553842742157 accuracy:  0.9534186870062653\n",
      "Epoch number: 3627/10000step_number: 0/29 cost:  0.13296585871986882 accuracy:  0.9534186870062653\n",
      "Epoch number: 3628/10000step_number: 0/29 cost:  0.13257716048251703 accuracy:  0.9535548896758377\n",
      "Epoch number: 3629/10000step_number: 0/29 cost:  0.1322503452190792 accuracy:  0.9517842549713974\n",
      "Epoch number: 3630/10000step_number: 0/29 cost:  0.13196445848499708 accuracy:  0.9516480523018251\n",
      "Epoch number: 3631/10000step_number: 0/29 cost:  0.13171717708450764 accuracy:  0.9515118496322528\n",
      "Epoch number: 3632/10000step_number: 0/29 cost:  0.13149776217710882 accuracy:  0.9517842549713974\n",
      "Epoch number: 3633/10000step_number: 0/29 cost:  0.13130157224704425 accuracy:  0.9515118496322528\n",
      "Epoch number: 3634/10000step_number: 0/29 cost:  0.1311229466503832 accuracy:  0.9516480523018251\n",
      "Epoch number: 3635/10000step_number: 0/29 cost:  0.13095824639761244 accuracy:  0.9517842549713974\n",
      "Epoch number: 3636/10000step_number: 0/29 cost:  0.1308041577512255 accuracy:  0.9517842549713974\n",
      "Epoch number: 3637/10000step_number: 0/29 cost:  0.13065861495668238 accuracy:  0.9513756469626805\n",
      "Epoch number: 3638/10000step_number: 0/29 cost:  0.13052032382455728 accuracy:  0.9512394442931081\n",
      "Epoch number: 3639/10000step_number: 0/29 cost:  0.13038867337685028 accuracy:  0.9512394442931081\n",
      "Epoch number: 3640/10000step_number: 0/29 cost:  0.1302634719556695 accuracy:  0.9513756469626805\n",
      "Epoch number: 3641/10000step_number: 0/29 cost:  0.13014488585566744 accuracy:  0.9513756469626805\n",
      "Epoch number: 3642/10000step_number: 0/29 cost:  0.1300333961954865 accuracy:  0.9516480523018251\n",
      "Epoch number: 3643/10000step_number: 0/29 cost:  0.12992979248925476 accuracy:  0.9517842549713974\n",
      "Epoch number: 3644/10000step_number: 0/29 cost:  0.12983510022196845 accuracy:  0.9517842549713974\n",
      "Epoch number: 3645/10000step_number: 0/29 cost:  0.12975039400674962 accuracy:  0.9519204576409698\n",
      "Epoch number: 3646/10000step_number: 0/29 cost:  0.12967650126385913 accuracy:  0.952056660310542\n",
      "Epoch number: 3647/10000step_number: 0/29 cost:  0.12961372283798323 accuracy:  0.9521928629801144\n",
      "Epoch number: 3648/10000step_number: 0/29 cost:  0.1295617274541588 accuracy:  0.9521928629801144\n",
      "Epoch number: 3649/10000step_number: 0/29 cost:  0.12951966549103178 accuracy:  0.9521928629801144\n",
      "Epoch number: 3650/10000step_number: 0/29 cost:  0.1294863976499094 accuracy:  0.9521928629801144\n",
      "Epoch number: 3651/10000step_number: 0/29 cost:  0.1294607007430702 accuracy:  0.9523290656496868\n",
      "Epoch number: 3652/10000step_number: 0/29 cost:  0.1294413886087292 accuracy:  0.9526014709888314\n",
      "Epoch number: 3653/10000step_number: 0/29 cost:  0.1294273592294324 accuracy:  0.9526014709888314\n",
      "Epoch number: 3654/10000step_number: 0/29 cost:  0.12941760025476584 accuracy:  0.952873876327976\n",
      "Epoch number: 3655/10000step_number: 0/29 cost:  0.1294111786257039 accuracy:  0.9530100789975483\n",
      "Epoch number: 3656/10000step_number: 0/29 cost:  0.12940722952691175 accuracy:  0.9526014709888314\n",
      "Epoch number: 3657/10000step_number: 0/29 cost:  0.12940495024468696 accuracy:  0.9526014709888314\n",
      "Epoch number: 3658/10000step_number: 0/29 cost:  0.1294035981712858 accuracy:  0.9526014709888314\n",
      "Epoch number: 3659/10000step_number: 0/29 cost:  0.12940249058037934 accuracy:  0.9523290656496868\n",
      "Epoch number: 3660/10000step_number: 0/29 cost:  0.12940100503572183 accuracy:  0.9523290656496868\n",
      "Epoch number: 3661/10000step_number: 0/29 cost:  0.12939858073264246 accuracy:  0.9523290656496868\n",
      "Epoch number: 3662/10000step_number: 0/29 cost:  0.12939472143786682 accuracy:  0.9521928629801144\n",
      "Epoch number: 3663/10000step_number: 0/29 cost:  0.12938900002552178 accuracy:  0.9521928629801144\n",
      "Epoch number: 3664/10000step_number: 0/29 cost:  0.1293810633159933 accuracy:  0.9521928629801144\n",
      "Epoch number: 3665/10000step_number: 0/29 cost:  0.12937063489067052 accuracy:  0.9521928629801144\n",
      "Epoch number: 3666/10000step_number: 0/29 cost:  0.1293575139575863 accuracy:  0.9519204576409698\n",
      "Epoch number: 3667/10000step_number: 0/29 cost:  0.12934156973569005 accuracy:  0.9517842549713974\n",
      "Epoch number: 3668/10000step_number: 0/29 cost:  0.12932273208896206 accuracy:  0.9517842549713974\n",
      "Epoch number: 3669/10000step_number: 0/29 cost:  0.1293009799550747 accuracy:  0.9517842549713974\n",
      "Epoch number: 3670/10000step_number: 0/29 cost:  0.12927632938354527 accuracy:  0.9519204576409698\n",
      "Epoch number: 3671/10000step_number: 0/29 cost:  0.1292488227122066 accuracy:  0.9517842549713974\n",
      "Epoch number: 3672/10000step_number: 0/29 cost:  0.12921851982047433 accuracy:  0.9516480523018251\n",
      "Epoch number: 3673/10000step_number: 0/29 cost:  0.129185491811101 accuracy:  0.9516480523018251\n",
      "Epoch number: 3674/10000step_number: 0/29 cost:  0.1291498170647461 accuracy:  0.9516480523018251\n",
      "Epoch number: 3675/10000step_number: 0/29 cost:  0.12911157940206783 accuracy:  0.9516480523018251\n",
      "Epoch number: 3676/10000step_number: 0/29 cost:  0.1290708680113176 accuracy:  0.9515118496322528\n",
      "Epoch number: 3677/10000step_number: 0/29 cost:  0.12902777878371896 accuracy:  0.9515118496322528\n",
      "Epoch number: 3678/10000step_number: 0/29 cost:  0.12898241670101623 accuracy:  0.9513756469626805\n",
      "Epoch number: 3679/10000step_number: 0/29 cost:  0.12893489892294097 accuracy:  0.9513756469626805\n",
      "Epoch number: 3680/10000step_number: 0/29 cost:  0.12888535821940808 accuracy:  0.9512394442931081\n",
      "Epoch number: 3681/10000step_number: 0/29 cost:  0.12883394637143503 accuracy:  0.9511032416235358\n",
      "Epoch number: 3682/10000step_number: 0/29 cost:  0.12878083711009736 accuracy:  0.9513756469626805\n",
      "Epoch number: 3683/10000step_number: 0/29 cost:  0.12872622806504957 accuracy:  0.9513756469626805\n",
      "Epoch number: 3684/10000step_number: 0/29 cost:  0.12867034106555775 accuracy:  0.9513756469626805\n",
      "Epoch number: 3685/10000step_number: 0/29 cost:  0.12861342002468085 accuracy:  0.9513756469626805\n",
      "Epoch number: 3686/10000step_number: 0/29 cost:  0.12855572562543993 accuracy:  0.9513756469626805\n",
      "Epoch number: 3687/10000step_number: 0/29 cost:  0.12849752622238256 accuracy:  0.9513756469626805\n",
      "Epoch number: 3688/10000step_number: 0/29 cost:  0.12843908485723768 accuracy:  0.9513756469626805\n",
      "Epoch number: 3689/10000step_number: 0/29 cost:  0.1283806430602797 accuracy:  0.9513756469626805\n",
      "Epoch number: 3690/10000step_number: 0/29 cost:  0.12832240302056885 accuracy:  0.9513756469626805\n",
      "Epoch number: 3691/10000step_number: 0/29 cost:  0.12826451047334922 accuracy:  0.9512394442931081\n",
      "Epoch number: 3692/10000step_number: 0/29 cost:  0.128207040985441 accuracy:  0.9512394442931081\n",
      "Epoch number: 3693/10000step_number: 0/29 cost:  0.12814999217156728 accuracy:  0.9512394442931081\n",
      "Epoch number: 3694/10000step_number: 0/29 cost:  0.12809328411213597 accuracy:  0.9512394442931081\n",
      "Epoch number: 3695/10000step_number: 0/29 cost:  0.1280367704443747 accuracy:  0.9512394442931081\n",
      "Epoch number: 3696/10000step_number: 0/29 cost:  0.12798026317987024 accuracy:  0.9512394442931081\n",
      "Epoch number: 3697/10000step_number: 0/29 cost:  0.12792357320554798 accuracy:  0.9512394442931081\n",
      "Epoch number: 3698/10000step_number: 0/29 cost:  0.12786656169827781 accuracy:  0.9512394442931081\n",
      "Epoch number: 3699/10000step_number: 0/29 cost:  0.12780918438261057 accuracy:  0.9512394442931081\n",
      "Epoch number: 3700/10000step_number: 0/29 cost:  0.127751501382819 accuracy:  0.9512394442931081\n",
      "Epoch number: 3701/10000step_number: 0/29 cost:  0.1276936393569061 accuracy:  0.9513756469626805\n",
      "Epoch number: 3702/10000step_number: 0/29 cost:  0.12763572853558003 accuracy:  0.9513756469626805\n",
      "Epoch number: 3703/10000step_number: 0/29 cost:  0.12757785817380346 accuracy:  0.9513756469626805\n",
      "Epoch number: 3704/10000step_number: 0/29 cost:  0.1275200725658652 accuracy:  0.9516480523018251\n",
      "Epoch number: 3705/10000step_number: 0/29 cost:  0.12746239355800731 accuracy:  0.9516480523018251\n",
      "Epoch number: 3706/10000step_number: 0/29 cost:  0.12740484452242198 accuracy:  0.9516480523018251\n",
      "Epoch number: 3707/10000step_number: 0/29 cost:  0.12734746355313561 accuracy:  0.9516480523018251\n",
      "Epoch number: 3708/10000step_number: 0/29 cost:  0.12729030650464512 accuracy:  0.9516480523018251\n",
      "Epoch number: 3709/10000step_number: 0/29 cost:  0.1272334442668792 accuracy:  0.9516480523018251\n",
      "Epoch number: 3710/10000step_number: 0/29 cost:  0.1271769577846835 accuracy:  0.9516480523018251\n",
      "Epoch number: 3711/10000step_number: 0/29 cost:  0.12712093292719168 accuracy:  0.9516480523018251\n",
      "Epoch number: 3712/10000step_number: 0/29 cost:  0.12706545624614402 accuracy:  0.9516480523018251\n",
      "Epoch number: 3713/10000step_number: 0/29 cost:  0.12701061188801 accuracy:  0.9516480523018251\n",
      "Epoch number: 3714/10000step_number: 0/29 cost:  0.12695647948589056 accuracy:  0.9516480523018251\n",
      "Epoch number: 3715/10000step_number: 0/29 cost:  0.1269031327314977 accuracy:  0.9517842549713974\n",
      "Epoch number: 3716/10000step_number: 0/29 cost:  0.12685063838125213 accuracy:  0.9517842549713974\n",
      "Epoch number: 3717/10000step_number: 0/29 cost:  0.12679905555568793 accuracy:  0.9517842549713974\n",
      "Epoch number: 3718/10000step_number: 0/29 cost:  0.12674843528071025 accuracy:  0.9517842549713974\n",
      "Epoch number: 3719/10000step_number: 0/29 cost:  0.12669882027081625 accuracy:  0.9516480523018251\n",
      "Epoch number: 3720/10000step_number: 0/29 cost:  0.12665024496769503 accuracy:  0.9516480523018251\n",
      "Epoch number: 3721/10000step_number: 0/29 cost:  0.12660273583238185 accuracy:  0.9516480523018251\n",
      "Epoch number: 3722/10000step_number: 0/29 cost:  0.12655631185912078 accuracy:  0.9516480523018251\n",
      "Epoch number: 3723/10000step_number: 0/29 cost:  0.1265109852477622 accuracy:  0.9516480523018251\n",
      "Epoch number: 3724/10000step_number: 0/29 cost:  0.12646676214938346 accuracy:  0.9516480523018251\n",
      "Epoch number: 3725/10000step_number: 0/29 cost:  0.12642364339274065 accuracy:  0.9516480523018251\n",
      "Epoch number: 3726/10000step_number: 0/29 cost:  0.12638162510862383 accuracy:  0.9516480523018251\n",
      "Epoch number: 3727/10000step_number: 0/29 cost:  0.12634069919334165 accuracy:  0.9516480523018251\n",
      "Epoch number: 3728/10000step_number: 0/29 cost:  0.12630085358788032 accuracy:  0.9516480523018251\n",
      "Epoch number: 3729/10000step_number: 0/29 cost:  0.12626207239140522 accuracy:  0.9516480523018251\n",
      "Epoch number: 3730/10000step_number: 0/29 cost:  0.12622433587103832 accuracy:  0.9516480523018251\n",
      "Epoch number: 3731/10000step_number: 0/29 cost:  0.12618762046591664 accuracy:  0.9517842549713974\n",
      "Epoch number: 3732/10000step_number: 0/29 cost:  0.12615189890118203 accuracy:  0.9519204576409698\n",
      "Epoch number: 3733/10000step_number: 0/29 cost:  0.12611714051548703 accuracy:  0.9519204576409698\n",
      "Epoch number: 3734/10000step_number: 0/29 cost:  0.12608331185853824 accuracy:  0.9519204576409698\n",
      "Epoch number: 3735/10000step_number: 0/29 cost:  0.12605037754065582 accuracy:  0.9519204576409698\n",
      "Epoch number: 3736/10000step_number: 0/29 cost:  0.12601830123641192 accuracy:  0.9519204576409698\n",
      "Epoch number: 3737/10000step_number: 0/29 cost:  0.12598704668869548 accuracy:  0.9519204576409698\n",
      "Epoch number: 3738/10000step_number: 0/29 cost:  0.1259565785508645 accuracy:  0.9519204576409698\n",
      "Epoch number: 3739/10000step_number: 0/29 cost:  0.12592686294648595 accuracy:  0.9519204576409698\n",
      "Epoch number: 3740/10000step_number: 0/29 cost:  0.12589786770046865 accuracy:  0.9519204576409698\n",
      "Epoch number: 3741/10000step_number: 0/29 cost:  0.12586956227272922 accuracy:  0.9517842549713974\n",
      "Epoch number: 3742/10000step_number: 0/29 cost:  0.12584191748023663 accuracy:  0.9517842549713974\n",
      "Epoch number: 3743/10000step_number: 0/29 cost:  0.12581490511393667 accuracy:  0.9516480523018251\n",
      "Epoch number: 3744/10000step_number: 0/29 cost:  0.1257884975473292 accuracy:  0.9516480523018251\n",
      "Epoch number: 3745/10000step_number: 0/29 cost:  0.1257626674057278 accuracy:  0.9516480523018251\n",
      "Epoch number: 3746/10000step_number: 0/29 cost:  0.1257373873327374 accuracy:  0.9515118496322528\n",
      "Epoch number: 3747/10000step_number: 0/29 cost:  0.12571262986254186 accuracy:  0.9515118496322528\n",
      "Epoch number: 3748/10000step_number: 0/29 cost:  0.1256883673871868 accuracy:  0.9516480523018251\n",
      "Epoch number: 3749/10000step_number: 0/29 cost:  0.12566457219728616 accuracy:  0.9516480523018251\n",
      "Epoch number: 3750/10000step_number: 0/29 cost:  0.1256412165706043 accuracy:  0.9516480523018251\n",
      "Epoch number: 3751/10000step_number: 0/29 cost:  0.12561827288338506 accuracy:  0.9516480523018251\n",
      "Epoch number: 3752/10000step_number: 0/29 cost:  0.12559571372227354 accuracy:  0.9516480523018251\n",
      "Epoch number: 3753/10000step_number: 0/29 cost:  0.12557351197892708 accuracy:  0.9516480523018251\n",
      "Epoch number: 3754/10000step_number: 0/29 cost:  0.1255516409144199 accuracy:  0.9516480523018251\n",
      "Epoch number: 3755/10000step_number: 0/29 cost:  0.12553007418596793 accuracy:  0.9516480523018251\n",
      "Epoch number: 3756/10000step_number: 0/29 cost:  0.1255087858343686 accuracy:  0.9516480523018251\n",
      "Epoch number: 3757/10000step_number: 0/29 cost:  0.12548775023647601 accuracy:  0.9516480523018251\n",
      "Epoch number: 3758/10000step_number: 0/29 cost:  0.12546694203266576 accuracy:  0.9516480523018251\n",
      "Epoch number: 3759/10000step_number: 0/29 cost:  0.12544633604379615 accuracy:  0.9516480523018251\n",
      "Epoch number: 3760/10000step_number: 0/29 cost:  0.12542590719491253 accuracy:  0.9516480523018251\n",
      "Epoch number: 3761/10000step_number: 0/29 cost:  0.1254056304632033 accuracy:  0.9516480523018251\n",
      "Epoch number: 3762/10000step_number: 0/29 cost:  0.12538548086523985 accuracy:  0.9515118496322528\n",
      "Epoch number: 3763/10000step_number: 0/29 cost:  0.12536543349373963 accuracy:  0.9515118496322528\n",
      "Epoch number: 3764/10000step_number: 0/29 cost:  0.12534546360764875 accuracy:  0.9516480523018251\n",
      "Epoch number: 3765/10000step_number: 0/29 cost:  0.12532554677259417 accuracy:  0.9516480523018251\n",
      "Epoch number: 3766/10000step_number: 0/29 cost:  0.12530565904266183 accuracy:  0.9516480523018251\n",
      "Epoch number: 3767/10000step_number: 0/29 cost:  0.12528577717007458 accuracy:  0.9516480523018251\n",
      "Epoch number: 3768/10000step_number: 0/29 cost:  0.1252658788269826 accuracy:  0.9516480523018251\n",
      "Epoch number: 3769/10000step_number: 0/29 cost:  0.1252459428234841 accuracy:  0.9516480523018251\n",
      "Epoch number: 3770/10000step_number: 0/29 cost:  0.1252259493077318 accuracy:  0.9516480523018251\n",
      "Epoch number: 3771/10000step_number: 0/29 cost:  0.12520587993723353 accuracy:  0.9516480523018251\n",
      "Epoch number: 3772/10000step_number: 0/29 cost:  0.12518571801447637 accuracy:  0.9515118496322528\n",
      "Epoch number: 3773/10000step_number: 0/29 cost:  0.12516544858420472 accuracy:  0.9515118496322528\n",
      "Epoch number: 3774/10000step_number: 0/29 cost:  0.12514505849357438 accuracy:  0.9515118496322528\n",
      "Epoch number: 3775/10000step_number: 0/29 cost:  0.12512453641941806 accuracy:  0.9515118496322528\n",
      "Epoch number: 3776/10000step_number: 0/29 cost:  0.12510387286905605 accuracy:  0.9515118496322528\n",
      "Epoch number: 3777/10000step_number: 0/29 cost:  0.12508306016218643 accuracy:  0.9515118496322528\n",
      "Epoch number: 3778/10000step_number: 0/29 cost:  0.12506209240175875 accuracy:  0.9515118496322528\n",
      "Epoch number: 3779/10000step_number: 0/29 cost:  0.1250409654414675 accuracy:  0.9515118496322528\n",
      "Epoch number: 3780/10000step_number: 0/29 cost:  0.12501967685688195 accuracy:  0.9515118496322528\n",
      "Epoch number: 3781/10000step_number: 0/29 cost:  0.12499822592649505 accuracy:  0.9513756469626805\n",
      "Epoch number: 3782/10000step_number: 0/29 cost:  0.12497661362831294 accuracy:  0.9513756469626805\n",
      "Epoch number: 3783/10000step_number: 0/29 cost:  0.12495484265712746 accuracy:  0.9513756469626805\n",
      "Epoch number: 3784/10000step_number: 0/29 cost:  0.12493291746747681 accuracy:  0.9513756469626805\n",
      "Epoch number: 3785/10000step_number: 0/29 cost:  0.12491084434757123 accuracy:  0.9513756469626805\n",
      "Epoch number: 3786/10000step_number: 0/29 cost:  0.12488863153024947 accuracy:  0.9513756469626805\n",
      "Epoch number: 3787/10000step_number: 0/29 cost:  0.12486628934853673 accuracy:  0.9513756469626805\n",
      "Epoch number: 3788/10000step_number: 0/29 cost:  0.124843830445812 accuracy:  0.9516480523018251\n",
      "Epoch number: 3789/10000step_number: 0/29 cost:  0.12482127005436394 accuracy:  0.9516480523018251\n",
      "Epoch number: 3790/10000step_number: 0/29 cost:  0.12479862636178027 accuracy:  0.9516480523018251\n",
      "Epoch number: 3791/10000step_number: 0/29 cost:  0.12477592099279683 accuracy:  0.9516480523018251\n",
      "Epoch number: 3792/10000step_number: 0/29 cost:  0.12475317964555757 accuracy:  0.9516480523018251\n",
      "Epoch number: 3793/10000step_number: 0/29 cost:  0.12473043293516298 accuracy:  0.9516480523018251\n",
      "Epoch number: 3794/10000step_number: 0/29 cost:  0.12470771751018868 accuracy:  0.9516480523018251\n",
      "Epoch number: 3795/10000step_number: 0/29 cost:  0.12468507750596851 accuracy:  0.9516480523018251\n",
      "Epoch number: 3796/10000step_number: 0/29 cost:  0.12466256634476476 accuracy:  0.9516480523018251\n",
      "Epoch number: 3797/10000step_number: 0/29 cost:  0.12464024869691723 accuracy:  0.9516480523018251\n",
      "Epoch number: 3798/10000step_number: 0/29 cost:  0.1246182018833538 accuracy:  0.9516480523018251\n",
      "Epoch number: 3799/10000step_number: 0/29 cost:  0.12459651477004317 accuracy:  0.9516480523018251\n",
      "Epoch number: 3800/10000step_number: 0/29 cost:  0.12457527979989785 accuracy:  0.9516480523018251\n",
      "Epoch number: 3801/10000step_number: 0/29 cost:  0.12455457012216493 accuracy:  0.9516480523018251\n",
      "Epoch number: 3802/10000step_number: 0/29 cost:  0.12453439070480983 accuracy:  0.9519204576409698\n",
      "Epoch number: 3803/10000step_number: 0/29 cost:  0.12451459660640175 accuracy:  0.952056660310542\n",
      "Epoch number: 3804/10000step_number: 0/29 cost:  0.12449479505778441 accuracy:  0.952056660310542\n",
      "Epoch number: 3805/10000step_number: 0/29 cost:  0.12447429387581035 accuracy:  0.952056660310542\n",
      "Epoch number: 3806/10000step_number: 0/29 cost:  0.12445219112609704 accuracy:  0.9521928629801144\n",
      "Epoch number: 3807/10000step_number: 0/29 cost:  0.12442764553433663 accuracy:  0.9521928629801144\n",
      "Epoch number: 3808/10000step_number: 0/29 cost:  0.12440021179271261 accuracy:  0.9521928629801144\n",
      "Epoch number: 3809/10000step_number: 0/29 cost:  0.12437001788868615 accuracy:  0.952056660310542\n",
      "Epoch number: 3810/10000step_number: 0/29 cost:  0.1243376626176696 accuracy:  0.952056660310542\n",
      "Epoch number: 3811/10000step_number: 0/29 cost:  0.12430393132177199 accuracy:  0.952056660310542\n",
      "Epoch number: 3812/10000step_number: 0/29 cost:  0.12426952744448695 accuracy:  0.952056660310542\n",
      "Epoch number: 3813/10000step_number: 0/29 cost:  0.12423493987788979 accuracy:  0.952056660310542\n",
      "Epoch number: 3814/10000step_number: 0/29 cost:  0.12420044439303458 accuracy:  0.952056660310542\n",
      "Epoch number: 3815/10000step_number: 0/29 cost:  0.1241661736134441 accuracy:  0.952056660310542\n",
      "Epoch number: 3816/10000step_number: 0/29 cost:  0.12413219457451825 accuracy:  0.952056660310542\n",
      "Epoch number: 3817/10000step_number: 0/29 cost:  0.12409857566493537 accuracy:  0.952056660310542\n",
      "Epoch number: 3818/10000step_number: 0/29 cost:  0.12406547259871979 accuracy:  0.952056660310542\n",
      "Epoch number: 3819/10000step_number: 0/29 cost:  0.1240332563027398 accuracy:  0.952056660310542\n",
      "Epoch number: 3820/10000step_number: 0/29 cost:  0.12400216342893418 accuracy:  0.952056660310542\n",
      "Epoch number: 3821/10000step_number: 0/29 cost:  0.12397090207570452 accuracy:  0.952056660310542\n",
      "Epoch number: 3822/10000step_number: 0/29 cost:  0.12393794138745128 accuracy:  0.952056660310542\n",
      "Epoch number: 3823/10000step_number: 0/29 cost:  0.12390431652629817 accuracy:  0.952056660310542\n",
      "Epoch number: 3824/10000step_number: 0/29 cost:  0.12387172119320661 accuracy:  0.952056660310542\n",
      "Epoch number: 3825/10000step_number: 0/29 cost:  0.1238396974834586 accuracy:  0.952056660310542\n",
      "Epoch number: 3826/10000step_number: 0/29 cost:  0.12380703908484098 accuracy:  0.952056660310542\n",
      "Epoch number: 3827/10000step_number: 0/29 cost:  0.12377401205016368 accuracy:  0.952056660310542\n",
      "Epoch number: 3828/10000step_number: 0/29 cost:  0.12374099866604958 accuracy:  0.9519204576409698\n",
      "Epoch number: 3829/10000step_number: 0/29 cost:  0.12370801908510123 accuracy:  0.9519204576409698\n",
      "Epoch number: 3830/10000step_number: 0/29 cost:  0.12367542492973572 accuracy:  0.9519204576409698\n",
      "Epoch number: 3831/10000step_number: 0/29 cost:  0.12364388602921761 accuracy:  0.9519204576409698\n",
      "Epoch number: 3832/10000step_number: 0/29 cost:  0.12361302661077649 accuracy:  0.9519204576409698\n",
      "Epoch number: 3833/10000step_number: 0/29 cost:  0.12358275281639539 accuracy:  0.9519204576409698\n",
      "Epoch number: 3834/10000step_number: 0/29 cost:  0.12355190985193742 accuracy:  0.9517842549713974\n",
      "Epoch number: 3835/10000step_number: 0/29 cost:  0.12352223567084528 accuracy:  0.9517842549713974\n",
      "Epoch number: 3836/10000step_number: 0/29 cost:  0.1234914194348922 accuracy:  0.9517842549713974\n",
      "Epoch number: 3837/10000step_number: 0/29 cost:  0.12346358703284725 accuracy:  0.9519204576409698\n",
      "Epoch number: 3838/10000step_number: 0/29 cost:  0.12342972211978356 accuracy:  0.9519204576409698\n",
      "Epoch number: 3839/10000step_number: 0/29 cost:  0.12340497655143923 accuracy:  0.9519204576409698\n",
      "Epoch number: 3840/10000step_number: 0/29 cost:  0.12336383162427987 accuracy:  0.9519204576409698\n",
      "Epoch number: 3841/10000step_number: 0/29 cost:  0.12335509086803521 accuracy:  0.9519204576409698\n",
      "Epoch number: 3842/10000step_number: 0/29 cost:  0.12329339047863339 accuracy:  0.9519204576409698\n",
      "Epoch number: 3843/10000step_number: 0/29 cost:  0.12331338450029479 accuracy:  0.9519204576409698\n",
      "Epoch number: 3844/10000step_number: 0/29 cost:  0.12321853956463581 accuracy:  0.9519204576409698\n",
      "Epoch number: 3845/10000step_number: 0/29 cost:  0.12325400115053749 accuracy:  0.9519204576409698\n",
      "Epoch number: 3846/10000step_number: 0/29 cost:  0.12316754646827677 accuracy:  0.952056660310542\n",
      "Epoch number: 3847/10000step_number: 0/29 cost:  0.12319272900454645 accuracy:  0.952056660310542\n",
      "Epoch number: 3848/10000step_number: 0/29 cost:  0.1231093963914558 accuracy:  0.952056660310542\n",
      "Epoch number: 3849/10000step_number: 0/29 cost:  0.12313223188648602 accuracy:  0.952056660310542\n",
      "Epoch number: 3850/10000step_number: 0/29 cost:  0.12305466093485916 accuracy:  0.952056660310542\n",
      "Epoch number: 3851/10000step_number: 0/29 cost:  0.12308074622250431 accuracy:  0.952056660310542\n",
      "Epoch number: 3852/10000step_number: 0/29 cost:  0.12300637084426831 accuracy:  0.952056660310542\n",
      "Epoch number: 3853/10000step_number: 0/29 cost:  0.12300998066192145 accuracy:  0.952056660310542\n",
      "Epoch number: 3854/10000step_number: 0/29 cost:  0.12293319525947809 accuracy:  0.952056660310542\n",
      "Epoch number: 3855/10000step_number: 0/29 cost:  0.12295839978029291 accuracy:  0.952056660310542\n",
      "Epoch number: 3856/10000step_number: 0/29 cost:  0.12291220038957096 accuracy:  0.952056660310542\n",
      "Epoch number: 3857/10000step_number: 0/29 cost:  0.12290735267162384 accuracy:  0.952056660310542\n",
      "Epoch number: 3858/10000step_number: 0/29 cost:  0.12280831524622596 accuracy:  0.952056660310542\n",
      "Epoch number: 3859/10000step_number: 0/29 cost:  0.12276567158906572 accuracy:  0.9519204576409698\n",
      "Epoch number: 3860/10000step_number: 0/29 cost:  0.12273847991908049 accuracy:  0.9519204576409698\n",
      "Epoch number: 3861/10000step_number: 0/29 cost:  0.12285435617210946 accuracy:  0.952465268319259\n",
      "Epoch number: 3862/10000step_number: 0/29 cost:  0.1227466455262526 accuracy:  0.952056660310542\n",
      "Epoch number: 3863/10000step_number: 0/29 cost:  0.1226509496691975 accuracy:  0.952056660310542\n",
      "Epoch number: 3864/10000step_number: 0/29 cost:  0.12230902060307793 accuracy:  0.952056660310542\n",
      "Epoch number: 3865/10000step_number: 0/29 cost:  0.12153439527878557 accuracy:  0.9513756469626805\n",
      "Epoch number: 3866/10000step_number: 0/29 cost:  0.22986496308014334 accuracy:  0.9448379188232089\n",
      "Epoch number: 3867/10000step_number: 0/29 cost:  0.17565664770545816 accuracy:  0.9449741214927813\n",
      "Epoch number: 3868/10000step_number: 0/29 cost:  0.12455061324526097 accuracy:  0.9539634976845546\n",
      "Epoch number: 3869/10000step_number: 0/29 cost:  0.12194734549782936 accuracy:  0.9547807137019886\n",
      "Epoch number: 3870/10000step_number: 0/29 cost:  0.12086350020703257 accuracy:  0.9553255243802778\n",
      "Epoch number: 3871/10000step_number: 0/29 cost:  0.11829447706765384 accuracy:  0.9549169163715608\n",
      "Epoch number: 3872/10000step_number: 0/29 cost:  0.11957881404629092 accuracy:  0.9549169163715608\n",
      "Epoch number: 3873/10000step_number: 0/29 cost:  0.11984529919493436 accuracy:  0.954508308362844\n",
      "Epoch number: 3874/10000step_number: 0/29 cost:  0.12011440557529474 accuracy:  0.954508308362844\n",
      "Epoch number: 3875/10000step_number: 0/29 cost:  0.12034360895430311 accuracy:  0.954508308362844\n",
      "Epoch number: 3876/10000step_number: 0/29 cost:  0.12052871207012188 accuracy:  0.954508308362844\n",
      "Epoch number: 3877/10000step_number: 0/29 cost:  0.12065714860197178 accuracy:  0.954099700354127\n",
      "Epoch number: 3878/10000step_number: 0/29 cost:  0.12075162110780335 accuracy:  0.9542359030236993\n",
      "Epoch number: 3879/10000step_number: 0/29 cost:  0.12081764792114522 accuracy:  0.9536910923454099\n",
      "Epoch number: 3880/10000step_number: 0/29 cost:  0.12085877347370956 accuracy:  0.9536910923454099\n",
      "Epoch number: 3881/10000step_number: 0/29 cost:  0.12087688369488031 accuracy:  0.9535548896758377\n",
      "Epoch number: 3882/10000step_number: 0/29 cost:  0.12087593064344838 accuracy:  0.952056660310542\n",
      "Epoch number: 3883/10000step_number: 0/29 cost:  0.12086166957300003 accuracy:  0.952056660310542\n",
      "Epoch number: 3884/10000step_number: 0/29 cost:  0.12084026694938849 accuracy:  0.952056660310542\n",
      "Epoch number: 3885/10000step_number: 0/29 cost:  0.12081625661936846 accuracy:  0.952056660310542\n",
      "Epoch number: 3886/10000step_number: 0/29 cost:  0.12079267689839683 accuracy:  0.9519204576409698\n",
      "Epoch number: 3887/10000step_number: 0/29 cost:  0.12077139611001295 accuracy:  0.9519204576409698\n",
      "Epoch number: 3888/10000step_number: 0/29 cost:  0.12075363339864319 accuracy:  0.9517842549713974\n",
      "Epoch number: 3889/10000step_number: 0/29 cost:  0.12074016641219053 accuracy:  0.9517842549713974\n",
      "Epoch number: 3890/10000step_number: 0/29 cost:  0.12073145751127864 accuracy:  0.9517842549713974\n",
      "Epoch number: 3891/10000step_number: 0/29 cost:  0.12072769558028949 accuracy:  0.9517842549713974\n",
      "Epoch number: 3892/10000step_number: 0/29 cost:  0.12072884986853676 accuracy:  0.9517842549713974\n",
      "Epoch number: 3893/10000step_number: 0/29 cost:  0.12073470352524782 accuracy:  0.9519204576409698\n",
      "Epoch number: 3894/10000step_number: 0/29 cost:  0.12074489031403594 accuracy:  0.952056660310542\n",
      "Epoch number: 3895/10000step_number: 0/29 cost:  0.12075892332520971 accuracy:  0.952056660310542\n",
      "Epoch number: 3896/10000step_number: 0/29 cost:  0.12077622768944196 accuracy:  0.952056660310542\n",
      "Epoch number: 3897/10000step_number: 0/29 cost:  0.12079616884231778 accuracy:  0.952056660310542\n",
      "Epoch number: 3898/10000step_number: 0/29 cost:  0.1208180840214721 accuracy:  0.952056660310542\n",
      "Epoch number: 3899/10000step_number: 0/29 cost:  0.12084130771546266 accuracy:  0.952056660310542\n",
      "Epoch number: 3900/10000step_number: 0/29 cost:  0.12086519832672701 accuracy:  0.952056660310542\n",
      "Epoch number: 3901/10000step_number: 0/29 cost:  0.12088915599609036 accuracy:  0.9521928629801144\n",
      "Epoch number: 3902/10000step_number: 0/29 cost:  0.12091264072200351 accuracy:  0.9521928629801144\n",
      "Epoch number: 3903/10000step_number: 0/29 cost:  0.12093517912405972 accuracy:  0.9521928629801144\n",
      "Epoch number: 3904/10000step_number: 0/29 cost:  0.12095637248341115 accuracy:  0.9521928629801144\n",
      "Epoch number: 3905/10000step_number: 0/29 cost:  0.12097589137323764 accuracy:  0.9521928629801144\n",
      "Epoch number: 3906/10000step_number: 0/29 cost:  0.12099347578004468 accuracy:  0.9521928629801144\n",
      "Epoch number: 3907/10000step_number: 0/29 cost:  0.12100892045707287 accuracy:  0.9523290656496868\n",
      "Epoch number: 3908/10000step_number: 0/29 cost:  0.1210220742731978 accuracy:  0.9526014709888314\n",
      "Epoch number: 3909/10000step_number: 0/29 cost:  0.12103282134918368 accuracy:  0.9527376736584037\n",
      "Epoch number: 3910/10000step_number: 0/29 cost:  0.12104108809634495 accuracy:  0.9527376736584037\n",
      "Epoch number: 3911/10000step_number: 0/29 cost:  0.12104682103766781 accuracy:  0.952873876327976\n",
      "Epoch number: 3912/10000step_number: 0/29 cost:  0.12105000791505957 accuracy:  0.952873876327976\n",
      "Epoch number: 3913/10000step_number: 0/29 cost:  0.12105064533703014 accuracy:  0.952873876327976\n",
      "Epoch number: 3914/10000step_number: 0/29 cost:  0.12104878050804067 accuracy:  0.952873876327976\n",
      "Epoch number: 3915/10000step_number: 0/29 cost:  0.12104445156186434 accuracy:  0.9530100789975483\n",
      "Epoch number: 3916/10000step_number: 0/29 cost:  0.12103776386486749 accuracy:  0.9530100789975483\n",
      "Epoch number: 3917/10000step_number: 0/29 cost:  0.12102877259102121 accuracy:  0.9530100789975483\n",
      "Epoch number: 3918/10000step_number: 0/29 cost:  0.12101763292016378 accuracy:  0.9530100789975483\n",
      "Epoch number: 3919/10000step_number: 0/29 cost:  0.12100436982222096 accuracy:  0.9530100789975483\n",
      "Epoch number: 3920/10000step_number: 0/29 cost:  0.1209891948370713 accuracy:  0.952873876327976\n",
      "Epoch number: 3921/10000step_number: 0/29 cost:  0.12097203839713984 accuracy:  0.952873876327976\n",
      "Epoch number: 3922/10000step_number: 0/29 cost:  0.1209532335605642 accuracy:  0.952873876327976\n",
      "Epoch number: 3923/10000step_number: 0/29 cost:  0.12093250940496202 accuracy:  0.952873876327976\n",
      "Epoch number: 3924/10000step_number: 0/29 cost:  0.12091050101562034 accuracy:  0.952873876327976\n",
      "Epoch number: 3925/10000step_number: 0/29 cost:  0.12088648016005903 accuracy:  0.9527376736584037\n",
      "Epoch number: 3926/10000step_number: 0/29 cost:  0.12086181029896782 accuracy:  0.9526014709888314\n",
      "Epoch number: 3927/10000step_number: 0/29 cost:  0.12083463901912501 accuracy:  0.9526014709888314\n",
      "Epoch number: 3928/10000step_number: 0/29 cost:  0.12080811254252755 accuracy:  0.9526014709888314\n",
      "Epoch number: 3929/10000step_number: 0/29 cost:  0.1207775391901305 accuracy:  0.9527376736584037\n",
      "Epoch number: 3930/10000step_number: 0/29 cost:  0.12075055295499963 accuracy:  0.9527376736584037\n",
      "Epoch number: 3931/10000step_number: 0/29 cost:  0.12071542912248825 accuracy:  0.9527376736584037\n",
      "Epoch number: 3932/10000step_number: 0/29 cost:  0.1206902838451968 accuracy:  0.9527376736584037\n",
      "Epoch number: 3933/10000step_number: 0/29 cost:  0.12064951473471257 accuracy:  0.9527376736584037\n",
      "Epoch number: 3934/10000step_number: 0/29 cost:  0.12062412708292872 accuracy:  0.952465268319259\n",
      "Epoch number: 3935/10000step_number: 0/29 cost:  0.12058177267677986 accuracy:  0.952465268319259\n",
      "Epoch number: 3936/10000step_number: 0/29 cost:  0.12054927123869857 accuracy:  0.952465268319259\n",
      "Epoch number: 3937/10000step_number: 0/29 cost:  0.12050851714996685 accuracy:  0.952465268319259\n",
      "Epoch number: 3938/10000step_number: 0/29 cost:  0.1204751662559543 accuracy:  0.952465268319259\n",
      "Epoch number: 3939/10000step_number: 0/29 cost:  0.12043249611763375 accuracy:  0.952465268319259\n",
      "Epoch number: 3940/10000step_number: 0/29 cost:  0.12039497829817088 accuracy:  0.9523290656496868\n",
      "Epoch number: 3941/10000step_number: 0/29 cost:  0.12035010988052784 accuracy:  0.9521928629801144\n",
      "Epoch number: 3942/10000step_number: 0/29 cost:  0.12030933628629085 accuracy:  0.9521928629801144\n",
      "Epoch number: 3943/10000step_number: 0/29 cost:  0.12026219470377043 accuracy:  0.9521928629801144\n",
      "Epoch number: 3944/10000step_number: 0/29 cost:  0.12021830744305831 accuracy:  0.9521928629801144\n",
      "Epoch number: 3945/10000step_number: 0/29 cost:  0.12016872837865858 accuracy:  0.952056660310542\n",
      "Epoch number: 3946/10000step_number: 0/29 cost:  0.12012197080998605 accuracy:  0.952056660310542\n",
      "Epoch number: 3947/10000step_number: 0/29 cost:  0.12007009765906879 accuracy:  0.952056660310542\n",
      "Epoch number: 3948/10000step_number: 0/29 cost:  0.12002095222698264 accuracy:  0.952056660310542\n",
      "Epoch number: 3949/10000step_number: 0/29 cost:  0.1199671906134704 accuracy:  0.9521928629801144\n",
      "Epoch number: 3950/10000step_number: 0/29 cost:  0.11991633886784216 accuracy:  0.9521928629801144\n",
      "Epoch number: 3951/10000step_number: 0/29 cost:  0.11986130753467981 accuracy:  0.9521928629801144\n",
      "Epoch number: 3952/10000step_number: 0/29 cost:  0.1198096090185679 accuracy:  0.9521928629801144\n",
      "Epoch number: 3953/10000step_number: 0/29 cost:  0.11975408830063347 accuracy:  0.9521928629801144\n",
      "Epoch number: 3954/10000step_number: 0/29 cost:  0.11970253033256137 accuracy:  0.9521928629801144\n",
      "Epoch number: 3955/10000step_number: 0/29 cost:  0.11964738568406404 accuracy:  0.9521928629801144\n",
      "Epoch number: 3956/10000step_number: 0/29 cost:  0.11959702139379086 accuracy:  0.9521928629801144\n",
      "Epoch number: 3957/10000step_number: 0/29 cost:  0.11954313137210534 accuracy:  0.9521928629801144\n",
      "Epoch number: 3958/10000step_number: 0/29 cost:  0.11949502903554267 accuracy:  0.9521928629801144\n",
      "Epoch number: 3959/10000step_number: 0/29 cost:  0.1194432233737669 accuracy:  0.9521928629801144\n",
      "Epoch number: 3960/10000step_number: 0/29 cost:  0.11939841267407957 accuracy:  0.9521928629801144\n",
      "Epoch number: 3961/10000step_number: 0/29 cost:  0.11934939055030024 accuracy:  0.9521928629801144\n",
      "Epoch number: 3962/10000step_number: 0/29 cost:  0.11930875899215901 accuracy:  0.9521928629801144\n",
      "Epoch number: 3963/10000step_number: 0/29 cost:  0.11926294449518313 accuracy:  0.9521928629801144\n",
      "Epoch number: 3964/10000step_number: 0/29 cost:  0.11922704659093958 accuracy:  0.9521928629801144\n",
      "Epoch number: 3965/10000step_number: 0/29 cost:  0.1191843878421705 accuracy:  0.9521928629801144\n",
      "Epoch number: 3966/10000step_number: 0/29 cost:  0.11915321367475476 accuracy:  0.9521928629801144\n",
      "Epoch number: 3967/10000step_number: 0/29 cost:  0.11911304129656591 accuracy:  0.952056660310542\n",
      "Epoch number: 3968/10000step_number: 0/29 cost:  0.11908591012631518 accuracy:  0.9519204576409698\n",
      "Epoch number: 3969/10000step_number: 0/29 cost:  0.11904704983061201 accuracy:  0.9519204576409698\n",
      "Epoch number: 3970/10000step_number: 0/29 cost:  0.11902283024869456 accuracy:  0.9519204576409698\n",
      "Epoch number: 3971/10000step_number: 0/29 cost:  0.1189840693972636 accuracy:  0.9519204576409698\n",
      "Epoch number: 3972/10000step_number: 0/29 cost:  0.11896170856569188 accuracy:  0.9519204576409698\n",
      "Epoch number: 3973/10000step_number: 0/29 cost:  0.11892234285743743 accuracy:  0.9519204576409698\n",
      "Epoch number: 3974/10000step_number: 0/29 cost:  0.11890126986650218 accuracy:  0.9519204576409698\n",
      "Epoch number: 3975/10000step_number: 0/29 cost:  0.11886122532986627 accuracy:  0.9517842549713974\n",
      "Epoch number: 3976/10000step_number: 0/29 cost:  0.11884127828202491 accuracy:  0.9517842549713974\n",
      "Epoch number: 3977/10000step_number: 0/29 cost:  0.11880079596204426 accuracy:  0.9516480523018251\n",
      "Epoch number: 3978/10000step_number: 0/29 cost:  0.11878192760492598 accuracy:  0.9516480523018251\n",
      "Epoch number: 3979/10000step_number: 0/29 cost:  0.11874125055536104 accuracy:  0.9516480523018251\n",
      "Epoch number: 3980/10000step_number: 0/29 cost:  0.11872337007317944 accuracy:  0.9516480523018251\n",
      "Epoch number: 3981/10000step_number: 0/29 cost:  0.11868264300715331 accuracy:  0.9516480523018251\n",
      "Epoch number: 3982/10000step_number: 0/29 cost:  0.11866562239614577 accuracy:  0.9516480523018251\n",
      "Epoch number: 3983/10000step_number: 0/29 cost:  0.11862491788607986 accuracy:  0.9516480523018251\n",
      "Epoch number: 3984/10000step_number: 0/29 cost:  0.11860864769427389 accuracy:  0.9516480523018251\n",
      "Epoch number: 3985/10000step_number: 0/29 cost:  0.11856800812906053 accuracy:  0.9516480523018251\n",
      "Epoch number: 3986/10000step_number: 0/29 cost:  0.11855243516307383 accuracy:  0.9516480523018251\n",
      "Epoch number: 3987/10000step_number: 0/29 cost:  0.11851189157259692 accuracy:  0.9516480523018251\n",
      "Epoch number: 3988/10000step_number: 0/29 cost:  0.11849702915905397 accuracy:  0.9516480523018251\n",
      "Epoch number: 3989/10000step_number: 0/29 cost:  0.11845660052659301 accuracy:  0.9516480523018251\n",
      "Epoch number: 3990/10000step_number: 0/29 cost:  0.1184425221177955 accuracy:  0.9516480523018251\n",
      "Epoch number: 3991/10000step_number: 0/29 cost:  0.11840220777696873 accuracy:  0.9516480523018251\n",
      "Epoch number: 3992/10000step_number: 0/29 cost:  0.11838903431389208 accuracy:  0.9516480523018251\n",
      "Epoch number: 3993/10000step_number: 0/29 cost:  0.11834880819874542 accuracy:  0.9516480523018251\n",
      "Epoch number: 3994/10000step_number: 0/29 cost:  0.11833669455190195 accuracy:  0.9516480523018251\n",
      "Epoch number: 3995/10000step_number: 0/29 cost:  0.11829650461460642 accuracy:  0.9516480523018251\n",
      "Epoch number: 3996/10000step_number: 0/29 cost:  0.11828562630153917 accuracy:  0.9516480523018251\n",
      "Epoch number: 3997/10000step_number: 0/29 cost:  0.11824539856397139 accuracy:  0.9516480523018251\n",
      "Epoch number: 3998/10000step_number: 0/29 cost:  0.11823593782908065 accuracy:  0.9517842549713974\n",
      "Epoch number: 3999/10000step_number: 0/29 cost:  0.11819558257678688 accuracy:  0.9517842549713974\n",
      "Epoch number: 4000/10000step_number: 0/29 cost:  0.11818771268044863 accuracy:  0.9517842549713974\n",
      "Epoch number: 4001/10000step_number: 0/29 cost:  0.11814712986852983 accuracy:  0.9517842549713974\n",
      "Epoch number: 4002/10000step_number: 0/29 cost:  0.1181409977704361 accuracy:  0.9517842549713974\n",
      "Epoch number: 4003/10000step_number: 0/29 cost:  0.11810007947769853 accuracy:  0.9517842549713974\n",
      "Epoch number: 4004/10000step_number: 0/29 cost:  0.11809578938525327 accuracy:  0.9519204576409698\n",
      "Epoch number: 4005/10000step_number: 0/29 cost:  0.11805441883140967 accuracy:  0.9519204576409698\n",
      "Epoch number: 4006/10000step_number: 0/29 cost:  0.11805202097045639 accuracy:  0.9519204576409698\n",
      "Epoch number: 4007/10000step_number: 0/29 cost:  0.11801006959313956 accuracy:  0.9519204576409698\n",
      "Epoch number: 4008/10000step_number: 0/29 cost:  0.11800955833561524 accuracy:  0.9519204576409698\n",
      "Epoch number: 4009/10000step_number: 0/29 cost:  0.11796688371923618 accuracy:  0.9519204576409698\n",
      "Epoch number: 4010/10000step_number: 0/29 cost:  0.11796820619516518 accuracy:  0.9519204576409698\n",
      "Epoch number: 4011/10000step_number: 0/29 cost:  0.11792465346029529 accuracy:  0.952056660310542\n",
      "Epoch number: 4012/10000step_number: 0/29 cost:  0.11792772546991637 accuracy:  0.952056660310542\n",
      "Epoch number: 4013/10000step_number: 0/29 cost:  0.11788313325020251 accuracy:  0.952056660310542\n",
      "Epoch number: 4014/10000step_number: 0/29 cost:  0.11788785638858633 accuracy:  0.952056660310542\n",
      "Epoch number: 4015/10000step_number: 0/29 cost:  0.11784206685666206 accuracy:  0.952056660310542\n",
      "Epoch number: 4016/10000step_number: 0/29 cost:  0.1178483408458691 accuracy:  0.952056660310542\n",
      "Epoch number: 4017/10000step_number: 0/29 cost:  0.11780121243806028 accuracy:  0.952056660310542\n",
      "Epoch number: 4018/10000step_number: 0/29 cost:  0.1178089390725905 accuracy:  0.952056660310542\n",
      "Epoch number: 4019/10000step_number: 0/29 cost:  0.11776036068794307 accuracy:  0.952056660310542\n",
      "Epoch number: 4020/10000step_number: 0/29 cost:  0.11776943880213359 accuracy:  0.952056660310542\n",
      "Epoch number: 4021/10000step_number: 0/29 cost:  0.11771934461372444 accuracy:  0.952056660310542\n",
      "Epoch number: 4022/10000step_number: 0/29 cost:  0.1177296578691655 accuracy:  0.952056660310542\n",
      "Epoch number: 4023/10000step_number: 0/29 cost:  0.11767804179920882 accuracy:  0.9521928629801144\n",
      "Epoch number: 4024/10000step_number: 0/29 cost:  0.1176894426289201 accuracy:  0.9521928629801144\n",
      "Epoch number: 4025/10000step_number: 0/29 cost:  0.11763637083807504 accuracy:  0.9523290656496868\n",
      "Epoch number: 4026/10000step_number: 0/29 cost:  0.1176486648059744 accuracy:  0.9523290656496868\n",
      "Epoch number: 4027/10000step_number: 0/29 cost:  0.11759428354871838 accuracy:  0.9523290656496868\n",
      "Epoch number: 4028/10000step_number: 0/29 cost:  0.1176072188334437 accuracy:  0.952465268319259\n",
      "Epoch number: 4029/10000step_number: 0/29 cost:  0.11755175430211376 accuracy:  0.952465268319259\n",
      "Epoch number: 4030/10000step_number: 0/29 cost:  0.1175650208174049 accuracy:  0.952465268319259\n",
      "Epoch number: 4031/10000step_number: 0/29 cost:  0.11750876777152373 accuracy:  0.952465268319259\n",
      "Epoch number: 4032/10000step_number: 0/29 cost:  0.11752200917121826 accuracy:  0.952465268319259\n",
      "Epoch number: 4033/10000step_number: 0/29 cost:  0.11746530675199623 accuracy:  0.952465268319259\n",
      "Epoch number: 4034/10000step_number: 0/29 cost:  0.11747814588386281 accuracy:  0.952465268319259\n",
      "Epoch number: 4035/10000step_number: 0/29 cost:  0.11742134217704155 accuracy:  0.952465268319259\n",
      "Epoch number: 4036/10000step_number: 0/29 cost:  0.11743341660781445 accuracy:  0.9526014709888314\n",
      "Epoch number: 4037/10000step_number: 0/29 cost:  0.11737682761790386 accuracy:  0.9526014709888314\n",
      "Epoch number: 4038/10000step_number: 0/29 cost:  0.11738782769585865 accuracy:  0.9526014709888314\n",
      "Epoch number: 4039/10000step_number: 0/29 cost:  0.11733169988449448 accuracy:  0.9527376736584037\n",
      "Epoch number: 4040/10000step_number: 0/29 cost:  0.11734139930741698 accuracy:  0.9527376736584037\n",
      "Epoch number: 4041/10000step_number: 0/29 cost:  0.11728588565660703 accuracy:  0.9527376736584037\n",
      "Epoch number: 4042/10000step_number: 0/29 cost:  0.11729415559220568 accuracy:  0.9527376736584037\n",
      "Epoch number: 4043/10000step_number: 0/29 cost:  0.11723931181833225 accuracy:  0.9527376736584037\n",
      "Epoch number: 4044/10000step_number: 0/29 cost:  0.11724611486638115 accuracy:  0.9527376736584037\n",
      "Epoch number: 4045/10000step_number: 0/29 cost:  0.11719191550423268 accuracy:  0.9527376736584037\n",
      "Epoch number: 4046/10000step_number: 0/29 cost:  0.11719728330431947 accuracy:  0.952873876327976\n",
      "Epoch number: 4047/10000step_number: 0/29 cost:  0.11714365004060773 accuracy:  0.952873876327976\n",
      "Epoch number: 4048/10000step_number: 0/29 cost:  0.11714765414744578 accuracy:  0.952873876327976\n",
      "Epoch number: 4049/10000step_number: 0/29 cost:  0.11709448522914262 accuracy:  0.952873876327976\n",
      "Epoch number: 4050/10000step_number: 0/29 cost:  0.11709721144074914 accuracy:  0.952873876327976\n",
      "Epoch number: 4051/10000step_number: 0/29 cost:  0.11704440337898457 accuracy:  0.952873876327976\n",
      "Epoch number: 4052/10000step_number: 0/29 cost:  0.11704593493376991 accuracy:  0.9531462816671207\n",
      "Epoch number: 4053/10000step_number: 0/29 cost:  0.11699339395651315 accuracy:  0.9531462816671207\n",
      "Epoch number: 4054/10000step_number: 0/29 cost:  0.1169938028735754 accuracy:  0.9531462816671207\n",
      "Epoch number: 4055/10000step_number: 0/29 cost:  0.11694144876021187 accuracy:  0.9531462816671207\n",
      "Epoch number: 4056/10000step_number: 0/29 cost:  0.11694079165108191 accuracy:  0.9531462816671207\n",
      "Epoch number: 4057/10000step_number: 0/29 cost:  0.11688855759420175 accuracy:  0.9531462816671207\n",
      "Epoch number: 4058/10000step_number: 0/29 cost:  0.11688687336203132 accuracy:  0.9531462816671207\n",
      "Epoch number: 4059/10000step_number: 0/29 cost:  0.11683470374087163 accuracy:  0.9531462816671207\n",
      "Epoch number: 4060/10000step_number: 0/29 cost:  0.11683201271271133 accuracy:  0.9531462816671207\n",
      "Epoch number: 4061/10000step_number: 0/29 cost:  0.11677985945336003 accuracy:  0.9531462816671207\n",
      "Epoch number: 4062/10000step_number: 0/29 cost:  0.11677616415058058 accuracy:  0.9531462816671207\n",
      "Epoch number: 4063/10000step_number: 0/29 cost:  0.1167239826075468 accuracy:  0.9531462816671207\n",
      "Epoch number: 4064/10000step_number: 0/29 cost:  0.11671927009149936 accuracy:  0.9531462816671207\n",
      "Epoch number: 4065/10000step_number: 0/29 cost:  0.11666701565934176 accuracy:  0.9531462816671207\n",
      "Epoch number: 4066/10000step_number: 0/29 cost:  0.11666126141048506 accuracy:  0.9531462816671207\n",
      "Epoch number: 4067/10000step_number: 0/29 cost:  0.11660888771946291 accuracy:  0.953282484336693\n",
      "Epoch number: 4068/10000step_number: 0/29 cost:  0.11660206095165074 accuracy:  0.953282484336693\n",
      "Epoch number: 4069/10000step_number: 0/29 cost:  0.11654952002108704 accuracy:  0.953282484336693\n",
      "Epoch number: 4070/10000step_number: 0/29 cost:  0.11654158970206058 accuracy:  0.953282484336693\n",
      "Epoch number: 4071/10000step_number: 0/29 cost:  0.11648883371937259 accuracy:  0.953282484336693\n",
      "Epoch number: 4072/10000step_number: 0/29 cost:  0.11647977378484171 accuracy:  0.953282484336693\n",
      "Epoch number: 4073/10000step_number: 0/29 cost:  0.11642675709390723 accuracy:  0.953282484336693\n",
      "Epoch number: 4074/10000step_number: 0/29 cost:  0.1164165487630377 accuracy:  0.9531462816671207\n",
      "Epoch number: 4075/10000step_number: 0/29 cost:  0.11636322788691372 accuracy:  0.9531462816671207\n",
      "Epoch number: 4076/10000step_number: 0/29 cost:  0.11635185705524097 accuracy:  0.9531462816671207\n",
      "Epoch number: 4077/10000step_number: 0/29 cost:  0.11629818693493904 accuracy:  0.9531462816671207\n",
      "Epoch number: 4078/10000step_number: 0/29 cost:  0.1162856361139051 accuracy:  0.9530100789975483\n",
      "Epoch number: 4079/10000step_number: 0/29 cost:  0.11623156269466066 accuracy:  0.9530100789975483\n",
      "Epoch number: 4080/10000step_number: 0/29 cost:  0.11621779998813828 accuracy:  0.9530100789975483\n",
      "Epoch number: 4081/10000step_number: 0/29 cost:  0.11616325256645568 accuracy:  0.9530100789975483\n",
      "Epoch number: 4082/10000step_number: 0/29 cost:  0.11614822364254543 accuracy:  0.9530100789975483\n",
      "Epoch number: 4083/10000step_number: 0/29 cost:  0.11609311341496575 accuracy:  0.9530100789975483\n",
      "Epoch number: 4084/10000step_number: 0/29 cost:  0.11607674418727223 accuracy:  0.9531462816671207\n",
      "Epoch number: 4085/10000step_number: 0/29 cost:  0.11602097586291808 accuracy:  0.953282484336693\n",
      "Epoch number: 4086/10000step_number: 0/29 cost:  0.11600319135154231 accuracy:  0.953282484336693\n",
      "Epoch number: 4087/10000step_number: 0/29 cost:  0.11594669068828602 accuracy:  0.953282484336693\n",
      "Epoch number: 4088/10000step_number: 0/29 cost:  0.11592744848481225 accuracy:  0.953282484336693\n",
      "Epoch number: 4089/10000step_number: 0/29 cost:  0.11587020034922019 accuracy:  0.953282484336693\n",
      "Epoch number: 4090/10000step_number: 0/29 cost:  0.11584952712025404 accuracy:  0.953282484336693\n",
      "Epoch number: 4091/10000step_number: 0/29 cost:  0.11579160904015441 accuracy:  0.953282484336693\n",
      "Epoch number: 4092/10000step_number: 0/29 cost:  0.11576962020417884 accuracy:  0.953282484336693\n",
      "Epoch number: 4093/10000step_number: 0/29 cost:  0.11571121061265531 accuracy:  0.953282484336693\n",
      "Epoch number: 4094/10000step_number: 0/29 cost:  0.1156880927929312 accuracy:  0.953282484336693\n",
      "Epoch number: 4095/10000step_number: 0/29 cost:  0.11562943698140866 accuracy:  0.953282484336693\n",
      "Epoch number: 4096/10000step_number: 0/29 cost:  0.11560538444551954 accuracy:  0.953282484336693\n",
      "Epoch number: 4097/10000step_number: 0/29 cost:  0.11554671718946269 accuracy:  0.953282484336693\n",
      "Epoch number: 4098/10000step_number: 0/29 cost:  0.11552183554743266 accuracy:  0.953282484336693\n",
      "Epoch number: 4099/10000step_number: 0/29 cost:  0.11546328304283755 accuracy:  0.953282484336693\n",
      "Epoch number: 4100/10000step_number: 0/29 cost:  0.11543749677283557 accuracy:  0.953282484336693\n",
      "Epoch number: 4101/10000step_number: 0/29 cost:  0.11537900174997795 accuracy:  0.953282484336693\n",
      "Epoch number: 4102/10000step_number: 0/29 cost:  0.11535201586844968 accuracy:  0.953282484336693\n",
      "Epoch number: 4103/10000step_number: 0/29 cost:  0.11529333985208025 accuracy:  0.953282484336693\n",
      "Epoch number: 4104/10000step_number: 0/29 cost:  0.11526470583071907 accuracy:  0.953282484336693\n",
      "Epoch number: 4105/10000step_number: 0/29 cost:  0.1152055575314314 accuracy:  0.953282484336693\n",
      "Epoch number: 4106/10000step_number: 0/29 cost:  0.11517487739793739 accuracy:  0.9530100789975483\n",
      "Epoch number: 4107/10000step_number: 0/29 cost:  0.11511518768838833 accuracy:  0.9530100789975483\n",
      "Epoch number: 4108/10000step_number: 0/29 cost:  0.11508244484350943 accuracy:  0.9531462816671207\n",
      "Epoch number: 4109/10000step_number: 0/29 cost:  0.11502273541193353 accuracy:  0.9530100789975483\n",
      "Epoch number: 4110/10000step_number: 0/29 cost:  0.1149886414370852 accuracy:  0.9530100789975483\n",
      "Epoch number: 4111/10000step_number: 0/29 cost:  0.11493029799339609 accuracy:  0.9530100789975483\n",
      "Epoch number: 4112/10000step_number: 0/29 cost:  0.11489639148127734 accuracy:  0.9530100789975483\n",
      "Epoch number: 4113/10000step_number: 0/29 cost:  0.11484150112245116 accuracy:  0.9530100789975483\n",
      "Epoch number: 4114/10000step_number: 0/29 cost:  0.11480963772530356 accuracy:  0.9530100789975483\n",
      "Epoch number: 4115/10000step_number: 0/29 cost:  0.11476008827287801 accuracy:  0.952873876327976\n",
      "Epoch number: 4116/10000step_number: 0/29 cost:  0.11473118136171741 accuracy:  0.952873876327976\n",
      "Epoch number: 4117/10000step_number: 0/29 cost:  0.11468719558544159 accuracy:  0.952873876327976\n",
      "Epoch number: 4118/10000step_number: 0/29 cost:  0.1146596949283581 accuracy:  0.952873876327976\n",
      "Epoch number: 4119/10000step_number: 0/29 cost:  0.11461862300402324 accuracy:  0.952873876327976\n",
      "Epoch number: 4120/10000step_number: 0/29 cost:  0.11458766596715354 accuracy:  0.952873876327976\n",
      "Epoch number: 4121/10000step_number: 0/29 cost:  0.11454378580092817 accuracy:  0.952873876327976\n",
      "Epoch number: 4122/10000step_number: 0/29 cost:  0.11450157599985752 accuracy:  0.9530100789975483\n",
      "Epoch number: 4123/10000step_number: 0/29 cost:  0.11444688223078495 accuracy:  0.9530100789975483\n",
      "Epoch number: 4124/10000step_number: 0/29 cost:  0.11438457846398002 accuracy:  0.9531462816671207\n",
      "Epoch number: 4125/10000step_number: 0/29 cost:  0.11431123970173587 accuracy:  0.9530100789975483\n",
      "Epoch number: 4126/10000step_number: 0/29 cost:  0.1142244954734787 accuracy:  0.9530100789975483\n",
      "Epoch number: 4127/10000step_number: 0/29 cost:  0.11413323507792777 accuracy:  0.952873876327976\n",
      "Epoch number: 4128/10000step_number: 0/29 cost:  0.1140360764595358 accuracy:  0.952873876327976\n",
      "Epoch number: 4129/10000step_number: 0/29 cost:  0.11395349400725747 accuracy:  0.952873876327976\n",
      "Epoch number: 4130/10000step_number: 0/29 cost:  0.11389088292017323 accuracy:  0.9530100789975483\n",
      "Epoch number: 4131/10000step_number: 0/29 cost:  0.11386780809779573 accuracy:  0.9531462816671207\n",
      "Epoch number: 4132/10000step_number: 0/29 cost:  0.11387106013466118 accuracy:  0.9531462816671207\n",
      "Epoch number: 4133/10000step_number: 0/29 cost:  0.11389552376022334 accuracy:  0.9531462816671207\n",
      "Epoch number: 4134/10000step_number: 0/29 cost:  0.11384760973035774 accuracy:  0.9531462816671207\n",
      "Epoch number: 4135/10000step_number: 0/29 cost:  0.11417500163218268 accuracy:  0.9531462816671207\n",
      "Epoch number: 4136/10000step_number: 0/29 cost:  0.11453093552659985 accuracy:  0.9530100789975483\n",
      "Epoch number: 4137/10000step_number: 0/29 cost:  0.11446767719642206 accuracy:  0.9531462816671207\n",
      "Epoch number: 4138/10000step_number: 0/29 cost:  0.11424211563803238 accuracy:  0.952873876327976\n",
      "Epoch number: 4139/10000step_number: 0/29 cost:  0.11412004220615966 accuracy:  0.9527376736584037\n",
      "Epoch number: 4140/10000step_number: 0/29 cost:  0.1157895070966124 accuracy:  0.952873876327976\n",
      "Epoch number: 4141/10000step_number: 0/29 cost:  0.1155539992291175 accuracy:  0.952465268319259\n",
      "Epoch number: 4142/10000step_number: 0/29 cost:  0.11498298603109987 accuracy:  0.952465268319259\n",
      "Epoch number: 4143/10000step_number: 0/29 cost:  0.11495975302304977 accuracy:  0.9521928629801144\n",
      "Epoch number: 4144/10000step_number: 0/29 cost:  nan accuracy:  0.952465268319259\n",
      "Epoch number: 4145/10000step_number: 0/29 cost:  0.11613018658941422 accuracy:  0.9517842549713974\n",
      "Epoch number: 4146/10000step_number: 0/29 cost:  0.11555069714710893 accuracy:  0.952873876327976\n",
      "Epoch number: 4147/10000step_number: 0/29 cost:  0.11255085372379625 accuracy:  0.9543721056932716\n",
      "Epoch number: 4148/10000step_number: 0/29 cost:  0.10846396637633547 accuracy:  0.9534186870062653\n",
      "Epoch number: 4149/10000step_number: 0/29 cost:  0.1136308194528094 accuracy:  0.9534186870062653\n",
      "Epoch number: 4150/10000step_number: 0/29 cost:  0.11821741197781052 accuracy:  0.954099700354127\n",
      "Epoch number: 4151/10000step_number: 0/29 cost:  nan accuracy:  0.9399346227186053\n",
      "Epoch number: 4152/10000step_number: 0/29 cost:  0.22384478128018728 accuracy:  0.9464723508580768\n",
      "Epoch number: 4153/10000step_number: 0/29 cost:  0.15585318094966294 accuracy:  0.9504222282756742\n",
      "Epoch number: 4154/10000step_number: 0/29 cost:  0.11726688363660995 accuracy:  0.9535548896758377\n",
      "Epoch number: 4155/10000step_number: 0/29 cost:  0.11021037219419232 accuracy:  0.9550531190411332\n",
      "Epoch number: 4156/10000step_number: 0/29 cost:  0.11212893545318094 accuracy:  0.9564151457368565\n",
      "Epoch number: 4157/10000step_number: 0/29 cost:  0.11039024420623397 accuracy:  0.9555979297194225\n",
      "Epoch number: 4158/10000step_number: 0/29 cost:  0.11117650455672372 accuracy:  0.9553255243802778\n",
      "Epoch number: 4159/10000step_number: 0/29 cost:  0.11095040214302483 accuracy:  0.9557341323889949\n",
      "Epoch number: 4160/10000step_number: 0/29 cost:  0.11154902130710215 accuracy:  0.9555979297194225\n",
      "Epoch number: 4161/10000step_number: 0/29 cost:  0.11162394170099019 accuracy:  0.9558703350585671\n",
      "Epoch number: 4162/10000step_number: 0/29 cost:  0.11204313749895556 accuracy:  0.9561427403977117\n",
      "Epoch number: 4163/10000step_number: 0/29 cost:  0.1122633172552088 accuracy:  0.9560065377281395\n",
      "Epoch number: 4164/10000step_number: 0/29 cost:  0.11257657634738731 accuracy:  0.9561427403977117\n",
      "Epoch number: 4165/10000step_number: 0/29 cost:  0.11280829806099639 accuracy:  0.9561427403977117\n",
      "Epoch number: 4166/10000step_number: 0/29 cost:  0.11305178725961654 accuracy:  0.9561427403977117\n",
      "Epoch number: 4167/10000step_number: 0/29 cost:  0.113260435352396 accuracy:  0.9558703350585671\n",
      "Epoch number: 4168/10000step_number: 0/29 cost:  0.11346310854271013 accuracy:  0.9542359030236993\n",
      "Epoch number: 4169/10000step_number: 0/29 cost:  0.11364612721397471 accuracy:  0.9543721056932716\n",
      "Epoch number: 4170/10000step_number: 0/29 cost:  0.11381663710239696 accuracy:  0.9543721056932716\n",
      "Epoch number: 4171/10000step_number: 0/29 cost:  0.11396928802449859 accuracy:  0.9543721056932716\n",
      "Epoch number: 4172/10000step_number: 0/29 cost:  0.11410561470852448 accuracy:  0.9543721056932716\n",
      "Epoch number: 4173/10000step_number: 0/29 cost:  0.1142248177878824 accuracy:  0.9543721056932716\n",
      "Epoch number: 4174/10000step_number: 0/29 cost:  0.11432813018858866 accuracy:  0.954099700354127\n",
      "Epoch number: 4175/10000step_number: 0/29 cost:  0.11441617952146896 accuracy:  0.954099700354127\n",
      "Epoch number: 4176/10000step_number: 0/29 cost:  0.11449001365131864 accuracy:  0.9536910923454099\n",
      "Epoch number: 4177/10000step_number: 0/29 cost:  0.11455047795559153 accuracy:  0.9536910923454099\n",
      "Epoch number: 4178/10000step_number: 0/29 cost:  0.11459843608413335 accuracy:  0.9536910923454099\n",
      "Epoch number: 4179/10000step_number: 0/29 cost:  0.11463458707391755 accuracy:  0.9535548896758377\n",
      "Epoch number: 4180/10000step_number: 0/29 cost:  0.11465947652870485 accuracy:  0.9536910923454099\n",
      "Epoch number: 4181/10000step_number: 0/29 cost:  0.1146734363425184 accuracy:  0.9536910923454099\n",
      "Epoch number: 4182/10000step_number: 0/29 cost:  0.11467661486521528 accuracy:  0.9535548896758377\n",
      "Epoch number: 4183/10000step_number: 0/29 cost:  0.11466910811912864 accuracy:  0.9535548896758377\n",
      "Epoch number: 4184/10000step_number: 0/29 cost:  0.11465135578411077 accuracy:  0.9536910923454099\n",
      "Epoch number: 4185/10000step_number: 0/29 cost:  0.11462482502055943 accuracy:  0.9536910923454099\n",
      "Epoch number: 4186/10000step_number: 0/29 cost:  0.11459236514911582 accuracy:  0.9536910923454099\n",
      "Epoch number: 4187/10000step_number: 0/29 cost:  0.11455712235704561 accuracy:  0.9536910923454099\n",
      "Epoch number: 4188/10000step_number: 0/29 cost:  0.11452096049658224 accuracy:  0.9535548896758377\n",
      "Epoch number: 4189/10000step_number: 0/29 cost:  0.11448450239468025 accuracy:  0.9534186870062653\n",
      "Epoch number: 4190/10000step_number: 0/29 cost:  0.11444777594851334 accuracy:  0.953282484336693\n",
      "Epoch number: 4191/10000step_number: 0/29 cost:  0.11441025404268955 accuracy:  0.953282484336693\n",
      "Epoch number: 4192/10000step_number: 0/29 cost:  0.11437108741788073 accuracy:  0.953282484336693\n",
      "Epoch number: 4193/10000step_number: 0/29 cost:  0.1143301290893098 accuracy:  0.953282484336693\n",
      "Epoch number: 4194/10000step_number: 0/29 cost:  0.11428719981979577 accuracy:  0.9530100789975483\n",
      "Epoch number: 4195/10000step_number: 0/29 cost:  0.11424216794681565 accuracy:  0.9530100789975483\n",
      "Epoch number: 4196/10000step_number: 0/29 cost:  0.1141950245929411 accuracy:  0.9531462816671207\n",
      "Epoch number: 4197/10000step_number: 0/29 cost:  0.11414587300511786 accuracy:  0.9531462816671207\n",
      "Epoch number: 4198/10000step_number: 0/29 cost:  0.11409485190230703 accuracy:  0.9531462816671207\n",
      "Epoch number: 4199/10000step_number: 0/29 cost:  0.11404213801245769 accuracy:  0.953282484336693\n",
      "Epoch number: 4200/10000step_number: 0/29 cost:  0.11398793382024226 accuracy:  0.953282484336693\n",
      "Epoch number: 4201/10000step_number: 0/29 cost:  0.11393246540614846 accuracy:  0.953282484336693\n",
      "Epoch number: 4202/10000step_number: 0/29 cost:  0.11387598107535767 accuracy:  0.953282484336693\n",
      "Epoch number: 4203/10000step_number: 0/29 cost:  0.11381875271517933 accuracy:  0.953282484336693\n",
      "Epoch number: 4204/10000step_number: 0/29 cost:  0.11376107653846848 accuracy:  0.9534186870062653\n",
      "Epoch number: 4205/10000step_number: 0/29 cost:  0.11370327192337815 accuracy:  0.953282484336693\n",
      "Epoch number: 4206/10000step_number: 0/29 cost:  0.11364567635913259 accuracy:  0.9535548896758377\n",
      "Epoch number: 4207/10000step_number: 0/29 cost:  0.11358863519751937 accuracy:  0.9535548896758377\n",
      "Epoch number: 4208/10000step_number: 0/29 cost:  0.1135324867011303 accuracy:  0.9534186870062653\n",
      "Epoch number: 4209/10000step_number: 0/29 cost:  0.11347754832008156 accuracy:  0.953282484336693\n",
      "Epoch number: 4210/10000step_number: 0/29 cost:  0.11342412399197997 accuracy:  0.9530100789975483\n",
      "Epoch number: 4211/10000step_number: 0/29 cost:  0.11337257860739226 accuracy:  0.9531462816671207\n",
      "Epoch number: 4212/10000step_number: 0/29 cost:  0.11332352542729647 accuracy:  0.953282484336693\n",
      "Epoch number: 4213/10000step_number: 0/29 cost:  0.11327793727178886 accuracy:  0.9534186870062653\n",
      "Epoch number: 4214/10000step_number: 0/29 cost:  0.11323644198069673 accuracy:  0.9535548896758377\n",
      "Epoch number: 4215/10000step_number: 0/29 cost:  0.11319781125157692 accuracy:  0.9538272950149823\n",
      "Epoch number: 4216/10000step_number: 0/29 cost:  0.11315902893775436 accuracy:  0.9539634976845546\n",
      "Epoch number: 4217/10000step_number: 0/29 cost:  0.11311725127520439 accuracy:  0.954099700354127\n",
      "Epoch number: 4218/10000step_number: 0/29 cost:  0.11307072532159526 accuracy:  0.9536910923454099\n",
      "Epoch number: 4219/10000step_number: 0/29 cost:  0.11301850048428007 accuracy:  0.9538272950149823\n",
      "Epoch number: 4220/10000step_number: 0/29 cost:  0.11296023345327336 accuracy:  0.9536910923454099\n",
      "Epoch number: 4221/10000step_number: 0/29 cost:  0.11289601995811713 accuracy:  0.9536910923454099\n",
      "Epoch number: 4222/10000step_number: 0/29 cost:  0.11282619604990984 accuracy:  0.9536910923454099\n",
      "Epoch number: 4223/10000step_number: 0/29 cost:  0.11275119649585474 accuracy:  0.9539634976845546\n",
      "Epoch number: 4224/10000step_number: 0/29 cost:  0.11267147901851197 accuracy:  0.954099700354127\n",
      "Epoch number: 4225/10000step_number: 0/29 cost:  0.11258749554876707 accuracy:  0.9542359030236993\n",
      "Epoch number: 4226/10000step_number: 0/29 cost:  0.11249968541108556 accuracy:  0.954099700354127\n",
      "Epoch number: 4227/10000step_number: 0/29 cost:  0.11240847559865262 accuracy:  0.954099700354127\n",
      "Epoch number: 4228/10000step_number: 0/29 cost:  0.11231427949615144 accuracy:  0.954099700354127\n",
      "Epoch number: 4229/10000step_number: 0/29 cost:  0.11221749070005393 accuracy:  0.9542359030236993\n",
      "Epoch number: 4230/10000step_number: 0/29 cost:  0.11211847432111978 accuracy:  0.9542359030236993\n",
      "Epoch number: 4231/10000step_number: 0/29 cost:  0.1120175611787073 accuracy:  0.9542359030236993\n",
      "Epoch number: 4232/10000step_number: 0/29 cost:  0.1119150481783605 accuracy:  0.9542359030236993\n",
      "Epoch number: 4233/10000step_number: 0/29 cost:  0.11181120354471767 accuracy:  0.9542359030236993\n",
      "Epoch number: 4234/10000step_number: 0/29 cost:  0.1117062730693277 accuracy:  0.9539634976845546\n",
      "Epoch number: 4235/10000step_number: 0/29 cost:  0.1116004844202105 accuracy:  0.9539634976845546\n",
      "Epoch number: 4236/10000step_number: 0/29 cost:  0.11149404881155815 accuracy:  0.9539634976845546\n",
      "Epoch number: 4237/10000step_number: 0/29 cost:  0.11138716088324656 accuracy:  0.9539634976845546\n",
      "Epoch number: 4238/10000step_number: 0/29 cost:  0.11127999798134075 accuracy:  0.9536910923454099\n",
      "Epoch number: 4239/10000step_number: 0/29 cost:  0.1111727196532887 accuracy:  0.9536910923454099\n",
      "Epoch number: 4240/10000step_number: 0/29 cost:  0.11106546766472401 accuracy:  0.9535548896758377\n",
      "Epoch number: 4241/10000step_number: 0/29 cost:  0.11095836650771328 accuracy:  0.9534186870062653\n",
      "Epoch number: 4242/10000step_number: 0/29 cost:  0.11085152422521956 accuracy:  0.953282484336693\n",
      "Epoch number: 4243/10000step_number: 0/29 cost:  0.11074503330851519 accuracy:  0.953282484336693\n",
      "Epoch number: 4244/10000step_number: 0/29 cost:  0.11063897136635624 accuracy:  0.953282484336693\n",
      "Epoch number: 4245/10000step_number: 0/29 cost:  0.11053340183462554 accuracy:  0.953282484336693\n",
      "Epoch number: 4246/10000step_number: 0/29 cost:  0.11042837874810231 accuracy:  0.953282484336693\n",
      "Epoch number: 4247/10000step_number: 0/29 cost:  0.11032394707952102 accuracy:  0.953282484336693\n",
      "Epoch number: 4248/10000step_number: 0/29 cost:  0.11022008392106242 accuracy:  0.953282484336693\n",
      "Epoch number: 4249/10000step_number: 0/29 cost:  0.11011673875262677 accuracy:  0.9531462816671207\n",
      "Epoch number: 4250/10000step_number: 0/29 cost:  0.110013985412913 accuracy:  0.9531462816671207\n",
      "Epoch number: 4251/10000step_number: 0/29 cost:  0.10991191260292359 accuracy:  0.9531462816671207\n",
      "Epoch number: 4252/10000step_number: 0/29 cost:  0.10981053656984065 accuracy:  0.9530100789975483\n",
      "Epoch number: 4253/10000step_number: 0/29 cost:  0.10970983947982674 accuracy:  0.9530100789975483\n",
      "Epoch number: 4254/10000step_number: 0/29 cost:  0.10960980466562419 accuracy:  0.9530100789975483\n",
      "Epoch number: 4255/10000step_number: 0/29 cost:  0.10951042545277061 accuracy:  0.952873876327976\n",
      "Epoch number: 4256/10000step_number: 0/29 cost:  0.10941170391411585 accuracy:  0.9527376736584037\n",
      "Epoch number: 4257/10000step_number: 0/29 cost:  0.10931364910201717 accuracy:  0.9527376736584037\n",
      "Epoch number: 4258/10000step_number: 0/29 cost:  0.10921627581594887 accuracy:  0.9527376736584037\n",
      "Epoch number: 4259/10000step_number: 0/29 cost:  0.10911960436908945 accuracy:  0.9527376736584037\n",
      "Epoch number: 4260/10000step_number: 0/29 cost:  0.10902366067586845 accuracy:  0.9527376736584037\n",
      "Epoch number: 4261/10000step_number: 0/29 cost:  0.10892847637353335 accuracy:  0.9527376736584037\n",
      "Epoch number: 4262/10000step_number: 0/29 cost:  0.10883408887405323 accuracy:  0.9527376736584037\n",
      "Epoch number: 4263/10000step_number: 0/29 cost:  0.10874054139880829 accuracy:  0.9527376736584037\n",
      "Epoch number: 4264/10000step_number: 0/29 cost:  0.10864788296655563 accuracy:  0.9527376736584037\n",
      "Epoch number: 4265/10000step_number: 0/29 cost:  0.10855616830521642 accuracy:  0.9527376736584037\n",
      "Epoch number: 4266/10000step_number: 0/29 cost:  0.10846545762343748 accuracy:  0.9527376736584037\n",
      "Epoch number: 4267/10000step_number: 0/29 cost:  0.10837581612314307 accuracy:  0.9527376736584037\n",
      "Epoch number: 4268/10000step_number: 0/29 cost:  0.10828731303127205 accuracy:  0.9527376736584037\n",
      "Epoch number: 4269/10000step_number: 0/29 cost:  0.10820001980773576 accuracy:  0.9527376736584037\n",
      "Epoch number: 4270/10000step_number: 0/29 cost:  0.10811400705500328 accuracy:  0.9527376736584037\n",
      "Epoch number: 4271/10000step_number: 0/29 cost:  0.10802933955739613 accuracy:  0.9527376736584037\n",
      "Epoch number: 4272/10000step_number: 0/29 cost:  0.10794606890565132 accuracy:  0.9527376736584037\n",
      "Epoch number: 4273/10000step_number: 0/29 cost:  0.10786422346113293 accuracy:  0.9526014709888314\n",
      "Epoch number: 4274/10000step_number: 0/29 cost:  0.10778379613505724 accuracy:  0.9526014709888314\n",
      "Epoch number: 4275/10000step_number: 0/29 cost:  0.10770473160875682 accuracy:  0.9526014709888314\n",
      "Epoch number: 4276/10000step_number: 0/29 cost:  0.10762691581200776 accuracy:  0.9526014709888314\n",
      "Epoch number: 4277/10000step_number: 0/29 cost:  0.10755017086917204 accuracy:  0.9526014709888314\n",
      "Epoch number: 4278/10000step_number: 0/29 cost:  0.1074742578881733 accuracy:  0.9526014709888314\n",
      "Epoch number: 4279/10000step_number: 0/29 cost:  0.10739888965935361 accuracy:  0.9526014709888314\n",
      "Epoch number: 4280/10000step_number: 0/29 cost:  0.10732375872498812 accuracy:  0.9526014709888314\n",
      "Epoch number: 4281/10000step_number: 0/29 cost:  0.10724858991963179 accuracy:  0.952465268319259\n",
      "Epoch number: 4282/10000step_number: 0/29 cost:  0.10717321519485683 accuracy:  0.9526014709888314\n",
      "Epoch number: 4283/10000step_number: 0/29 cost:  0.10709763925534063 accuracy:  0.952465268319259\n",
      "Epoch number: 4284/10000step_number: 0/29 cost:  0.10702205373339159 accuracy:  0.952465268319259\n",
      "Epoch number: 4285/10000step_number: 0/29 cost:  0.10694679299133682 accuracy:  0.952465268319259\n",
      "Epoch number: 4286/10000step_number: 0/29 cost:  0.10687226418152125 accuracy:  0.952465268319259\n",
      "Epoch number: 4287/10000step_number: 0/29 cost:  0.10679888327192644 accuracy:  0.952465268319259\n",
      "Epoch number: 4288/10000step_number: 0/29 cost:  0.10672702862766625 accuracy:  0.9523290656496868\n",
      "Epoch number: 4289/10000step_number: 0/29 cost:  0.1066570143259826 accuracy:  0.9523290656496868\n",
      "Epoch number: 4290/10000step_number: 0/29 cost:  0.10658908262076106 accuracy:  0.9523290656496868\n",
      "Epoch number: 4291/10000step_number: 0/29 cost:  0.10652341062500927 accuracy:  0.9523290656496868\n",
      "Epoch number: 4292/10000step_number: 0/29 cost:  0.1064601235984237 accuracy:  0.9523290656496868\n",
      "Epoch number: 4293/10000step_number: 0/29 cost:  0.10639930862001734 accuracy:  0.9523290656496868\n",
      "Epoch number: 4294/10000step_number: 0/29 cost:  0.10634102568187143 accuracy:  0.9521928629801144\n",
      "Epoch number: 4295/10000step_number: 0/29 cost:  0.10628531601303039 accuracy:  0.9521928629801144\n",
      "Epoch number: 4296/10000step_number: 0/29 cost:  0.10623220929788796 accuracy:  0.9521928629801144\n",
      "Epoch number: 4297/10000step_number: 0/29 cost:  0.10618173346225669 accuracy:  0.9521928629801144\n",
      "Epoch number: 4298/10000step_number: 0/29 cost:  0.10613393230454228 accuracy:  0.9523290656496868\n",
      "Epoch number: 4299/10000step_number: 0/29 cost:  0.10608886276918665 accuracy:  0.9523290656496868\n",
      "Epoch number: 4300/10000step_number: 0/29 cost:  0.10604625827293189 accuracy:  0.9523290656496868\n",
      "Epoch number: 4301/10000step_number: 0/29 cost:  0.10600491155157803 accuracy:  0.9523290656496868\n",
      "Epoch number: 4302/10000step_number: 0/29 cost:  0.10596867886755143 accuracy:  0.9523290656496868\n",
      "Epoch number: 4303/10000step_number: 0/29 cost:  0.10592866141475676 accuracy:  0.9523290656496868\n",
      "Epoch number: 4304/10000step_number: 0/29 cost:  0.10593620989050333 accuracy:  0.9521928629801144\n",
      "Epoch number: 4305/10000step_number: 0/29 cost:  0.10580808144849775 accuracy:  0.9521928629801144\n",
      "Epoch number: 4306/10000step_number: 0/29 cost:  0.10592706781956227 accuracy:  0.9521928629801144\n",
      "Epoch number: 4307/10000step_number: 0/29 cost:  0.10585449514453013 accuracy:  0.9521928629801144\n",
      "Epoch number: 4308/10000step_number: 0/29 cost:  0.10580331963692421 accuracy:  0.952056660310542\n",
      "Epoch number: 4309/10000step_number: 0/29 cost:  0.10579715954745211 accuracy:  0.952056660310542\n",
      "Epoch number: 4310/10000step_number: 0/29 cost:  0.10578483323442006 accuracy:  0.952056660310542\n",
      "Epoch number: 4311/10000step_number: 0/29 cost:  0.10576262211817615 accuracy:  0.952056660310542\n",
      "Epoch number: 4312/10000step_number: 0/29 cost:  0.10574400435149316 accuracy:  0.952056660310542\n",
      "Epoch number: 4313/10000step_number: 0/29 cost:  0.10573071458559832 accuracy:  0.952056660310542\n",
      "Epoch number: 4314/10000step_number: 0/29 cost:  0.10572148555223791 accuracy:  0.952056660310542\n",
      "Epoch number: 4315/10000step_number: 0/29 cost:  nan accuracy:  0.952056660310542\n",
      "Epoch number: 4316/10000step_number: 0/29 cost:  nan accuracy:  0.952056660310542\n",
      "Epoch number: 4317/10000step_number: 0/29 cost:  nan accuracy:  0.952056660310542\n",
      "Epoch number: 4318/10000step_number: 0/29 cost:  nan accuracy:  0.952056660310542\n",
      "Epoch number: 4319/10000step_number: 0/29 cost:  nan accuracy:  0.952056660310542\n",
      "Epoch number: 4320/10000step_number: 0/29 cost:  nan accuracy:  0.9523290656496868\n",
      "Epoch number: 4321/10000step_number: 0/29 cost:  nan accuracy:  0.9523290656496868\n",
      "Epoch number: 4322/10000step_number: 0/29 cost:  nan accuracy:  0.9526014709888314\n",
      "Epoch number: 4323/10000step_number: 0/29 cost:  nan accuracy:  0.9526014709888314\n",
      "Epoch number: 4324/10000step_number: 0/29 cost:  nan accuracy:  0.9526014709888314\n",
      "Epoch number: 4325/10000step_number: 0/29 cost:  nan accuracy:  0.9526014709888314\n",
      "Epoch number: 4326/10000step_number: 0/29 cost:  nan accuracy:  0.9527376736584037\n",
      "Epoch number: 4327/10000step_number: 0/29 cost:  nan accuracy:  0.9527376736584037\n",
      "Epoch number: 4328/10000step_number: 0/29 cost:  nan accuracy:  0.9527376736584037\n",
      "Epoch number: 4329/10000step_number: 0/29 cost:  nan accuracy:  0.9527376736584037\n",
      "Epoch number: 4330/10000step_number: 0/29 cost:  nan accuracy:  0.9527376736584037\n",
      "Epoch number: 4331/10000step_number: 0/29 cost:  nan accuracy:  0.952873876327976\n",
      "Epoch number: 4332/10000step_number: 0/29 cost:  nan accuracy:  0.952873876327976\n",
      "Epoch number: 4333/10000step_number: 0/29 cost:  nan accuracy:  0.952873876327976\n",
      "Epoch number: 4334/10000step_number: 0/29 cost:  nan accuracy:  0.952873876327976\n",
      "Epoch number: 4335/10000step_number: 0/29 cost:  nan accuracy:  0.952873876327976\n",
      "Epoch number: 4336/10000step_number: 0/29 cost:  nan accuracy:  0.952873876327976\n",
      "Epoch number: 4337/10000step_number: 0/29 cost:  nan accuracy:  0.952873876327976\n",
      "Epoch number: 4338/10000step_number: 0/29 cost:  nan accuracy:  0.9530100789975483\n",
      "Epoch number: 4339/10000step_number: 0/29 cost:  nan accuracy:  0.9530100789975483\n",
      "Epoch number: 4340/10000step_number: 0/29 cost:  nan accuracy:  0.9530100789975483\n",
      "Epoch number: 4341/10000step_number: 0/29 cost:  nan accuracy:  0.9530100789975483\n",
      "Epoch number: 4342/10000step_number: 0/29 cost:  nan accuracy:  0.9531462816671207\n",
      "Epoch number: 4343/10000step_number: 0/29 cost:  nan accuracy:  0.953282484336693\n",
      "Epoch number: 4344/10000step_number: 0/29 cost:  nan accuracy:  0.953282484336693\n",
      "Epoch number: 4345/10000step_number: 0/29 cost:  nan accuracy:  0.953282484336693\n",
      "Epoch number: 4346/10000step_number: 0/29 cost:  nan accuracy:  0.953282484336693\n",
      "Epoch number: 4347/10000step_number: 0/29 cost:  nan accuracy:  0.953282484336693\n",
      "Epoch number: 4348/10000step_number: 0/29 cost:  nan accuracy:  0.953282484336693\n",
      "Epoch number: 4349/10000step_number: 0/29 cost:  nan accuracy:  0.953282484336693\n",
      "Epoch number: 4350/10000step_number: 0/29 cost:  nan accuracy:  0.9534186870062653\n",
      "Epoch number: 4351/10000step_number: 0/29 cost:  nan accuracy:  0.9534186870062653\n",
      "Epoch number: 4352/10000step_number: 0/29 cost:  nan accuracy:  0.953282484336693\n",
      "Epoch number: 4353/10000step_number: 0/29 cost:  nan accuracy:  0.953282484336693\n",
      "Epoch number: 4354/10000step_number: 0/29 cost:  nan accuracy:  0.953282484336693\n",
      "Epoch number: 4355/10000step_number: 0/29 cost:  nan accuracy:  0.9534186870062653\n",
      "Epoch number: 4356/10000step_number: 0/29 cost:  nan accuracy:  0.9534186870062653\n",
      "Epoch number: 4357/10000step_number: 0/29 cost:  nan accuracy:  0.9534186870062653\n",
      "Epoch number: 4358/10000step_number: 0/29 cost:  nan accuracy:  0.9534186870062653\n",
      "Epoch number: 4359/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4360/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4361/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4362/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4363/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4364/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4365/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4366/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4367/10000step_number: 0/29 cost:  nan accuracy:  0.9534186870062653\n",
      "Epoch number: 4368/10000step_number: 0/29 cost:  nan accuracy:  0.9534186870062653\n",
      "Epoch number: 4369/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4370/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4371/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4372/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4373/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4374/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4375/10000step_number: 0/29 cost:  nan accuracy:  0.9534186870062653\n",
      "Epoch number: 4376/10000step_number: 0/29 cost:  nan accuracy:  0.9534186870062653\n",
      "Epoch number: 4377/10000step_number: 0/29 cost:  nan accuracy:  0.9534186870062653\n",
      "Epoch number: 4378/10000step_number: 0/29 cost:  nan accuracy:  0.9534186870062653\n",
      "Epoch number: 4379/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4380/10000step_number: 0/29 cost:  nan accuracy:  0.9534186870062653\n",
      "Epoch number: 4381/10000step_number: 0/29 cost:  nan accuracy:  0.9534186870062653\n",
      "Epoch number: 4382/10000step_number: 0/29 cost:  nan accuracy:  0.9534186870062653\n",
      "Epoch number: 4383/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4384/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4385/10000step_number: 0/29 cost:  nan accuracy:  0.9536910923454099\n",
      "Epoch number: 4386/10000step_number: 0/29 cost:  nan accuracy:  0.9536910923454099\n",
      "Epoch number: 4387/10000step_number: 0/29 cost:  nan accuracy:  0.9534186870062653\n",
      "Epoch number: 4388/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4389/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4390/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4391/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4392/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4393/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4394/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4395/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4396/10000step_number: 0/29 cost:  nan accuracy:  0.9536910923454099\n",
      "Epoch number: 4397/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4398/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4399/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4400/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 4401/10000step_number: 0/29 cost:  nan accuracy:  0.9536910923454099\n",
      "Epoch number: 4402/10000step_number: 0/29 cost:  nan accuracy:  0.9536910923454099\n",
      "Epoch number: 4403/10000step_number: 0/29 cost:  nan accuracy:  0.9539634976845546\n",
      "Epoch number: 4404/10000step_number: 0/29 cost:  nan accuracy:  0.9543721056932716\n",
      "Epoch number: 4405/10000step_number: 0/29 cost:  nan accuracy:  0.9543721056932716\n",
      "Epoch number: 4406/10000step_number: 0/29 cost:  nan accuracy:  0.954099700354127\n",
      "Epoch number: 4407/10000step_number: 0/29 cost:  nan accuracy:  0.9538272950149823\n",
      "Epoch number: 4408/10000step_number: 0/29 cost:  nan accuracy:  0.9534186870062653\n",
      "Epoch number: 4409/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4410/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4411/10000step_number: 0/29 cost:  nan accuracy:  0.9519204576409698\n",
      "Epoch number: 4412/10000step_number: 0/29 cost:  0.13795667364834788 accuracy:  0.9515118496322528\n",
      "Epoch number: 4413/10000step_number: 0/29 cost:  nan accuracy:  0.9517842549713974\n",
      "Epoch number: 4414/10000step_number: 0/29 cost:  nan accuracy:  0.9536910923454099\n",
      "Epoch number: 4415/10000step_number: 0/29 cost:  nan accuracy:  0.9543721056932716\n",
      "Epoch number: 4416/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4417/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 4418/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 4419/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 4420/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 4421/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4422/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4423/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 4424/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 4425/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4426/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4427/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4428/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4429/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4430/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 4431/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4432/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4433/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4434/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4435/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4436/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4437/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4438/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4439/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4440/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4441/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4442/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4443/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4444/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4445/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4446/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4447/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4448/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4449/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4450/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4451/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4452/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4453/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4454/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4455/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4456/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4457/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4458/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4459/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4460/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4461/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4462/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4463/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4464/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4465/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4466/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4467/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4468/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4469/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4470/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4471/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4472/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4473/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4474/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4475/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4476/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4477/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4478/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4479/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4480/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4481/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4482/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4483/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4484/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4485/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4486/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4487/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4488/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4489/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4490/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4491/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4492/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4493/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4494/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4495/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4496/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4497/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4498/10000step_number: 0/29 cost:  nan accuracy:  0.9546445110324162\n",
      "Epoch number: 4499/10000step_number: 0/29 cost:  nan accuracy:  0.9546445110324162\n",
      "Epoch number: 4500/10000step_number: 0/29 cost:  nan accuracy:  0.9546445110324162\n",
      "Epoch number: 4501/10000step_number: 0/29 cost:  nan accuracy:  0.9546445110324162\n",
      "Epoch number: 4502/10000step_number: 0/29 cost:  nan accuracy:  0.9546445110324162\n",
      "Epoch number: 4503/10000step_number: 0/29 cost:  nan accuracy:  0.9546445110324162\n",
      "Epoch number: 4504/10000step_number: 0/29 cost:  nan accuracy:  0.954508308362844\n",
      "Epoch number: 4505/10000step_number: 0/29 cost:  nan accuracy:  0.954508308362844\n",
      "Epoch number: 4506/10000step_number: 0/29 cost:  nan accuracy:  0.9543721056932716\n",
      "Epoch number: 4507/10000step_number: 0/29 cost:  nan accuracy:  0.9543721056932716\n",
      "Epoch number: 4508/10000step_number: 0/29 cost:  nan accuracy:  0.9542359030236993\n",
      "Epoch number: 4509/10000step_number: 0/29 cost:  nan accuracy:  0.9542359030236993\n",
      "Epoch number: 4510/10000step_number: 0/29 cost:  nan accuracy:  0.9543721056932716\n",
      "Epoch number: 4511/10000step_number: 0/29 cost:  nan accuracy:  0.9543721056932716\n",
      "Epoch number: 4512/10000step_number: 0/29 cost:  nan accuracy:  0.9543721056932716\n",
      "Epoch number: 4513/10000step_number: 0/29 cost:  nan accuracy:  0.9543721056932716\n",
      "Epoch number: 4514/10000step_number: 0/29 cost:  nan accuracy:  0.9543721056932716\n",
      "Epoch number: 4515/10000step_number: 0/29 cost:  nan accuracy:  0.9543721056932716\n",
      "Epoch number: 4516/10000step_number: 0/29 cost:  nan accuracy:  0.9543721056932716\n",
      "Epoch number: 4517/10000step_number: 0/29 cost:  nan accuracy:  0.9543721056932716\n",
      "Epoch number: 4518/10000step_number: 0/29 cost:  nan accuracy:  0.9543721056932716\n",
      "Epoch number: 4519/10000step_number: 0/29 cost:  nan accuracy:  0.9543721056932716\n",
      "Epoch number: 4520/10000step_number: 0/29 cost:  nan accuracy:  0.9543721056932716\n",
      "Epoch number: 4521/10000step_number: 0/29 cost:  nan accuracy:  0.9543721056932716\n",
      "Epoch number: 4522/10000step_number: 0/29 cost:  nan accuracy:  0.954508308362844\n",
      "Epoch number: 4523/10000step_number: 0/29 cost:  nan accuracy:  0.954508308362844\n",
      "Epoch number: 4524/10000step_number: 0/29 cost:  nan accuracy:  0.954508308362844\n",
      "Epoch number: 4525/10000step_number: 0/29 cost:  nan accuracy:  0.9546445110324162\n",
      "Epoch number: 4526/10000step_number: 0/29 cost:  nan accuracy:  0.9546445110324162\n",
      "Epoch number: 4527/10000step_number: 0/29 cost:  nan accuracy:  0.9546445110324162\n",
      "Epoch number: 4528/10000step_number: 0/29 cost:  nan accuracy:  0.9546445110324162\n",
      "Epoch number: 4529/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4530/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4531/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4532/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4533/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4534/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4535/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4536/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4537/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4538/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4539/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4540/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4541/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4542/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4543/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4544/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4545/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4546/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4547/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4548/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4549/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4550/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4551/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4552/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4553/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4554/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4555/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4556/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4557/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4558/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4559/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4560/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4561/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4562/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4563/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4564/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4565/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4566/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4567/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4568/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4569/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4570/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4571/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4572/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4573/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4574/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4575/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4576/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4577/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4578/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4579/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4580/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4581/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4582/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4583/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4584/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4585/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4586/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4587/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4588/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4589/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4590/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4591/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4592/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4593/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4594/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 4595/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 4596/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 4597/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 4598/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4599/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4600/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4601/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4602/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4603/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4604/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4605/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4606/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4607/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4608/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4609/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 4610/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4611/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 4612/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 4613/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 4614/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 4615/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 4616/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 4617/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 4618/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 4619/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 4620/10000step_number: 0/29 cost:  nan accuracy:  0.9542359030236993\n",
      "Epoch number: 4621/10000step_number: 0/29 cost:  nan accuracy:  0.9456551348406429\n",
      "Epoch number: 4622/10000step_number: 0/29 cost:  nan accuracy:  0.9506946336148189\n",
      "Epoch number: 4623/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4624/10000step_number: 0/29 cost:  nan accuracy:  0.9569599564151458\n",
      "Epoch number: 4625/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 4626/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4627/10000step_number: 0/29 cost:  nan accuracy:  0.9569599564151458\n",
      "Epoch number: 4628/10000step_number: 0/29 cost:  nan accuracy:  0.9569599564151458\n",
      "Epoch number: 4629/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 4630/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 4631/10000step_number: 0/29 cost:  nan accuracy:  0.9569599564151458\n",
      "Epoch number: 4632/10000step_number: 0/29 cost:  nan accuracy:  0.9569599564151458\n",
      "Epoch number: 4633/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 4634/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4635/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4636/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4637/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4638/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4639/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4640/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4641/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4642/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4643/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4644/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4645/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4646/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4647/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4648/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4649/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4650/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4651/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4652/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4653/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4654/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4655/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4656/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4657/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4658/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4659/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4660/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4661/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4662/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4663/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4664/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4665/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4666/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4667/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4668/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4669/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4670/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4671/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4672/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4673/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4674/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4675/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4676/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4677/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4678/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4679/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4680/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4681/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4682/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4683/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4684/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4685/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4686/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4687/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4688/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4689/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4690/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4691/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4692/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4693/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4694/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4695/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4696/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4697/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4698/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4699/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4700/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4701/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4702/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4703/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4704/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4705/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4706/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4707/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4708/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4709/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4710/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4711/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4712/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4713/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4714/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4715/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4716/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4717/10000step_number: 0/29 cost:  nan accuracy:  0.9546445110324162\n",
      "Epoch number: 4718/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4719/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4720/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4721/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4722/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4723/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4724/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4725/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4726/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4727/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4728/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4729/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4730/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4731/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4732/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4733/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4734/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4735/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4736/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4737/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4738/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4739/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4740/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4741/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4742/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4743/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4744/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4745/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4746/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4747/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4748/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4749/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4750/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4751/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4752/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4753/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4754/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4755/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4756/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4757/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4758/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4759/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4760/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4761/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4762/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4763/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4764/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4765/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4766/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4767/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4768/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4769/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4770/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4771/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4772/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4773/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4774/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4775/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4776/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4777/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4778/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4779/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4780/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4781/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4782/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4783/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4784/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4785/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4786/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4787/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4788/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4789/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4790/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4791/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4792/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4793/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4794/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4795/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4796/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4797/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4798/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4799/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4800/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4801/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4802/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4803/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4804/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4805/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4806/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4807/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4808/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4809/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4810/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4811/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4812/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4813/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4814/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4815/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4816/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4817/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 4818/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4819/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4820/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4821/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4822/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4823/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 4824/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4825/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4826/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4827/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4828/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4829/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4830/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4831/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4832/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 4833/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 4834/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 4835/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 4836/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 4837/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 4838/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 4839/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 4840/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 4841/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 4842/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 4843/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 4844/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 4845/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 4846/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 4847/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 4848/10000step_number: 0/29 cost:  nan accuracy:  0.9569599564151458\n",
      "Epoch number: 4849/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 4850/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 4851/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 4852/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 4853/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 4854/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 4855/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 4856/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 4857/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 4858/10000step_number: 0/29 cost:  nan accuracy:  0.9569599564151458\n",
      "Epoch number: 4859/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 4860/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 4861/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 4862/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 4863/10000step_number: 0/29 cost:  nan accuracy:  0.9569599564151458\n",
      "Epoch number: 4864/10000step_number: 0/29 cost:  nan accuracy:  0.9569599564151458\n",
      "Epoch number: 4865/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 4866/10000step_number: 0/29 cost:  nan accuracy:  0.9569599564151458\n",
      "Epoch number: 4867/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 4868/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 4869/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 4870/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4871/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4872/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4873/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4874/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4875/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4876/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 4877/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 4878/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 4879/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 4880/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4881/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4882/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4883/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 4884/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 4885/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4886/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4887/10000step_number: 0/29 cost:  nan accuracy:  0.9538272950149823\n",
      "Epoch number: 4888/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4889/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 4890/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4891/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 4892/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 4893/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 4894/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 4895/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 4896/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 4897/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 4898/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 4899/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 4900/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4901/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 4902/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 4903/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 4904/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 4905/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 4906/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 4907/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 4908/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 4909/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 4910/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4911/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 4912/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 4913/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 4914/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4915/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4916/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4917/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 4918/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 4919/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 4920/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4921/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4922/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4923/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4924/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4925/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4926/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4927/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4928/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4929/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4930/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4931/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4932/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4933/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4934/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 4935/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4936/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4937/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4938/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4939/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4940/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4941/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4942/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4943/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4944/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4945/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4946/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4947/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4948/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 4949/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4950/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4951/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4952/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4953/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 4954/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 4955/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4956/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4957/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4958/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4959/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4960/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4961/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4962/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4963/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4964/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4965/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 4966/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4967/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4968/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4969/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4970/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4971/10000step_number: 0/29 cost:  nan accuracy:  0.9555979297194225\n",
      "Epoch number: 4972/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4973/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4974/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4975/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4976/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4977/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4978/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4979/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4980/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4981/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4982/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4983/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4984/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4985/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4986/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 4987/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 4988/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 4989/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 4990/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4991/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4992/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4993/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4994/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4995/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4996/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 4997/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4998/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 4999/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 5000/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 5001/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 5002/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 5003/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 5004/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 5005/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 5006/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 5007/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 5008/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 5009/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 5010/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 5011/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 5012/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 5013/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 5014/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 5015/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 5016/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 5017/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 5018/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 5019/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 5020/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 5021/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 5022/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 5023/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 5024/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 5025/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 5026/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 5027/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 5028/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 5029/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 5030/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 5031/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 5032/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 5033/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 5034/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 5035/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 5036/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 5037/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 5038/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 5039/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 5040/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 5041/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 5042/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 5043/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 5044/10000step_number: 0/29 cost:  nan accuracy:  0.9569599564151458\n",
      "Epoch number: 5045/10000step_number: 0/29 cost:  nan accuracy:  0.9569599564151458\n",
      "Epoch number: 5046/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 5047/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 5048/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 5049/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 5050/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5051/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5052/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5053/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5054/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5055/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5056/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 5057/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5058/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5059/10000step_number: 0/29 cost:  nan accuracy:  0.9485153909016617\n",
      "Epoch number: 5060/10000step_number: 0/29 cost:  nan accuracy:  0.9496050122582402\n",
      "Epoch number: 5061/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 5062/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5063/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5064/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 5065/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5066/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5067/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5068/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5069/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5070/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5071/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5072/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5073/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5074/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5075/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5076/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5077/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5078/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5079/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5080/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5081/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5082/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5083/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5084/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5085/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5086/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5087/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5088/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5089/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5090/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5091/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5092/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5093/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5094/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5095/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5096/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5097/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5098/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5099/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5100/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5101/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5102/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5103/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5104/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5105/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5106/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5107/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5108/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5109/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5110/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5111/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5112/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5113/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5114/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5115/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5116/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5117/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5118/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5119/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5120/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5121/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5122/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5123/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5124/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5125/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5126/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5127/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5128/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5129/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5130/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5131/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5132/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5133/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5134/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5135/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5136/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5137/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5138/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5139/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5140/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5141/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5142/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5143/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5144/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5145/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5146/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5147/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5148/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5149/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5150/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5151/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5152/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5153/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5154/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5155/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5156/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5157/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5158/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5159/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5160/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5161/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5162/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5163/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5164/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5165/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5166/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5167/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5168/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5169/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 5170/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 5171/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 5172/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 5173/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 5174/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5175/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5176/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5177/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5178/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5179/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 5180/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 5181/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 5182/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5183/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5184/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5185/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5186/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 5187/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 5188/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 5189/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 5190/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 5191/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5192/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 5193/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 5194/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 5195/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 5196/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 5197/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 5198/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5199/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5200/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5201/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5202/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5203/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5204/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5205/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5206/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5207/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5208/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5209/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5210/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5211/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5212/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5213/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5214/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5215/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5216/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5217/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5218/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5219/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5220/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5221/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5222/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5223/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5224/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5225/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5226/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5227/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5228/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5229/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5230/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5231/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5232/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5233/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5234/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5235/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5236/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5237/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5238/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5239/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5240/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5241/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5242/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5243/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5244/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5245/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5246/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5247/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5248/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5249/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5250/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5251/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5252/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5253/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5254/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5255/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5256/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5257/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5258/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5259/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5260/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5261/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5262/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5263/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5264/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5265/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5266/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5267/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5268/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5269/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5270/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5271/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5272/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5273/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5274/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5275/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5276/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5277/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5278/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5279/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5280/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5281/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5282/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5283/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5284/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5285/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5286/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5287/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5288/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5289/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5290/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 5291/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 5292/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5293/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 5294/10000step_number: 0/29 cost:  nan accuracy:  0.9523290656496868\n",
      "Epoch number: 5295/10000step_number: 0/29 cost:  nan accuracy:  0.9516480523018251\n",
      "Epoch number: 5296/10000step_number: 0/29 cost:  nan accuracy:  0.9546445110324162\n",
      "Epoch number: 5297/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5298/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5299/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 5300/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5301/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5302/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5303/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5304/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5305/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5306/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5307/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5308/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5309/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5310/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5311/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5312/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5313/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5314/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5315/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5316/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5317/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5318/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5319/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5320/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5321/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5322/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5323/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5324/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5325/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5326/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5327/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5328/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5329/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5330/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5331/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5332/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5333/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5334/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5335/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5336/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5337/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5338/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5339/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5340/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5341/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5342/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5343/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5344/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5345/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5346/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5347/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5348/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5349/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5350/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5351/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5352/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5353/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5354/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5355/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5356/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5357/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5358/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5359/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5360/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5361/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5362/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5363/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5364/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5365/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5366/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5367/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5368/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5369/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5370/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5371/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5372/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5373/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5374/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5375/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5376/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5377/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5378/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5379/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5380/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5381/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5382/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5383/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5384/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5385/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5386/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5387/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5388/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5389/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5390/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5391/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5392/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5393/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5394/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5395/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5396/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5397/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5398/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5399/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5400/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5401/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5402/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5403/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5404/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5405/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5406/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5407/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5408/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5409/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5410/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5411/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5412/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5413/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5414/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5415/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5416/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5417/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5418/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5419/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 5420/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 5421/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 5422/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5423/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5424/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5425/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5426/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5427/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5428/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5429/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5430/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5431/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5432/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5433/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5434/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5435/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 5436/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5437/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 5438/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5439/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5440/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5441/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5442/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5443/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5444/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5445/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5446/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5447/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5448/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5449/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5450/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5451/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5452/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5453/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5454/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5455/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5456/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5457/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5458/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5459/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5460/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5461/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5462/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5463/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5464/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5465/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5466/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5467/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5468/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5469/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5470/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5471/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5472/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5473/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5474/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5475/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5476/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5477/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5478/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5479/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5480/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5481/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5482/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5483/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5484/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5485/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5486/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5487/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5488/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5489/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5490/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5491/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5492/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5493/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5494/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5495/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5496/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5497/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5498/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5499/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5500/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5501/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5502/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5503/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5504/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5505/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5506/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5507/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5508/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5509/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5510/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5511/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5512/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5513/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5514/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5515/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5516/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5517/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5518/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5519/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5520/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5521/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5522/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5523/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5524/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5525/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5526/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5527/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5528/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5529/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5530/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5531/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5532/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5533/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5534/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5535/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5536/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5537/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5538/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5539/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5540/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5541/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 5542/10000step_number: 0/29 cost:  nan accuracy:  0.953282484336693\n",
      "Epoch number: 5543/10000step_number: 0/29 cost:  nan accuracy:  0.9539634976845546\n",
      "Epoch number: 5544/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5545/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 5546/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5547/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5548/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5549/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5550/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 5551/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 5552/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 5553/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 5554/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5555/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5556/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5557/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5558/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 5559/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5560/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 5561/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5562/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5563/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5564/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5565/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5566/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5567/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5568/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5569/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5570/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5571/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5572/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5573/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5574/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5575/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5576/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5577/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5578/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5579/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5580/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5581/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5582/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5583/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5584/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5585/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5586/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5587/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5588/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5589/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5590/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5591/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5592/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5593/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5594/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5595/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5596/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5597/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5598/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5599/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5600/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5601/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5602/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5603/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5604/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5605/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5606/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5607/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5608/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5609/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5610/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5611/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5612/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5613/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5614/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5615/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5616/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5617/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5618/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5619/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5620/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5621/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5622/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5623/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5624/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5625/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5626/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5627/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5628/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5629/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5630/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5631/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5632/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5633/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5634/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5635/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5636/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5637/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5638/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5639/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5640/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5641/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5642/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5643/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5644/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5645/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5646/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5647/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5648/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5649/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5650/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5651/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5652/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5653/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5654/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5655/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5656/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5657/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5658/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5659/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5660/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5661/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5662/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5663/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5664/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5665/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5666/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5667/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5668/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5669/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5670/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5671/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5672/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5673/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5674/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5675/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5676/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5677/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5678/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5679/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5680/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5681/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5682/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5683/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5684/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5685/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5686/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5687/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5688/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5689/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5690/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5691/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 5692/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5693/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5694/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5695/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5696/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5697/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5698/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5699/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5700/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5701/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5702/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5703/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5704/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5705/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5706/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5707/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5708/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5709/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5710/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5711/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5712/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5713/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5714/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5715/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5716/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5717/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5718/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 5719/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5720/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5721/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5722/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5723/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5724/10000step_number: 0/29 cost:  nan accuracy:  0.9463361481885045\n",
      "Epoch number: 5725/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 5726/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 5727/10000step_number: 0/29 cost:  nan accuracy:  0.9566875510760011\n",
      "Epoch number: 5728/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5729/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5730/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5731/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 5732/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 5733/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 5734/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 5735/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 5736/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 5737/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 5738/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 5739/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 5740/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 5741/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 5742/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 5743/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5744/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5745/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5746/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 5747/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5748/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5749/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5750/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5751/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5752/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5753/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5754/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5755/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5756/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5757/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5758/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5759/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5760/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5761/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5762/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5763/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5764/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5765/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5766/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5767/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5768/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5769/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5770/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5771/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5772/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5773/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5774/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5775/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5776/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5777/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5778/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5779/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5780/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5781/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5782/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5783/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5784/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5785/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5786/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5787/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5788/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5789/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5790/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5791/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5792/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5793/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5794/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5795/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5796/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5797/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5798/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5799/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5800/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5801/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5802/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5803/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5804/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5805/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5806/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5807/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5808/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5809/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5810/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5811/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5812/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5813/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5814/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5815/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5816/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5817/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5818/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5819/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5820/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5821/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5822/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5823/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5824/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5825/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5826/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5827/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 5828/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5829/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5830/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5831/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5832/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5833/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5834/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5835/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5836/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5837/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5838/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5839/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5840/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5841/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5842/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5843/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5844/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5845/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5846/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5847/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5848/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5849/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5850/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5851/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5852/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5853/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5854/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5855/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5856/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5857/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5858/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5859/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5860/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5861/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5862/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5863/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5864/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5865/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5866/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5867/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5868/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 5869/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5870/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5871/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5872/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5873/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5874/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5875/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5876/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5877/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5878/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5879/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5880/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5881/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5882/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5883/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5884/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5885/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5886/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5887/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5888/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5889/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5890/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5891/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5892/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5893/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5894/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5895/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5896/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5897/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5898/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5899/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5900/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5901/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5902/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5903/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5904/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5905/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5906/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5907/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5908/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5909/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5910/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5911/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5912/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5913/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5914/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5915/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5916/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5917/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5918/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5919/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5920/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5921/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5922/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5923/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5924/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5925/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5926/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5927/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5928/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5929/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5930/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5931/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5932/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5933/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5934/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5935/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5936/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5937/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5938/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5939/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5940/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5941/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5942/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5943/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5944/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 5945/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5946/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 5947/10000step_number: 0/29 cost:  nan accuracy:  0.9461999455189322\n",
      "Epoch number: 5948/10000step_number: 0/29 cost:  nan accuracy:  0.9527376736584037\n",
      "Epoch number: 5949/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 5950/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 5951/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5952/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 5953/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5954/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5955/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5956/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5957/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5958/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 5959/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5960/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5961/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5962/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5963/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5964/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5965/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5966/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5967/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5968/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5969/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5970/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5971/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5972/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5973/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5974/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5975/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 5976/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5977/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5978/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5979/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5980/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5981/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5982/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5983/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5984/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5985/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5986/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5987/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5988/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5989/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 5990/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5991/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5992/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5993/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5994/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5995/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 5996/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 5997/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 5998/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 5999/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6000/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6001/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6002/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6003/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6004/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6005/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6006/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6007/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6008/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6009/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6010/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6011/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6012/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6013/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6014/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6015/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6016/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6017/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6018/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6019/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6020/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6021/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6022/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6023/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6024/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6025/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6026/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6027/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6028/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6029/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6030/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6031/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6032/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6033/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6034/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6035/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6036/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6037/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6038/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6039/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6040/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6041/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6042/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6043/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6044/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6045/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6046/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6047/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6048/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6049/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6050/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6051/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6052/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6053/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6054/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6055/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6056/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6057/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6058/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6059/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6060/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6061/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6062/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6063/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6064/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6065/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6066/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6067/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6068/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6069/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6070/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6071/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6072/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6073/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6074/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6075/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6076/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6077/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6078/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6079/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6080/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6081/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6082/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6083/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6084/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6085/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6086/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6087/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6088/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6089/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6090/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6091/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6092/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6093/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6094/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6095/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6096/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6097/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6098/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6099/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6100/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6101/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6102/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6103/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6104/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6105/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6106/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6107/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6108/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6109/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6110/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6111/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6112/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6113/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6114/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6115/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6116/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6117/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6118/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6119/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6120/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6121/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6122/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6123/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6124/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6125/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 6126/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6127/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 6128/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 6129/10000step_number: 0/29 cost:  nan accuracy:  0.952465268319259\n",
      "Epoch number: 6130/10000step_number: 0/29 cost:  nan accuracy:  0.9553255243802778\n",
      "Epoch number: 6131/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6132/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6133/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6134/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6135/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6136/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6137/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6138/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6139/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6140/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6141/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6142/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6143/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6144/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6145/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6146/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6147/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6148/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6149/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6150/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6151/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6152/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6153/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6154/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6155/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6156/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6157/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6158/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6159/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6160/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6161/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6162/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6163/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6164/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6165/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6166/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6167/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6168/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6169/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6170/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6171/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6172/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6173/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6174/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6175/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6176/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6177/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6178/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6179/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6180/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6181/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6182/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6183/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6184/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6185/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6186/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6187/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6188/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6189/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6190/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6191/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6192/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6193/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6194/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6195/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6196/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6197/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6198/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6199/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6200/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6201/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6202/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6203/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6204/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6205/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6206/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6207/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6208/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6209/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6210/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6211/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6212/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6213/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6214/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6215/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6216/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6217/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6218/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6219/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6220/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6221/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6222/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6223/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6224/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6225/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6226/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6227/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6228/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6229/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6230/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6231/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6232/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6233/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6234/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6235/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6236/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6237/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6238/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6239/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6240/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6241/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6242/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6243/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6244/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6245/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6246/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6247/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6248/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6249/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6250/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6251/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6252/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6253/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6254/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6255/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6256/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6257/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6258/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6259/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6260/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6261/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6262/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6263/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6264/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6265/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6266/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6267/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6268/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6269/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6270/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6271/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6272/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6273/10000step_number: 0/29 cost:  nan accuracy:  0.9526014709888314\n",
      "Epoch number: 6274/10000step_number: 0/29 cost:  nan accuracy:  0.9517842549713974\n",
      "Epoch number: 6275/10000step_number: 0/29 cost:  nan accuracy:  0.9515118496322528\n",
      "Epoch number: 6276/10000step_number: 0/29 cost:  nan accuracy:  0.9542359030236993\n",
      "Epoch number: 6277/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6278/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6279/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6280/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6281/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6282/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6283/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6284/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6285/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6286/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6287/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6288/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6289/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6290/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6291/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6292/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6293/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6294/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6295/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6296/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6297/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6298/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6299/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6300/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6301/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6302/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6303/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6304/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6305/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6306/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6307/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6308/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6309/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6310/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6311/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6312/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6313/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6314/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6315/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6316/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6317/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6318/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6319/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6320/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6321/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6322/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6323/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6324/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6325/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6326/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6327/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6328/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6329/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6330/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6331/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6332/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6333/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6334/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6335/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6336/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6337/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6338/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6339/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6340/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6341/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6342/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6343/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6344/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6345/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6346/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6347/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6348/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6349/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6350/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6351/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6352/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6353/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6354/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6355/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6356/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6357/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6358/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6359/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6360/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6361/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6362/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6363/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6364/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6365/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6366/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6367/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6368/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6369/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6370/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6371/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6372/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6373/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6374/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6375/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6376/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6377/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6378/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6379/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6380/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6381/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6382/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6383/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6384/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6385/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6386/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6387/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6388/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6389/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6390/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6391/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6392/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6393/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6394/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6395/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6396/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6397/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6398/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6399/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6400/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6401/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6402/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6403/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6404/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6405/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6406/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6407/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6408/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6409/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6410/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6411/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6412/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6413/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6414/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6415/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6416/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6417/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6418/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6419/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6420/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6421/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6422/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6423/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6424/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6425/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6426/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6427/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6428/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6429/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6430/10000step_number: 0/29 cost:  nan accuracy:  0.9497412149278126\n",
      "Epoch number: 6431/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 6432/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6433/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6434/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6435/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6436/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6437/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6438/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6439/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6440/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6441/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6442/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6443/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6444/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6445/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6446/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6447/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6448/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6449/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6450/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6451/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6452/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6453/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6454/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6455/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6456/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6457/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6458/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6459/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6460/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6461/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6462/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6463/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6464/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6465/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6466/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6467/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6468/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6469/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6470/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6471/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6472/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6473/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6474/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6475/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6476/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6477/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6478/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6479/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6480/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6481/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6482/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6483/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6484/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6485/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6486/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6487/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6488/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6489/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6490/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6491/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6492/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6493/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6494/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6495/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6496/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6497/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6498/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6499/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6500/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6501/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6502/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6503/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6504/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6505/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6506/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6507/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6508/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6509/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6510/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6511/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6512/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6513/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6514/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6515/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6516/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6517/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6518/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6519/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6520/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6521/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6522/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6523/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6524/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6525/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6526/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6527/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6528/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6529/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6530/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6531/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6532/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6533/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6534/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6535/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6536/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6537/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6538/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6539/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6540/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6541/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6542/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6543/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6544/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6545/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6546/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6547/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6548/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6549/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6550/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6551/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6552/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6553/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6554/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6555/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6556/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6557/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6558/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6559/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6560/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6561/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6562/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6563/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6564/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6565/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6566/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6567/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6568/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6569/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6570/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6571/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6572/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6573/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6574/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6575/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6576/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6577/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6578/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6579/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6580/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6581/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6582/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6583/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6584/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6585/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6586/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6587/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6588/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6589/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6590/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6591/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6592/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6593/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6594/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6595/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6596/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6597/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6598/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6599/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6600/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6601/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6602/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6603/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6604/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6605/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6606/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6607/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6608/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6609/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6610/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6611/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6612/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6613/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6614/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6615/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6616/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6617/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6618/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6619/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6620/10000step_number: 0/29 cost:  nan accuracy:  0.9572323617542904\n",
      "Epoch number: 6621/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6622/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6623/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6624/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 6625/10000step_number: 0/29 cost:  nan accuracy:  0.9500136202669572\n",
      "Epoch number: 6626/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 6627/10000step_number: 0/29 cost:  nan accuracy:  0.954508308362844\n",
      "Epoch number: 6628/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6629/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6630/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6631/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6632/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6633/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 6634/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 6635/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 6636/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 6637/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6638/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6639/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6640/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6641/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6642/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 6643/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 6644/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6645/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6646/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6647/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6648/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6649/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6650/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 6651/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 6652/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6653/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6654/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6655/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 6656/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 6657/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 6658/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 6659/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 6660/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 6661/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 6662/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 6663/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6664/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6665/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6666/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6667/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6668/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6669/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6670/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6671/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6672/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6673/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6674/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6675/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6676/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6677/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6678/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6679/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6680/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6681/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6682/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6683/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6684/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6685/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6686/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6687/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6688/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6689/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6690/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6691/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6692/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6693/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6694/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6695/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6696/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6697/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6698/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6699/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6700/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6701/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6702/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6703/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6704/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6705/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6706/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6707/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6708/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6709/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6710/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6711/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6712/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6713/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6714/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6715/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6716/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6717/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6718/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6719/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6720/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6721/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6722/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6723/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6724/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6725/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6726/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6727/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6728/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6729/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6730/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6731/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6732/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6733/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6734/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6735/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6736/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6737/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6738/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6739/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6740/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6741/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6742/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6743/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6744/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6745/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6746/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6747/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6748/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6749/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6750/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6751/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6752/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6753/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6754/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6755/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6756/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6757/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6758/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6759/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6760/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6761/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6762/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6763/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6764/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6765/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6766/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6767/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6768/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6769/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6770/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6771/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6772/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6773/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6774/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6775/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6776/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6777/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 6778/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 6779/10000step_number: 0/29 cost:  nan accuracy:  0.9527376736584037\n",
      "Epoch number: 6780/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6781/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6782/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6783/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 6784/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6785/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6786/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6787/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6788/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6789/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6790/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6791/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6792/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 6793/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 6794/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6795/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6796/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6797/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6798/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6799/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6800/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6801/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6802/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6803/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6804/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6805/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6806/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6807/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6808/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6809/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6810/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6811/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6812/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6813/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6814/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6815/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6816/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6817/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6818/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6819/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6820/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6821/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6822/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6823/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6824/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6825/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6826/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6827/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6828/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6829/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6830/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6831/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6832/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6833/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6834/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6835/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6836/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6837/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6838/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6839/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6840/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6841/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6842/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6843/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6844/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6845/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6846/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6847/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6848/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6849/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6850/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6851/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6852/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6853/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6854/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6855/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6856/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6857/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6858/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6859/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6860/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6861/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6862/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6863/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6864/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6865/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6866/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6867/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6868/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6869/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6870/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6871/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6872/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6873/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6874/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6875/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6876/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6877/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6878/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6879/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6880/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6881/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6882/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6883/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6884/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6885/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6886/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6887/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6888/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6889/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6890/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 6891/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6892/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 6893/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 6894/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6895/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 6896/10000step_number: 0/29 cost:  nan accuracy:  0.948651593571234\n",
      "Epoch number: 6897/10000step_number: 0/29 cost:  nan accuracy:  0.9466085535276492\n",
      "Epoch number: 6898/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 6899/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6900/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6901/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6902/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6903/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6904/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 6905/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6906/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 6907/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6908/10000step_number: 0/29 cost:  nan accuracy:  0.957504767093435\n",
      "Epoch number: 6909/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 6910/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 6911/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 6912/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6913/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6914/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6915/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6916/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6917/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6918/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6919/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6920/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6921/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6922/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6923/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6924/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6925/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6926/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 6927/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6928/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6929/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6930/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6931/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6932/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6933/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6934/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6935/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6936/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6937/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 6938/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 6939/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6940/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 6941/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6942/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6943/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6944/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6945/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6946/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6947/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6948/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6949/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6950/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 6951/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6952/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6953/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6954/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6955/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6956/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6957/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 6958/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6959/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6960/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6961/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6962/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6963/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6964/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6965/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6966/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6967/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6968/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6969/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6970/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 6971/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6972/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6973/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6974/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 6975/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6976/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6977/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6978/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6979/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6980/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6981/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6982/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 6983/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6984/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6985/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6986/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6987/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 6988/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6989/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6990/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6991/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6992/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6993/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6994/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6995/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6996/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6997/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6998/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 6999/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 7000/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 7001/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 7002/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7003/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7004/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7005/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7006/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7007/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7008/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7009/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 7010/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7011/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 7012/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 7013/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 7014/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 7015/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 7016/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 7017/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 7018/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 7019/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 7020/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7021/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7022/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7023/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7024/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7025/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7026/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7027/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7028/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7029/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7030/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7031/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7032/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7033/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7034/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7035/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7036/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7037/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7038/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7039/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7040/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7041/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7042/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7043/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7044/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7045/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7046/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7047/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7048/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7049/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7050/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7051/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7052/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7053/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7054/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7055/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7056/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7057/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7058/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7059/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7060/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7061/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 7062/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7063/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7064/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 7065/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 7066/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 7067/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 7068/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7069/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7070/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7071/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7072/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7073/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 7074/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 7075/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 7076/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 7077/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 7078/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7079/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7080/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7081/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7082/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7083/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7084/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7085/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7086/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7087/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7088/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7089/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7090/10000step_number: 0/29 cost:  nan accuracy:  0.9521928629801144\n",
      "Epoch number: 7091/10000step_number: 0/29 cost:  nan accuracy:  0.9565513484064287\n",
      "Epoch number: 7092/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 7093/10000step_number: 0/29 cost:  nan accuracy:  0.9546445110324162\n",
      "Epoch number: 7094/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7095/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 7096/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7097/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7098/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7099/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7100/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7101/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7102/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7103/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7104/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7105/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7106/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7107/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7108/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7109/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7110/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7111/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7112/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7113/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7114/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7115/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7116/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7117/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7118/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7119/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7120/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7121/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7122/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7123/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7124/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7125/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7126/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7127/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7128/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7129/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7130/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7131/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7132/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7133/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7134/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7135/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7136/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7137/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7138/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7139/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7140/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7141/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7142/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7143/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7144/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7145/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7146/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7147/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7148/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7149/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7150/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7151/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7152/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7153/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7154/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7155/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7156/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7157/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7158/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7159/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7160/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7161/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7162/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7163/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7164/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7165/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7166/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7167/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7168/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7169/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7170/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7171/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7172/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7173/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7174/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7175/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7176/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7177/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7178/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7179/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7180/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7181/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7182/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7183/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7184/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7185/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7186/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7187/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7188/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7189/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7190/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7191/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7192/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7193/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7194/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7195/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7196/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7197/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7198/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7199/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7200/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7201/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7202/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7203/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7204/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7205/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7206/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7207/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7208/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7209/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 7210/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7211/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 7212/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7213/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7214/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7215/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7216/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7217/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7218/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7219/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7220/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7221/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7222/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7223/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7224/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7225/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7226/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7227/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7228/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7229/10000step_number: 0/29 cost:  nan accuracy:  0.9392536093707436\n",
      "Epoch number: 7230/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 7231/10000step_number: 0/29 cost:  nan accuracy:  0.9562789430672841\n",
      "Epoch number: 7232/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 7233/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 7234/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 7235/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 7236/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 7237/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7238/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 7239/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 7240/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 7241/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 7242/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 7243/10000step_number: 0/29 cost:  nan accuracy:  0.9584581857804413\n",
      "Epoch number: 7244/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 7245/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 7246/10000step_number: 0/29 cost:  nan accuracy:  0.9587305911195859\n",
      "Epoch number: 7247/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7248/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7249/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7250/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7251/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7252/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7253/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7254/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7255/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7256/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7257/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7258/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7259/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7260/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7261/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7262/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7263/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7264/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7265/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7266/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7267/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7268/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7269/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7270/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7271/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7272/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7273/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7274/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7275/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7276/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7277/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7278/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7279/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7280/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7281/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7282/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7283/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7284/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7285/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7286/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7287/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7288/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7289/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7290/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7291/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7292/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7293/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7294/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7295/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7296/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7297/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7298/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7299/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7300/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7301/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7302/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7303/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7304/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7305/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7306/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7307/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7308/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7309/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7310/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7311/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7312/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7313/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7314/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7315/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7316/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7317/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7318/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7319/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7320/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7321/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7322/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7323/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7324/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7325/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7326/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7327/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7328/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7329/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7330/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7331/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7332/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7333/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7334/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7335/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7336/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7337/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7338/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7339/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7340/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7341/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7342/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7343/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7344/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7345/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7346/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7347/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7348/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7349/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7350/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7351/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7352/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7353/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7354/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7355/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7356/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7357/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7358/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7359/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7360/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7361/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7362/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7363/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7364/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7365/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7366/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7367/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7368/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7369/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7370/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7371/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7372/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7373/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7374/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7375/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7376/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7377/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7378/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7379/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7380/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7381/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7382/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7383/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7384/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7385/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7386/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7387/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7388/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7389/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7390/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7391/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7392/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7393/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7394/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7395/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7396/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7397/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7398/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7399/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7400/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7401/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7402/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7403/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7404/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7405/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7406/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7407/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7408/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7409/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7410/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7411/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7412/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7413/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7414/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7415/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7416/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7417/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7418/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7419/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7420/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7421/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7422/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7423/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7424/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7425/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7426/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 7427/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7428/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7429/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7430/10000step_number: 0/29 cost:  nan accuracy:  0.9569599564151458\n",
      "Epoch number: 7431/10000step_number: 0/29 cost:  nan accuracy:  0.9576409697630074\n",
      "Epoch number: 7432/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 7433/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7434/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7435/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 7436/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 7437/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7438/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7439/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7440/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7441/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7442/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7443/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7444/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7445/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7446/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7447/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7448/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7449/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7450/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7451/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7452/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7453/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7454/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7455/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7456/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7457/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7458/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7459/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7460/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7461/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7462/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7463/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7464/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7465/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7466/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7467/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7468/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7469/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7470/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7471/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7472/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7473/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7474/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7475/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7476/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7477/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7478/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7479/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7480/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7481/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7482/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7483/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7484/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7485/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7486/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7487/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7488/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7489/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7490/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7491/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7492/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7493/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7494/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7495/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7496/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7497/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7498/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7499/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7500/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7501/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7502/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7503/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7504/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7505/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7506/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7507/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7508/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7509/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7510/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7511/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7512/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7513/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7514/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7515/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7516/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7517/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7518/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7519/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7520/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7521/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7522/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7523/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7524/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7525/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7526/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7527/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7528/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7529/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7530/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7531/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7532/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7533/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7534/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7535/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7536/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7537/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7538/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7539/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7540/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7541/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7542/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7543/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7544/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7545/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7546/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7547/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7548/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7549/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7550/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7551/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7552/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7553/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7554/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7555/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7556/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7557/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7558/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7559/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7560/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7561/10000step_number: 0/29 cost:  nan accuracy:  0.9535548896758377\n",
      "Epoch number: 7562/10000step_number: 0/29 cost:  nan accuracy:  0.9531462816671207\n",
      "Epoch number: 7563/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 7564/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7565/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7566/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7567/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7568/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7569/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7570/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7571/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7572/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7573/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7574/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7575/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7576/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7577/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7578/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7579/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7580/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7581/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7582/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7583/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7584/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7585/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7586/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7587/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7588/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7589/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7590/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7591/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 7592/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7593/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7594/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7595/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 7596/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 7597/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7598/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7599/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7600/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7601/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 7602/10000step_number: 0/29 cost:  nan accuracy:  0.9592754017978753\n",
      "Epoch number: 7603/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7604/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7605/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7606/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7607/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7608/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7609/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7610/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 7611/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7612/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7613/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7614/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7615/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7616/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7617/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7618/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7619/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7620/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7621/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7622/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7623/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7624/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7625/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7626/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7627/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7628/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7629/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7630/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7631/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7632/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7633/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7634/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7635/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7636/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7637/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7638/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7639/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7640/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7641/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7642/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7643/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7644/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7645/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7646/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7647/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7648/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7649/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7650/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7651/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7652/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7653/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7654/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7655/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7656/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7657/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7658/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7659/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7660/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7661/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7662/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7663/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7664/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7665/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7666/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7667/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7668/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7669/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7670/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7671/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7672/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7673/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7674/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7675/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7676/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7677/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7678/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7679/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7680/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7681/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7682/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7683/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7684/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7685/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7686/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7687/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7688/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7689/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7690/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7691/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7692/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7693/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7694/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7695/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7696/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7697/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7698/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7699/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7700/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7701/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7702/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7703/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7704/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7705/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7706/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7707/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7708/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7709/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7710/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7711/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7712/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7713/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7714/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7715/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7716/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7717/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7718/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7719/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7720/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7721/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7722/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7723/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7724/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7725/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7726/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7727/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7728/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7729/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7730/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7731/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7732/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7733/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7734/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7735/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7736/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7737/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7738/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7739/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7740/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7741/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7742/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 7743/10000step_number: 0/29 cost:  nan accuracy:  0.952056660310542\n",
      "Epoch number: 7744/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 7745/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 7746/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7747/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7748/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7749/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7750/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7751/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7752/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7753/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7754/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7755/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7756/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7757/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7758/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7759/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7760/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7761/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7762/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7763/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7764/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7765/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7766/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7767/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7768/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7769/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7770/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7771/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7772/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7773/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7774/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7775/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7776/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7777/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7778/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7779/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7780/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7781/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7782/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7783/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7784/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7785/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7786/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7787/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7788/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7789/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7790/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7791/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7792/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7793/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7794/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7795/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7796/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7797/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7798/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7799/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7800/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7801/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7802/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7803/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7804/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7805/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7806/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7807/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7808/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7809/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7810/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7811/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7812/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7813/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7814/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7815/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7816/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7817/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7818/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7819/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7820/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7821/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7822/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7823/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7824/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7825/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7826/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7827/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7828/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7829/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7830/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7831/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7832/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7833/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7834/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7835/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7836/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7837/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7838/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7839/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7840/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7841/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7842/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7843/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7844/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7845/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7846/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7847/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7848/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7849/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7850/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7851/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7852/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7853/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7854/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7855/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7856/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7857/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7858/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7859/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7860/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7861/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7862/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7863/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7864/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7865/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7866/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7867/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7868/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7869/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7870/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7871/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7872/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 7873/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7874/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7875/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7876/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7877/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7878/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7879/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7880/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7881/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7882/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7883/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7884/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7885/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7886/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7887/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7888/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7889/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7890/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7891/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7892/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7893/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7894/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7895/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7896/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7897/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7898/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7899/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7900/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7901/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7902/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7903/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7904/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7905/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7906/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7907/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7908/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7909/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7910/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7911/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7912/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7913/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7914/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7915/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7916/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7917/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7918/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7919/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7920/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7921/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7922/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7923/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7924/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7925/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7926/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7927/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7928/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7929/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7930/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7931/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7932/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7933/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7934/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7935/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7936/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7937/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7938/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7939/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7940/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7941/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7942/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7943/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7944/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7945/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7946/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7947/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7948/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 7949/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7950/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7951/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7952/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7953/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7954/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7955/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7956/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7957/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7958/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 7959/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 7960/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 7961/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 7962/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 7963/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7964/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7965/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 7966/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7967/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7968/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7969/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 7970/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 7971/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 7972/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 7973/10000step_number: 0/29 cost:  nan accuracy:  0.9489239989103786\n",
      "Epoch number: 7974/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 7975/10000step_number: 0/29 cost:  nan accuracy:  0.958321983110869\n",
      "Epoch number: 7976/10000step_number: 0/29 cost:  nan accuracy:  0.9580495777717243\n",
      "Epoch number: 7977/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 7978/10000step_number: 0/29 cost:  nan accuracy:  0.9595478071370199\n",
      "Epoch number: 7979/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7980/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7981/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7982/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7983/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7984/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7985/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7986/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7987/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7988/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7989/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7990/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7991/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7992/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7993/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7994/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7995/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 7996/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 7997/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7998/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 7999/10000step_number: 0/29 cost:  nan accuracy:  0.9596840098065922\n",
      "Epoch number: 8000/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 8001/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8002/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8003/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8004/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8005/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8006/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8007/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 8008/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 8009/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 8010/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 8011/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 8012/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 8013/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8014/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8015/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8016/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8017/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8018/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8019/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8020/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8021/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8022/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8023/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8024/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8025/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8026/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8027/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8028/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8029/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8030/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8031/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8032/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8033/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8034/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8035/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8036/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8037/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8038/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8039/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8040/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8041/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8042/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8043/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8044/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8045/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8046/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8047/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8048/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8049/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8050/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8051/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8052/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8053/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8054/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8055/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8056/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8057/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8058/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8059/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8060/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8061/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8062/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8063/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8064/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8065/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8066/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8067/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8068/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8069/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8070/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8071/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8072/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8073/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8074/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8075/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8076/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8077/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8078/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8079/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8080/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8081/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8082/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8083/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8084/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8085/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8086/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8087/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8088/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8089/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8090/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8091/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8092/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8093/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8094/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8095/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8096/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8097/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8098/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8099/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8100/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8101/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8102/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8103/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8104/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8105/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8106/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8107/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8108/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8109/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8110/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8111/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8112/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8113/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8114/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8115/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8116/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8117/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8118/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8119/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8120/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8121/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8122/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8123/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8124/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8125/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8126/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8127/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8128/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8129/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8130/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8131/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8132/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8133/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8134/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8135/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8136/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8137/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8138/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8139/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8140/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8141/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8142/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8143/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8144/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8145/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8146/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8147/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8148/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8149/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8150/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8151/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8152/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8153/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8154/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8155/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8156/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8157/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8158/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8159/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8160/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8161/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8162/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8163/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8164/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8165/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8166/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8167/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8168/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8169/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8170/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8171/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8172/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8173/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8174/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8175/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8176/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8177/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8178/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8179/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8180/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8181/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8182/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8183/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8184/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8185/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8186/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8187/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8188/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8189/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8190/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8191/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8192/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8193/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8194/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8195/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8196/10000step_number: 0/29 cost:  nan accuracy:  0.9539634976845546\n",
      "Epoch number: 8197/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 8198/10000step_number: 0/29 cost:  nan accuracy:  0.9568237537455734\n",
      "Epoch number: 8199/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 8200/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8201/10000step_number: 0/29 cost:  nan accuracy:  0.9588667937891583\n",
      "Epoch number: 8202/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 8203/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 8204/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8205/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8206/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 8207/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8208/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8209/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8210/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8211/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 8212/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8213/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8214/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8215/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8216/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8217/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8218/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8219/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8220/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8221/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8222/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8223/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8224/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8225/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8226/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8227/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8228/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8229/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8230/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8231/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8232/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8233/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8234/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8235/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8236/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8237/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8238/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8239/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8240/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8241/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8242/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8243/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8244/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8245/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8246/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8247/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8248/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8249/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8250/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8251/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8252/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8253/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8254/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8255/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8256/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8257/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8258/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8259/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8260/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8261/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8262/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8263/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8264/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8265/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8266/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8267/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8268/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8269/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8270/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8271/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8272/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8273/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8274/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8275/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8276/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8277/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8278/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8279/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8280/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8281/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8282/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8283/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8284/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8285/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8286/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8287/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8288/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8289/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8290/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8291/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8292/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8293/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8294/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8295/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8296/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8297/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8298/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8299/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8300/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8301/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8302/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8303/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8304/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8305/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8306/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8307/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8308/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8309/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8310/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8311/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8312/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8313/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8314/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8315/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8316/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8317/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8318/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8319/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8320/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8321/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8322/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8323/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8324/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8325/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8326/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8327/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8328/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8329/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8330/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8331/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8332/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8333/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8334/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8335/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8336/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8337/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8338/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8339/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8340/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8341/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8342/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8343/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8344/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8345/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8346/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8347/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8348/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8349/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8350/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8351/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8352/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8353/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8354/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8355/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8356/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8357/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8358/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8359/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8360/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8361/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8362/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8363/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8364/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8365/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8366/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8367/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8368/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8369/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8370/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8371/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8372/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8373/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8374/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8375/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8376/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8377/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8378/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8379/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8380/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8381/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8382/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8383/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8384/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8385/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8386/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8387/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8388/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8389/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8390/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8391/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8392/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8393/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8394/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8395/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8396/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8397/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8398/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8399/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8400/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8401/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8402/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8403/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8404/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8405/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8406/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8407/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8408/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8409/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8410/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8411/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8412/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8413/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8414/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8415/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8416/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8417/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8418/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8419/10000step_number: 0/29 cost:  nan accuracy:  0.9506946336148189\n",
      "Epoch number: 8420/10000step_number: 0/29 cost:  nan accuracy:  0.9561427403977117\n",
      "Epoch number: 8421/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 8422/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 8423/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8424/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8425/10000step_number: 0/29 cost:  nan accuracy:  0.9599564151457368\n",
      "Epoch number: 8426/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8427/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8428/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8429/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8430/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8431/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8432/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8433/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8434/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8435/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8436/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8437/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8438/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8439/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8440/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8441/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8442/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8443/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8444/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8445/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8446/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8447/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8448/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8449/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8450/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8451/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8452/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8453/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8454/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8455/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8456/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8457/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8458/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8459/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8460/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8461/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8462/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8463/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8464/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8465/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8466/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8467/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8468/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8469/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8470/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8471/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8472/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8473/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8474/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8475/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8476/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8477/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8478/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8479/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8480/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8481/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8482/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8483/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8484/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8485/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8486/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8487/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8488/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8489/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8490/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8491/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8492/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8493/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8494/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8495/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8496/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8497/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8498/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8499/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8500/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8501/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8502/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8503/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8504/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8505/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8506/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8507/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8508/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8509/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8510/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8511/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8512/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8513/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8514/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8515/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8516/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8517/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8518/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8519/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8520/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8521/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8522/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8523/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8524/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8525/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8526/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8527/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8528/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8529/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8530/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8531/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8532/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8533/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8534/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8535/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8536/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8537/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8538/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8539/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8540/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8541/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8542/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8543/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8544/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8545/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8546/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8547/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8548/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8549/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8550/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8551/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8552/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8553/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8554/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8555/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8556/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8557/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8558/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8559/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8560/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8561/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8562/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8563/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8564/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8565/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8566/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8567/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8568/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8569/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8570/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8571/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8572/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8573/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8574/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8575/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8576/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8577/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8578/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8579/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8580/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8581/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8582/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 8583/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 8584/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 8585/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8586/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8587/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8588/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8589/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 8590/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 8591/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 8592/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 8593/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 8594/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 8595/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 8596/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 8597/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 8598/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 8599/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 8600/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8601/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8602/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8603/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8604/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8605/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8606/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8607/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8608/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 8609/10000step_number: 0/29 cost:  nan accuracy:  0.9550531190411332\n",
      "Epoch number: 8610/10000step_number: 0/29 cost:  nan accuracy:  0.9581857804412967\n",
      "Epoch number: 8611/10000step_number: 0/29 cost:  nan accuracy:  0.9557341323889949\n",
      "Epoch number: 8612/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n",
      "Epoch number: 8613/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8614/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8615/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8616/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8617/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8618/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8619/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8620/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8621/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8622/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8623/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8624/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8625/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8626/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8627/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8628/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8629/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8630/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8631/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8632/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8633/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8634/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8635/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8636/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8637/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8638/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8639/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8640/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8641/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8642/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8643/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8644/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8645/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8646/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8647/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8648/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8649/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8650/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8651/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8652/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8653/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8654/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8655/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8656/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8657/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8658/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8659/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8660/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8661/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8662/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8663/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8664/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8665/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8666/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8667/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8668/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8669/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8670/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8671/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8672/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8673/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8674/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8675/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8676/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8677/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8678/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8679/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8680/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8681/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8682/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8683/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8684/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8685/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8686/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8687/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8688/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8689/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8690/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8691/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8692/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8693/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8694/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8695/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8696/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8697/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8698/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8699/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8700/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8701/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8702/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8703/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8704/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8705/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8706/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8707/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8708/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8709/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8710/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8711/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8712/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8713/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8714/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8715/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8716/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8717/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8718/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8719/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8720/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8721/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8722/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8723/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8724/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8725/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8726/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8727/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8728/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8729/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8730/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8731/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8732/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8733/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8734/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8735/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8736/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8737/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8738/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8739/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8740/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8741/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8742/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8743/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8744/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8745/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8746/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8747/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8748/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8749/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8750/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8751/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8752/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8753/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8754/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8755/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8756/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8757/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8758/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8759/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8760/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8761/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 8762/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8763/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8764/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8765/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8766/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 8767/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 8768/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 8769/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 8770/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 8771/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 8772/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 8773/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 8774/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 8775/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 8776/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 8777/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 8778/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8779/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8780/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8781/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8782/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8783/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 8784/10000step_number: 0/29 cost:  nan accuracy:  0.9547807137019886\n",
      "Epoch number: 8785/10000step_number: 0/29 cost:  nan accuracy:  0.9585943884500137\n",
      "Epoch number: 8786/10000step_number: 0/29 cost:  nan accuracy:  0.9594116044674476\n",
      "Epoch number: 8787/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8788/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8789/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8790/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8791/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8792/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8793/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8794/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8795/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8796/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8797/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8798/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8799/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8800/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8801/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8802/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8803/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8804/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8805/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8806/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8807/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8808/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8809/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8810/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8811/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8812/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8813/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8814/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8815/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8816/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8817/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8818/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8819/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8820/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8821/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8822/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8823/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8824/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8825/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8826/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8827/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8828/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8829/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8830/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8831/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8832/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8833/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8834/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8835/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8836/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8837/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8838/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8839/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8840/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8841/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8842/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8843/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8844/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8845/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8846/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8847/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8848/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8849/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8850/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8851/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8852/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8853/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8854/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8855/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8856/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8857/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8858/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8859/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8860/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8861/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8862/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8863/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8864/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8865/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8866/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8867/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8868/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8869/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8870/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8871/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8872/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8873/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8874/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8875/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8876/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8877/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8878/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8879/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8880/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8881/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8882/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8883/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8884/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8885/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8886/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8887/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8888/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8889/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8890/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8891/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8892/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8893/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8894/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8895/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8896/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8897/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8898/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8899/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8900/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8901/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8902/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8903/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8904/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8905/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8906/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8907/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8908/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8909/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8910/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8911/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8912/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8913/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8914/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8915/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8916/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8917/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8918/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8919/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8920/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8921/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8922/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8923/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8924/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8925/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8926/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8927/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8928/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8929/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8930/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8931/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8932/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8933/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8934/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8935/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8936/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8937/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8938/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 8939/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8940/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8941/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8942/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 8943/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8944/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8945/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8946/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8947/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8948/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 8949/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 8950/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8951/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 8952/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 8953/10000step_number: 0/29 cost:  nan accuracy:  0.957913375102152\n",
      "Epoch number: 8954/10000step_number: 0/29 cost:  nan accuracy:  0.9577771724325796\n",
      "Epoch number: 8955/10000step_number: 0/29 cost:  nan accuracy:  0.9600926178153092\n",
      "Epoch number: 8956/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8957/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8958/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8959/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8960/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8961/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8962/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8963/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8964/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8965/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8966/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8967/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8968/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8969/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8970/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8971/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 8972/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8973/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8974/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8975/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8976/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8977/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8978/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8979/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8980/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8981/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8982/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8983/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8984/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8985/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8986/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 8987/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8988/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 8989/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8990/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8991/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8992/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 8993/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8994/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8995/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 8996/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8997/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8998/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 8999/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9000/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 9001/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 9002/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 9003/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 9004/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9005/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9006/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9007/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9008/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9009/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9010/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9011/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9012/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9013/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9014/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9015/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9016/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9017/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9018/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9019/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9020/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9021/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9022/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9023/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9024/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9025/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9026/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9027/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9028/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9029/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9030/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9031/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9032/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9033/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9034/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9035/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9036/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9037/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9038/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9039/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9040/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9041/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9042/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9043/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9044/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9045/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9046/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9047/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9048/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9049/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9050/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9051/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9052/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9053/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9054/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9055/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9056/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9057/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9058/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9059/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9060/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9061/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9062/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9063/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9064/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9065/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9066/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9067/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9068/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9069/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9070/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9071/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9072/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9073/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9074/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9075/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9076/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9077/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9078/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9079/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9080/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9081/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9082/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9083/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9084/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9085/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9086/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9087/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9088/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9089/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9090/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9091/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9092/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9093/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9094/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9095/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9096/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9097/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9098/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9099/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9100/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9101/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9102/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9103/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9104/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9105/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9106/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9107/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9108/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9109/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9110/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9111/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9112/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9113/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9114/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9115/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9116/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9117/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9118/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9119/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9120/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9121/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9122/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9123/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9124/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9125/10000step_number: 0/29 cost:  nan accuracy:  0.9591391991283029\n",
      "Epoch number: 9126/10000step_number: 0/29 cost:  nan accuracy:  0.9558703350585671\n",
      "Epoch number: 9127/10000step_number: 0/29 cost:  nan accuracy:  0.9560065377281395\n",
      "Epoch number: 9128/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9129/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9130/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9131/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9132/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9133/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9134/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9135/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9136/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9137/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9138/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9139/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9140/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9141/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9142/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9143/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9144/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9145/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9146/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9147/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9148/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9149/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9150/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9151/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9152/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9153/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9154/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 9155/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 9156/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 9157/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9158/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9159/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9160/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9161/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9162/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9163/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9164/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9165/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9166/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9167/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9168/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9169/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9170/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9171/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9172/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9173/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9174/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9175/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9176/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9177/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9178/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9179/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9180/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9181/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9182/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9183/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9184/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9185/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9186/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9187/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9188/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9189/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9190/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9191/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9192/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9193/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9194/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9195/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9196/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9197/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9198/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9199/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9200/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9201/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9202/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9203/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9204/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9205/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9206/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9207/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9208/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9209/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9210/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9211/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9212/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9213/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9214/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9215/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9216/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9217/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9218/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9219/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9220/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9221/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9222/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9223/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9224/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9225/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9226/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9227/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9228/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9229/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9230/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9231/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9232/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9233/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9234/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9235/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9236/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9237/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9238/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9239/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9240/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9241/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9242/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9243/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9244/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9245/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9246/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9247/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9248/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9249/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9250/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9251/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9252/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9253/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9254/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9255/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9256/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9257/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9258/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9259/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9260/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9261/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9262/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9263/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9264/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9265/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9266/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9267/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9268/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9269/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9270/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9271/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9272/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9273/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9274/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9275/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9276/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9277/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9278/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9279/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9280/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9281/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9282/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9283/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9284/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9285/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9286/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9287/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9288/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9289/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9290/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9291/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9292/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9293/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9294/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9295/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9296/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9297/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9298/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9299/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9300/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9301/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9302/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9303/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9304/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9305/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9306/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9307/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9308/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9309/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9310/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9311/10000step_number: 0/29 cost:  nan accuracy:  0.9551893217107055\n",
      "Epoch number: 9312/10000step_number: 0/29 cost:  nan accuracy:  0.9549169163715608\n",
      "Epoch number: 9313/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9314/10000step_number: 0/29 cost:  nan accuracy:  0.962135657858894\n",
      "Epoch number: 9315/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9316/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9317/10000step_number: 0/29 cost:  nan accuracy:  0.962135657858894\n",
      "Epoch number: 9318/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9319/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9320/10000step_number: 0/29 cost:  nan accuracy:  0.962135657858894\n",
      "Epoch number: 9321/10000step_number: 0/29 cost:  nan accuracy:  0.962135657858894\n",
      "Epoch number: 9322/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9323/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9324/10000step_number: 0/29 cost:  nan accuracy:  0.9626804685371834\n",
      "Epoch number: 9325/10000step_number: 0/29 cost:  nan accuracy:  0.9626804685371834\n",
      "Epoch number: 9326/10000step_number: 0/29 cost:  nan accuracy:  0.9626804685371834\n",
      "Epoch number: 9327/10000step_number: 0/29 cost:  nan accuracy:  0.9626804685371834\n",
      "Epoch number: 9328/10000step_number: 0/29 cost:  nan accuracy:  0.9626804685371834\n",
      "Epoch number: 9329/10000step_number: 0/29 cost:  nan accuracy:  0.9626804685371834\n",
      "Epoch number: 9330/10000step_number: 0/29 cost:  nan accuracy:  0.9626804685371834\n",
      "Epoch number: 9331/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9332/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9333/10000step_number: 0/29 cost:  nan accuracy:  0.9626804685371834\n",
      "Epoch number: 9334/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9335/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9336/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9337/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9338/10000step_number: 0/29 cost:  nan accuracy:  0.9626804685371834\n",
      "Epoch number: 9339/10000step_number: 0/29 cost:  nan accuracy:  0.9626804685371834\n",
      "Epoch number: 9340/10000step_number: 0/29 cost:  nan accuracy:  0.9626804685371834\n",
      "Epoch number: 9341/10000step_number: 0/29 cost:  nan accuracy:  0.9628166712067556\n",
      "Epoch number: 9342/10000step_number: 0/29 cost:  nan accuracy:  0.9628166712067556\n",
      "Epoch number: 9343/10000step_number: 0/29 cost:  nan accuracy:  0.9626804685371834\n",
      "Epoch number: 9344/10000step_number: 0/29 cost:  nan accuracy:  0.9626804685371834\n",
      "Epoch number: 9345/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9346/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9347/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9348/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9349/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9350/10000step_number: 0/29 cost:  nan accuracy:  0.9626804685371834\n",
      "Epoch number: 9351/10000step_number: 0/29 cost:  nan accuracy:  0.9628166712067556\n",
      "Epoch number: 9352/10000step_number: 0/29 cost:  nan accuracy:  0.9628166712067556\n",
      "Epoch number: 9353/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9354/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9355/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9356/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9357/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9358/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9359/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9360/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9361/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9362/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9363/10000step_number: 0/29 cost:  nan accuracy:  0.9622718605284664\n",
      "Epoch number: 9364/10000step_number: 0/29 cost:  nan accuracy:  0.962135657858894\n",
      "Epoch number: 9365/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9366/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9367/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9368/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9369/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9370/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9371/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9372/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9373/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9374/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9375/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9376/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9377/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9378/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9379/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9380/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9381/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9382/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9383/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9384/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9385/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9386/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9387/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9388/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9389/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9390/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9391/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9392/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9393/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9394/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9395/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9396/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9397/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9398/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9399/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9400/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9401/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9402/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9403/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9404/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9405/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9406/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9407/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9408/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9409/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9410/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9411/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9412/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9413/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9414/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9415/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9416/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9417/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9418/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9419/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9420/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9421/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9422/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9423/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9424/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9425/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9426/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9427/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9428/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9429/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9430/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9431/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9432/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9433/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9434/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9435/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9436/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9437/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9438/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9439/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9440/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9441/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9442/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9443/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9444/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9445/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9446/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9447/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9448/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9449/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9450/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9451/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9452/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9453/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9454/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9455/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9456/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9457/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9458/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9459/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9460/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9461/10000step_number: 0/29 cost:  nan accuracy:  0.9605012258240262\n",
      "Epoch number: 9462/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9463/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9464/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9465/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9466/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9467/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9468/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9469/10000step_number: 0/29 cost:  nan accuracy:  0.9607736311631708\n",
      "Epoch number: 9470/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9471/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9472/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9473/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9474/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9475/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9476/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9477/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9478/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9479/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9480/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9481/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9482/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9483/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9484/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9485/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9486/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9487/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9488/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9489/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9490/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9491/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9492/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9493/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9494/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9495/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9496/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9497/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9498/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9499/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9500/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9501/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9502/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9503/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9504/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9505/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9506/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9507/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9508/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9509/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9510/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9511/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9512/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9513/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9514/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9515/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9516/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9517/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9518/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9519/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9520/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9521/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9522/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9523/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9524/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9525/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9526/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9527/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9528/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9529/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9530/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9531/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9532/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9533/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9534/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9535/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9536/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9537/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9538/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9539/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9540/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9541/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9542/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9543/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9544/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9545/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9546/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9547/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9548/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9549/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9550/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9551/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9552/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9553/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9554/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9555/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9556/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9557/10000step_number: 0/29 cost:  nan accuracy:  0.962135657858894\n",
      "Epoch number: 9558/10000step_number: 0/29 cost:  nan accuracy:  0.9622718605284664\n",
      "Epoch number: 9559/10000step_number: 0/29 cost:  nan accuracy:  0.9622718605284664\n",
      "Epoch number: 9560/10000step_number: 0/29 cost:  nan accuracy:  0.9622718605284664\n",
      "Epoch number: 9561/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9562/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9563/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9564/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9565/10000step_number: 0/29 cost:  nan accuracy:  0.9468809588667938\n",
      "Epoch number: 9566/10000step_number: 0/29 cost:  nan accuracy:  0.9531462816671207\n",
      "Epoch number: 9567/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9568/10000step_number: 0/29 cost:  nan accuracy:  0.9606374284935985\n",
      "Epoch number: 9569/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9570/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9571/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9572/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9573/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9574/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9575/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9576/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9577/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9578/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9579/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9580/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9581/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9582/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9583/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9584/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9585/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9586/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9587/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9588/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9589/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9590/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9591/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9592/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9593/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9594/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9595/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9596/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9597/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9598/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9599/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9600/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9601/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9602/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9603/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9604/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9605/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9606/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9607/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9608/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9609/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9610/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9611/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9612/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9613/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9614/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9615/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9616/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9617/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9618/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9619/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9620/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9621/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9622/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9623/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9624/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9625/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9626/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9627/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9628/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9629/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9630/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9631/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9632/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9633/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9634/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9635/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9636/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9637/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9638/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9639/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9640/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9641/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9642/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9643/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9644/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9645/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9646/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9647/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9648/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9649/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9650/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9651/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9652/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9653/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9654/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9655/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9656/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9657/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9658/10000step_number: 0/29 cost:  nan accuracy:  0.9610460365023155\n",
      "Epoch number: 9659/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9660/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9661/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9662/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9663/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9664/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9665/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9666/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9667/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9668/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9669/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9670/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9671/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9672/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9673/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9674/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9675/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9676/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9677/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9678/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9679/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9680/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9681/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9682/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9683/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9684/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9685/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9686/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9687/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9688/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9689/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9690/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9691/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9692/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9693/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9694/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9695/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9696/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9697/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9698/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9699/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9700/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9701/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9702/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9703/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9704/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9705/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9706/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9707/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9708/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9709/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9710/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9711/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9712/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9713/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9714/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9715/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9716/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9717/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9718/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9719/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9720/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9721/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9722/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9723/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9724/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9725/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9726/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9727/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9728/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9729/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9730/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9731/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9732/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9733/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9734/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9735/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9736/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9737/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9738/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9739/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9740/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9741/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9742/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9743/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9744/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9745/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9746/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9747/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9748/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9749/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9750/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9751/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9752/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9753/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9754/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9755/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9756/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9757/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9758/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9759/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9760/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9761/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9762/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9763/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9764/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9765/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9766/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9767/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9768/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9769/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9770/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9771/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9772/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9773/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9774/10000step_number: 0/29 cost:  nan accuracy:  0.9598202124761646\n",
      "Epoch number: 9775/10000step_number: 0/29 cost:  nan accuracy:  0.9554617270498502\n",
      "Epoch number: 9776/10000step_number: 0/29 cost:  nan accuracy:  0.9573685644238628\n",
      "Epoch number: 9777/10000step_number: 0/29 cost:  nan accuracy:  0.9602288204848815\n",
      "Epoch number: 9778/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9779/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9780/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9781/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9782/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9783/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9784/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9785/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9786/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9787/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9788/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9789/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9790/10000step_number: 0/29 cost:  nan accuracy:  0.9626804685371834\n",
      "Epoch number: 9791/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9792/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9793/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9794/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9795/10000step_number: 0/29 cost:  nan accuracy:  0.9626804685371834\n",
      "Epoch number: 9796/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9797/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9798/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9799/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9800/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9801/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9802/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9803/10000step_number: 0/29 cost:  nan accuracy:  0.9624080631980387\n",
      "Epoch number: 9804/10000step_number: 0/29 cost:  nan accuracy:  0.9622718605284664\n",
      "Epoch number: 9805/10000step_number: 0/29 cost:  nan accuracy:  0.962135657858894\n",
      "Epoch number: 9806/10000step_number: 0/29 cost:  nan accuracy:  0.962135657858894\n",
      "Epoch number: 9807/10000step_number: 0/29 cost:  nan accuracy:  0.962135657858894\n",
      "Epoch number: 9808/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9809/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9810/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9811/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9812/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9813/10000step_number: 0/29 cost:  nan accuracy:  0.962135657858894\n",
      "Epoch number: 9814/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9815/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9816/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9817/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9818/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9819/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9820/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9821/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9822/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9823/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9824/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9825/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9826/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9827/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9828/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9829/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9830/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9831/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9832/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9833/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9834/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9835/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9836/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9837/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9838/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9839/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9840/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9841/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9842/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9843/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9844/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9845/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9846/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9847/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9848/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9849/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9850/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9851/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9852/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9853/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9854/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9855/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9856/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9857/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9858/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9859/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9860/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9861/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9862/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9863/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9864/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9865/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9866/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9867/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9868/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9869/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9870/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9871/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9872/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9873/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9874/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9875/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9876/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9877/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9878/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9879/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9880/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9881/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9882/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9883/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9884/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9885/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9886/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9887/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9888/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9889/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9890/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9891/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9892/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9893/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9894/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9895/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9896/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9897/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9898/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9899/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9900/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9901/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9902/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9903/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9904/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9905/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9906/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9907/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9908/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9909/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9910/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9911/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9912/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9913/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9914/10000step_number: 0/29 cost:  nan accuracy:  0.9611822391718877\n",
      "Epoch number: 9915/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9916/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9917/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9918/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9919/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9920/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9921/10000step_number: 0/29 cost:  nan accuracy:  0.9613184418414601\n",
      "Epoch number: 9922/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9923/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9924/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9925/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9926/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9927/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9928/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9929/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9930/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9931/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9932/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9933/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9934/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9935/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9936/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9937/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9938/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9939/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9940/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9941/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9942/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9943/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9944/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9945/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9946/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9947/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9948/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9949/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9950/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9951/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9952/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9953/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9954/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9955/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9956/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9957/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9958/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9959/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9960/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9961/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9962/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9963/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9964/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9965/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9966/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9967/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9968/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9969/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9970/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9971/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9972/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9973/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9974/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9975/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9976/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9977/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9978/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9979/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9980/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9981/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9982/10000step_number: 0/29 cost:  nan accuracy:  0.962135657858894\n",
      "Epoch number: 9983/10000step_number: 0/29 cost:  nan accuracy:  0.9614546445110325\n",
      "Epoch number: 9984/10000step_number: 0/29 cost:  nan accuracy:  0.9622718605284664\n",
      "Epoch number: 9985/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9986/10000step_number: 0/29 cost:  nan accuracy:  0.962135657858894\n",
      "Epoch number: 9987/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9988/10000step_number: 0/29 cost:  nan accuracy:  0.962135657858894\n",
      "Epoch number: 9989/10000step_number: 0/29 cost:  nan accuracy:  0.9615908471806047\n",
      "Epoch number: 9990/10000step_number: 0/29 cost:  nan accuracy:  0.962544265867611\n",
      "Epoch number: 9991/10000step_number: 0/29 cost:  nan accuracy:  0.9618632525197494\n",
      "Epoch number: 9992/10000step_number: 0/29 cost:  nan accuracy:  0.9619994551893217\n",
      "Epoch number: 9993/10000step_number: 0/29 cost:  nan accuracy:  0.9603650231544538\n",
      "Epoch number: 9994/10000step_number: 0/29 cost:  nan accuracy:  0.9493326069190956\n",
      "Epoch number: 9995/10000step_number: 0/29 cost:  nan accuracy:  0.9564151457368565\n",
      "Epoch number: 9996/10000step_number: 0/29 cost:  nan accuracy:  0.9609098338327431\n",
      "Epoch number: 9997/10000step_number: 0/29 cost:  nan accuracy:  0.9617270498501771\n",
      "Epoch number: 9998/10000step_number: 0/29 cost:  nan accuracy:  0.957096159084718\n",
      "Epoch number: 9999/10000step_number: 0/29 cost:  nan accuracy:  0.9590029964587305\n"
     ]
    }
   ],
   "source": [
    "NN= Neural_Network(X_train,y_train,76,76,0.0001,1000) #v7\n",
    "NN.train(X_train,y_train,10000,X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1/10000step_number: 0/29 cost:  3.1753539356116462 accuracy:  0.18033233451375646\n",
      "Epoch number: 2/10000step_number: 0/29 cost:  2.8010628229428387 accuracy:  0.18033233451375646\n",
      "Epoch number: 3/10000step_number: 0/29 cost:  2.6165244161342507 accuracy:  0.18033233451375646\n",
      "Epoch number: 4/10000step_number: 0/29 cost:  2.5467740236036134 accuracy:  0.18033233451375646\n",
      "Epoch number: 5/10000step_number: 0/29 cost:  2.520402845828965 accuracy:  0.18033233451375646\n",
      "Epoch number: 6/10000step_number: 0/29 cost:  2.5091742458132114 accuracy:  0.18033233451375646\n",
      "Epoch number: 7/10000step_number: 0/29 cost:  2.5039285246017142 accuracy:  0.2094797058022337\n",
      "Epoch number: 8/10000step_number: 0/29 cost:  2.5013771850859894 accuracy:  0.2094797058022337\n",
      "Epoch number: 9/10000step_number: 0/29 cost:  2.50011213091843 accuracy:  0.2094797058022337\n",
      "Epoch number: 10/10000step_number: 0/29 cost:  2.499472639205354 accuracy:  0.2094797058022337\n",
      "Epoch number: 11/10000step_number: 0/29 cost:  2.4991409706547265 accuracy:  0.2094797058022337\n",
      "Epoch number: 12/10000step_number: 0/29 cost:  2.498962982004454 accuracy:  0.2094797058022337\n",
      "Epoch number: 13/10000step_number: 0/29 cost:  2.4988585690256158 accuracy:  0.2094797058022337\n",
      "Epoch number: 14/10000step_number: 0/29 cost:  2.498785372670535 accuracy:  0.2094797058022337\n",
      "Epoch number: 15/10000step_number: 0/29 cost:  2.498723781021831 accuracy:  0.2094797058022337\n",
      "Epoch number: 16/10000step_number: 0/29 cost:  2.4986651630967294 accuracy:  0.2094797058022337\n",
      "Epoch number: 17/10000step_number: 0/29 cost:  2.4986052567904897 accuracy:  0.2094797058022337\n",
      "Epoch number: 18/10000step_number: 0/29 cost:  2.498541846188392 accuracy:  0.2094797058022337\n",
      "Epoch number: 19/10000step_number: 0/29 cost:  2.4984740842105904 accuracy:  0.2094797058022337\n",
      "Epoch number: 20/10000step_number: 0/29 cost:  2.4984025887650825 accuracy:  0.2094797058022337\n",
      "Epoch number: 21/10000step_number: 0/29 cost:  2.49832876546491 accuracy:  0.2094797058022337\n",
      "Epoch number: 22/10000step_number: 0/29 cost:  2.498251331400038 accuracy:  0.2094797058022337\n",
      "Epoch number: 23/10000step_number: 0/29 cost:  2.498166704613282 accuracy:  0.2094797058022337\n",
      "Epoch number: 24/10000step_number: 0/29 cost:  2.4980743941559114 accuracy:  0.2094797058022337\n",
      "Epoch number: 25/10000step_number: 0/29 cost:  2.497971683453712 accuracy:  0.2094797058022337\n",
      "Epoch number: 26/10000step_number: 0/29 cost:  2.497844064614704 accuracy:  0.2094797058022337\n",
      "Epoch number: 27/10000step_number: 0/29 cost:  2.4976561313314107 accuracy:  0.2094797058022337\n",
      "Epoch number: 28/10000step_number: 0/29 cost:  2.497438367782219 accuracy:  0.2094797058022337\n",
      "Epoch number: 29/10000step_number: 0/29 cost:  2.497271535754554 accuracy:  0.2094797058022337\n",
      "Epoch number: 30/10000step_number: 0/29 cost:  2.4970643261244354 accuracy:  0.2094797058022337\n",
      "Epoch number: 31/10000step_number: 0/29 cost:  2.4968058080840874 accuracy:  0.2094797058022337\n",
      "Epoch number: 32/10000step_number: 0/29 cost:  2.4965004926497185 accuracy:  0.2094797058022337\n",
      "Epoch number: 33/10000step_number: 0/29 cost:  2.4961455961499515 accuracy:  0.2094797058022337\n",
      "Epoch number: 34/10000step_number: 0/29 cost:  2.495731855579303 accuracy:  0.2094797058022337\n",
      "Epoch number: 35/10000step_number: 0/29 cost:  2.495221983389004 accuracy:  0.2094797058022337\n",
      "Epoch number: 36/10000step_number: 0/29 cost:  2.494568240065536 accuracy:  0.2094797058022337\n",
      "Epoch number: 37/10000step_number: 0/29 cost:  2.493909926371926 accuracy:  0.2094797058022337\n",
      "Epoch number: 38/10000step_number: 0/29 cost:  2.493139533476296 accuracy:  0.2094797058022337\n",
      "Epoch number: 39/10000step_number: 0/29 cost:  2.4922310685668765 accuracy:  0.2094797058022337\n",
      "Epoch number: 40/10000step_number: 0/29 cost:  2.491202083076387 accuracy:  0.2094797058022337\n",
      "Epoch number: 41/10000step_number: 0/29 cost:  2.490058954340724 accuracy:  0.2094797058022337\n",
      "Epoch number: 42/10000step_number: 0/29 cost:  2.4887474440002877 accuracy:  0.2094797058022337\n",
      "Epoch number: 43/10000step_number: 0/29 cost:  2.4871203962062283 accuracy:  0.2094797058022337\n",
      "Epoch number: 44/10000step_number: 0/29 cost:  2.4855139833440743 accuracy:  0.2094797058022337\n",
      "Epoch number: 45/10000step_number: 0/29 cost:  2.4837718830809736 accuracy:  0.2094797058022337\n",
      "Epoch number: 46/10000step_number: 0/29 cost:  2.4817360451495785 accuracy:  0.2094797058022337\n",
      "Epoch number: 47/10000step_number: 0/29 cost:  2.4793230787468428 accuracy:  0.2094797058022337\n",
      "Epoch number: 48/10000step_number: 0/29 cost:  2.476570003335878 accuracy:  0.2094797058022337\n",
      "Epoch number: 49/10000step_number: 0/29 cost:  2.4737494728576723 accuracy:  0.2094797058022337\n",
      "Epoch number: 50/10000step_number: 0/29 cost:  2.4699768458188047 accuracy:  0.2094797058022337\n",
      "Epoch number: 51/10000step_number: 0/29 cost:  2.466490282883322 accuracy:  0.2094797058022337\n",
      "Epoch number: 52/10000step_number: 0/29 cost:  2.4624582201484566 accuracy:  0.2094797058022337\n",
      "Epoch number: 53/10000step_number: 0/29 cost:  2.4579069055422917 accuracy:  0.2094797058022337\n",
      "Epoch number: 54/10000step_number: 0/29 cost:  2.45293965734432 accuracy:  0.2094797058022337\n",
      "Epoch number: 55/10000step_number: 0/29 cost:  2.44781547415619 accuracy:  0.2094797058022337\n",
      "Epoch number: 56/10000step_number: 0/29 cost:  2.4420976268258983 accuracy:  0.2094797058022337\n",
      "Epoch number: 57/10000step_number: 0/29 cost:  2.436244263013539 accuracy:  0.2094797058022337\n",
      "Epoch number: 58/10000step_number: 0/29 cost:  2.429918132451377 accuracy:  0.24897847997820757\n",
      "Epoch number: 59/10000step_number: 0/29 cost:  2.423450581586648 accuracy:  0.2928357395804958\n",
      "Epoch number: 60/10000step_number: 0/29 cost:  2.4168071176600594 accuracy:  0.30890765459002995\n",
      "Epoch number: 61/10000step_number: 0/29 cost:  2.40999867068914 accuracy:  0.32252792154726234\n",
      "Epoch number: 62/10000step_number: 0/29 cost:  2.402969810723677 accuracy:  0.332062108417325\n",
      "Epoch number: 63/10000step_number: 0/29 cost:  2.395024677323119 accuracy:  0.34459275401797873\n",
      "Epoch number: 64/10000step_number: 0/29 cost:  2.3879221061761156 accuracy:  0.34867883410514844\n",
      "Epoch number: 65/10000step_number: 0/29 cost:  2.3800754691533283 accuracy:  0.3522201035140289\n",
      "Epoch number: 66/10000step_number: 0/29 cost:  2.371982461576173 accuracy:  0.35426314355761374\n",
      "Epoch number: 67/10000step_number: 0/29 cost:  2.3635620530557255 accuracy:  0.35671479160991554\n",
      "Epoch number: 68/10000step_number: 0/29 cost:  2.355921149041761 accuracy:  0.35957504767093434\n",
      "Epoch number: 69/10000step_number: 0/29 cost:  2.3478379587949867 accuracy:  0.360256061018796\n",
      "Epoch number: 70/10000step_number: 0/29 cost:  2.339981053580795 accuracy:  0.36093707436665756\n",
      "Epoch number: 71/10000step_number: 0/29 cost:  2.332348043328596 accuracy:  0.3617542903840915\n",
      "Epoch number: 72/10000step_number: 0/29 cost:  2.324960825920792 accuracy:  0.36229910106238084\n",
      "Epoch number: 73/10000step_number: 0/29 cost:  2.317837936837757 accuracy:  0.36229910106238084\n",
      "Epoch number: 74/10000step_number: 0/29 cost:  2.3109642518633553 accuracy:  0.36243530373195315\n",
      "Epoch number: 75/10000step_number: 0/29 cost:  2.304530756415196 accuracy:  0.36229910106238084\n",
      "Epoch number: 76/10000step_number: 0/29 cost:  2.298080974648345 accuracy:  0.3621628983928085\n",
      "Epoch number: 77/10000step_number: 0/29 cost:  2.291952025208758 accuracy:  0.36189049305366383\n",
      "Epoch number: 78/10000step_number: 0/29 cost:  2.286111506603109 accuracy:  0.36189049305366383\n",
      "Epoch number: 79/10000step_number: 0/29 cost:  2.2805838077101357 accuracy:  0.3614818850449469\n",
      "Epoch number: 80/10000step_number: 0/29 cost:  2.275315666624305 accuracy:  0.36189049305366383\n",
      "Epoch number: 81/10000step_number: 0/29 cost:  2.2703001932599203 accuracy:  0.36189049305366383\n",
      "Epoch number: 82/10000step_number: 0/29 cost:  2.2655368253586743 accuracy:  0.3621628983928085\n",
      "Epoch number: 83/10000step_number: 0/29 cost:  2.261028187753987 accuracy:  0.3629801144102424\n",
      "Epoch number: 84/10000step_number: 0/29 cost:  2.256787613288557 accuracy:  0.36229910106238084\n",
      "Epoch number: 85/10000step_number: 0/29 cost:  2.2528238243977006 accuracy:  0.3621628983928085\n",
      "Epoch number: 86/10000step_number: 0/29 cost:  2.249133711316454 accuracy:  0.36257150640152547\n",
      "Epoch number: 87/10000step_number: 0/29 cost:  2.245705308127325 accuracy:  0.36243530373195315\n",
      "Epoch number: 88/10000step_number: 0/29 cost:  2.2425138373313644 accuracy:  0.36257150640152547\n",
      "Epoch number: 89/10000step_number: 0/29 cost:  2.2395122880964973 accuracy:  0.3218469081994007\n",
      "Epoch number: 90/10000step_number: 0/29 cost:  2.2366705841167134 accuracy:  0.32947425769545086\n",
      "Epoch number: 91/10000step_number: 0/29 cost:  2.233779978698437 accuracy:  0.33764641786979027\n",
      "Epoch number: 92/10000step_number: 0/29 cost:  2.23084575971052 accuracy:  0.3499046581312994\n",
      "Epoch number: 93/10000step_number: 0/29 cost:  2.227916884684257 accuracy:  0.3546717515663307\n",
      "Epoch number: 94/10000step_number: 0/29 cost:  2.2249637376325984 accuracy:  0.3591664396622174\n",
      "Epoch number: 95/10000step_number: 0/29 cost:  2.222113613564965 accuracy:  0.36352492508853174\n",
      "Epoch number: 96/10000step_number: 0/29 cost:  2.2190025599332674 accuracy:  0.36747480250612913\n",
      "Epoch number: 97/10000step_number: 0/29 cost:  2.2161456286223764 accuracy:  0.36897303187142466\n",
      "Epoch number: 98/10000step_number: 0/29 cost:  2.2134932306085204 accuracy:  0.37006265322800325\n",
      "Epoch number: 99/10000step_number: 0/29 cost:  2.2106896902127255 accuracy:  0.3707436665758649\n",
      "Epoch number: 100/10000step_number: 0/29 cost:  2.208162955839136 accuracy:  0.369109234540997\n",
      "Epoch number: 101/10000step_number: 0/29 cost:  2.2057334536468973 accuracy:  0.36992645055843093\n",
      "Epoch number: 102/10000step_number: 0/29 cost:  2.2028126637221974 accuracy:  0.37047126123672025\n",
      "Epoch number: 103/10000step_number: 0/29 cost:  2.2004227175136815 accuracy:  0.369517842549714\n",
      "Epoch number: 104/10000step_number: 0/29 cost:  2.1977584402284767 accuracy:  0.36938163988014167\n",
      "Epoch number: 105/10000step_number: 0/29 cost:  2.1948409080370572 accuracy:  0.3696540452192863\n",
      "Epoch number: 106/10000step_number: 0/29 cost:  2.191881207226731 accuracy:  0.3726505039498774\n",
      "Epoch number: 107/10000step_number: 0/29 cost:  2.18888124932717 accuracy:  0.3760555706891855\n",
      "Epoch number: 108/10000step_number: 0/29 cost:  2.185885130349025 accuracy:  0.3874965949332607\n",
      "Epoch number: 109/10000step_number: 0/29 cost:  2.183405383203817 accuracy:  0.4441569054753473\n",
      "Epoch number: 110/10000step_number: 0/29 cost:  2.181351285483051 accuracy:  0.4177335875783165\n",
      "Epoch number: 111/10000step_number: 0/29 cost:  2.179441566378929 accuracy:  0.3812312721329338\n",
      "Epoch number: 112/10000step_number: 0/29 cost:  2.1775878540069655 accuracy:  0.3760555706891855\n",
      "Epoch number: 113/10000step_number: 0/29 cost:  2.175782615849378 accuracy:  0.37455734132388996\n",
      "Epoch number: 114/10000step_number: 0/29 cost:  2.1739844083502944 accuracy:  0.38368292018523564\n",
      "Epoch number: 115/10000step_number: 0/29 cost:  2.172057735298792 accuracy:  0.38899482429855625\n",
      "Epoch number: 116/10000step_number: 0/29 cost:  2.1698912492695883 accuracy:  0.39594116044674477\n",
      "Epoch number: 117/10000step_number: 0/29 cost:  2.1674676730596203 accuracy:  0.40343230727322255\n",
      "Epoch number: 118/10000step_number: 0/29 cost:  2.1647527294116036 accuracy:  0.41283029147371286\n",
      "Epoch number: 119/10000step_number: 0/29 cost:  2.161721254994171 accuracy:  0.42086624897847996\n",
      "Epoch number: 120/10000step_number: 0/29 cost:  2.1583183416730565 accuracy:  0.4241351130482158\n",
      "Epoch number: 121/10000step_number: 0/29 cost:  2.1544544952372036 accuracy:  0.4284935984745301\n",
      "Epoch number: 122/10000step_number: 0/29 cost:  2.1501054734396554 accuracy:  0.4336692999182784\n",
      "Epoch number: 123/10000step_number: 0/29 cost:  2.1452461250010564 accuracy:  0.44102424407518387\n",
      "Epoch number: 124/10000step_number: 0/29 cost:  2.1398239713229352 accuracy:  0.44606374284935985\n",
      "Epoch number: 125/10000step_number: 0/29 cost:  2.133785562174189 accuracy:  0.4535548896758376\n",
      "Epoch number: 126/10000step_number: 0/29 cost:  2.127074735426134 accuracy:  0.457913375102152\n",
      "Epoch number: 127/10000step_number: 0/29 cost:  2.119601085331511 accuracy:  0.46499591391991285\n",
      "Epoch number: 128/10000step_number: 0/29 cost:  2.111489868809871 accuracy:  0.47262326341596295\n",
      "Epoch number: 129/10000step_number: 0/29 cost:  2.102155652661264 accuracy:  0.4803868155815854\n",
      "Epoch number: 130/10000step_number: 0/29 cost:  2.092619394549399 accuracy:  0.48828657041678014\n",
      "Epoch number: 131/10000step_number: 0/29 cost:  2.0825559504401836 accuracy:  0.49509670389539634\n",
      "Epoch number: 132/10000step_number: 0/29 cost:  2.0716307508971896 accuracy:  0.5066739308090439\n",
      "Epoch number: 133/10000step_number: 0/29 cost:  2.0599598870138998 accuracy:  0.5280577499318987\n",
      "Epoch number: 134/10000step_number: 0/29 cost:  2.048469526125121 accuracy:  0.5514846090983383\n",
      "Epoch number: 135/10000step_number: 0/29 cost:  2.035977926675678 accuracy:  0.5809043857259603\n",
      "Epoch number: 136/10000step_number: 0/29 cost:  2.0229854675501784 accuracy:  0.5960228820484882\n",
      "Epoch number: 137/10000step_number: 0/29 cost:  2.0099857159050876 accuracy:  0.6044674475619722\n",
      "Epoch number: 138/10000step_number: 0/29 cost:  1.9964935211696806 accuracy:  0.6107327703622991\n",
      "Epoch number: 139/10000step_number: 0/29 cost:  1.9834996354161518 accuracy:  0.6171342958321984\n",
      "Epoch number: 140/10000step_number: 0/29 cost:  1.9705094956217566 accuracy:  0.6219013892672296\n",
      "Epoch number: 141/10000step_number: 0/29 cost:  1.9573751460185844 accuracy:  0.6263960773631163\n",
      "Epoch number: 142/10000step_number: 0/29 cost:  1.9441884408068095 accuracy:  0.6281667120675565\n",
      "Epoch number: 143/10000step_number: 0/29 cost:  1.9307105803736435 accuracy:  0.6325251974938709\n",
      "Epoch number: 144/10000step_number: 0/29 cost:  1.9175574023837914 accuracy:  0.6341596295287387\n",
      "Epoch number: 145/10000step_number: 0/29 cost:  1.9047384879613318 accuracy:  0.6374284935984745\n",
      "Epoch number: 146/10000step_number: 0/29 cost:  1.8919885559014848 accuracy:  0.6453282484336693\n",
      "Epoch number: 147/10000step_number: 0/29 cost:  1.8793272173546585 accuracy:  0.6526831925905747\n",
      "Epoch number: 148/10000step_number: 0/29 cost:  1.8667341536420667 accuracy:  0.6596295287387632\n",
      "Epoch number: 149/10000step_number: 0/29 cost:  1.8543075601096184 accuracy:  0.6657586488695179\n",
      "Epoch number: 150/10000step_number: 0/29 cost:  1.841992597837193 accuracy:  0.6736584037047126\n",
      "Epoch number: 151/10000step_number: 0/29 cost:  1.8301915278352054 accuracy:  0.6766548624353037\n",
      "Epoch number: 152/10000step_number: 0/29 cost:  1.8185034671799163 accuracy:  0.6833287932443476\n",
      "Epoch number: 153/10000step_number: 0/29 cost:  1.807157966776947 accuracy:  0.6875510760010897\n",
      "Epoch number: 154/10000step_number: 0/29 cost:  1.7958834213458628 accuracy:  0.6898665213838191\n",
      "Epoch number: 155/10000step_number: 0/29 cost:  1.7847288680328384 accuracy:  0.6898665213838191\n",
      "Epoch number: 156/10000step_number: 0/29 cost:  1.7736701577786789 accuracy:  0.6925905747752656\n",
      "Epoch number: 157/10000step_number: 0/29 cost:  1.7628439527097535 accuracy:  0.6949060201579951\n",
      "Epoch number: 158/10000step_number: 0/29 cost:  1.7522760790029588 accuracy:  0.6991283029147372\n",
      "Epoch number: 159/10000step_number: 0/29 cost:  1.7420658798198156 accuracy:  0.7062108417324979\n",
      "Epoch number: 160/10000step_number: 0/29 cost:  1.7323080001562658 accuracy:  0.710841732497957\n",
      "Epoch number: 161/10000step_number: 0/29 cost:  1.722835356851324 accuracy:  0.7122037591936802\n",
      "Epoch number: 162/10000step_number: 0/29 cost:  1.7136186731736949 accuracy:  0.7135657858894034\n",
      "Epoch number: 163/10000step_number: 0/29 cost:  1.7046881305696588 accuracy:  0.7153364205938436\n",
      "Epoch number: 164/10000step_number: 0/29 cost:  1.6959597493736072 accuracy:  0.718469081994007\n",
      "Epoch number: 165/10000step_number: 0/29 cost:  1.68744325368327 accuracy:  0.720512122037592\n",
      "Epoch number: 166/10000step_number: 0/29 cost:  1.679221646936217 accuracy:  0.7207845273767366\n",
      "Epoch number: 167/10000step_number: 0/29 cost:  1.671219135986037 accuracy:  0.7216017433941705\n",
      "Epoch number: 168/10000step_number: 0/29 cost:  1.6634059492038378 accuracy:  0.7206483247071642\n",
      "Epoch number: 169/10000step_number: 0/29 cost:  1.6557323332837524 accuracy:  0.7211931353854536\n",
      "Epoch number: 170/10000step_number: 0/29 cost:  1.6482083325518002 accuracy:  0.7225551620811768\n",
      "Epoch number: 171/10000step_number: 0/29 cost:  1.6408333942247815 accuracy:  0.7233723780986108\n",
      "Epoch number: 172/10000step_number: 0/29 cost:  1.6336124917640595 accuracy:  0.724325796785617\n",
      "Epoch number: 173/10000step_number: 0/29 cost:  1.6265372297997673 accuracy:  0.7245982021247617\n",
      "Epoch number: 174/10000step_number: 0/29 cost:  1.6196161784025485 accuracy:  0.739035685099428\n",
      "Epoch number: 175/10000step_number: 0/29 cost:  1.6128554641752713 accuracy:  0.739035685099428\n",
      "Epoch number: 176/10000step_number: 0/29 cost:  1.6062475430155674 accuracy:  0.7406701171342959\n",
      "Epoch number: 177/10000step_number: 0/29 cost:  1.5997795979564322 accuracy:  0.7410787251430128\n",
      "Epoch number: 178/10000step_number: 0/29 cost:  1.5934437452653578 accuracy:  0.7413511304821575\n",
      "Epoch number: 179/10000step_number: 0/29 cost:  1.5872350021433013 accuracy:  0.7425769545083084\n",
      "Epoch number: 180/10000step_number: 0/29 cost:  1.5811486286261227 accuracy:  0.742849359847453\n",
      "Epoch number: 181/10000step_number: 0/29 cost:  1.5751795495589374 accuracy:  0.7436665758648869\n",
      "Epoch number: 182/10000step_number: 0/29 cost:  1.5693223702346928 accuracy:  0.7444837918823209\n",
      "Epoch number: 183/10000step_number: 0/29 cost:  1.5635718255856368 accuracy:  0.7459820212476165\n",
      "Epoch number: 184/10000step_number: 0/29 cost:  1.5579235566690637 accuracy:  0.7454372105693272\n",
      "Epoch number: 185/10000step_number: 0/29 cost:  1.5523749469812502 accuracy:  0.7480250612912013\n",
      "Epoch number: 186/10000step_number: 0/29 cost:  1.5469257225611996 accuracy:  0.7485698719694907\n",
      "Epoch number: 187/10000step_number: 0/29 cost:  1.541578289291279 accuracy:  0.7487060746390629\n",
      "Epoch number: 188/10000step_number: 0/29 cost:  1.536338505670135 accuracy:  0.7489784799782075\n",
      "Epoch number: 189/10000step_number: 0/29 cost:  1.531216614044411 accuracy:  0.7488422773086353\n",
      "Epoch number: 190/10000step_number: 0/29 cost:  1.5262232502770612 accuracy:  0.7489784799782075\n",
      "Epoch number: 191/10000step_number: 0/29 cost:  1.5213573960462745 accuracy:  0.7495232906564969\n",
      "Epoch number: 192/10000step_number: 0/29 cost:  1.5166019932738168 accuracy:  0.7493870879869245\n",
      "Epoch number: 193/10000step_number: 0/29 cost:  1.5119352727900568 accuracy:  0.7497956959956416\n",
      "Epoch number: 194/10000step_number: 0/29 cost:  1.5073402560314253 accuracy:  0.7496594933260692\n",
      "Epoch number: 195/10000step_number: 0/29 cost:  1.5028053402706678 accuracy:  0.7502043040043584\n",
      "Epoch number: 196/10000step_number: 0/29 cost:  1.4983212093728009 accuracy:  0.7507491146826478\n",
      "Epoch number: 197/10000step_number: 0/29 cost:  1.4938799983405886 accuracy:  0.7508853173522201\n",
      "Epoch number: 198/10000step_number: 0/29 cost:  1.4894773978764992 accuracy:  0.7515663307000817\n",
      "Epoch number: 199/10000step_number: 0/29 cost:  1.4851157657927256 accuracy:  0.752928357395805\n",
      "Epoch number: 200/10000step_number: 0/29 cost:  1.4808034617644308 accuracy:  0.7530645600653773\n",
      "Epoch number: 201/10000step_number: 0/29 cost:  1.4765449935206678 accuracy:  0.7540179787523835\n",
      "Epoch number: 202/10000step_number: 0/29 cost:  1.4723301756223013 accuracy:  0.7541541814219559\n",
      "Epoch number: 203/10000step_number: 0/29 cost:  1.468139634657427 accuracy:  0.7544265867611005\n",
      "Epoch number: 204/10000step_number: 0/29 cost:  1.4639595684360394 accuracy:  0.7549713974393898\n",
      "Epoch number: 205/10000step_number: 0/29 cost:  1.4597892021157763 accuracy:  0.7553800054481068\n",
      "Epoch number: 206/10000step_number: 0/29 cost:  1.4556380405882097 accuracy:  0.7553800054481068\n",
      "Epoch number: 207/10000step_number: 0/29 cost:  1.451511906388344 accuracy:  0.7556524107872514\n",
      "Epoch number: 208/10000step_number: 0/29 cost:  1.4473963469011575 accuracy:  0.7564696268046853\n",
      "Epoch number: 209/10000step_number: 0/29 cost:  1.4432714924142898 accuracy:  0.757150640152547\n",
      "Epoch number: 210/10000step_number: 0/29 cost:  1.439148103785547 accuracy:  0.7583764641786979\n",
      "Epoch number: 211/10000step_number: 0/29 cost:  1.4350634646859695 accuracy:  0.7593298828657041\n",
      "Epoch number: 212/10000step_number: 0/29 cost:  1.4310138123498266 accuracy:  0.7596022882048488\n",
      "Epoch number: 213/10000step_number: 0/29 cost:  1.4269882376337333 accuracy:  0.7598746935439935\n",
      "Epoch number: 214/10000step_number: 0/29 cost:  1.422985453394209 accuracy:  0.7631435576137292\n",
      "Epoch number: 215/10000step_number: 0/29 cost:  1.4190059188392212 accuracy:  0.7634159629528738\n",
      "Epoch number: 216/10000step_number: 0/29 cost:  1.4150495005798012 accuracy:  0.7636883682920185\n",
      "Epoch number: 217/10000step_number: 0/29 cost:  1.4111152058455527 accuracy:  0.7681830563879052\n",
      "Epoch number: 218/10000step_number: 0/29 cost:  1.4072014145806189 accuracy:  0.7687278670661944\n",
      "Epoch number: 219/10000step_number: 0/29 cost:  1.4033062155353477 accuracy:  0.7690002724053392\n",
      "Epoch number: 220/10000step_number: 0/29 cost:  1.3994283852842972 accuracy:  0.7694088804140561\n",
      "Epoch number: 221/10000step_number: 0/29 cost:  1.3955713808667056 accuracy:  0.7699536910923455\n",
      "Epoch number: 222/10000step_number: 0/29 cost:  1.3917461460877043 accuracy:  0.7695450830836285\n",
      "Epoch number: 223/10000step_number: 0/29 cost:  1.3879596021801128 accuracy:  0.7695450830836285\n",
      "Epoch number: 224/10000step_number: 0/29 cost:  1.3842037291152578 accuracy:  0.770634704440207\n",
      "Epoch number: 225/10000step_number: 0/29 cost:  1.3804651277077264 accuracy:  0.7709071097793517\n",
      "Epoch number: 226/10000step_number: 0/29 cost:  1.3767363795239522 accuracy:  0.7718605284663579\n",
      "Epoch number: 227/10000step_number: 0/29 cost:  1.3730156831673381 accuracy:  0.7722691364750749\n",
      "Epoch number: 228/10000step_number: 0/29 cost:  1.3693032535369078 accuracy:  0.7721329338055026\n",
      "Epoch number: 229/10000step_number: 0/29 cost:  1.3655991017947913 accuracy:  0.7734949605012258\n",
      "Epoch number: 230/10000step_number: 0/29 cost:  1.3619038161163386 accuracy:  0.7743121765186598\n",
      "Epoch number: 231/10000step_number: 0/29 cost:  1.3582149858078334 accuracy:  0.7749931898665214\n",
      "Epoch number: 232/10000step_number: 0/29 cost:  1.3544672601613188 accuracy:  0.7751293925360937\n",
      "Epoch number: 233/10000step_number: 0/29 cost:  1.3507342617028184 accuracy:  0.7754017978752383\n",
      "Epoch number: 234/10000step_number: 0/29 cost:  1.346417206825681 accuracy:  0.7759466085535276\n",
      "Epoch number: 235/10000step_number: 0/29 cost:  1.3430967918314132 accuracy:  0.7777172432579679\n",
      "Epoch number: 236/10000step_number: 0/29 cost:  1.3396129402332084 accuracy:  0.7785344592754018\n",
      "Epoch number: 237/10000step_number: 0/29 cost:  1.3360878831328313 accuracy:  0.7804412966494143\n",
      "Epoch number: 238/10000step_number: 0/29 cost:  1.3325723317490128 accuracy:  0.7823481340234268\n",
      "Epoch number: 239/10000step_number: 0/29 cost:  1.3290593974862017 accuracy:  0.7850721874148733\n",
      "Epoch number: 240/10000step_number: 0/29 cost:  1.325554169859109 accuracy:  0.7860256061018795\n",
      "Epoch number: 241/10000step_number: 0/29 cost:  1.3220581798736886 accuracy:  0.7861618087714519\n",
      "Epoch number: 242/10000step_number: 0/29 cost:  1.3185758184748293 accuracy:  0.7862980114410243\n",
      "Epoch number: 243/10000step_number: 0/29 cost:  1.3151117995562185 accuracy:  0.7862980114410243\n",
      "Epoch number: 244/10000step_number: 0/29 cost:  1.3116714649011654 accuracy:  0.7862980114410243\n",
      "Epoch number: 245/10000step_number: 0/29 cost:  1.30825507374194 accuracy:  0.7862980114410243\n",
      "Epoch number: 246/10000step_number: 0/29 cost:  1.3048444526256744 accuracy:  0.7865704167801689\n",
      "Epoch number: 247/10000step_number: 0/29 cost:  1.3014366761581233 accuracy:  0.7867066194497412\n",
      "Epoch number: 248/10000step_number: 0/29 cost:  1.2980434922421795 accuracy:  0.7871152274584582\n",
      "Epoch number: 249/10000step_number: 0/29 cost:  1.2946588721400385 accuracy:  0.7873876327976028\n",
      "Epoch number: 250/10000step_number: 0/29 cost:  1.291247164419853 accuracy:  0.7871152274584582\n",
      "Epoch number: 251/10000step_number: 0/29 cost:  1.2878505776399507 accuracy:  0.7875238354671752\n",
      "Epoch number: 252/10000step_number: 0/29 cost:  1.2844764923012282 accuracy:  0.7883410514846091\n",
      "Epoch number: 253/10000step_number: 0/29 cost:  1.2810871389210947 accuracy:  0.7883410514846091\n",
      "Epoch number: 254/10000step_number: 0/29 cost:  1.2777504697720496 accuracy:  0.7886134568237537\n",
      "Epoch number: 255/10000step_number: 0/29 cost:  1.2744499027724832 accuracy:  0.7888858621628984\n",
      "Epoch number: 256/10000step_number: 0/29 cost:  1.271167629119283 accuracy:  0.7886134568237537\n",
      "Epoch number: 257/10000step_number: 0/29 cost:  1.2678996920804007 accuracy:  0.7888858621628984\n",
      "Epoch number: 258/10000step_number: 0/29 cost:  1.2646427734830215 accuracy:  0.789158267502043\n",
      "Epoch number: 259/10000step_number: 0/29 cost:  1.2613996115492785 accuracy:  0.789158267502043\n",
      "Epoch number: 260/10000step_number: 0/29 cost:  1.2581270735400345 accuracy:  0.7894306728411877\n",
      "Epoch number: 261/10000step_number: 0/29 cost:  1.2547845103342703 accuracy:  0.7897030781803324\n",
      "Epoch number: 262/10000step_number: 0/29 cost:  1.2514447654694099 accuracy:  0.789158267502043\n",
      "Epoch number: 263/10000step_number: 0/29 cost:  1.2482147851207823 accuracy:  0.7894306728411877\n",
      "Epoch number: 264/10000step_number: 0/29 cost:  1.244988997905311 accuracy:  0.7888858621628984\n",
      "Epoch number: 265/10000step_number: 0/29 cost:  1.2417906125299105 accuracy:  0.7892944701716154\n",
      "Epoch number: 266/10000step_number: 0/29 cost:  1.2386017199366166 accuracy:  0.7890220648324707\n",
      "Epoch number: 267/10000step_number: 0/29 cost:  1.2354254837574827 accuracy:  0.789158267502043\n",
      "Epoch number: 268/10000step_number: 0/29 cost:  1.2322684101721666 accuracy:  0.7901116861890493\n",
      "Epoch number: 269/10000step_number: 0/29 cost:  1.2288880050179176 accuracy:  0.7906564968673386\n",
      "Epoch number: 270/10000step_number: 0/29 cost:  1.225871427315075 accuracy:  0.7909289022064833\n",
      "Epoch number: 271/10000step_number: 0/29 cost:  1.2226171135605248 accuracy:  0.7910651048760555\n",
      "Epoch number: 272/10000step_number: 0/29 cost:  1.21951010538483 accuracy:  0.7916099155543449\n",
      "Epoch number: 273/10000step_number: 0/29 cost:  1.2163732332247588 accuracy:  0.7918823208934895\n",
      "Epoch number: 274/10000step_number: 0/29 cost:  1.2132447617842579 accuracy:  0.7922909289022065\n",
      "Epoch number: 275/10000step_number: 0/29 cost:  1.2101198178000094 accuracy:  0.7924271315717788\n",
      "Epoch number: 276/10000step_number: 0/29 cost:  1.2069998803125026 accuracy:  0.7925633342413512\n",
      "Epoch number: 277/10000step_number: 0/29 cost:  1.203882013467464 accuracy:  0.7925633342413512\n",
      "Epoch number: 278/10000step_number: 0/29 cost:  1.2007642129104732 accuracy:  0.7924271315717788\n",
      "Epoch number: 279/10000step_number: 0/29 cost:  1.1976429856845907 accuracy:  0.7926995369109234\n",
      "Epoch number: 280/10000step_number: 0/29 cost:  1.1945156814584712 accuracy:  0.7926995369109234\n",
      "Epoch number: 281/10000step_number: 0/29 cost:  1.1913823093552036 accuracy:  0.7928357395804958\n",
      "Epoch number: 282/10000step_number: 0/29 cost:  1.188249353948033 accuracy:  0.7933805502587851\n",
      "Epoch number: 283/10000step_number: 0/29 cost:  1.1851320943701003 accuracy:  0.7933805502587851\n",
      "Epoch number: 284/10000step_number: 0/29 cost:  1.1820499575500258 accuracy:  0.7935167529283574\n",
      "Epoch number: 285/10000step_number: 0/29 cost:  1.1790085742434648 accuracy:  0.7935167529283574\n",
      "Epoch number: 286/10000step_number: 0/29 cost:  1.1759888875333468 accuracy:  0.7932443475892127\n",
      "Epoch number: 287/10000step_number: 0/29 cost:  1.1729695272402432 accuracy:  0.7931081449196404\n",
      "Epoch number: 288/10000step_number: 0/29 cost:  1.169947471470956 accuracy:  0.7936529555979297\n",
      "Epoch number: 289/10000step_number: 0/29 cost:  1.1669270353804144 accuracy:  0.7940615636066467\n",
      "Epoch number: 290/10000step_number: 0/29 cost:  1.1639128425138814 accuracy:  0.795014982293653\n",
      "Epoch number: 291/10000step_number: 0/29 cost:  1.1609034908498344 accuracy:  0.7951511849632252\n",
      "Epoch number: 292/10000step_number: 0/29 cost:  1.1578987408316332 accuracy:  0.7952873876327976\n",
      "Epoch number: 293/10000step_number: 0/29 cost:  1.1549155995359943 accuracy:  0.7955597929719422\n",
      "Epoch number: 294/10000step_number: 0/29 cost:  1.1519322346115386 accuracy:  0.7956959956415146\n",
      "Epoch number: 295/10000step_number: 0/29 cost:  1.1489151228309562 accuracy:  0.7956959956415146\n",
      "Epoch number: 296/10000step_number: 0/29 cost:  1.1459215019167448 accuracy:  0.7967856169980931\n",
      "Epoch number: 297/10000step_number: 0/29 cost:  1.1429563596682557 accuracy:  0.7970580223372378\n",
      "Epoch number: 298/10000step_number: 0/29 cost:  1.1400071058719614 accuracy:  0.7969218196676655\n",
      "Epoch number: 299/10000step_number: 0/29 cost:  1.1370681003647514 accuracy:  0.7971942250068101\n",
      "Epoch number: 300/10000step_number: 0/29 cost:  1.134135442204896 accuracy:  0.7974666303459548\n",
      "Epoch number: 301/10000step_number: 0/29 cost:  1.1312054931187139 accuracy:  0.7976028330155271\n",
      "Epoch number: 302/10000step_number: 0/29 cost:  1.1282783149926343 accuracy:  0.7974666303459548\n",
      "Epoch number: 303/10000step_number: 0/29 cost:  1.1253567931341057 accuracy:  0.7977390356850994\n",
      "Epoch number: 304/10000step_number: 0/29 cost:  1.122449483977272 accuracy:  0.7978752383546718\n",
      "Epoch number: 305/10000step_number: 0/29 cost:  1.119577682675595 accuracy:  0.7986924543721057\n",
      "Epoch number: 306/10000step_number: 0/29 cost:  1.116751974945009 accuracy:  0.7991010623808227\n",
      "Epoch number: 307/10000step_number: 0/29 cost:  1.1139463334834845 accuracy:  0.7989648597112503\n",
      "Epoch number: 308/10000step_number: 0/29 cost:  1.1111592110713033 accuracy:  0.7993734677199673\n",
      "Epoch number: 309/10000step_number: 0/29 cost:  1.1083954695047302 accuracy:  0.7993734677199673\n",
      "Epoch number: 310/10000step_number: 0/29 cost:  1.1056697047704382 accuracy:  0.7992372650503949\n",
      "Epoch number: 311/10000step_number: 0/29 cost:  1.1029863090501604 accuracy:  0.7992372650503949\n",
      "Epoch number: 312/10000step_number: 0/29 cost:  1.100338204768752 accuracy:  0.7993734677199673\n",
      "Epoch number: 313/10000step_number: 0/29 cost:  1.0977191299159268 accuracy:  0.7993734677199673\n",
      "Epoch number: 314/10000step_number: 0/29 cost:  1.0951242319699819 accuracy:  0.7995096703895397\n",
      "Epoch number: 315/10000step_number: 0/29 cost:  1.092547189321612 accuracy:  0.7999182783982566\n",
      "Epoch number: 316/10000step_number: 0/29 cost:  1.0899829033216855 accuracy:  0.7997820757286843\n",
      "Epoch number: 317/10000step_number: 0/29 cost:  1.0874366505210964 accuracy:  0.8001906837374012\n",
      "Epoch number: 318/10000step_number: 0/29 cost:  1.0849180366945625 accuracy:  0.8005992917461182\n",
      "Epoch number: 319/10000step_number: 0/29 cost:  1.0824304702078782 accuracy:  0.8011441024244075\n",
      "Epoch number: 320/10000step_number: 0/29 cost:  1.079972095419877 accuracy:  0.8011441024244075\n",
      "Epoch number: 321/10000step_number: 0/29 cost:  1.0775362785416134 accuracy:  0.8015527104331245\n",
      "Epoch number: 322/10000step_number: 0/29 cost:  1.0751003871580245 accuracy:  0.8018251157722691\n",
      "Epoch number: 323/10000step_number: 0/29 cost:  1.0726650898381263 accuracy:  0.8019613184418415\n",
      "Epoch number: 324/10000step_number: 0/29 cost:  1.0702980101862347 accuracy:  0.8025061291201308\n",
      "Epoch number: 325/10000step_number: 0/29 cost:  1.0679844818918132 accuracy:  0.8026423317897031\n",
      "Epoch number: 326/10000step_number: 0/29 cost:  1.0656858228267307 accuracy:  0.80305093979842\n",
      "Epoch number: 327/10000step_number: 0/29 cost:  1.0632968844507658 accuracy:  0.8029147371288478\n",
      "Epoch number: 328/10000step_number: 0/29 cost:  1.0609236443225933 accuracy:  0.8023699264505584\n",
      "Epoch number: 329/10000step_number: 0/29 cost:  1.058606391207259 accuracy:  0.8022337237809861\n",
      "Epoch number: 330/10000step_number: 0/29 cost:  1.0564137102531315 accuracy:  0.8029147371288478\n",
      "Epoch number: 331/10000step_number: 0/29 cost:  1.0543873450912113 accuracy:  0.8033233451375646\n",
      "Epoch number: 332/10000step_number: 0/29 cost:  1.0523829479364801 accuracy:  0.8040043584854263\n",
      "Epoch number: 333/10000step_number: 0/29 cost:  1.0504070477259329 accuracy:  0.8052301825115772\n",
      "Epoch number: 334/10000step_number: 0/29 cost:  1.0484634459703952 accuracy:  0.8057749931898666\n",
      "Epoch number: 335/10000step_number: 0/29 cost:  1.0465490504730208 accuracy:  0.8065922092073005\n",
      "Epoch number: 336/10000step_number: 0/29 cost:  1.0446615893935847 accuracy:  0.8068646145464451\n",
      "Epoch number: 337/10000step_number: 0/29 cost:  1.0428166395992298 accuracy:  0.8070008172160175\n",
      "Epoch number: 338/10000step_number: 0/29 cost:  1.0410537770423087 accuracy:  0.8074094252247344\n",
      "Epoch number: 339/10000step_number: 0/29 cost:  1.039413493887218 accuracy:  0.8079542359030237\n",
      "Epoch number: 340/10000step_number: 0/29 cost:  1.0378639790862025 accuracy:  0.8082266412421684\n",
      "Epoch number: 341/10000step_number: 0/29 cost:  1.0363298608866809 accuracy:  0.8082266412421684\n",
      "Epoch number: 342/10000step_number: 0/29 cost:  1.0347694175778952 accuracy:  0.808499046581313\n",
      "Epoch number: 343/10000step_number: 0/29 cost:  1.0331754992110063 accuracy:  0.80890765459003\n",
      "Epoch number: 344/10000step_number: 0/29 cost:  1.0315449078069128 accuracy:  0.8094524652683193\n",
      "Epoch number: 345/10000step_number: 0/29 cost:  1.0298639266998475 accuracy:  0.8101334786161809\n",
      "Epoch number: 346/10000step_number: 0/29 cost:  1.028130633690395 accuracy:  0.8109506946336148\n",
      "Epoch number: 347/10000step_number: 0/29 cost:  1.0263651017390139 accuracy:  0.8110868973031872\n",
      "Epoch number: 348/10000step_number: 0/29 cost:  1.0245853202965032 accuracy:  0.8114955053119041\n",
      "Epoch number: 349/10000step_number: 0/29 cost:  1.0227907295472618 accuracy:  0.8117679106510488\n",
      "Epoch number: 350/10000step_number: 0/29 cost:  1.0209701904997122 accuracy:  0.8116317079814764\n",
      "Epoch number: 351/10000step_number: 0/29 cost:  1.0191183037890243 accuracy:  0.8116317079814764\n",
      "Epoch number: 352/10000step_number: 0/29 cost:  1.0172380060195632 accuracy:  0.8123127213293381\n",
      "Epoch number: 353/10000step_number: 0/29 cost:  1.0153337885673803 accuracy:  0.8124489239989103\n",
      "Epoch number: 354/10000step_number: 0/29 cost:  1.013407280944869 accuracy:  0.8123127213293381\n",
      "Epoch number: 355/10000step_number: 0/29 cost:  1.011460757421982 accuracy:  0.8132661400163443\n",
      "Epoch number: 356/10000step_number: 0/29 cost:  1.0094980601522745 accuracy:  0.8140833560337782\n",
      "Epoch number: 357/10000step_number: 0/29 cost:  1.0075213188043601 accuracy:  0.8143557613729229\n",
      "Epoch number: 358/10000step_number: 0/29 cost:  1.0055314426284578 accuracy:  0.8149005720512122\n",
      "Epoch number: 359/10000step_number: 0/29 cost:  1.0035292249137884 accuracy:  0.8149005720512122\n",
      "Epoch number: 360/10000step_number: 0/29 cost:  1.0015154761000131 accuracy:  0.8192590574775266\n",
      "Epoch number: 361/10000step_number: 0/29 cost:  0.9994911276869535 accuracy:  0.8195314628166712\n",
      "Epoch number: 362/10000step_number: 0/29 cost:  0.9974572337220388 accuracy:  0.8192590574775266\n",
      "Epoch number: 363/10000step_number: 0/29 cost:  0.9954148375319036 accuracy:  0.8195314628166712\n",
      "Epoch number: 364/10000step_number: 0/29 cost:  0.9933648896557674 accuracy:  0.8196676654862435\n",
      "Epoch number: 365/10000step_number: 0/29 cost:  0.991308293099923 accuracy:  0.8199400708253882\n",
      "Epoch number: 366/10000step_number: 0/29 cost:  0.9892460092347515 accuracy:  0.8199400708253882\n",
      "Epoch number: 367/10000step_number: 0/29 cost:  0.9871791307113348 accuracy:  0.8203486788341051\n",
      "Epoch number: 368/10000step_number: 0/29 cost:  0.9851088599383925 accuracy:  0.8206210841732497\n",
      "Epoch number: 369/10000step_number: 0/29 cost:  0.983036334971627 accuracy:  0.821574502860256\n",
      "Epoch number: 370/10000step_number: 0/29 cost:  0.9809622315921674 accuracy:  0.821574502860256\n",
      "Epoch number: 371/10000step_number: 0/29 cost:  0.9788862122273091 accuracy:  0.821983110868973\n",
      "Epoch number: 372/10000step_number: 0/29 cost:  0.9768070108379038 accuracy:  0.82239171887769\n",
      "Epoch number: 373/10000step_number: 0/29 cost:  0.9747251431271774 accuracy:  0.8228003268864069\n",
      "Epoch number: 374/10000step_number: 0/29 cost:  0.972647139216874 accuracy:  0.8228003268864069\n",
      "Epoch number: 375/10000step_number: 0/29 cost:  0.9705756611950237 accuracy:  0.8229365295559793\n",
      "Epoch number: 376/10000step_number: 0/29 cost:  0.9684853222494494 accuracy:  0.8228003268864069\n",
      "Epoch number: 377/10000step_number: 0/29 cost:  0.9663454268796035 accuracy:  0.8230727322255517\n",
      "Epoch number: 378/10000step_number: 0/29 cost:  0.9641634141211459 accuracy:  0.8233451375646963\n",
      "Epoch number: 379/10000step_number: 0/29 cost:  0.9619572682674409 accuracy:  0.8233451375646963\n",
      "Epoch number: 380/10000step_number: 0/29 cost:  0.9597353719359776 accuracy:  0.8233451375646963\n",
      "Epoch number: 381/10000step_number: 0/29 cost:  0.9574990016530573 accuracy:  0.8236175429038409\n",
      "Epoch number: 382/10000step_number: 0/29 cost:  0.955246144572611 accuracy:  0.8238899482429856\n",
      "Epoch number: 383/10000step_number: 0/29 cost:  0.9529742035720037 accuracy:  0.8240261509125579\n",
      "Epoch number: 384/10000step_number: 0/29 cost:  0.9506815709414277 accuracy:  0.8240261509125579\n",
      "Epoch number: 385/10000step_number: 0/29 cost:  0.9483680437030843 accuracy:  0.8242985562517026\n",
      "Epoch number: 386/10000step_number: 0/29 cost:  0.9460345378077084 accuracy:  0.8241623535821302\n",
      "Epoch number: 387/10000step_number: 0/29 cost:  0.9436826173248626 accuracy:  0.8241623535821302\n",
      "Epoch number: 388/10000step_number: 0/29 cost:  0.9413141226176501 accuracy:  0.8242985562517026\n",
      "Epoch number: 389/10000step_number: 0/29 cost:  0.938930938922764 accuracy:  0.8248433669299918\n",
      "Epoch number: 390/10000step_number: 0/29 cost:  0.9365348681430846 accuracy:  0.8242985562517026\n",
      "Epoch number: 391/10000step_number: 0/29 cost:  0.934127582574306 accuracy:  0.8248433669299918\n",
      "Epoch number: 392/10000step_number: 0/29 cost:  0.9317106509833118 accuracy:  0.8255243802778535\n",
      "Epoch number: 393/10000step_number: 0/29 cost:  0.929285627037581 accuracy:  0.8262053936257151\n",
      "Epoch number: 394/10000step_number: 0/29 cost:  0.9268542032301743 accuracy:  0.826614001634432\n",
      "Epoch number: 395/10000step_number: 0/29 cost:  0.9244184694071385 accuracy:  0.8263415962952874\n",
      "Epoch number: 396/10000step_number: 0/29 cost:  0.9219813356642189 accuracy:  0.8267502043040044\n",
      "Epoch number: 397/10000step_number: 0/29 cost:  0.9195470016783331 accuracy:  0.8271588123127214\n",
      "Epoch number: 398/10000step_number: 0/29 cost:  0.9171206973387692 accuracy:  0.8272950149822936\n",
      "Epoch number: 399/10000step_number: 0/29 cost:  0.9147068035728767 accuracy:  0.8272950149822936\n",
      "Epoch number: 400/10000step_number: 0/29 cost:  0.912307126513397 accuracy:  0.8275674203214383\n",
      "Epoch number: 401/10000step_number: 0/29 cost:  0.9099218048696978 accuracy:  0.8277036229910106\n",
      "Epoch number: 402/10000step_number: 0/29 cost:  0.9075508640118465 accuracy:  0.8279760283301553\n",
      "Epoch number: 403/10000step_number: 0/29 cost:  0.9051944453322283 accuracy:  0.8289294470171615\n",
      "Epoch number: 404/10000step_number: 0/29 cost:  0.9028525423000493 accuracy:  0.8294742576954508\n",
      "Epoch number: 405/10000step_number: 0/29 cost:  0.90052493457481 accuracy:  0.8298828657041678\n",
      "Epoch number: 406/10000step_number: 0/29 cost:  0.8982112011183374 accuracy:  0.8302914737128848\n",
      "Epoch number: 407/10000step_number: 0/29 cost:  0.8959106406540416 accuracy:  0.8301552710433124\n",
      "Epoch number: 408/10000step_number: 0/29 cost:  0.8936221020075172 accuracy:  0.8307000817216017\n",
      "Epoch number: 409/10000step_number: 0/29 cost:  0.8913437465443319 accuracy:  0.8311086897303187\n",
      "Epoch number: 410/10000step_number: 0/29 cost:  0.889072354851231 accuracy:  0.8315172977390357\n",
      "Epoch number: 411/10000step_number: 0/29 cost:  0.8868021438653958 accuracy:  0.8319259057477526\n",
      "Epoch number: 412/10000step_number: 0/29 cost:  0.8845264274361988 accuracy:  0.831653500408608\n",
      "Epoch number: 413/10000step_number: 0/29 cost:  0.8822461009356815 accuracy:  0.8317897030781803\n",
      "Epoch number: 414/10000step_number: 0/29 cost:  0.8799796065636046 accuracy:  0.8330155271043312\n",
      "Epoch number: 415/10000step_number: 0/29 cost:  0.877761405166724 accuracy:  0.8335603377826205\n",
      "Epoch number: 416/10000step_number: 0/29 cost:  0.8756375270356722 accuracy:  0.8338327431217651\n",
      "Epoch number: 417/10000step_number: 0/29 cost:  0.8736695412216684 accuracy:  0.8339689457913375\n",
      "Epoch number: 418/10000step_number: 0/29 cost:  0.8717595630661739 accuracy:  0.8341051484609099\n",
      "Epoch number: 419/10000step_number: 0/29 cost:  0.8697212155983327 accuracy:  0.8342413511304821\n",
      "Epoch number: 420/10000step_number: 0/29 cost:  0.8680698831848088 accuracy:  0.8339689457913375\n",
      "Epoch number: 421/10000step_number: 0/29 cost:  0.866827802465277 accuracy:  0.8350585671479162\n",
      "Epoch number: 422/10000step_number: 0/29 cost:  0.8651264409534775 accuracy:  0.8351947698174884\n",
      "Epoch number: 423/10000step_number: 0/29 cost:  0.8633461920796309 accuracy:  0.8353309724870608\n",
      "Epoch number: 424/10000step_number: 0/29 cost:  0.8615768976145055 accuracy:  0.835467175156633\n",
      "Epoch number: 425/10000step_number: 0/29 cost:  0.8598121631681186 accuracy:  0.8356033778262054\n",
      "Epoch number: 426/10000step_number: 0/29 cost:  0.8580590756575345 accuracy:  0.8353309724870608\n",
      "Epoch number: 427/10000step_number: 0/29 cost:  0.8563170300662637 accuracy:  0.835467175156633\n",
      "Epoch number: 428/10000step_number: 0/29 cost:  0.8545850608953649 accuracy:  0.8357395804957777\n",
      "Epoch number: 429/10000step_number: 0/29 cost:  0.8528617505023738 accuracy:  0.8361481885044947\n",
      "Epoch number: 430/10000step_number: 0/29 cost:  0.8511457853830064 accuracy:  0.83587578316535\n",
      "Epoch number: 431/10000step_number: 0/29 cost:  0.8494359887329757 accuracy:  0.8357395804957777\n",
      "Epoch number: 432/10000step_number: 0/29 cost:  0.8477313965165951 accuracy:  0.8361481885044947\n",
      "Epoch number: 433/10000step_number: 0/29 cost:  0.8460312154631957 accuracy:  0.836692999182784\n",
      "Epoch number: 434/10000step_number: 0/29 cost:  0.8443347951790711 accuracy:  0.836284391174067\n",
      "Epoch number: 435/10000step_number: 0/29 cost:  0.8426415827954213 accuracy:  0.836284391174067\n",
      "Epoch number: 436/10000step_number: 0/29 cost:  0.8409510901610305 accuracy:  0.8365567965132117\n",
      "Epoch number: 437/10000step_number: 0/29 cost:  0.8392628681975307 accuracy:  0.8360119858349223\n",
      "Epoch number: 438/10000step_number: 0/29 cost:  0.8375764855643137 accuracy:  0.83587578316535\n",
      "Epoch number: 439/10000step_number: 0/29 cost:  0.8358914134950806 accuracy:  0.8360119858349223\n",
      "Epoch number: 440/10000step_number: 0/29 cost:  0.8342064627050356 accuracy:  0.8364205938436393\n",
      "Epoch number: 441/10000step_number: 0/29 cost:  0.83251957916729 accuracy:  0.836284391174067\n",
      "Epoch number: 442/10000step_number: 0/29 cost:  0.8308300958084662 accuracy:  0.8361481885044947\n",
      "Epoch number: 443/10000step_number: 0/29 cost:  0.8291368722218244 accuracy:  0.8364205938436393\n",
      "Epoch number: 444/10000step_number: 0/29 cost:  0.8274374524374891 accuracy:  0.8365567965132117\n",
      "Epoch number: 445/10000step_number: 0/29 cost:  0.8257307413437655 accuracy:  0.8365567965132117\n",
      "Epoch number: 446/10000step_number: 0/29 cost:  0.8240189435092923 accuracy:  0.8365567965132117\n",
      "Epoch number: 447/10000step_number: 0/29 cost:  0.8223095769234839 accuracy:  0.836692999182784\n",
      "Epoch number: 448/10000step_number: 0/29 cost:  0.8206155329236218 accuracy:  0.8369654045219286\n",
      "Epoch number: 449/10000step_number: 0/29 cost:  0.8189527494368465 accuracy:  0.8369654045219286\n",
      "Epoch number: 450/10000step_number: 0/29 cost:  0.8173352272654353 accuracy:  0.8372378098610733\n",
      "Epoch number: 451/10000step_number: 0/29 cost:  0.8157638697894319 accuracy:  0.837510215200218\n",
      "Epoch number: 452/10000step_number: 0/29 cost:  0.8142271818706156 accuracy:  0.8376464178697902\n",
      "Epoch number: 453/10000step_number: 0/29 cost:  0.8127142283240969 accuracy:  0.8377826205393626\n",
      "Epoch number: 454/10000step_number: 0/29 cost:  0.8112094959670518 accuracy:  0.8379188232089348\n",
      "Epoch number: 455/10000step_number: 0/29 cost:  0.8097071930599922 accuracy:  0.8380550258785072\n",
      "Epoch number: 456/10000step_number: 0/29 cost:  0.8082048971009272 accuracy:  0.8381912285480796\n",
      "Epoch number: 457/10000step_number: 0/29 cost:  0.8067012445998164 accuracy:  0.8381912285480796\n",
      "Epoch number: 458/10000step_number: 0/29 cost:  0.8051921448820912 accuracy:  0.8380550258785072\n",
      "Epoch number: 459/10000step_number: 0/29 cost:  0.8036709585752511 accuracy:  0.8380550258785072\n",
      "Epoch number: 460/10000step_number: 0/29 cost:  0.8021332964625157 accuracy:  0.8380550258785072\n",
      "Epoch number: 461/10000step_number: 0/29 cost:  0.8005791312567312 accuracy:  0.8381912285480796\n",
      "Epoch number: 462/10000step_number: 0/29 cost:  0.7990095063739054 accuracy:  0.8380550258785072\n",
      "Epoch number: 463/10000step_number: 0/29 cost:  0.7974230818178923 accuracy:  0.8380550258785072\n",
      "Epoch number: 464/10000step_number: 0/29 cost:  0.7958199389213894 accuracy:  0.8379188232089348\n",
      "Epoch number: 465/10000step_number: 0/29 cost:  0.7941885850524546 accuracy:  0.8381912285480796\n",
      "Epoch number: 466/10000step_number: 0/29 cost:  0.7922880309319124 accuracy:  0.8381912285480796\n",
      "Epoch number: 467/10000step_number: 0/29 cost:  0.7900995416011053 accuracy:  0.8379188232089348\n",
      "Epoch number: 468/10000step_number: 0/29 cost:  0.7886884539519372 accuracy:  0.8381912285480796\n",
      "Epoch number: 469/10000step_number: 0/29 cost:  0.787172653234792 accuracy:  0.8384636338872242\n",
      "Epoch number: 470/10000step_number: 0/29 cost:  0.7855825562030825 accuracy:  0.8385998365567965\n",
      "Epoch number: 471/10000step_number: 0/29 cost:  0.7839788713112151 accuracy:  0.8390084445655135\n",
      "Epoch number: 472/10000step_number: 0/29 cost:  0.7823597293214476 accuracy:  0.8391446472350859\n",
      "Epoch number: 473/10000step_number: 0/29 cost:  0.7807189062955838 accuracy:  0.8392808499046581\n",
      "Epoch number: 474/10000step_number: 0/29 cost:  0.7790527075795073 accuracy:  0.8394170525742305\n",
      "Epoch number: 475/10000step_number: 0/29 cost:  0.7773562028419736 accuracy:  0.8395532552438028\n",
      "Epoch number: 476/10000step_number: 0/29 cost:  0.7756254977450019 accuracy:  0.8395532552438028\n",
      "Epoch number: 477/10000step_number: 0/29 cost:  0.7738639992288213 accuracy:  0.8396894579133751\n",
      "Epoch number: 478/10000step_number: 0/29 cost:  0.7720893644352216 accuracy:  0.8394170525742305\n",
      "Epoch number: 479/10000step_number: 0/29 cost:  0.7703289016980112 accuracy:  0.8394170525742305\n",
      "Epoch number: 480/10000step_number: 0/29 cost:  0.7685961336777839 accuracy:  0.8394170525742305\n",
      "Epoch number: 481/10000step_number: 0/29 cost:  0.7668850444144965 accuracy:  0.8406428766003814\n",
      "Epoch number: 482/10000step_number: 0/29 cost:  0.7651900617663657 accuracy:  0.8406428766003814\n",
      "Epoch number: 483/10000step_number: 0/29 cost:  0.763509999897726 accuracy:  0.840506673930809\n",
      "Epoch number: 484/10000step_number: 0/29 cost:  0.7618405323624932 accuracy:  0.8403704712612368\n",
      "Epoch number: 485/10000step_number: 0/29 cost:  0.7601720319087997 accuracy:  0.8403704712612368\n",
      "Epoch number: 486/10000step_number: 0/29 cost:  0.7584983819765876 accuracy:  0.8402342685916644\n",
      "Epoch number: 487/10000step_number: 0/29 cost:  0.7568451167962601 accuracy:  0.8402342685916644\n",
      "Epoch number: 488/10000step_number: 0/29 cost:  0.7552558125722144 accuracy:  0.8402342685916644\n",
      "Epoch number: 489/10000step_number: 0/29 cost:  0.7537162942505038 accuracy:  0.840098065922092\n",
      "Epoch number: 490/10000step_number: 0/29 cost:  0.7521946432160352 accuracy:  0.8407790792699537\n",
      "Epoch number: 491/10000step_number: 0/29 cost:  0.7506817452156956 accuracy:  0.840506673930809\n",
      "Epoch number: 492/10000step_number: 0/29 cost:  0.7491785328285919 accuracy:  0.840506673930809\n",
      "Epoch number: 493/10000step_number: 0/29 cost:  0.7476856376761019 accuracy:  0.840098065922092\n",
      "Epoch number: 494/10000step_number: 0/29 cost:  0.746202870462503 accuracy:  0.840098065922092\n",
      "Epoch number: 495/10000step_number: 0/29 cost:  0.7447296780708305 accuracy:  0.840098065922092\n",
      "Epoch number: 496/10000step_number: 0/29 cost:  0.743265225261634 accuracy:  0.840098065922092\n",
      "Epoch number: 497/10000step_number: 0/29 cost:  0.74180847528253 accuracy:  0.8402342685916644\n",
      "Epoch number: 498/10000step_number: 0/29 cost:  0.7403582912822263 accuracy:  0.8403704712612368\n",
      "Epoch number: 499/10000step_number: 0/29 cost:  0.7389134813574938 accuracy:  0.8403704712612368\n",
      "Epoch number: 500/10000step_number: 0/29 cost:  0.7374728515287536 accuracy:  0.8406428766003814\n",
      "Epoch number: 501/10000step_number: 0/29 cost:  0.7360353699679004 accuracy:  0.8407790792699537\n",
      "Epoch number: 502/10000step_number: 0/29 cost:  0.734600424817698 accuracy:  0.8407790792699537\n",
      "Epoch number: 503/10000step_number: 0/29 cost:  0.7331680110676859 accuracy:  0.840506673930809\n",
      "Epoch number: 504/10000step_number: 0/29 cost:  0.7317390275468265 accuracy:  0.8406428766003814\n",
      "Epoch number: 505/10000step_number: 0/29 cost:  0.7303149358822694 accuracy:  0.8407790792699537\n",
      "Epoch number: 506/10000step_number: 0/29 cost:  0.728895934141492 accuracy:  0.8407790792699537\n",
      "Epoch number: 507/10000step_number: 0/29 cost:  0.727480627713157 accuracy:  0.8410514846090983\n",
      "Epoch number: 508/10000step_number: 0/29 cost:  0.7260672505511998 accuracy:  0.840915281939526\n",
      "Epoch number: 509/10000step_number: 0/29 cost:  0.7246540619702367 accuracy:  0.8410514846090983\n",
      "Epoch number: 510/10000step_number: 0/29 cost:  0.7232392422422822 accuracy:  0.841323889948243\n",
      "Epoch number: 511/10000step_number: 0/29 cost:  0.721821548310997 accuracy:  0.8418687006265323\n",
      "Epoch number: 512/10000step_number: 0/29 cost:  0.7204015060391082 accuracy:  0.8418687006265323\n",
      "Epoch number: 513/10000step_number: 0/29 cost:  0.7189808475056993 accuracy:  0.8418687006265323\n",
      "Epoch number: 514/10000step_number: 0/29 cost:  0.717560661307052 accuracy:  0.8418687006265323\n",
      "Epoch number: 515/10000step_number: 0/29 cost:  0.7161410206659383 accuracy:  0.8417324979569599\n",
      "Epoch number: 516/10000step_number: 0/29 cost:  0.7147214397370205 accuracy:  0.8421411059656769\n",
      "Epoch number: 517/10000step_number: 0/29 cost:  0.7133010607781654 accuracy:  0.8424135113048216\n",
      "Epoch number: 518/10000step_number: 0/29 cost:  0.7118788708774701 accuracy:  0.8425497139743939\n",
      "Epoch number: 519/10000step_number: 0/29 cost:  0.7104539518798834 accuracy:  0.8425497139743939\n",
      "Epoch number: 520/10000step_number: 0/29 cost:  0.7090255726607098 accuracy:  0.8436393353309725\n",
      "Epoch number: 521/10000step_number: 0/29 cost:  0.7075931684583256 accuracy:  0.8439117406701171\n",
      "Epoch number: 522/10000step_number: 0/29 cost:  0.7061563014392133 accuracy:  0.8450013620266957\n",
      "Epoch number: 523/10000step_number: 0/29 cost:  0.7047146357113534 accuracy:  0.8454099700354127\n",
      "Epoch number: 524/10000step_number: 0/29 cost:  0.7032679295195751 accuracy:  0.8454099700354127\n",
      "Epoch number: 525/10000step_number: 0/29 cost:  0.7018160400958 accuracy:  0.8454099700354127\n",
      "Epoch number: 526/10000step_number: 0/29 cost:  0.7003589360014382 accuracy:  0.845546172704985\n",
      "Epoch number: 527/10000step_number: 0/29 cost:  0.698896712133565 accuracy:  0.8458185780441296\n",
      "Epoch number: 528/10000step_number: 0/29 cost:  0.6974296010179596 accuracy:  0.8456823753745574\n",
      "Epoch number: 529/10000step_number: 0/29 cost:  0.695957970672705 accuracy:  0.845954780713702\n",
      "Epoch number: 530/10000step_number: 0/29 cost:  0.6944823005014267 accuracy:  0.8462271860528466\n",
      "Epoch number: 531/10000step_number: 0/29 cost:  0.6930031393625712 accuracy:  0.846363388722419\n",
      "Epoch number: 532/10000step_number: 0/29 cost:  0.6915210666274907 accuracy:  0.846363388722419\n",
      "Epoch number: 533/10000step_number: 0/29 cost:  0.6900366749295475 accuracy:  0.8464995913919913\n",
      "Epoch number: 534/10000step_number: 0/29 cost:  0.6885505706264322 accuracy:  0.8466357940615636\n",
      "Epoch number: 535/10000step_number: 0/29 cost:  0.6870633983737989 accuracy:  0.8464995913919913\n",
      "Epoch number: 536/10000step_number: 0/29 cost:  0.6855760181251174 accuracy:  0.8471806047398529\n",
      "Epoch number: 537/10000step_number: 0/29 cost:  0.6840899784869805 accuracy:  0.8473168074094253\n",
      "Epoch number: 538/10000step_number: 0/29 cost:  0.6826074046829568 accuracy:  0.8474530100789975\n",
      "Epoch number: 539/10000step_number: 0/29 cost:  0.6811297295038595 accuracy:  0.8477254154181422\n",
      "Epoch number: 540/10000step_number: 0/29 cost:  0.6796578956051215 accuracy:  0.8479978207572868\n",
      "Epoch number: 541/10000step_number: 0/29 cost:  0.6781935102982622 accuracy:  0.8486788341051484\n",
      "Epoch number: 542/10000step_number: 0/29 cost:  0.6767387677917257 accuracy:  0.8484064287660038\n",
      "Epoch number: 543/10000step_number: 0/29 cost:  0.6752952399561496 accuracy:  0.8485426314355762\n",
      "Epoch number: 544/10000step_number: 0/29 cost:  0.6738631103466712 accuracy:  0.8485426314355762\n",
      "Epoch number: 545/10000step_number: 0/29 cost:  0.6724419248127184 accuracy:  0.8488150367747208\n",
      "Epoch number: 546/10000step_number: 0/29 cost:  0.6710316854908985 accuracy:  0.8488150367747208\n",
      "Epoch number: 547/10000step_number: 0/29 cost:  0.6696330077474718 accuracy:  0.8492236447834377\n",
      "Epoch number: 548/10000step_number: 0/29 cost:  0.6682465077153386 accuracy:  0.8494960501225824\n",
      "Epoch number: 549/10000step_number: 0/29 cost:  0.6668722481996253 accuracy:  0.8494960501225824\n",
      "Epoch number: 550/10000step_number: 0/29 cost:  0.6655097038682474 accuracy:  0.8500408608008717\n",
      "Epoch number: 551/10000step_number: 0/29 cost:  0.6641580440050964 accuracy:  0.8503132661400163\n",
      "Epoch number: 552/10000step_number: 0/29 cost:  0.6628163938405737 accuracy:  0.8503132661400163\n",
      "Epoch number: 553/10000step_number: 0/29 cost:  0.6614839629023923 accuracy:  0.8507218741487333\n",
      "Epoch number: 554/10000step_number: 0/29 cost:  0.6601600571643924 accuracy:  0.8511304821574502\n",
      "Epoch number: 555/10000step_number: 0/29 cost:  0.6588439825789241 accuracy:  0.8511304821574502\n",
      "Epoch number: 556/10000step_number: 0/29 cost:  0.657534792913086 accuracy:  0.8511304821574502\n",
      "Epoch number: 557/10000step_number: 0/29 cost:  0.6562306542171634 accuracy:  0.8515390901661672\n",
      "Epoch number: 558/10000step_number: 0/29 cost:  0.6549271128320274 accuracy:  0.8523563061836013\n",
      "Epoch number: 559/10000step_number: 0/29 cost:  0.6536211518498947 accuracy:  0.8523563061836013\n",
      "Epoch number: 560/10000step_number: 0/29 cost:  0.6523674243763571 accuracy:  0.8526287115227459\n",
      "Epoch number: 561/10000step_number: 0/29 cost:  0.651125002872988 accuracy:  0.8526287115227459\n",
      "Epoch number: 562/10000step_number: 0/29 cost:  0.649864112547531 accuracy:  0.8533097248706074\n",
      "Epoch number: 563/10000step_number: 0/29 cost:  0.6485957458596956 accuracy:  0.8535821302097522\n",
      "Epoch number: 564/10000step_number: 0/29 cost:  0.6473317418301548 accuracy:  0.8537183328793244\n",
      "Epoch number: 565/10000step_number: 0/29 cost:  0.6460696763912768 accuracy:  0.8537183328793244\n",
      "Epoch number: 566/10000step_number: 0/29 cost:  0.6448109430913074 accuracy:  0.853990738218469\n",
      "Epoch number: 567/10000step_number: 0/29 cost:  0.6435561701564955 accuracy:  0.8541269408880414\n",
      "Epoch number: 568/10000step_number: 0/29 cost:  0.6423057561958321 accuracy:  0.8542631435576137\n",
      "Epoch number: 569/10000step_number: 0/29 cost:  0.6410600724685693 accuracy:  0.8542631435576137\n",
      "Epoch number: 570/10000step_number: 0/29 cost:  0.6398193865449237 accuracy:  0.8542631435576137\n",
      "Epoch number: 571/10000step_number: 0/29 cost:  0.6385838242649582 accuracy:  0.854399346227186\n",
      "Epoch number: 572/10000step_number: 0/29 cost:  0.6373533879901786 accuracy:  0.8548079542359031\n",
      "Epoch number: 573/10000step_number: 0/29 cost:  0.6361279802185618 accuracy:  0.8550803595750477\n",
      "Epoch number: 574/10000step_number: 0/29 cost:  0.6349074342294689 accuracy:  0.85521656224462\n",
      "Epoch number: 575/10000step_number: 0/29 cost:  0.6336915382237176 accuracy:  0.8554889675837647\n",
      "Epoch number: 576/10000step_number: 0/29 cost:  0.6324800526265252 accuracy:  0.8554889675837647\n",
      "Epoch number: 577/10000step_number: 0/29 cost:  0.6312727201328753 accuracy:  0.8557613729229093\n",
      "Epoch number: 578/10000step_number: 0/29 cost:  0.6300692707665678 accuracy:  0.8558975755924816\n",
      "Epoch number: 579/10000step_number: 0/29 cost:  0.6288694236257218 accuracy:  0.856442386270771\n",
      "Epoch number: 580/10000step_number: 0/29 cost:  0.6276728865357801 accuracy:  0.8565785889403432\n",
      "Epoch number: 581/10000step_number: 0/29 cost:  0.6264793541944003 accuracy:  0.8565785889403432\n",
      "Epoch number: 582/10000step_number: 0/29 cost:  0.625288505060915 accuracy:  0.8568509942794879\n",
      "Epoch number: 583/10000step_number: 0/29 cost:  0.6240999971286207 accuracy:  0.8573958049577771\n",
      "Epoch number: 584/10000step_number: 0/29 cost:  0.6229134628035533 accuracy:  0.8579406156360665\n",
      "Epoch number: 585/10000step_number: 0/29 cost:  0.6217285033519443 accuracy:  0.8580768183056388\n",
      "Epoch number: 586/10000step_number: 0/29 cost:  0.6205446837930791 accuracy:  0.8582130209752111\n",
      "Epoch number: 587/10000step_number: 0/29 cost:  0.6193615297660476 accuracy:  0.8583492236447834\n",
      "Epoch number: 588/10000step_number: 0/29 cost:  0.6181785288919165 accuracy:  0.8586216289839281\n",
      "Epoch number: 589/10000step_number: 0/29 cost:  0.616995140610867 accuracy:  0.859030236992645\n",
      "Epoch number: 590/10000step_number: 0/29 cost:  0.6158108204932996 accuracy:  0.8593026423317897\n",
      "Epoch number: 591/10000step_number: 0/29 cost:  0.6146250675438646 accuracy:  0.8593026423317897\n",
      "Epoch number: 592/10000step_number: 0/29 cost:  0.6134375055264064 accuracy:  0.859438845001362\n",
      "Epoch number: 593/10000step_number: 0/29 cost:  0.6122480103180649 accuracy:  0.8595750476709344\n",
      "Epoch number: 594/10000step_number: 0/29 cost:  0.6110568914285123 accuracy:  0.8599836556796513\n",
      "Epoch number: 595/10000step_number: 0/29 cost:  0.6098651214650765 accuracy:  0.8605284663579407\n",
      "Epoch number: 596/10000step_number: 0/29 cost:  0.6086745761776515 accuracy:  0.8605284663579407\n",
      "Epoch number: 597/10000step_number: 0/29 cost:  0.6074881999517175 accuracy:  0.8605284663579407\n",
      "Epoch number: 598/10000step_number: 0/29 cost:  0.6063099680343773 accuracy:  0.8606646690275129\n",
      "Epoch number: 599/10000step_number: 0/29 cost:  0.6051445281148574 accuracy:  0.8606646690275129\n",
      "Epoch number: 600/10000step_number: 0/29 cost:  0.6039965222157299 accuracy:  0.8609370743666576\n",
      "Epoch number: 601/10000step_number: 0/29 cost:  0.6028697867893773 accuracy:  0.8612094797058022\n",
      "Epoch number: 602/10000step_number: 0/29 cost:  0.6017667503006562 accuracy:  0.8614818850449468\n",
      "Epoch number: 603/10000step_number: 0/29 cost:  0.6006882451602046 accuracy:  0.8614818850449468\n",
      "Epoch number: 604/10000step_number: 0/29 cost:  0.5996336940887798 accuracy:  0.8612094797058022\n",
      "Epoch number: 605/10000step_number: 0/29 cost:  0.5986014657972887 accuracy:  0.8612094797058022\n",
      "Epoch number: 606/10000step_number: 0/29 cost:  0.597589206355352 accuracy:  0.8613456823753746\n",
      "Epoch number: 607/10000step_number: 0/29 cost:  0.5965939988398348 accuracy:  0.8617542903840916\n",
      "Epoch number: 608/10000step_number: 0/29 cost:  0.5956122397796381 accuracy:  0.8618904930536638\n",
      "Epoch number: 609/10000step_number: 0/29 cost:  0.5946387887634944 accuracy:  0.8625715064015255\n",
      "Epoch number: 610/10000step_number: 0/29 cost:  0.5936665007915791 accuracy:  0.8631163170798147\n",
      "Epoch number: 611/10000step_number: 0/29 cost:  0.5926976918761276 accuracy:  0.8635249250885317\n",
      "Epoch number: 612/10000step_number: 0/29 cost:  0.5917481887585027 accuracy:  0.8636611277581041\n",
      "Epoch number: 613/10000step_number: 0/29 cost:  0.5908256303311569 accuracy:  0.8642059384363934\n",
      "Epoch number: 614/10000step_number: 0/29 cost:  0.5899269176314591 accuracy:  0.8646145464451104\n",
      "Epoch number: 615/10000step_number: 0/29 cost:  0.5890472513993122 accuracy:  0.8647507491146826\n",
      "Epoch number: 616/10000step_number: 0/29 cost:  0.5881829437892434 accuracy:  0.8651593571233996\n",
      "Epoch number: 617/10000step_number: 0/29 cost:  0.58733115493222 accuracy:  0.8654317624625443\n",
      "Epoch number: 618/10000step_number: 0/29 cost:  0.5864896712482556 accuracy:  0.8654317624625443\n",
      "Epoch number: 619/10000step_number: 0/29 cost:  0.5856567395337738 accuracy:  0.8655679651321165\n",
      "Epoch number: 620/10000step_number: 0/29 cost:  0.5848309344808805 accuracy:  0.8657041678016889\n",
      "Epoch number: 621/10000step_number: 0/29 cost:  0.5840111437856297 accuracy:  0.8658403704712613\n",
      "Epoch number: 622/10000step_number: 0/29 cost:  0.5831965925225384 accuracy:  0.8657041678016889\n",
      "Epoch number: 623/10000step_number: 0/29 cost:  0.5823868109311421 accuracy:  0.8659765731408335\n",
      "Epoch number: 624/10000step_number: 0/29 cost:  0.5815815552786492 accuracy:  0.8662489784799782\n",
      "Epoch number: 625/10000step_number: 0/29 cost:  0.5807807290716899 accuracy:  0.8665213838191228\n",
      "Epoch number: 626/10000step_number: 0/29 cost:  0.5799843257077086 accuracy:  0.8666575864886952\n",
      "Epoch number: 627/10000step_number: 0/29 cost:  0.5791923889293482 accuracy:  0.8666575864886952\n",
      "Epoch number: 628/10000step_number: 0/29 cost:  0.578404983490314 accuracy:  0.8663851811495505\n",
      "Epoch number: 629/10000step_number: 0/29 cost:  0.5776221715262454 accuracy:  0.8665213838191228\n",
      "Epoch number: 630/10000step_number: 0/29 cost:  0.5768439929937134 accuracy:  0.8663851811495505\n",
      "Epoch number: 631/10000step_number: 0/29 cost:  0.5760704501843579 accuracy:  0.8665213838191228\n",
      "Epoch number: 632/10000step_number: 0/29 cost:  0.5753014973005004 accuracy:  0.8665213838191228\n",
      "Epoch number: 633/10000step_number: 0/29 cost:  0.5745370361468638 accuracy:  0.8665213838191228\n",
      "Epoch number: 634/10000step_number: 0/29 cost:  0.5737769179681046 accuracy:  0.8666575864886952\n",
      "Epoch number: 635/10000step_number: 0/29 cost:  0.5730209499480109 accuracy:  0.8674748025061291\n",
      "Epoch number: 636/10000step_number: 0/29 cost:  0.5722689038127688 accuracy:  0.8674748025061291\n",
      "Epoch number: 637/10000step_number: 0/29 cost:  0.5715205237297687 accuracy:  0.8677472078452738\n",
      "Epoch number: 638/10000step_number: 0/29 cost:  0.5707755309593118 accuracy:  0.8676110051757014\n",
      "Epoch number: 639/10000step_number: 0/29 cost:  0.570033622955009 accuracy:  0.8677472078452738\n",
      "Epoch number: 640/10000step_number: 0/29 cost:  0.5692944645455676 accuracy:  0.8676110051757014\n",
      "Epoch number: 641/10000step_number: 0/29 cost:  0.5685576692146215 accuracy:  0.8678834105148461\n",
      "Epoch number: 642/10000step_number: 0/29 cost:  0.5678227736937086 accuracy:  0.8678834105148461\n",
      "Epoch number: 643/10000step_number: 0/29 cost:  0.5670892353771307 accuracy:  0.8678834105148461\n",
      "Epoch number: 644/10000step_number: 0/29 cost:  0.5663565685896553 accuracy:  0.8678834105148461\n",
      "Epoch number: 645/10000step_number: 0/29 cost:  0.5656248636717643 accuracy:  0.8681558158539907\n",
      "Epoch number: 646/10000step_number: 0/29 cost:  0.5648956022573645 accuracy:  0.8681558158539907\n",
      "Epoch number: 647/10000step_number: 0/29 cost:  0.5641714186462877 accuracy:  0.8681558158539907\n",
      "Epoch number: 648/10000step_number: 0/29 cost:  0.5634542554248277 accuracy:  0.8681558158539907\n",
      "Epoch number: 649/10000step_number: 0/29 cost:  0.5627444837955635 accuracy:  0.8681558158539907\n",
      "Epoch number: 650/10000step_number: 0/29 cost:  0.5620417299278974 accuracy:  0.8682920185235631\n",
      "Epoch number: 651/10000step_number: 0/29 cost:  0.5613456592797734 accuracy:  0.8688368292018523\n",
      "Epoch number: 652/10000step_number: 0/29 cost:  0.5606561179944656 accuracy:  0.8689730318714247\n",
      "Epoch number: 653/10000step_number: 0/29 cost:  0.5599729943273438 accuracy:  0.8688368292018523\n",
      "Epoch number: 654/10000step_number: 0/29 cost:  0.5592960616548383 accuracy:  0.8688368292018523\n",
      "Epoch number: 655/10000step_number: 0/29 cost:  0.5586248792457539 accuracy:  0.869109234540997\n",
      "Epoch number: 656/10000step_number: 0/29 cost:  0.5579587724853607 accuracy:  0.8689730318714247\n",
      "Epoch number: 657/10000step_number: 0/29 cost:  0.5572968817976406 accuracy:  0.869517842549714\n",
      "Epoch number: 658/10000step_number: 0/29 cost:  0.5566382522990216 accuracy:  0.869517842549714\n",
      "Epoch number: 659/10000step_number: 0/29 cost:  0.5559819342829806 accuracy:  0.869517842549714\n",
      "Epoch number: 660/10000step_number: 0/29 cost:  0.5553270704230401 accuracy:  0.8696540452192864\n",
      "Epoch number: 661/10000step_number: 0/29 cost:  0.5546729558295483 accuracy:  0.8700626532280032\n",
      "Epoch number: 662/10000step_number: 0/29 cost:  0.5540190680262197 accuracy:  0.8700626532280032\n",
      "Epoch number: 663/10000step_number: 0/29 cost:  0.5533650722556858 accuracy:  0.869926450558431\n",
      "Epoch number: 664/10000step_number: 0/29 cost:  0.5527108120122171 accuracy:  0.8700626532280032\n",
      "Epoch number: 665/10000step_number: 0/29 cost:  0.5520562950165805 accuracy:  0.8703350585671479\n",
      "Epoch number: 666/10000step_number: 0/29 cost:  0.5514016796314583 accuracy:  0.8704712612367203\n",
      "Epoch number: 667/10000step_number: 0/29 cost:  0.5507472547190623 accuracy:  0.8707436665758649\n",
      "Epoch number: 668/10000step_number: 0/29 cost:  0.550093395468621 accuracy:  0.8719694906020158\n",
      "Epoch number: 669/10000step_number: 0/29 cost:  0.5494404908905356 accuracy:  0.8719694906020158\n",
      "Epoch number: 670/10000step_number: 0/29 cost:  0.5487888735119765 accuracy:  0.8722418959411604\n",
      "Epoch number: 671/10000step_number: 0/29 cost:  0.5481387865754727 accuracy:  0.8722418959411604\n",
      "Epoch number: 672/10000step_number: 0/29 cost:  0.5474903878089792 accuracy:  0.8723780986107328\n",
      "Epoch number: 673/10000step_number: 0/29 cost:  0.5468437678545908 accuracy:  0.872514301280305\n",
      "Epoch number: 674/10000step_number: 0/29 cost:  0.5461989687562328 accuracy:  0.8727867066194498\n",
      "Epoch number: 675/10000step_number: 0/29 cost:  0.5455559982951865 accuracy:  0.8727867066194498\n",
      "Epoch number: 676/10000step_number: 0/29 cost:  0.544914840561303 accuracy:  0.8727867066194498\n",
      "Epoch number: 677/10000step_number: 0/29 cost:  0.5442754638286899 accuracy:  0.8730591119585944\n",
      "Epoch number: 678/10000step_number: 0/29 cost:  0.5436378263074674 accuracy:  0.8730591119585944\n",
      "Epoch number: 679/10000step_number: 0/29 cost:  0.543001880135047 accuracy:  0.872922909289022\n",
      "Epoch number: 680/10000step_number: 0/29 cost:  0.542367574106383 accuracy:  0.872922909289022\n",
      "Epoch number: 681/10000step_number: 0/29 cost:  0.5417348558365466 accuracy:  0.872922909289022\n",
      "Epoch number: 682/10000step_number: 0/29 cost:  0.5411036741332271 accuracy:  0.8730591119585944\n",
      "Epoch number: 683/10000step_number: 0/29 cost:  0.5404739821267802 accuracy:  0.8737401253064561\n",
      "Epoch number: 684/10000step_number: 0/29 cost:  0.5398457408643983 accuracy:  0.8738763279760283\n",
      "Epoch number: 685/10000step_number: 0/29 cost:  0.5392189216657634 accuracy:  0.8740125306456007\n",
      "Epoch number: 686/10000step_number: 0/29 cost:  0.5385935046259053 accuracy:  0.8740125306456007\n",
      "Epoch number: 687/10000step_number: 0/29 cost:  0.5379694719347379 accuracy:  0.874148733315173\n",
      "Epoch number: 688/10000step_number: 0/29 cost:  0.537346798141081 accuracy:  0.874148733315173\n",
      "Epoch number: 689/10000step_number: 0/29 cost:  0.5367254421057145 accuracy:  0.8751021520021792\n",
      "Epoch number: 690/10000step_number: 0/29 cost:  0.5361053444550595 accuracy:  0.8751021520021792\n",
      "Epoch number: 691/10000step_number: 0/29 cost:  0.5354864310000775 accuracy:  0.8748297466630346\n",
      "Epoch number: 692/10000step_number: 0/29 cost:  0.5348686198606151 accuracy:  0.8748297466630346\n",
      "Epoch number: 693/10000step_number: 0/29 cost:  0.5342518292822286 accuracy:  0.8748297466630346\n",
      "Epoch number: 694/10000step_number: 0/29 cost:  0.5336359838403941 accuracy:  0.8751021520021792\n",
      "Epoch number: 695/10000step_number: 0/29 cost:  0.5330210180233474 accuracy:  0.8756469626804685\n",
      "Epoch number: 696/10000step_number: 0/29 cost:  0.532406877386483 accuracy:  0.8756469626804685\n",
      "Epoch number: 697/10000step_number: 0/29 cost:  0.5317935180348091 accuracy:  0.8755107600108962\n",
      "Epoch number: 698/10000step_number: 0/29 cost:  0.5311809049177103 accuracy:  0.8753745573413239\n",
      "Epoch number: 699/10000step_number: 0/29 cost:  0.5305690086766561 accuracy:  0.8753745573413239\n",
      "Epoch number: 700/10000step_number: 0/29 cost:  0.5299578002618446 accuracy:  0.8756469626804685\n",
      "Epoch number: 701/10000step_number: 0/29 cost:  0.5293472427809693 accuracy:  0.8756469626804685\n",
      "Epoch number: 702/10000step_number: 0/29 cost:  0.5287372811933899 accuracy:  0.8755107600108962\n",
      "Epoch number: 703/10000step_number: 0/29 cost:  0.5281278321143298 accuracy:  0.8757831653500409\n",
      "Epoch number: 704/10000step_number: 0/29 cost:  0.5275187772226398 accuracy:  0.8759193680196132\n",
      "Epoch number: 705/10000step_number: 0/29 cost:  0.5269099635071175 accuracy:  0.8759193680196132\n",
      "Epoch number: 706/10000step_number: 0/29 cost:  0.5263012114697107 accuracy:  0.8763279760283301\n",
      "Epoch number: 707/10000step_number: 0/29 cost:  0.5256923293813476 accuracy:  0.8761917733587579\n",
      "Epoch number: 708/10000step_number: 0/29 cost:  0.5250831295460833 accuracy:  0.8764641786979025\n",
      "Epoch number: 709/10000step_number: 0/29 cost:  0.5244734424766629 accuracy:  0.8763279760283301\n",
      "Epoch number: 710/10000step_number: 0/29 cost:  0.5238631266025454 accuracy:  0.8763279760283301\n",
      "Epoch number: 711/10000step_number: 0/29 cost:  0.5232520732632295 accuracy:  0.8766003813674748\n",
      "Epoch number: 712/10000step_number: 0/29 cost:  0.5226402081008634 accuracy:  0.8766003813674748\n",
      "Epoch number: 713/10000step_number: 0/29 cost:  0.5220274902316477 accuracy:  0.8767365840370471\n",
      "Epoch number: 714/10000step_number: 0/29 cost:  0.5214139101056157 accuracy:  0.8767365840370471\n",
      "Epoch number: 715/10000step_number: 0/29 cost:  0.5207994862961616 accuracy:  0.8768727867066195\n",
      "Epoch number: 716/10000step_number: 0/29 cost:  0.5201842609704793 accuracy:  0.8770089893761918\n",
      "Epoch number: 717/10000step_number: 0/29 cost:  0.5195682936384487 accuracy:  0.8771451920457641\n",
      "Epoch number: 718/10000step_number: 0/29 cost:  0.5189516530216068 accuracy:  0.8767365840370471\n",
      "Epoch number: 719/10000step_number: 0/29 cost:  0.5183344076172386 accuracy:  0.8767365840370471\n",
      "Epoch number: 720/10000step_number: 0/29 cost:  0.5177166167838794 accuracy:  0.8767365840370471\n",
      "Epoch number: 721/10000step_number: 0/29 cost:  0.5170983254611465 accuracy:  0.8772813947153364\n",
      "Epoch number: 722/10000step_number: 0/29 cost:  0.5164795656242827 accuracy:  0.8774175973849088\n",
      "Epoch number: 723/10000step_number: 0/29 cost:  0.5158603649872322 accuracy:  0.878371016071915\n",
      "Epoch number: 724/10000step_number: 0/29 cost:  0.5152407592442029 accuracy:  0.8786434214110597\n",
      "Epoch number: 725/10000step_number: 0/29 cost:  0.5146208017728788 accuracy:  0.878371016071915\n",
      "Epoch number: 726/10000step_number: 0/29 cost:  0.5140005666525178 accuracy:  0.8785072187414873\n",
      "Epoch number: 727/10000step_number: 0/29 cost:  0.51338014526073 accuracy:  0.8786434214110597\n",
      "Epoch number: 728/10000step_number: 0/29 cost:  0.5127596397554997 accuracy:  0.8790520294197767\n",
      "Epoch number: 729/10000step_number: 0/29 cost:  0.5121391568229265 accuracy:  0.8790520294197767\n",
      "Epoch number: 730/10000step_number: 0/29 cost:  0.5115188034107747 accuracy:  0.8791882320893489\n",
      "Epoch number: 731/10000step_number: 0/29 cost:  0.5108986845304266 accuracy:  0.8791882320893489\n",
      "Epoch number: 732/10000step_number: 0/29 cost:  0.5102789023555551 accuracy:  0.8793244347589213\n",
      "Epoch number: 733/10000step_number: 0/29 cost:  0.5096595556727774 accuracy:  0.8793244347589213\n",
      "Epoch number: 734/10000step_number: 0/29 cost:  0.5090407389080623 accuracy:  0.8795968400980659\n",
      "Epoch number: 735/10000step_number: 0/29 cost:  0.5084225402254138 accuracy:  0.8795968400980659\n",
      "Epoch number: 736/10000step_number: 0/29 cost:  0.5078050384759335 accuracy:  0.8795968400980659\n",
      "Epoch number: 737/10000step_number: 0/29 cost:  0.5071882990454514 accuracy:  0.8798692454372106\n",
      "Epoch number: 738/10000step_number: 0/29 cost:  0.5065723689017236 accuracy:  0.8801416507763552\n",
      "Epoch number: 739/10000step_number: 0/29 cost:  0.505957271357664 accuracy:  0.8801416507763552\n",
      "Epoch number: 740/10000step_number: 0/29 cost:  0.5053430012085104 accuracy:  0.8802778534459276\n",
      "Epoch number: 741/10000step_number: 0/29 cost:  0.5047295209302646 accuracy:  0.8802778534459276\n",
      "Epoch number: 742/10000step_number: 0/29 cost:  0.5041167585262076 accuracy:  0.8802778534459276\n",
      "Epoch number: 743/10000step_number: 0/29 cost:  0.5035046073945147 accuracy:  0.8805502587850722\n",
      "Epoch number: 744/10000step_number: 0/29 cost:  0.5028929283115281 accuracy:  0.8806864614546445\n",
      "Epoch number: 745/10000step_number: 0/29 cost:  0.5022815533426327 accuracy:  0.8805502587850722\n",
      "Epoch number: 746/10000step_number: 0/29 cost:  0.5016702912533116 accuracy:  0.8805502587850722\n",
      "Epoch number: 747/10000step_number: 0/29 cost:  0.5010589338177108 accuracy:  0.8808226641242168\n",
      "Epoch number: 748/10000step_number: 0/29 cost:  0.5004472623119655 accuracy:  0.8809588667937892\n",
      "Epoch number: 749/10000step_number: 0/29 cost:  0.4998350534360321 accuracy:  0.8809588667937892\n",
      "Epoch number: 750/10000step_number: 0/29 cost:  0.49922208394868983 accuracy:  0.8809588667937892\n",
      "Epoch number: 751/10000step_number: 0/29 cost:  0.49860813345597776 accuracy:  0.8808226641242168\n",
      "Epoch number: 752/10000step_number: 0/29 cost:  0.49799298508172635 accuracy:  0.8810950694633615\n",
      "Epoch number: 753/10000step_number: 0/29 cost:  0.497376424147428 accuracy:  0.8812312721329338\n",
      "Epoch number: 754/10000step_number: 0/29 cost:  0.4967582354263527 accuracy:  0.8813674748025061\n",
      "Epoch number: 755/10000step_number: 0/29 cost:  0.49613819991781466 accuracy:  0.8813674748025061\n",
      "Epoch number: 756/10000step_number: 0/29 cost:  0.4955160923346446 accuracy:  0.8813674748025061\n",
      "Epoch number: 757/10000step_number: 0/29 cost:  0.4948916805848629 accuracy:  0.8817760828112231\n",
      "Epoch number: 758/10000step_number: 0/29 cost:  0.4942647284855676 accuracy:  0.8824570961590847\n",
      "Epoch number: 759/10000step_number: 0/29 cost:  0.49363500282743245 accuracy:  0.8824570961590847\n",
      "Epoch number: 760/10000step_number: 0/29 cost:  0.49300228575407584 accuracy:  0.8828657041678016\n",
      "Epoch number: 761/10000step_number: 0/29 cost:  0.492366393232971 accuracy:  0.8828657041678016\n",
      "Epoch number: 762/10000step_number: 0/29 cost:  0.49172720012167986 accuracy:  0.883001906837374\n",
      "Epoch number: 763/10000step_number: 0/29 cost:  0.49108467187621013 accuracy:  0.8831381095069464\n",
      "Epoch number: 764/10000step_number: 0/29 cost:  0.49043890218686426 accuracy:  0.8831381095069464\n",
      "Epoch number: 765/10000step_number: 0/29 cost:  0.4897901546718603 accuracy:  0.8831381095069464\n",
      "Epoch number: 766/10000step_number: 0/29 cost:  0.48913890523972703 accuracy:  0.8831381095069464\n",
      "Epoch number: 767/10000step_number: 0/29 cost:  0.48848588010212013 accuracy:  0.8835467175156633\n",
      "Epoch number: 768/10000step_number: 0/29 cost:  0.4878320832001348 accuracy:  0.8836829201852356\n",
      "Epoch number: 769/10000step_number: 0/29 cost:  0.48717880658464363 accuracy:  0.8838191228548079\n",
      "Epoch number: 770/10000step_number: 0/29 cost:  0.4865276180697773 accuracy:  0.8839553255243803\n",
      "Epoch number: 771/10000step_number: 0/29 cost:  0.48588032081114524 accuracy:  0.8840915281939526\n",
      "Epoch number: 772/10000step_number: 0/29 cost:  0.48523887685979167 accuracy:  0.8845001362026695\n",
      "Epoch number: 773/10000step_number: 0/29 cost:  0.48460528217715265 accuracy:  0.8846363388722419\n",
      "Epoch number: 774/10000step_number: 0/29 cost:  0.48398138566850535 accuracy:  0.8861345682375374\n",
      "Epoch number: 775/10000step_number: 0/29 cost:  0.4833686757565403 accuracy:  0.8866793789158267\n",
      "Epoch number: 776/10000step_number: 0/29 cost:  0.4827681027547737 accuracy:  0.8868155815853991\n",
      "Epoch number: 777/10000step_number: 0/29 cost:  0.4821800105435972 accuracy:  0.8869517842549713\n",
      "Epoch number: 778/10000step_number: 0/29 cost:  0.4816041924546205 accuracy:  0.8869517842549713\n",
      "Epoch number: 779/10000step_number: 0/29 cost:  0.48104002060583617 accuracy:  0.8870879869245437\n",
      "Epoch number: 780/10000step_number: 0/29 cost:  0.480486581608927 accuracy:  0.8870879869245437\n",
      "Epoch number: 781/10000step_number: 0/29 cost:  0.47994277486443215 accuracy:  0.8873603922636883\n",
      "Epoch number: 782/10000step_number: 0/29 cost:  0.47940736723348254 accuracy:  0.8872241895941161\n",
      "Epoch number: 783/10000step_number: 0/29 cost:  0.47887903952201216 accuracy:  0.8873603922636883\n",
      "Epoch number: 784/10000step_number: 0/29 cost:  0.4783564809370806 accuracy:  0.8873603922636883\n",
      "Epoch number: 785/10000step_number: 0/29 cost:  0.4778385471938629 accuracy:  0.8872241895941161\n",
      "Epoch number: 786/10000step_number: 0/29 cost:  0.47732441091550404 accuracy:  0.8872241895941161\n",
      "Epoch number: 787/10000step_number: 0/29 cost:  0.4768136039822097 accuracy:  0.8874965949332607\n",
      "Epoch number: 788/10000step_number: 0/29 cost:  0.4763059344746809 accuracy:  0.887632797602833\n",
      "Epoch number: 789/10000step_number: 0/29 cost:  0.4758013529966676 accuracy:  0.887632797602833\n",
      "Epoch number: 790/10000step_number: 0/29 cost:  0.47529984652548196 accuracy:  0.887632797602833\n",
      "Epoch number: 791/10000step_number: 0/29 cost:  0.4748013858792201 accuracy:  0.8877690002724054\n",
      "Epoch number: 792/10000step_number: 0/29 cost:  0.47430591341051703 accuracy:  0.8879052029419776\n",
      "Epoch number: 793/10000step_number: 0/29 cost:  0.4738133488820824 accuracy:  0.88804140561155\n",
      "Epoch number: 794/10000step_number: 0/29 cost:  0.47332359914989336 accuracy:  0.8881776082811224\n",
      "Epoch number: 795/10000step_number: 0/29 cost:  0.4728365660644971 accuracy:  0.8883138109506946\n",
      "Epoch number: 796/10000step_number: 0/29 cost:  0.47235215158449273 accuracy:  0.8883138109506946\n",
      "Epoch number: 797/10000step_number: 0/29 cost:  0.4718702605850697 accuracy:  0.88804140561155\n",
      "Epoch number: 798/10000step_number: 0/29 cost:  0.4713908021075772 accuracy:  0.88804140561155\n",
      "Epoch number: 799/10000step_number: 0/29 cost:  0.4709136896742625 accuracy:  0.88804140561155\n",
      "Epoch number: 800/10000step_number: 0/29 cost:  0.47043884108568196 accuracy:  0.88804140561155\n",
      "Epoch number: 801/10000step_number: 0/29 cost:  0.4699661779488031 accuracy:  0.88804140561155\n",
      "Epoch number: 802/10000step_number: 0/29 cost:  0.4694956250719116 accuracy:  0.88804140561155\n",
      "Epoch number: 803/10000step_number: 0/29 cost:  0.4690271097966783 accuracy:  0.88804140561155\n",
      "Epoch number: 804/10000step_number: 0/29 cost:  0.46856056130858803 accuracy:  0.88804140561155\n",
      "Epoch number: 805/10000step_number: 0/29 cost:  0.4680959099626553 accuracy:  0.8881776082811224\n",
      "Epoch number: 806/10000step_number: 0/29 cost:  0.4676330866677381 accuracy:  0.8881776082811224\n",
      "Epoch number: 807/10000step_number: 0/29 cost:  0.46717202237746014 accuracy:  0.8881776082811224\n",
      "Epoch number: 808/10000step_number: 0/29 cost:  0.4667126477303348 accuracy:  0.8881776082811224\n",
      "Epoch number: 809/10000step_number: 0/29 cost:  0.4662548928637578 accuracy:  0.8881776082811224\n",
      "Epoch number: 810/10000step_number: 0/29 cost:  0.4657986874003288 accuracy:  0.8896758376464179\n",
      "Epoch number: 811/10000step_number: 0/29 cost:  0.46534396057883143 accuracy:  0.8896758376464179\n",
      "Epoch number: 812/10000step_number: 0/29 cost:  0.4648906414840174 accuracy:  0.8896758376464179\n",
      "Epoch number: 813/10000step_number: 0/29 cost:  0.4644386593230512 accuracy:  0.8896758376464179\n",
      "Epoch number: 814/10000step_number: 0/29 cost:  0.4639879437010858 accuracy:  0.8899482429855625\n",
      "Epoch number: 815/10000step_number: 0/29 cost:  0.46353842485979774 accuracy:  0.8900844456551349\n",
      "Epoch number: 816/10000step_number: 0/29 cost:  0.4630900338557847 accuracy:  0.8900844456551349\n",
      "Epoch number: 817/10000step_number: 0/29 cost:  0.46264270266667584 accuracy:  0.8902206483247072\n",
      "Epoch number: 818/10000step_number: 0/29 cost:  0.4621963642195782 accuracy:  0.8902206483247072\n",
      "Epoch number: 819/10000step_number: 0/29 cost:  0.4617509523386449 accuracy:  0.8903568509942795\n",
      "Epoch number: 820/10000step_number: 0/29 cost:  0.4613064016067272 accuracy:  0.8900844456551349\n",
      "Epoch number: 821/10000step_number: 0/29 cost:  0.46086264713163283 accuracy:  0.8899482429855625\n",
      "Epoch number: 822/10000step_number: 0/29 cost:  0.4604196242025907 accuracy:  0.8902206483247072\n",
      "Epoch number: 823/10000step_number: 0/29 cost:  0.45997726782058285 accuracy:  0.8902206483247072\n",
      "Epoch number: 824/10000step_number: 0/29 cost:  0.4595355120925727 accuracy:  0.8903568509942795\n",
      "Epoch number: 825/10000step_number: 0/29 cost:  0.4590942895016766 accuracy:  0.8903568509942795\n",
      "Epoch number: 826/10000step_number: 0/29 cost:  0.45865353011020005 accuracy:  0.8904930536638518\n",
      "Epoch number: 827/10000step_number: 0/29 cost:  0.4582131608214068 accuracy:  0.8904930536638518\n",
      "Epoch number: 828/10000step_number: 0/29 cost:  0.4577731049039362 accuracy:  0.8904930536638518\n",
      "Epoch number: 829/10000step_number: 0/29 cost:  0.45733328203014517 accuracy:  0.8904930536638518\n",
      "Epoch number: 830/10000step_number: 0/29 cost:  0.4568936090383734 accuracy:  0.8903568509942795\n",
      "Epoch number: 831/10000step_number: 0/29 cost:  0.4564540014587872 accuracy:  0.8906292563334242\n",
      "Epoch number: 832/10000step_number: 0/29 cost:  0.4560143755739535 accuracy:  0.8906292563334242\n",
      "Epoch number: 833/10000step_number: 0/29 cost:  0.4555746505420027 accuracy:  0.8911740670117134\n",
      "Epoch number: 834/10000step_number: 0/29 cost:  0.4551347500448784 accuracy:  0.8911740670117134\n",
      "Epoch number: 835/10000step_number: 0/29 cost:  0.454694603098601 accuracy:  0.8913102696812858\n",
      "Epoch number: 836/10000step_number: 0/29 cost:  0.45425414398368036 accuracy:  0.8913102696812858\n",
      "Epoch number: 837/10000step_number: 0/29 cost:  0.45381331154269094 accuracy:  0.8913102696812858\n",
      "Epoch number: 838/10000step_number: 0/29 cost:  0.4533720482192751 accuracy:  0.8913102696812858\n",
      "Epoch number: 839/10000step_number: 0/29 cost:  0.45293029917099387 accuracy:  0.8913102696812858\n",
      "Epoch number: 840/10000step_number: 0/29 cost:  0.4524880116558458 accuracy:  0.8915826750204304\n",
      "Epoch number: 841/10000step_number: 0/29 cost:  0.4520451347543539 accuracy:  0.8918550803595751\n",
      "Epoch number: 842/10000step_number: 0/29 cost:  0.45160161939125293 accuracy:  0.8921274856987197\n",
      "Epoch number: 843/10000step_number: 0/29 cost:  0.4511574185680113 accuracy:  0.8921274856987197\n",
      "Epoch number: 844/10000step_number: 0/29 cost:  0.4507124876954038 accuracy:  0.8922636883682921\n",
      "Epoch number: 845/10000step_number: 0/29 cost:  0.450266784909009 accuracy:  0.8922636883682921\n",
      "Epoch number: 846/10000step_number: 0/29 cost:  0.4498202712517562 accuracy:  0.8922636883682921\n",
      "Epoch number: 847/10000step_number: 0/29 cost:  0.4493729106159813 accuracy:  0.8922636883682921\n",
      "Epoch number: 848/10000step_number: 0/29 cost:  0.44892466935710673 accuracy:  0.8922636883682921\n",
      "Epoch number: 849/10000step_number: 0/29 cost:  0.4484755155274311 accuracy:  0.8922636883682921\n",
      "Epoch number: 850/10000step_number: 0/29 cost:  0.4480254177343359 accuracy:  0.8922636883682921\n",
      "Epoch number: 851/10000step_number: 0/29 cost:  0.44757434369870713 accuracy:  0.8922636883682921\n",
      "Epoch number: 852/10000step_number: 0/29 cost:  0.44712225866407734 accuracy:  0.8922636883682921\n",
      "Epoch number: 853/10000step_number: 0/29 cost:  0.4466691238648052 accuracy:  0.8922636883682921\n",
      "Epoch number: 854/10000step_number: 0/29 cost:  0.44621489528085134 accuracy:  0.8923998910378643\n",
      "Epoch number: 855/10000step_number: 0/29 cost:  0.4457595228738419 accuracy:  0.8923998910378643\n",
      "Epoch number: 856/10000step_number: 0/29 cost:  0.4453029504174655 accuracy:  0.8925360937074367\n",
      "Epoch number: 857/10000step_number: 0/29 cost:  0.4448451159267222 accuracy:  0.892672296377009\n",
      "Epoch number: 858/10000step_number: 0/29 cost:  0.4443859525875866 accuracy:  0.8925360937074367\n",
      "Epoch number: 859/10000step_number: 0/29 cost:  0.4439253900202896 accuracy:  0.8925360937074367\n",
      "Epoch number: 860/10000step_number: 0/29 cost:  0.4434633556893898 accuracy:  0.892672296377009\n",
      "Epoch number: 861/10000step_number: 0/29 cost:  0.4429997762974409 accuracy:  0.8925360937074367\n",
      "Epoch number: 862/10000step_number: 0/29 cost:  0.44253457904921784 accuracy:  0.892672296377009\n",
      "Epoch number: 863/10000step_number: 0/29 cost:  0.4420676927301638 accuracy:  0.892672296377009\n",
      "Epoch number: 864/10000step_number: 0/29 cost:  0.4415990485910834 accuracy:  0.892672296377009\n",
      "Epoch number: 865/10000step_number: 0/29 cost:  0.44112858106414327 accuracy:  0.892672296377009\n",
      "Epoch number: 866/10000step_number: 0/29 cost:  0.4406562283527694 accuracy:  0.8921274856987197\n",
      "Epoch number: 867/10000step_number: 0/29 cost:  0.4401819329436942 accuracy:  0.8921274856987197\n",
      "Epoch number: 868/10000step_number: 0/29 cost:  0.4397056420877965 accuracy:  0.8921274856987197\n",
      "Epoch number: 869/10000step_number: 0/29 cost:  0.4392273082914106 accuracy:  0.8923998910378643\n",
      "Epoch number: 870/10000step_number: 0/29 cost:  0.43874688985399485 accuracy:  0.8925360937074367\n",
      "Epoch number: 871/10000step_number: 0/29 cost:  0.4382643514826034 accuracy:  0.892672296377009\n",
      "Epoch number: 872/10000step_number: 0/29 cost:  0.43777966500865284 accuracy:  0.8925360937074367\n",
      "Epoch number: 873/10000step_number: 0/29 cost:  0.4372928102274299 accuracy:  0.8925360937074367\n",
      "Epoch number: 874/10000step_number: 0/29 cost:  0.43680377587473995 accuracy:  0.8925360937074367\n",
      "Epoch number: 875/10000step_number: 0/29 cost:  0.4363125607470569 accuracy:  0.892672296377009\n",
      "Epoch number: 876/10000step_number: 0/29 cost:  0.43581917496081496 accuracy:  0.892672296377009\n",
      "Epoch number: 877/10000step_number: 0/29 cost:  0.43532364133289764 accuracy:  0.892672296377009\n",
      "Epoch number: 878/10000step_number: 0/29 cost:  0.4348259968485947 accuracy:  0.8928084990465813\n",
      "Epoch number: 879/10000step_number: 0/29 cost:  0.4343262941667544 accuracy:  0.8928084990465813\n",
      "Epoch number: 880/10000step_number: 0/29 cost:  0.43382460309666226 accuracy:  0.8928084990465813\n",
      "Epoch number: 881/10000step_number: 0/29 cost:  0.4333210119696622 accuracy:  0.8929447017161536\n",
      "Epoch number: 882/10000step_number: 0/29 cost:  0.432815628822589 accuracy:  0.893080904385726\n",
      "Epoch number: 883/10000step_number: 0/29 cost:  0.43230858231072433 accuracy:  0.893080904385726\n",
      "Epoch number: 884/10000step_number: 0/29 cost:  0.4318000222750029 accuracy:  0.893080904385726\n",
      "Epoch number: 885/10000step_number: 0/29 cost:  0.4312901199002866 accuracy:  0.8938981204031599\n",
      "Epoch number: 886/10000step_number: 0/29 cost:  0.4307790674168093 accuracy:  0.8938981204031599\n",
      "Epoch number: 887/10000step_number: 0/29 cost:  0.43026707731348085 accuracy:  0.8938981204031599\n",
      "Epoch number: 888/10000step_number: 0/29 cost:  0.4297543810482863 accuracy:  0.8938981204031599\n",
      "Epoch number: 889/10000step_number: 0/29 cost:  0.4292412272569354 accuracy:  0.8938981204031599\n",
      "Epoch number: 890/10000step_number: 0/29 cost:  0.42872787947625485 accuracy:  0.8938981204031599\n",
      "Epoch number: 891/10000step_number: 0/29 cost:  0.42821461341391037 accuracy:  0.8944429310814492\n",
      "Epoch number: 892/10000step_number: 0/29 cost:  0.4277017138111492 accuracy:  0.8947153364205939\n",
      "Epoch number: 893/10000step_number: 0/29 cost:  0.4271894709602551 accuracy:  0.8953963497684555\n",
      "Epoch number: 894/10000step_number: 0/29 cost:  0.4266781769528 accuracy:  0.8951239444293109\n",
      "Epoch number: 895/10000step_number: 0/29 cost:  0.4261681217476925 accuracy:  0.8951239444293109\n",
      "Epoch number: 896/10000step_number: 0/29 cost:  0.42565958915849195 accuracy:  0.8953963497684555\n",
      "Epoch number: 897/10000step_number: 0/29 cost:  0.4251528528664601 accuracy:  0.8955325524380278\n",
      "Epoch number: 898/10000step_number: 0/29 cost:  0.4246481725684929 accuracy:  0.8955325524380278\n",
      "Epoch number: 899/10000step_number: 0/29 cost:  0.4241457903666834 accuracy:  0.8956687551076001\n",
      "Epoch number: 900/10000step_number: 0/29 cost:  0.4236459274983215 accuracy:  0.8958049577771724\n",
      "Epoch number: 901/10000step_number: 0/29 cost:  0.42314878149145657 accuracy:  0.8956687551076001\n",
      "Epoch number: 902/10000step_number: 0/29 cost:  0.42265452381205 accuracy:  0.8956687551076001\n",
      "Epoch number: 903/10000step_number: 0/29 cost:  0.42216329804504016 accuracy:  0.8963497684554618\n",
      "Epoch number: 904/10000step_number: 0/29 cost:  0.42167521862481194 accuracy:  0.896485971125034\n",
      "Epoch number: 905/10000step_number: 0/29 cost:  0.42119037010244653 accuracy:  0.8963497684554618\n",
      "Epoch number: 906/10000step_number: 0/29 cost:  0.42070880690985313 accuracy:  0.896485971125034\n",
      "Epoch number: 907/10000step_number: 0/29 cost:  0.4202305535563947 accuracy:  0.896485971125034\n",
      "Epoch number: 908/10000step_number: 0/29 cost:  0.41975560517350413 accuracy:  0.8966221737946064\n",
      "Epoch number: 909/10000step_number: 0/29 cost:  0.41928392830804295 accuracy:  0.8967583764641787\n",
      "Epoch number: 910/10000step_number: 0/29 cost:  0.41881546185627727 accuracy:  0.896894579133751\n",
      "Epoch number: 911/10000step_number: 0/29 cost:  0.4183501180275193 accuracy:  0.896894579133751\n",
      "Epoch number: 912/10000step_number: 0/29 cost:  0.41788778323016734 accuracy:  0.896894579133751\n",
      "Epoch number: 913/10000step_number: 0/29 cost:  0.41742831878450637 accuracy:  0.896894579133751\n",
      "Epoch number: 914/10000step_number: 0/29 cost:  0.41697156138990105 accuracy:  0.8970307818033233\n",
      "Epoch number: 915/10000step_number: 0/29 cost:  0.4165173233166303 accuracy:  0.8970307818033233\n",
      "Epoch number: 916/10000step_number: 0/29 cost:  0.4160653923691588 accuracy:  0.896894579133751\n",
      "Epoch number: 917/10000step_number: 0/29 cost:  0.41561553180378136 accuracy:  0.8970307818033233\n",
      "Epoch number: 918/10000step_number: 0/29 cost:  0.4151674806221472 accuracy:  0.8970307818033233\n",
      "Epoch number: 919/10000step_number: 0/29 cost:  0.4147209550700128 accuracy:  0.8970307818033233\n",
      "Epoch number: 920/10000step_number: 0/29 cost:  0.4142756528426047 accuracy:  0.8971669844728957\n",
      "Epoch number: 921/10000step_number: 0/29 cost:  0.4138312625444909 accuracy:  0.897303187142468\n",
      "Epoch number: 922/10000step_number: 0/29 cost:  0.4133874824374166 accuracy:  0.897303187142468\n",
      "Epoch number: 923/10000step_number: 0/29 cost:  0.41294405427562736 accuracy:  0.8977117951511849\n",
      "Epoch number: 924/10000step_number: 0/29 cost:  0.41250081930203475 accuracy:  0.8979842004903296\n",
      "Epoch number: 925/10000step_number: 0/29 cost:  0.4120578022333227 accuracy:  0.8979842004903296\n",
      "Epoch number: 926/10000step_number: 0/29 cost:  0.4116153215174254 accuracy:  0.8981204031599019\n",
      "Epoch number: 927/10000step_number: 0/29 cost:  0.41117410592558706 accuracy:  0.8981204031599019\n",
      "Epoch number: 928/10000step_number: 0/29 cost:  0.41073536924125115 accuracy:  0.8979842004903296\n",
      "Epoch number: 929/10000step_number: 0/29 cost:  0.4103007721752565 accuracy:  0.8997548351947698\n",
      "Epoch number: 930/10000step_number: 0/29 cost:  0.40987221722527606 accuracy:  0.8998910378643421\n",
      "Epoch number: 931/10000step_number: 0/29 cost:  0.40945150081544307 accuracy:  0.8998910378643421\n",
      "Epoch number: 932/10000step_number: 0/29 cost:  0.40903994830553436 accuracy:  0.9000272405339145\n",
      "Epoch number: 933/10000step_number: 0/29 cost:  0.4086381861918606 accuracy:  0.9001634432034867\n",
      "Epoch number: 934/10000step_number: 0/29 cost:  0.40824611925507187 accuracy:  0.9002996458730591\n",
      "Epoch number: 935/10000step_number: 0/29 cost:  0.40786305907909476 accuracy:  0.9002996458730591\n",
      "Epoch number: 936/10000step_number: 0/29 cost:  0.407487902215747 accuracy:  0.9001634432034867\n",
      "Epoch number: 937/10000step_number: 0/29 cost:  0.40711929183653733 accuracy:  0.9001634432034867\n",
      "Epoch number: 938/10000step_number: 0/29 cost:  0.4067557497810896 accuracy:  0.9000272405339145\n",
      "Epoch number: 939/10000step_number: 0/29 cost:  0.4063957902014236 accuracy:  0.9000272405339145\n",
      "Epoch number: 940/10000step_number: 0/29 cost:  0.4060380250350762 accuracy:  0.9000272405339145\n",
      "Epoch number: 941/10000step_number: 0/29 cost:  0.40568126370780194 accuracy:  0.9013892672296377\n",
      "Epoch number: 942/10000step_number: 0/29 cost:  0.4053246023198507 accuracy:  0.9016616725687824\n",
      "Epoch number: 943/10000step_number: 0/29 cost:  0.40496748961936524 accuracy:  0.9016616725687824\n",
      "Epoch number: 944/10000step_number: 0/29 cost:  0.4046097471762935 accuracy:  0.9017978752383546\n",
      "Epoch number: 945/10000step_number: 0/29 cost:  0.40425151635848827 accuracy:  0.9017978752383546\n",
      "Epoch number: 946/10000step_number: 0/29 cost:  0.40389312110863096 accuracy:  0.9017978752383546\n",
      "Epoch number: 947/10000step_number: 0/29 cost:  0.4035348803510384 accuracy:  0.9020702805774993\n",
      "Epoch number: 948/10000step_number: 0/29 cost:  0.40317694822182093 accuracy:  0.9020702805774993\n",
      "Epoch number: 949/10000step_number: 0/29 cost:  0.4028192537604305 accuracy:  0.9022064832470716\n",
      "Epoch number: 950/10000step_number: 0/29 cost:  0.4024615486884731 accuracy:  0.9022064832470716\n",
      "Epoch number: 951/10000step_number: 0/29 cost:  0.4021035116430629 accuracy:  0.9022064832470716\n",
      "Epoch number: 952/10000step_number: 0/29 cost:  0.4017448494412507 accuracy:  0.9024788885862163\n",
      "Epoch number: 953/10000step_number: 0/29 cost:  0.40138536725422885 accuracy:  0.9024788885862163\n",
      "Epoch number: 954/10000step_number: 0/29 cost:  0.40102500991183565 accuracy:  0.9024788885862163\n",
      "Epoch number: 955/10000step_number: 0/29 cost:  0.40066388796226304 accuracy:  0.9026150912557886\n",
      "Epoch number: 956/10000step_number: 0/29 cost:  0.4003023000359557 accuracy:  0.9027512939253609\n",
      "Epoch number: 957/10000step_number: 0/29 cost:  0.3999407565284454 accuracy:  0.9027512939253609\n",
      "Epoch number: 958/10000step_number: 0/29 cost:  0.3995800024567473 accuracy:  0.9027512939253609\n",
      "Epoch number: 959/10000step_number: 0/29 cost:  0.3992210299191706 accuracy:  0.9030236992645055\n",
      "Epoch number: 960/10000step_number: 0/29 cost:  0.39886506295038826 accuracy:  0.9028874965949333\n",
      "Epoch number: 961/10000step_number: 0/29 cost:  0.398513491899544 accuracy:  0.9028874965949333\n",
      "Epoch number: 962/10000step_number: 0/29 cost:  0.39816773649334836 accuracy:  0.9028874965949333\n",
      "Epoch number: 963/10000step_number: 0/29 cost:  0.39782903412840576 accuracy:  0.9030236992645055\n",
      "Epoch number: 964/10000step_number: 0/29 cost:  0.3974981853780371 accuracy:  0.9031599019340779\n",
      "Epoch number: 965/10000step_number: 0/29 cost:  0.3971753300046277 accuracy:  0.9028874965949333\n",
      "Epoch number: 966/10000step_number: 0/29 cost:  0.3968598451758893 accuracy:  0.9028874965949333\n",
      "Epoch number: 967/10000step_number: 0/29 cost:  0.3965504267045224 accuracy:  0.9030236992645055\n",
      "Epoch number: 968/10000step_number: 0/29 cost:  0.39624533919018673 accuracy:  0.9031599019340779\n",
      "Epoch number: 969/10000step_number: 0/29 cost:  0.39594274456939726 accuracy:  0.9034323072732225\n",
      "Epoch number: 970/10000step_number: 0/29 cost:  0.39564099048523815 accuracy:  0.9035685099427949\n",
      "Epoch number: 971/10000step_number: 0/29 cost:  0.395338778058682 accuracy:  0.9035685099427949\n",
      "Epoch number: 972/10000step_number: 0/29 cost:  0.3950352019665138 accuracy:  0.9042495232906564\n",
      "Epoch number: 973/10000step_number: 0/29 cost:  0.3947297081863454 accuracy:  0.9043857259602288\n",
      "Epoch number: 974/10000step_number: 0/29 cost:  0.3944220202116161 accuracy:  0.9042495232906564\n",
      "Epoch number: 975/10000step_number: 0/29 cost:  0.39411206405148586 accuracy:  0.9045219286298012\n",
      "Epoch number: 976/10000step_number: 0/29 cost:  0.3937999040767372 accuracy:  0.9047943339689458\n",
      "Epoch number: 977/10000step_number: 0/29 cost:  0.3934856926983662 accuracy:  0.9049305366385181\n",
      "Epoch number: 978/10000step_number: 0/29 cost:  0.39316963298992796 accuracy:  0.9050667393080905\n",
      "Epoch number: 979/10000step_number: 0/29 cost:  0.3928519519966847 accuracy:  0.9052029419776627\n",
      "Epoch number: 980/10000step_number: 0/29 cost:  0.3925328824046255 accuracy:  0.9052029419776627\n",
      "Epoch number: 981/10000step_number: 0/29 cost:  0.39221265053358695 accuracy:  0.9052029419776627\n",
      "Epoch number: 982/10000step_number: 0/29 cost:  0.39189146893004956 accuracy:  0.9050667393080905\n",
      "Epoch number: 983/10000step_number: 0/29 cost:  0.3915695322006992 accuracy:  0.9053391446472351\n",
      "Epoch number: 984/10000step_number: 0/29 cost:  0.3912470150897908 accuracy:  0.9054753473168075\n",
      "Epoch number: 985/10000step_number: 0/29 cost:  0.39092407206939994 accuracy:  0.9053391446472351\n",
      "Epoch number: 986/10000step_number: 0/29 cost:  0.3906008379053593 accuracy:  0.9052029419776627\n",
      "Epoch number: 987/10000step_number: 0/29 cost:  0.3902774288187588 accuracy:  0.9052029419776627\n",
      "Epoch number: 988/10000step_number: 0/29 cost:  0.38995394397843225 accuracy:  0.9052029419776627\n",
      "Epoch number: 989/10000step_number: 0/29 cost:  0.3896304671405979 accuracy:  0.9053391446472351\n",
      "Epoch number: 990/10000step_number: 0/29 cost:  0.38930706831262557 accuracy:  0.9053391446472351\n",
      "Epoch number: 991/10000step_number: 0/29 cost:  0.3889838053626542 accuracy:  0.9052029419776627\n",
      "Epoch number: 992/10000step_number: 0/29 cost:  0.3886607255279414 accuracy:  0.9053391446472351\n",
      "Epoch number: 993/10000step_number: 0/29 cost:  0.38833786679669147 accuracy:  0.9052029419776627\n",
      "Epoch number: 994/10000step_number: 0/29 cost:  0.3880152591533665 accuracy:  0.9052029419776627\n",
      "Epoch number: 995/10000step_number: 0/29 cost:  0.38769292568753533 accuracy:  0.9052029419776627\n",
      "Epoch number: 996/10000step_number: 0/29 cost:  0.38737088357268296 accuracy:  0.9052029419776627\n",
      "Epoch number: 997/10000step_number: 0/29 cost:  0.3870491449251593 accuracy:  0.9050667393080905\n",
      "Epoch number: 998/10000step_number: 0/29 cost:  0.3867277175553982 accuracy:  0.9050667393080905\n",
      "Epoch number: 999/10000step_number: 0/29 cost:  0.3864066056242373 accuracy:  0.9052029419776627\n",
      "Epoch number: 1000/10000step_number: 0/29 cost:  0.38608581021703003 accuracy:  0.9053391446472351\n",
      "Epoch number: 1001/10000step_number: 0/29 cost:  0.38576532984759854 accuracy:  0.9050667393080905\n",
      "Epoch number: 1002/10000step_number: 0/29 cost:  0.38544516090311887 accuracy:  0.9052029419776627\n",
      "Epoch number: 1003/10000step_number: 0/29 cost:  0.3851252980398858 accuracy:  0.9052029419776627\n",
      "Epoch number: 1004/10000step_number: 0/29 cost:  0.38480573453871486 accuracy:  0.9049305366385181\n",
      "Epoch number: 1005/10000step_number: 0/29 cost:  0.38448646262751895 accuracy:  0.9047943339689458\n",
      "Epoch number: 1006/10000step_number: 0/29 cost:  0.38416747377745913 accuracy:  0.9058839553255243\n",
      "Epoch number: 1007/10000step_number: 0/29 cost:  0.38384875897797227 accuracy:  0.9058839553255243\n",
      "Epoch number: 1008/10000step_number: 0/29 cost:  0.3835303089950076 accuracy:  0.9062925633342414\n",
      "Epoch number: 1009/10000step_number: 0/29 cost:  0.3832121146159048 accuracy:  0.9064287660038137\n",
      "Epoch number: 1010/10000step_number: 0/29 cost:  0.38289416688351424 accuracy:  0.9064287660038137\n",
      "Epoch number: 1011/10000step_number: 0/29 cost:  0.3825764573213909 accuracy:  0.906564968673386\n",
      "Epoch number: 1012/10000step_number: 0/29 cost:  0.3822589781510925 accuracy:  0.9067011713429584\n",
      "Epoch number: 1013/10000step_number: 0/29 cost:  0.38194172250181685 accuracy:  0.906564968673386\n",
      "Epoch number: 1014/10000step_number: 0/29 cost:  0.3816246846117122 accuracy:  0.9067011713429584\n",
      "Epoch number: 1015/10000step_number: 0/29 cost:  0.3813078600192261 accuracy:  0.9068373740125306\n",
      "Epoch number: 1016/10000step_number: 0/29 cost:  0.38099124574176535 accuracy:  0.9068373740125306\n",
      "Epoch number: 1017/10000step_number: 0/29 cost:  0.3806748404377872 accuracy:  0.9068373740125306\n",
      "Epoch number: 1018/10000step_number: 0/29 cost:  0.38035864454728757 accuracy:  0.9068373740125306\n",
      "Epoch number: 1019/10000step_number: 0/29 cost:  0.38004266040481555 accuracy:  0.906973576682103\n",
      "Epoch number: 1020/10000step_number: 0/29 cost:  0.3797268923191066 accuracy:  0.906973576682103\n",
      "Epoch number: 1021/10000step_number: 0/29 cost:  0.3794113466152097 accuracy:  0.906973576682103\n",
      "Epoch number: 1022/10000step_number: 0/29 cost:  0.37909603163993055 accuracy:  0.906973576682103\n",
      "Epoch number: 1023/10000step_number: 0/29 cost:  0.37878095774126214 accuracy:  0.9076545900299646\n",
      "Epoch number: 1024/10000step_number: 0/29 cost:  0.3784661372483766 accuracy:  0.9075183873603923\n",
      "Epoch number: 1025/10000step_number: 0/29 cost:  0.3781515845000379 accuracy:  0.9076545900299646\n",
      "Epoch number: 1026/10000step_number: 0/29 cost:  0.3778373159902064 accuracy:  0.9076545900299646\n",
      "Epoch number: 1027/10000step_number: 0/29 cost:  0.3775233507053192 accuracy:  0.9076545900299646\n",
      "Epoch number: 1028/10000step_number: 0/29 cost:  0.3772097106900719 accuracy:  0.9076545900299646\n",
      "Epoch number: 1029/10000step_number: 0/29 cost:  0.3768964217585512 accuracy:  0.9077907926995369\n",
      "Epoch number: 1030/10000step_number: 0/29 cost:  0.37658351403772067 accuracy:  0.9079269953691093\n",
      "Epoch number: 1031/10000step_number: 0/29 cost:  0.37627102173598725 accuracy:  0.9080631980386815\n",
      "Epoch number: 1032/10000step_number: 0/29 cost:  0.3759589813807994 accuracy:  0.9080631980386815\n",
      "Epoch number: 1033/10000step_number: 0/29 cost:  0.3756474281325029 accuracy:  0.9081994007082539\n",
      "Epoch number: 1034/10000step_number: 0/29 cost:  0.3753363908218911 accuracy:  0.9081994007082539\n",
      "Epoch number: 1035/10000step_number: 0/29 cost:  0.37502588748134785 accuracy:  0.9087442113865432\n",
      "Epoch number: 1036/10000step_number: 0/29 cost:  0.3747159232194983 accuracy:  0.9084718060473985\n",
      "Epoch number: 1037/10000step_number: 0/29 cost:  0.37440649101874984 accuracy:  0.9083356033778262\n",
      "Epoch number: 1038/10000step_number: 0/29 cost:  0.3740975745228212 accuracy:  0.9083356033778262\n",
      "Epoch number: 1039/10000step_number: 0/29 cost:  0.3737891513186414 accuracy:  0.9086080087169709\n",
      "Epoch number: 1040/10000step_number: 0/29 cost:  0.37348119562025506 accuracy:  0.9084718060473985\n",
      "Epoch number: 1041/10000step_number: 0/29 cost:  0.3731736799303732 accuracy:  0.9088804140561155\n",
      "Epoch number: 1042/10000step_number: 0/29 cost:  0.3728665757164777 accuracy:  0.9090166167256878\n",
      "Epoch number: 1043/10000step_number: 0/29 cost:  0.37255985333228364 accuracy:  0.9088804140561155\n",
      "Epoch number: 1044/10000step_number: 0/29 cost:  0.37225348143534864 accuracy:  0.9088804140561155\n",
      "Epoch number: 1045/10000step_number: 0/29 cost:  0.3719474260925231 accuracy:  0.9088804140561155\n",
      "Epoch number: 1046/10000step_number: 0/29 cost:  0.37164164969095137 accuracy:  0.9090166167256878\n",
      "Epoch number: 1047/10000step_number: 0/29 cost:  0.37133610971249165 accuracy:  0.9090166167256878\n",
      "Epoch number: 1048/10000step_number: 0/29 cost:  0.3710307573879779 accuracy:  0.9094252247344048\n",
      "Epoch number: 1049/10000step_number: 0/29 cost:  0.370725536221288 accuracy:  0.9094252247344048\n",
      "Epoch number: 1050/10000step_number: 0/29 cost:  0.37042038035856173 accuracy:  0.9092890220648324\n",
      "Epoch number: 1051/10000step_number: 0/29 cost:  0.3701152127734478 accuracy:  0.9091528193952602\n",
      "Epoch number: 1052/10000step_number: 0/29 cost:  0.36980994324560984 accuracy:  0.9091528193952602\n",
      "Epoch number: 1053/10000step_number: 0/29 cost:  0.36950446613095256 accuracy:  0.9091528193952602\n",
      "Epoch number: 1054/10000step_number: 0/29 cost:  0.369198657965513 accuracy:  0.9091528193952602\n",
      "Epoch number: 1055/10000step_number: 0/29 cost:  0.36889237502057143 accuracy:  0.9091528193952602\n",
      "Epoch number: 1056/10000step_number: 0/29 cost:  0.3685854510430684 accuracy:  0.9091528193952602\n",
      "Epoch number: 1057/10000step_number: 0/29 cost:  0.3682776955713369 accuracy:  0.9092890220648324\n",
      "Epoch number: 1058/10000step_number: 0/29 cost:  0.3679688933797377 accuracy:  0.9092890220648324\n",
      "Epoch number: 1059/10000step_number: 0/29 cost:  0.3676588056848698 accuracy:  0.9092890220648324\n",
      "Epoch number: 1060/10000step_number: 0/29 cost:  0.3673471735641011 accuracy:  0.9092890220648324\n",
      "Epoch number: 1061/10000step_number: 0/29 cost:  0.3670337233853915 accuracy:  0.9091528193952602\n",
      "Epoch number: 1062/10000step_number: 0/29 cost:  0.3667181729633595 accuracy:  0.9091528193952602\n",
      "Epoch number: 1063/10000step_number: 0/29 cost:  0.3664002365919621 accuracy:  0.9091528193952602\n",
      "Epoch number: 1064/10000step_number: 0/29 cost:  0.36607962970504754 accuracy:  0.9091528193952602\n",
      "Epoch number: 1065/10000step_number: 0/29 cost:  0.3657560832460695 accuracy:  0.9090166167256878\n",
      "Epoch number: 1066/10000step_number: 0/29 cost:  0.3654293928902789 accuracy:  0.9090166167256878\n",
      "Epoch number: 1067/10000step_number: 0/29 cost:  0.3650995343349835 accuracy:  0.9090166167256878\n",
      "Epoch number: 1068/10000step_number: 0/29 cost:  0.36476684702037754 accuracy:  0.9092890220648324\n",
      "Epoch number: 1069/10000step_number: 0/29 cost:  0.3644322125432414 accuracy:  0.9092890220648324\n",
      "Epoch number: 1070/10000step_number: 0/29 cost:  0.3640970588228813 accuracy:  0.9094252247344048\n",
      "Epoch number: 1071/10000step_number: 0/29 cost:  0.3637630427151196 accuracy:  0.9094252247344048\n",
      "Epoch number: 1072/10000step_number: 0/29 cost:  0.36343155656523063 accuracy:  0.9094252247344048\n",
      "Epoch number: 1073/10000step_number: 0/29 cost:  0.36310342822571706 accuracy:  0.9096976300735494\n",
      "Epoch number: 1074/10000step_number: 0/29 cost:  0.3627789379388911 accuracy:  0.9099700354126941\n",
      "Epoch number: 1075/10000step_number: 0/29 cost:  0.3624579963132163 accuracy:  0.9102424407518387\n",
      "Epoch number: 1076/10000step_number: 0/29 cost:  0.3621403333294246 accuracy:  0.9103786434214111\n",
      "Epoch number: 1077/10000step_number: 0/29 cost:  0.3618256274920191 accuracy:  0.9105148460909834\n",
      "Epoch number: 1078/10000step_number: 0/29 cost:  0.3615135665400169 accuracy:  0.9109234540997003\n",
      "Epoch number: 1079/10000step_number: 0/29 cost:  0.36120386902228224 accuracy:  0.9109234540997003\n",
      "Epoch number: 1080/10000step_number: 0/29 cost:  0.36089629205780926 accuracy:  0.9110596567692727\n",
      "Epoch number: 1081/10000step_number: 0/29 cost:  0.36059063144231235 accuracy:  0.9110596567692727\n",
      "Epoch number: 1082/10000step_number: 0/29 cost:  0.3602867157794057 accuracy:  0.9110596567692727\n",
      "Epoch number: 1083/10000step_number: 0/29 cost:  0.35998439663960047 accuracy:  0.9110596567692727\n",
      "Epoch number: 1084/10000step_number: 0/29 cost:  0.35968353644651097 accuracy:  0.911195859438845\n",
      "Epoch number: 1085/10000step_number: 0/29 cost:  0.35938399424604883 accuracy:  0.9113320621084173\n",
      "Epoch number: 1086/10000step_number: 0/29 cost:  0.35908561109869075 accuracy:  0.9113320621084173\n",
      "Epoch number: 1087/10000step_number: 0/29 cost:  0.35878819754992597 accuracy:  0.9113320621084173\n",
      "Epoch number: 1088/10000step_number: 0/29 cost:  0.358491527619115 accuracy:  0.9114682647779897\n",
      "Epoch number: 1089/10000step_number: 0/29 cost:  0.3581953429928473 accuracy:  0.9117406701171343\n",
      "Epoch number: 1090/10000step_number: 0/29 cost:  0.3578993694896448 accuracy:  0.9117406701171343\n",
      "Epoch number: 1091/10000step_number: 0/29 cost:  0.3576033421793246 accuracy:  0.9117406701171343\n",
      "Epoch number: 1092/10000step_number: 0/29 cost:  0.35730703172366973 accuracy:  0.9118768727867066\n",
      "Epoch number: 1093/10000step_number: 0/29 cost:  0.35701026268897657 accuracy:  0.9122854807954236\n",
      "Epoch number: 1094/10000step_number: 0/29 cost:  0.3567129193257741 accuracy:  0.9122854807954236\n",
      "Epoch number: 1095/10000step_number: 0/29 cost:  0.356414939243418 accuracy:  0.9122854807954236\n",
      "Epoch number: 1096/10000step_number: 0/29 cost:  0.356116300309639 accuracy:  0.9122854807954236\n",
      "Epoch number: 1097/10000step_number: 0/29 cost:  0.3558170056680136 accuracy:  0.9128302914737129\n",
      "Epoch number: 1098/10000step_number: 0/29 cost:  0.35551707100969315 accuracy:  0.9128302914737129\n",
      "Epoch number: 1099/10000step_number: 0/29 cost:  0.35521651507454005 accuracy:  0.9129664941432852\n",
      "Epoch number: 1100/10000step_number: 0/29 cost:  0.3549153538791676 accuracy:  0.9129664941432852\n",
      "Epoch number: 1101/10000step_number: 0/29 cost:  0.3546135974190652 accuracy:  0.9129664941432852\n",
      "Epoch number: 1102/10000step_number: 0/29 cost:  0.35431124853415996 accuracy:  0.9129664941432852\n",
      "Epoch number: 1103/10000step_number: 0/29 cost:  0.3540083026552219 accuracy:  0.9129664941432852\n",
      "Epoch number: 1104/10000step_number: 0/29 cost:  0.3537047484744163 accuracy:  0.9131026968128575\n",
      "Epoch number: 1105/10000step_number: 0/29 cost:  0.35340056860979396 accuracy:  0.9132388994824299\n",
      "Epoch number: 1106/10000step_number: 0/29 cost:  0.35309574065182053 accuracy:  0.9132388994824299\n",
      "Epoch number: 1107/10000step_number: 0/29 cost:  0.3527902378625865 accuracy:  0.9131026968128575\n",
      "Epoch number: 1108/10000step_number: 0/29 cost:  0.35248403010068696 accuracy:  0.9131026968128575\n",
      "Epoch number: 1109/10000step_number: 0/29 cost:  0.3521770843044629 accuracy:  0.9132388994824299\n",
      "Epoch number: 1110/10000step_number: 0/29 cost:  0.35186936519823014 accuracy:  0.9139199128302915\n",
      "Epoch number: 1111/10000step_number: 0/29 cost:  0.3515608355461187 accuracy:  0.9137837101607191\n",
      "Epoch number: 1112/10000step_number: 0/29 cost:  0.35125145667405827 accuracy:  0.9139199128302915\n",
      "Epoch number: 1113/10000step_number: 0/29 cost:  0.35094118854518525 accuracy:  0.9139199128302915\n",
      "Epoch number: 1114/10000step_number: 0/29 cost:  0.3506299901575593 accuracy:  0.9140561154998638\n",
      "Epoch number: 1115/10000step_number: 0/29 cost:  0.3503178194945471 accuracy:  0.9148733315172978\n",
      "Epoch number: 1116/10000step_number: 0/29 cost:  0.35000463384989255 accuracy:  0.9151457368564424\n",
      "Epoch number: 1117/10000step_number: 0/29 cost:  0.34969038969172 accuracy:  0.9152819395260147\n",
      "Epoch number: 1118/10000step_number: 0/29 cost:  0.3493750429510195 accuracy:  0.9152819395260147\n",
      "Epoch number: 1119/10000step_number: 0/29 cost:  0.34905854882094245 accuracy:  0.9152819395260147\n",
      "Epoch number: 1120/10000step_number: 0/29 cost:  0.34874086202990123 accuracy:  0.9151457368564424\n",
      "Epoch number: 1121/10000step_number: 0/29 cost:  0.34842193658211057 accuracy:  0.91500953418687\n",
      "Epoch number: 1122/10000step_number: 0/29 cost:  0.34810172602340833 accuracy:  0.9152819395260147\n",
      "Epoch number: 1123/10000step_number: 0/29 cost:  0.3477801831141795 accuracy:  0.9152819395260147\n",
      "Epoch number: 1124/10000step_number: 0/29 cost:  0.3474572600840641 accuracy:  0.9152819395260147\n",
      "Epoch number: 1125/10000step_number: 0/29 cost:  0.34713290821371584 accuracy:  0.9152819395260147\n",
      "Epoch number: 1126/10000step_number: 0/29 cost:  0.3468070780638275 accuracy:  0.9151457368564424\n",
      "Epoch number: 1127/10000step_number: 0/29 cost:  0.3464797189281078 accuracy:  0.9151457368564424\n",
      "Epoch number: 1128/10000step_number: 0/29 cost:  0.3461507790143329 accuracy:  0.9152819395260147\n",
      "Epoch number: 1129/10000step_number: 0/29 cost:  0.3458202047195912 accuracy:  0.9155543448651594\n",
      "Epoch number: 1130/10000step_number: 0/29 cost:  0.34548794073969474 accuracy:  0.9155543448651594\n",
      "Epoch number: 1131/10000step_number: 0/29 cost:  0.3451539291114708 accuracy:  0.9156905475347317\n",
      "Epoch number: 1132/10000step_number: 0/29 cost:  0.34481810923422723 accuracy:  0.915418142195587\n",
      "Epoch number: 1133/10000step_number: 0/29 cost:  0.34448041662125445 accuracy:  0.9156905475347317\n",
      "Epoch number: 1134/10000step_number: 0/29 cost:  0.3441407828294348 accuracy:  0.9160991555434487\n",
      "Epoch number: 1135/10000step_number: 0/29 cost:  0.34379913385079264 accuracy:  0.9160991555434487\n",
      "Epoch number: 1136/10000step_number: 0/29 cost:  0.3434553899452623 accuracy:  0.9162353582130209\n",
      "Epoch number: 1137/10000step_number: 0/29 cost:  0.34310946354745486 accuracy:  0.9162353582130209\n",
      "Epoch number: 1138/10000step_number: 0/29 cost:  0.3427612589347758 accuracy:  0.9162353582130209\n",
      "Epoch number: 1139/10000step_number: 0/29 cost:  0.3424106693445676 accuracy:  0.9162353582130209\n",
      "Epoch number: 1140/10000step_number: 0/29 cost:  0.34205757618299776 accuracy:  0.9162353582130209\n",
      "Epoch number: 1141/10000step_number: 0/29 cost:  0.3417018445884216 accuracy:  0.9160991555434487\n",
      "Epoch number: 1142/10000step_number: 0/29 cost:  0.34134332131623374 accuracy:  0.915826750204304\n",
      "Epoch number: 1143/10000step_number: 0/29 cost:  0.3409818270060067 accuracy:  0.915826750204304\n",
      "Epoch number: 1144/10000step_number: 0/29 cost:  0.3406171507623096 accuracy:  0.9156905475347317\n",
      "Epoch number: 1145/10000step_number: 0/29 cost:  0.34024903572277765 accuracy:  0.915826750204304\n",
      "Epoch number: 1146/10000step_number: 0/29 cost:  0.3398771668505116 accuracy:  0.915826750204304\n",
      "Epoch number: 1147/10000step_number: 0/29 cost:  0.3395011445178636 accuracy:  0.915826750204304\n",
      "Epoch number: 1148/10000step_number: 0/29 cost:  0.33912046104540694 accuracy:  0.9160991555434487\n",
      "Epoch number: 1149/10000step_number: 0/29 cost:  0.3387344545950933 accuracy:  0.9160991555434487\n",
      "Epoch number: 1150/10000step_number: 0/29 cost:  0.3383422642822424 accuracy:  0.9162353582130209\n",
      "Epoch number: 1151/10000step_number: 0/29 cost:  0.3379427327383851 accuracy:  0.9162353582130209\n",
      "Epoch number: 1152/10000step_number: 0/29 cost:  0.33753426740348197 accuracy:  0.9166439662217379\n",
      "Epoch number: 1153/10000step_number: 0/29 cost:  0.3371145118176562 accuracy:  0.9169163715608826\n",
      "Epoch number: 1154/10000step_number: 0/29 cost:  0.33667976683400225 accuracy:  0.9169163715608826\n",
      "Epoch number: 1155/10000step_number: 0/29 cost:  0.3362238117473819 accuracy:  0.9169163715608826\n",
      "Epoch number: 1156/10000step_number: 0/29 cost:  0.33573618092560525 accuracy:  0.9170525742304549\n",
      "Epoch number: 1157/10000step_number: 0/29 cost:  0.3352008037205718 accuracy:  0.9173249795695996\n",
      "Epoch number: 1158/10000step_number: 0/29 cost:  0.33460198925095147 accuracy:  0.9177335875783166\n",
      "Epoch number: 1159/10000step_number: 0/29 cost:  0.3339506136825413 accuracy:  0.9180059929174612\n",
      "Epoch number: 1160/10000step_number: 0/29 cost:  0.33331243958943285 accuracy:  0.9181421955870335\n",
      "Epoch number: 1161/10000step_number: 0/29 cost:  0.33275887916455 accuracy:  0.9181421955870335\n",
      "Epoch number: 1162/10000step_number: 0/29 cost:  0.3322935130923732 accuracy:  0.9181421955870335\n",
      "Epoch number: 1163/10000step_number: 0/29 cost:  0.33187641216544755 accuracy:  0.9180059929174612\n",
      "Epoch number: 1164/10000step_number: 0/29 cost:  0.33148246985661345 accuracy:  0.9181421955870335\n",
      "Epoch number: 1165/10000step_number: 0/29 cost:  0.3311027317895927 accuracy:  0.9184146009261781\n",
      "Epoch number: 1166/10000step_number: 0/29 cost:  0.33073158110646983 accuracy:  0.9185508035957505\n",
      "Epoch number: 1167/10000step_number: 0/29 cost:  0.33035690664904593 accuracy:  0.9186870062653228\n",
      "Epoch number: 1168/10000step_number: 0/29 cost:  0.32997975558961934 accuracy:  0.9186870062653228\n",
      "Epoch number: 1169/10000step_number: 0/29 cost:  0.32960444443142756 accuracy:  0.9186870062653228\n",
      "Epoch number: 1170/10000step_number: 0/29 cost:  0.32923093528346087 accuracy:  0.9186870062653228\n",
      "Epoch number: 1171/10000step_number: 0/29 cost:  0.3288535658427903 accuracy:  0.9186870062653228\n",
      "Epoch number: 1172/10000step_number: 0/29 cost:  0.3284867212595209 accuracy:  0.9185508035957505\n",
      "Epoch number: 1173/10000step_number: 0/29 cost:  0.32809567673201273 accuracy:  0.9184146009261781\n",
      "Epoch number: 1174/10000step_number: 0/29 cost:  0.3277605101160283 accuracy:  0.9184146009261781\n",
      "Epoch number: 1175/10000step_number: 0/29 cost:  0.3273435960354278 accuracy:  0.9184146009261781\n",
      "Epoch number: 1176/10000step_number: 0/29 cost:  0.32704057842202133 accuracy:  0.9184146009261781\n",
      "Epoch number: 1177/10000step_number: 0/29 cost:  0.326608668698566 accuracy:  0.9181421955870335\n",
      "Epoch number: 1178/10000step_number: 0/29 cost:  0.32631341980428524 accuracy:  0.9180059929174612\n",
      "Epoch number: 1179/10000step_number: 0/29 cost:  0.32589079983281716 accuracy:  0.9180059929174612\n",
      "Epoch number: 1180/10000step_number: 0/29 cost:  0.3255888156357182 accuracy:  0.9180059929174612\n",
      "Epoch number: 1181/10000step_number: 0/29 cost:  0.32518671275558775 accuracy:  0.9180059929174612\n",
      "Epoch number: 1182/10000step_number: 0/29 cost:  0.32487744879910124 accuracy:  0.9180059929174612\n",
      "Epoch number: 1183/10000step_number: 0/29 cost:  0.32449588466356233 accuracy:  0.9180059929174612\n",
      "Epoch number: 1184/10000step_number: 0/29 cost:  0.32418072899468897 accuracy:  0.9178697902478888\n",
      "Epoch number: 1185/10000step_number: 0/29 cost:  0.3238168311334067 accuracy:  0.9180059929174612\n",
      "Epoch number: 1186/10000step_number: 0/29 cost:  0.3234977005642984 accuracy:  0.9180059929174612\n",
      "Epoch number: 1187/10000step_number: 0/29 cost:  0.3231473906279044 accuracy:  0.9181421955870335\n",
      "Epoch number: 1188/10000step_number: 0/29 cost:  0.32282565130026686 accuracy:  0.9181421955870335\n",
      "Epoch number: 1189/10000step_number: 0/29 cost:  0.32248472948474527 accuracy:  0.9181421955870335\n",
      "Epoch number: 1190/10000step_number: 0/29 cost:  0.3221609286037348 accuracy:  0.9181421955870335\n",
      "Epoch number: 1191/10000step_number: 0/29 cost:  0.32182530406969684 accuracy:  0.9180059929174612\n",
      "Epoch number: 1192/10000step_number: 0/29 cost:  0.32149888598340276 accuracy:  0.9180059929174612\n",
      "Epoch number: 1193/10000step_number: 0/29 cost:  0.3211644661488524 accuracy:  0.9181421955870335\n",
      "Epoch number: 1194/10000step_number: 0/29 cost:  0.3208335398736679 accuracy:  0.9182783982566058\n",
      "Epoch number: 1195/10000step_number: 0/29 cost:  0.3204957022137227 accuracy:  0.9182783982566058\n",
      "Epoch number: 1196/10000step_number: 0/29 cost:  0.32015653545260647 accuracy:  0.9184146009261781\n",
      "Epoch number: 1197/10000step_number: 0/29 cost:  0.31980911619094105 accuracy:  0.9184146009261781\n",
      "Epoch number: 1198/10000step_number: 0/29 cost:  0.319455051872845 accuracy:  0.9184146009261781\n",
      "Epoch number: 1199/10000step_number: 0/29 cost:  0.3190885303240953 accuracy:  0.9188232089348951\n",
      "Epoch number: 1200/10000step_number: 0/29 cost:  0.3187077960042418 accuracy:  0.9189594116044675\n",
      "Epoch number: 1201/10000step_number: 0/29 cost:  0.3183061253087176 accuracy:  0.9190956142740397\n",
      "Epoch number: 1202/10000step_number: 0/29 cost:  0.317877983743833 accuracy:  0.9192318169436121\n",
      "Epoch number: 1203/10000step_number: 0/29 cost:  0.3174140152702369 accuracy:  0.9190956142740397\n",
      "Epoch number: 1204/10000step_number: 0/29 cost:  0.3169050959837028 accuracy:  0.9195042222827567\n",
      "Epoch number: 1205/10000step_number: 0/29 cost:  0.3163419160757222 accuracy:  0.9196404249523291\n",
      "Epoch number: 1206/10000step_number: 0/29 cost:  0.3157228849332605 accuracy:  0.9195042222827567\n",
      "Epoch number: 1207/10000step_number: 0/29 cost:  0.31506183012640554 accuracy:  0.9201852356306184\n",
      "Epoch number: 1208/10000step_number: 0/29 cost:  0.31439257903334666 accuracy:  0.9203214383001906\n",
      "Epoch number: 1209/10000step_number: 0/29 cost:  0.3137561319506966 accuracy:  0.9201852356306184\n",
      "Epoch number: 1210/10000step_number: 0/29 cost:  0.31318691452785535 accuracy:  0.920049032961046\n",
      "Epoch number: 1211/10000step_number: 0/29 cost:  0.31270091748157597 accuracy:  0.920049032961046\n",
      "Epoch number: 1212/10000step_number: 0/29 cost:  0.31228948008521573 accuracy:  0.9199128302914737\n",
      "Epoch number: 1213/10000step_number: 0/29 cost:  0.3119344071167106 accuracy:  0.9197766276219014\n",
      "Epoch number: 1214/10000step_number: 0/29 cost:  0.3116219707442285 accuracy:  0.9199128302914737\n",
      "Epoch number: 1215/10000step_number: 0/29 cost:  0.31134223716694387 accuracy:  0.9199128302914737\n",
      "Epoch number: 1216/10000step_number: 0/29 cost:  0.31108692355398865 accuracy:  0.9199128302914737\n",
      "Epoch number: 1217/10000step_number: 0/29 cost:  0.31084959457151873 accuracy:  0.9199128302914737\n",
      "Epoch number: 1218/10000step_number: 0/29 cost:  0.3106257688864655 accuracy:  0.9199128302914737\n",
      "Epoch number: 1219/10000step_number: 0/29 cost:  0.31041216951065465 accuracy:  0.9199128302914737\n",
      "Epoch number: 1220/10000step_number: 0/29 cost:  0.310206296040156 accuracy:  0.9199128302914737\n",
      "Epoch number: 1221/10000step_number: 0/29 cost:  0.31000621149544555 accuracy:  0.920049032961046\n",
      "Epoch number: 1222/10000step_number: 0/29 cost:  0.3098104642257352 accuracy:  0.920049032961046\n",
      "Epoch number: 1223/10000step_number: 0/29 cost:  0.3096179230223149 accuracy:  0.920049032961046\n",
      "Epoch number: 1224/10000step_number: 0/29 cost:  0.3094277031340542 accuracy:  0.9201852356306184\n",
      "Epoch number: 1225/10000step_number: 0/29 cost:  0.3092391002647265 accuracy:  0.9201852356306184\n",
      "Epoch number: 1226/10000step_number: 0/29 cost:  0.3090515697158785 accuracy:  0.9201852356306184\n",
      "Epoch number: 1227/10000step_number: 0/29 cost:  0.3088646858648505 accuracy:  0.9199128302914737\n",
      "Epoch number: 1228/10000step_number: 0/29 cost:  0.3086781252462896 accuracy:  0.9199128302914737\n",
      "Epoch number: 1229/10000step_number: 0/29 cost:  0.3084916429514246 accuracy:  0.9199128302914737\n",
      "Epoch number: 1230/10000step_number: 0/29 cost:  0.3083050622262546 accuracy:  0.920049032961046\n",
      "Epoch number: 1231/10000step_number: 0/29 cost:  0.30811825845938096 accuracy:  0.9201852356306184\n",
      "Epoch number: 1232/10000step_number: 0/29 cost:  0.3079311507511591 accuracy:  0.9203214383001906\n",
      "Epoch number: 1233/10000step_number: 0/29 cost:  0.30774369152169534 accuracy:  0.9203214383001906\n",
      "Epoch number: 1234/10000step_number: 0/29 cost:  0.3075558611439738 accuracy:  0.9203214383001906\n",
      "Epoch number: 1235/10000step_number: 0/29 cost:  0.3073676619351895 accuracy:  0.920457640969763\n",
      "Epoch number: 1236/10000step_number: 0/29 cost:  0.30717911532135384 accuracy:  0.9207300463089076\n",
      "Epoch number: 1237/10000step_number: 0/29 cost:  0.3069902588593841 accuracy:  0.9207300463089076\n",
      "Epoch number: 1238/10000step_number: 0/29 cost:  0.3068011449770795 accuracy:  0.9207300463089076\n",
      "Epoch number: 1239/10000step_number: 0/29 cost:  0.3066118391911258 accuracy:  0.9207300463089076\n",
      "Epoch number: 1240/10000step_number: 0/29 cost:  0.3064224182642728 accuracy:  0.9207300463089076\n",
      "Epoch number: 1241/10000step_number: 0/29 cost:  0.30623296575962694 accuracy:  0.9211386543176246\n",
      "Epoch number: 1242/10000step_number: 0/29 cost:  0.3060435624457761 accuracy:  0.9218196676654863\n",
      "Epoch number: 1243/10000step_number: 0/29 cost:  0.3058542639883108 accuracy:  0.9222282756742032\n",
      "Epoch number: 1244/10000step_number: 0/29 cost:  0.3056650522573356 accuracy:  0.9223644783437756\n",
      "Epoch number: 1245/10000step_number: 0/29 cost:  0.30547573617910145 accuracy:  0.9225006810133478\n",
      "Epoch number: 1246/10000step_number: 0/29 cost:  0.3052857835308123 accuracy:  0.9223644783437756\n",
      "Epoch number: 1247/10000step_number: 0/29 cost:  0.3050941578214102 accuracy:  0.9222282756742032\n",
      "Epoch number: 1248/10000step_number: 0/29 cost:  0.3048995675958345 accuracy:  0.9222282756742032\n",
      "Epoch number: 1249/10000step_number: 0/29 cost:  0.30470197382139225 accuracy:  0.9223644783437756\n",
      "Epoch number: 1250/10000step_number: 0/29 cost:  0.304504837480794 accuracy:  0.9223644783437756\n",
      "Epoch number: 1251/10000step_number: 0/29 cost:  0.30431295072136305 accuracy:  0.9225006810133478\n",
      "Epoch number: 1252/10000step_number: 0/29 cost:  0.304126284903657 accuracy:  0.9225006810133478\n",
      "Epoch number: 1253/10000step_number: 0/29 cost:  0.30394100972648985 accuracy:  0.9225006810133478\n",
      "Epoch number: 1254/10000step_number: 0/29 cost:  0.3037544963799581 accuracy:  0.9226368836829202\n",
      "Epoch number: 1255/10000step_number: 0/29 cost:  0.30356614852185776 accuracy:  0.9229092890220648\n",
      "Epoch number: 1256/10000step_number: 0/29 cost:  0.3033760381794827 accuracy:  0.9229092890220648\n",
      "Epoch number: 1257/10000step_number: 0/29 cost:  0.30318430937472574 accuracy:  0.9229092890220648\n",
      "Epoch number: 1258/10000step_number: 0/29 cost:  0.30299118616623083 accuracy:  0.9229092890220648\n",
      "Epoch number: 1259/10000step_number: 0/29 cost:  0.30279696769463044 accuracy:  0.9230454916916372\n",
      "Epoch number: 1260/10000step_number: 0/29 cost:  0.3026019388433714 accuracy:  0.9231816943612094\n",
      "Epoch number: 1261/10000step_number: 0/29 cost:  0.3024063262400034 accuracy:  0.9242713157177881\n",
      "Epoch number: 1262/10000step_number: 0/29 cost:  0.30221031551936844 accuracy:  0.9242713157177881\n",
      "Epoch number: 1263/10000step_number: 0/29 cost:  0.3020140658018327 accuracy:  0.9244075183873603\n",
      "Epoch number: 1264/10000step_number: 0/29 cost:  0.3018177107433431 accuracy:  0.9244075183873603\n",
      "Epoch number: 1265/10000step_number: 0/29 cost:  0.30162135802800066 accuracy:  0.9244075183873603\n",
      "Epoch number: 1266/10000step_number: 0/29 cost:  0.3014250939808525 accuracy:  0.9244075183873603\n",
      "Epoch number: 1267/10000step_number: 0/29 cost:  0.3012289872328587 accuracy:  0.9245437210569327\n",
      "Epoch number: 1268/10000step_number: 0/29 cost:  0.30103309124811073 accuracy:  0.9245437210569327\n",
      "Epoch number: 1269/10000step_number: 0/29 cost:  0.3008374453008122 accuracy:  0.9245437210569327\n",
      "Epoch number: 1270/10000step_number: 0/29 cost:  0.30064207603491466 accuracy:  0.9246799237265051\n",
      "Epoch number: 1271/10000step_number: 0/29 cost:  0.30044699811038156 accuracy:  0.9245437210569327\n",
      "Epoch number: 1272/10000step_number: 0/29 cost:  0.30025221485583997 accuracy:  0.9252247344047944\n",
      "Epoch number: 1273/10000step_number: 0/29 cost:  0.3000577179495526 accuracy:  0.9252247344047944\n",
      "Epoch number: 1274/10000step_number: 0/29 cost:  0.2998634871238978 accuracy:  0.9252247344047944\n",
      "Epoch number: 1275/10000step_number: 0/29 cost:  0.2996694889384361 accuracy:  0.9252247344047944\n",
      "Epoch number: 1276/10000step_number: 0/29 cost:  0.29947567528849767 accuracy:  0.9252247344047944\n",
      "Epoch number: 1277/10000step_number: 0/29 cost:  0.2992819807213968 accuracy:  0.9252247344047944\n",
      "Epoch number: 1278/10000step_number: 0/29 cost:  0.2990883190026873 accuracy:  0.9252247344047944\n",
      "Epoch number: 1279/10000step_number: 0/29 cost:  0.2988945778690196 accuracy:  0.9253609370743666\n",
      "Epoch number: 1280/10000step_number: 0/29 cost:  0.29870061198202497 accuracy:  0.9253609370743666\n",
      "Epoch number: 1281/10000step_number: 0/29 cost:  0.2985062325625214 accuracy:  0.925497139743939\n",
      "Epoch number: 1282/10000step_number: 0/29 cost:  0.29831119283812985 accuracy:  0.925497139743939\n",
      "Epoch number: 1283/10000step_number: 0/29 cost:  0.29811516649379816 accuracy:  0.9256333424135113\n",
      "Epoch number: 1284/10000step_number: 0/29 cost:  0.2979177160057206 accuracy:  0.925497139743939\n",
      "Epoch number: 1285/10000step_number: 0/29 cost:  0.29771824434088584 accuracy:  0.9256333424135113\n",
      "Epoch number: 1286/10000step_number: 0/29 cost:  0.2975159204148967 accuracy:  0.9257695450830836\n",
      "Epoch number: 1287/10000step_number: 0/29 cost:  0.2973095604024754 accuracy:  0.9280849904658132\n",
      "Epoch number: 1288/10000step_number: 0/29 cost:  0.29709743481642237 accuracy:  0.9282211931353854\n",
      "Epoch number: 1289/10000step_number: 0/29 cost:  0.29687694649403207 accuracy:  0.9283573958049578\n",
      "Epoch number: 1290/10000step_number: 0/29 cost:  0.2966440838088628 accuracy:  0.9284935984745301\n",
      "Epoch number: 1291/10000step_number: 0/29 cost:  0.2963924867667174 accuracy:  0.9284935984745301\n",
      "Epoch number: 1292/10000step_number: 0/29 cost:  0.29611190118035857 accuracy:  0.9289022064832471\n",
      "Epoch number: 1293/10000step_number: 0/29 cost:  0.2957859337402794 accuracy:  0.9289022064832471\n",
      "Epoch number: 1294/10000step_number: 0/29 cost:  0.29539020984954867 accuracy:  0.9290384091528194\n",
      "Epoch number: 1295/10000step_number: 0/29 cost:  0.2948962856658313 accuracy:  0.9291746118223917\n",
      "Epoch number: 1296/10000step_number: 0/29 cost:  0.29429254871711497 accuracy:  0.9294470171615363\n",
      "Epoch number: 1297/10000step_number: 0/29 cost:  0.29362135675633205 accuracy:  0.9291746118223917\n",
      "Epoch number: 1298/10000step_number: 0/29 cost:  0.29299299284076497 accuracy:  0.9284935984745301\n",
      "Epoch number: 1299/10000step_number: 0/29 cost:  0.292519671054668 accuracy:  0.9286298011441024\n",
      "Epoch number: 1300/10000step_number: 0/29 cost:  0.29219752795501497 accuracy:  0.9284935984745301\n",
      "Epoch number: 1301/10000step_number: 0/29 cost:  0.2919308342784782 accuracy:  0.9287660038136748\n",
      "Epoch number: 1302/10000step_number: 0/29 cost:  0.2916692907259641 accuracy:  0.9284935984745301\n",
      "Epoch number: 1303/10000step_number: 0/29 cost:  0.2914180530108522 accuracy:  0.9284935984745301\n",
      "Epoch number: 1304/10000step_number: 0/29 cost:  0.29118036100196104 accuracy:  0.9284935984745301\n",
      "Epoch number: 1305/10000step_number: 0/29 cost:  0.2909513297764559 accuracy:  0.9287660038136748\n",
      "Epoch number: 1306/10000step_number: 0/29 cost:  0.29072813126900937 accuracy:  0.929719422500681\n",
      "Epoch number: 1307/10000step_number: 0/29 cost:  0.29051264670496424 accuracy:  0.9295832198311087\n",
      "Epoch number: 1308/10000step_number: 0/29 cost:  0.2903045258012677 accuracy:  0.9294470171615363\n",
      "Epoch number: 1309/10000step_number: 0/29 cost:  0.29010356373635987 accuracy:  0.9291746118223917\n",
      "Epoch number: 1310/10000step_number: 0/29 cost:  0.28990834377148816 accuracy:  0.9290384091528194\n",
      "Epoch number: 1311/10000step_number: 0/29 cost:  0.28972015461581246 accuracy:  0.9290384091528194\n",
      "Epoch number: 1312/10000step_number: 0/29 cost:  0.28953819434514233 accuracy:  0.9291746118223917\n",
      "Epoch number: 1313/10000step_number: 0/29 cost:  0.28936342342642685 accuracy:  0.9291746118223917\n",
      "Epoch number: 1314/10000step_number: 0/29 cost:  0.2891934837209423 accuracy:  0.9291746118223917\n",
      "Epoch number: 1315/10000step_number: 0/29 cost:  0.28902881168339123 accuracy:  0.9291746118223917\n",
      "Epoch number: 1316/10000step_number: 0/29 cost:  0.2888664700457212 accuracy:  0.9291746118223917\n",
      "Epoch number: 1317/10000step_number: 0/29 cost:  0.2887077383414857 accuracy:  0.9293108144919641\n",
      "Epoch number: 1318/10000step_number: 0/29 cost:  0.28854961251510214 accuracy:  0.9293108144919641\n",
      "Epoch number: 1319/10000step_number: 0/29 cost:  0.28839459763648617 accuracy:  0.9293108144919641\n",
      "Epoch number: 1320/10000step_number: 0/29 cost:  0.2882391641271118 accuracy:  0.9293108144919641\n",
      "Epoch number: 1321/10000step_number: 0/29 cost:  0.2880871166273373 accuracy:  0.929719422500681\n",
      "Epoch number: 1322/10000step_number: 0/29 cost:  0.28793368917042195 accuracy:  0.929719422500681\n",
      "Epoch number: 1323/10000step_number: 0/29 cost:  0.287784416246672 accuracy:  0.929719422500681\n",
      "Epoch number: 1324/10000step_number: 0/29 cost:  0.2876324955190794 accuracy:  0.929719422500681\n",
      "Epoch number: 1325/10000step_number: 0/29 cost:  0.28748606989504377 accuracy:  0.929719422500681\n",
      "Epoch number: 1326/10000step_number: 0/29 cost:  0.28733510967769055 accuracy:  0.9298556251702533\n",
      "Epoch number: 1327/10000step_number: 0/29 cost:  0.2871918308224167 accuracy:  0.9298556251702533\n",
      "Epoch number: 1328/10000step_number: 0/29 cost:  0.28704108882718254 accuracy:  0.9298556251702533\n",
      "Epoch number: 1329/10000step_number: 0/29 cost:  0.2869015674750056 accuracy:  0.929719422500681\n",
      "Epoch number: 1330/10000step_number: 0/29 cost:  0.28674994389186803 accuracy:  0.9294470171615363\n",
      "Epoch number: 1331/10000step_number: 0/29 cost:  0.2866152843830657 accuracy:  0.9294470171615363\n",
      "Epoch number: 1332/10000step_number: 0/29 cost:  0.2864610813400354 accuracy:  0.9294470171615363\n",
      "Epoch number: 1333/10000step_number: 0/29 cost:  0.28633319208197827 accuracy:  0.9294470171615363\n",
      "Epoch number: 1334/10000step_number: 0/29 cost:  0.2861737459139233 accuracy:  0.9294470171615363\n",
      "Epoch number: 1335/10000step_number: 0/29 cost:  0.2860558130213011 accuracy:  0.9295832198311087\n",
      "Epoch number: 1336/10000step_number: 0/29 cost:  0.28588699290529634 accuracy:  0.9295832198311087\n",
      "Epoch number: 1337/10000step_number: 0/29 cost:  0.28578404990516965 accuracy:  0.9295832198311087\n",
      "Epoch number: 1338/10000step_number: 0/29 cost:  0.2855998894799023 accuracy:  0.929719422500681\n",
      "Epoch number: 1339/10000step_number: 0/29 cost:  0.2855188756998121 accuracy:  0.929719422500681\n",
      "Epoch number: 1340/10000step_number: 0/29 cost:  0.2853126217014511 accuracy:  0.929719422500681\n",
      "Epoch number: 1341/10000step_number: 0/29 cost:  0.2852597602116191 accuracy:  0.929719422500681\n",
      "Epoch number: 1342/10000step_number: 0/29 cost:  0.285028997066133 accuracy:  0.930128030509398\n",
      "Epoch number: 1343/10000step_number: 0/29 cost:  0.28500244909903194 accuracy:  0.929719422500681\n",
      "Epoch number: 1344/10000step_number: 0/29 cost:  0.28475459113683177 accuracy:  0.9299918278398257\n",
      "Epoch number: 1345/10000step_number: 0/29 cost:  0.2847440616186392 accuracy:  0.930128030509398\n",
      "Epoch number: 1346/10000step_number: 0/29 cost:  0.2844900896326859 accuracy:  0.930128030509398\n",
      "Epoch number: 1347/10000step_number: 0/29 cost:  0.28448903679464205 accuracy:  0.930128030509398\n",
      "Epoch number: 1348/10000step_number: 0/29 cost:  0.28423623789113966 accuracy:  0.930128030509398\n",
      "Epoch number: 1349/10000step_number: 0/29 cost:  0.284236568725036 accuracy:  0.930128030509398\n",
      "Epoch number: 1350/10000step_number: 0/29 cost:  0.2839854685077336 accuracy:  0.930128030509398\n",
      "Epoch number: 1351/10000step_number: 0/29 cost:  0.2839862062202687 accuracy:  0.930128030509398\n",
      "Epoch number: 1352/10000step_number: 0/29 cost:  0.2837376231989952 accuracy:  0.930128030509398\n",
      "Epoch number: 1353/10000step_number: 0/29 cost:  0.28374093761283675 accuracy:  0.930128030509398\n",
      "Epoch number: 1354/10000step_number: 0/29 cost:  0.2834951781098117 accuracy:  0.930128030509398\n",
      "Epoch number: 1355/10000step_number: 0/29 cost:  0.28350071196392146 accuracy:  0.930128030509398\n",
      "Epoch number: 1356/10000step_number: 0/29 cost:  0.28325749079575746 accuracy:  0.9302642331789703\n",
      "Epoch number: 1357/10000step_number: 0/29 cost:  0.28326489239176433 accuracy:  0.930128030509398\n",
      "Epoch number: 1358/10000step_number: 0/29 cost:  0.28302387859433975 accuracy:  0.9304004358485426\n",
      "Epoch number: 1359/10000step_number: 0/29 cost:  0.2830328990792822 accuracy:  0.930128030509398\n",
      "Epoch number: 1360/10000step_number: 0/29 cost:  0.2827937897598795 accuracy:  0.930536638518115\n",
      "Epoch number: 1361/10000step_number: 0/29 cost:  0.28280422444693865 accuracy:  0.9302642331789703\n",
      "Epoch number: 1362/10000step_number: 0/29 cost:  0.28256679712607424 accuracy:  0.9308090438572596\n",
      "Epoch number: 1363/10000step_number: 0/29 cost:  0.2825784792035838 accuracy:  0.930536638518115\n",
      "Epoch number: 1364/10000step_number: 0/29 cost:  0.28234257538466656 accuracy:  0.9308090438572596\n",
      "Epoch number: 1365/10000step_number: 0/29 cost:  0.282355346913572 accuracy:  0.9306728411876872\n",
      "Epoch number: 1366/10000step_number: 0/29 cost:  0.2821208465509377 accuracy:  0.9308090438572596\n",
      "Epoch number: 1367/10000step_number: 0/29 cost:  0.2821345422478191 accuracy:  0.9310814491964042\n",
      "Epoch number: 1368/10000step_number: 0/29 cost:  0.2819013308444631 accuracy:  0.9310814491964042\n",
      "Epoch number: 1369/10000step_number: 0/29 cost:  0.2819157709765882 accuracy:  0.9312176518659766\n",
      "Epoch number: 1370/10000step_number: 0/29 cost:  0.28168370948759686 accuracy:  0.9312176518659766\n",
      "Epoch number: 1371/10000step_number: 0/29 cost:  0.2816987051892481 accuracy:  0.9312176518659766\n",
      "Epoch number: 1372/10000step_number: 0/29 cost:  0.2814676075946231 accuracy:  0.9312176518659766\n",
      "Epoch number: 1373/10000step_number: 0/29 cost:  0.2814829780461416 accuracy:  0.9314900572051212\n",
      "Epoch number: 1374/10000step_number: 0/29 cost:  0.2812525982693135 accuracy:  0.9313538545355489\n",
      "Epoch number: 1375/10000step_number: 0/29 cost:  0.2812681961141185 accuracy:  0.9317624625442659\n",
      "Epoch number: 1376/10000step_number: 0/29 cost:  0.2810382181626759 accuracy:  0.9316262598746935\n",
      "Epoch number: 1377/10000step_number: 0/29 cost:  0.2810539577939831 accuracy:  0.9317624625442659\n",
      "Epoch number: 1378/10000step_number: 0/29 cost:  0.2808239728293122 accuracy:  0.9317624625442659\n",
      "Epoch number: 1379/10000step_number: 0/29 cost:  0.2808398588114804 accuracy:  0.9317624625442659\n",
      "Epoch number: 1380/10000step_number: 0/29 cost:  0.28060929946467467 accuracy:  0.9318986652138382\n",
      "Epoch number: 1381/10000step_number: 0/29 cost:  0.28062546120998844 accuracy:  0.9318986652138382\n",
      "Epoch number: 1382/10000step_number: 0/29 cost:  0.2803934625191189 accuracy:  0.9318986652138382\n",
      "Epoch number: 1383/10000step_number: 0/29 cost:  0.2804102323661736 accuracy:  0.9318986652138382\n",
      "Epoch number: 1384/10000step_number: 0/29 cost:  0.2801756139561012 accuracy:  0.9318986652138382\n",
      "Epoch number: 1385/10000step_number: 0/29 cost:  0.28019383779368634 accuracy:  0.9318986652138382\n",
      "Epoch number: 1386/10000step_number: 0/29 cost:  0.2799570909142856 accuracy:  0.9318986652138382\n",
      "Epoch number: 1387/10000step_number: 0/29 cost:  0.2799789386001769 accuracy:  0.9318986652138382\n",
      "Epoch number: 1388/10000step_number: 0/29 cost:  0.27974965164896776 accuracy:  0.9318986652138382\n",
      "Epoch number: 1389/10000step_number: 0/29 cost:  0.2797732572004877 accuracy:  0.9320348678834105\n",
      "Epoch number: 1390/10000step_number: 0/29 cost:  0.27955462462140906 accuracy:  0.9318986652138382\n",
      "Epoch number: 1391/10000step_number: 0/29 cost:  0.2795672931530785 accuracy:  0.9320348678834105\n",
      "Epoch number: 1392/10000step_number: 0/29 cost:  0.2793432586841808 accuracy:  0.9318986652138382\n",
      "Epoch number: 1393/10000step_number: 0/29 cost:  0.27935251217303686 accuracy:  0.9320348678834105\n",
      "Epoch number: 1394/10000step_number: 0/29 cost:  0.27912555826474883 accuracy:  0.9321710705529829\n",
      "Epoch number: 1395/10000step_number: 0/29 cost:  0.2791354997512156 accuracy:  0.9320348678834105\n",
      "Epoch number: 1396/10000step_number: 0/29 cost:  0.27890571051519225 accuracy:  0.9321710705529829\n",
      "Epoch number: 1397/10000step_number: 0/29 cost:  0.2789164100671084 accuracy:  0.9320348678834105\n",
      "Epoch number: 1398/10000step_number: 0/29 cost:  0.27868464130332044 accuracy:  0.9323072732225551\n",
      "Epoch number: 1399/10000step_number: 0/29 cost:  0.2786955720666497 accuracy:  0.9320348678834105\n",
      "Epoch number: 1400/10000step_number: 0/29 cost:  0.27846219892184015 accuracy:  0.9323072732225551\n",
      "Epoch number: 1401/10000step_number: 0/29 cost:  0.2784730974810548 accuracy:  0.9323072732225551\n",
      "Epoch number: 1402/10000step_number: 0/29 cost:  0.27823848234264376 accuracy:  0.9324434758921275\n",
      "Epoch number: 1403/10000step_number: 0/29 cost:  0.2782491652138001 accuracy:  0.9323072732225551\n",
      "Epoch number: 1404/10000step_number: 0/29 cost:  0.27801350269756914 accuracy:  0.9324434758921275\n",
      "Epoch number: 1405/10000step_number: 0/29 cost:  0.2780238688923792 accuracy:  0.9324434758921275\n",
      "Epoch number: 1406/10000step_number: 0/29 cost:  0.27778730458227313 accuracy:  0.9324434758921275\n",
      "Epoch number: 1407/10000step_number: 0/29 cost:  0.2777972546143418 accuracy:  0.9327158812312721\n",
      "Epoch number: 1408/10000step_number: 0/29 cost:  0.2775598911940422 accuracy:  0.9324434758921275\n",
      "Epoch number: 1409/10000step_number: 0/29 cost:  0.27756933209513934 accuracy:  0.9328520839008445\n",
      "Epoch number: 1410/10000step_number: 0/29 cost:  0.2773312587486072 accuracy:  0.9328520839008445\n",
      "Epoch number: 1411/10000step_number: 0/29 cost:  0.2773400992365641 accuracy:  0.9328520839008445\n",
      "Epoch number: 1412/10000step_number: 0/29 cost:  0.27710140112634474 accuracy:  0.9328520839008445\n",
      "Epoch number: 1413/10000step_number: 0/29 cost:  0.27710956088265504 accuracy:  0.9328520839008445\n",
      "Epoch number: 1414/10000step_number: 0/29 cost:  0.27687033189461624 accuracy:  0.9328520839008445\n",
      "Epoch number: 1415/10000step_number: 0/29 cost:  0.27687774620219513 accuracy:  0.9328520839008445\n",
      "Epoch number: 1416/10000step_number: 0/29 cost:  0.2766380992420692 accuracy:  0.9328520839008445\n",
      "Epoch number: 1417/10000step_number: 0/29 cost:  0.27664472584840716 accuracy:  0.9329882865704168\n",
      "Epoch number: 1418/10000step_number: 0/29 cost:  0.2764048040837804 accuracy:  0.9331244892399891\n",
      "Epoch number: 1419/10000step_number: 0/29 cost:  0.2764106292255947 accuracy:  0.9329882865704168\n",
      "Epoch number: 1420/10000step_number: 0/29 cost:  0.27617061618811284 accuracy:  0.9331244892399891\n",
      "Epoch number: 1421/10000step_number: 0/29 cost:  0.27617565926847865 accuracy:  0.9328520839008445\n",
      "Epoch number: 1422/10000step_number: 0/29 cost:  0.2759357858211345 accuracy:  0.9332606919095614\n",
      "Epoch number: 1423/10000step_number: 0/29 cost:  0.2759400992983246 accuracy:  0.9328520839008445\n",
      "Epoch number: 1424/10000step_number: 0/29 cost:  0.2757006439203018 accuracy:  0.9332606919095614\n",
      "Epoch number: 1425/10000step_number: 0/29 cost:  0.27570430575780275 accuracy:  0.9328520839008445\n",
      "Epoch number: 1426/10000step_number: 0/29 cost:  0.2754655854534569 accuracy:  0.9333968945791338\n",
      "Epoch number: 1427/10000step_number: 0/29 cost:  0.2754686829787109 accuracy:  0.9328520839008445\n",
      "Epoch number: 1428/10000step_number: 0/29 cost:  0.2752310345846879 accuracy:  0.9331244892399891\n",
      "Epoch number: 1429/10000step_number: 0/29 cost:  0.2752336419489471 accuracy:  0.9328520839008445\n",
      "Epoch number: 1430/10000step_number: 0/29 cost:  0.2749973972726414 accuracy:  0.9332606919095614\n",
      "Epoch number: 1431/10000step_number: 0/29 cost:  0.27499955173567703 accuracy:  0.9331244892399891\n",
      "Epoch number: 1432/10000step_number: 0/29 cost:  0.2747650125357583 accuracy:  0.9333968945791338\n",
      "Epoch number: 1433/10000step_number: 0/29 cost:  0.2747666959071939 accuracy:  0.9331244892399891\n",
      "Epoch number: 1434/10000step_number: 0/29 cost:  0.274534114585067 accuracy:  0.9333968945791338\n",
      "Epoch number: 1435/10000step_number: 0/29 cost:  0.2745352445253807 accuracy:  0.9331244892399891\n",
      "Epoch number: 1436/10000step_number: 0/29 cost:  0.27430481373180066 accuracy:  0.933533097248706\n",
      "Epoch number: 1437/10000step_number: 0/29 cost:  0.274305246323863 accuracy:  0.9331244892399891\n",
      "Epoch number: 1438/10000step_number: 0/29 cost:  0.27407709730224344 accuracy:  0.933533097248706\n",
      "Epoch number: 1439/10000step_number: 0/29 cost:  0.27407663909840346 accuracy:  0.9333968945791338\n",
      "Epoch number: 1440/10000step_number: 0/29 cost:  0.2738508461707444 accuracy:  0.9338055025878507\n",
      "Epoch number: 1441/10000step_number: 0/29 cost:  0.2738492720573455 accuracy:  0.933533097248706\n",
      "Epoch number: 1442/10000step_number: 0/29 cost:  0.2736258598117232 accuracy:  0.9338055025878507\n",
      "Epoch number: 1443/10000step_number: 0/29 cost:  0.2736229327935475 accuracy:  0.933533097248706\n",
      "Epoch number: 1444/10000step_number: 0/29 cost:  0.27340188297190327 accuracy:  0.9338055025878507\n",
      "Epoch number: 1445/10000step_number: 0/29 cost:  0.27339737291313204 accuracy:  0.933533097248706\n",
      "Epoch number: 1446/10000step_number: 0/29 cost:  0.2731786290923524 accuracy:  0.9338055025878507\n",
      "Epoch number: 1447/10000step_number: 0/29 cost:  0.27317232881790793 accuracy:  0.9338055025878507\n",
      "Epoch number: 1448/10000step_number: 0/29 cost:  0.272955798125122 accuracy:  0.933941705257423\n",
      "Epoch number: 1449/10000step_number: 0/29 cost:  0.2729475364692297 accuracy:  0.9338055025878507\n",
      "Epoch number: 1450/10000step_number: 0/29 cost:  0.27273308841365995 accuracy:  0.9340779079269954\n",
      "Epoch number: 1451/10000step_number: 0/29 cost:  0.2727227405143119 accuracy:  0.9338055025878507\n",
      "Epoch number: 1452/10000step_number: 0/29 cost:  0.272510203467182 accuracy:  0.9340779079269954\n",
      "Epoch number: 1453/10000step_number: 0/29 cost:  0.27249769885590225 accuracy:  0.9338055025878507\n",
      "Epoch number: 1454/10000step_number: 0/29 cost:  0.2722868548551341 accuracy:  0.9342141105965677\n",
      "Epoch number: 1455/10000step_number: 0/29 cost:  0.27227218383119134 accuracy:  0.933941705257423\n",
      "Epoch number: 1456/10000step_number: 0/29 cost:  0.2720627623643289 accuracy:  0.9344865159357123\n",
      "Epoch number: 1457/10000step_number: 0/29 cost:  0.2720459809301088 accuracy:  0.933941705257423\n",
      "Epoch number: 1458/10000step_number: 0/29 cost:  0.27183765225599094 accuracy:  0.9344865159357123\n",
      "Epoch number: 1459/10000step_number: 0/29 cost:  0.27181888564547796 accuracy:  0.9340779079269954\n",
      "Epoch number: 1460/10000step_number: 0/29 cost:  0.27161125407690256 accuracy:  0.9344865159357123\n",
      "Epoch number: 1461/10000step_number: 0/29 cost:  0.27159069873309305 accuracy:  0.93435031326614\n",
      "Epoch number: 1462/10000step_number: 0/29 cost:  0.2713832960535807 accuracy:  0.9344865159357123\n",
      "Epoch number: 1463/10000step_number: 0/29 cost:  0.27136121993680845 accuracy:  0.93435031326614\n",
      "Epoch number: 1464/10000step_number: 0/29 cost:  0.2711534985973218 accuracy:  0.9346227186052847\n",
      "Epoch number: 1465/10000step_number: 0/29 cost:  0.2711302401749492 accuracy:  0.9346227186052847\n",
      "Epoch number: 1466/10000step_number: 0/29 cost:  0.2709215648323476 accuracy:  0.9346227186052847\n",
      "Epoch number: 1467/10000step_number: 0/29 cost:  0.2708975325055644 accuracy:  0.9347589212748569\n",
      "Epoch number: 1468/10000step_number: 0/29 cost:  0.2706871664371953 accuracy:  0.9348951239444293\n",
      "Epoch number: 1469/10000step_number: 0/29 cost:  0.27066284378152433 accuracy:  0.9347589212748569\n",
      "Epoch number: 1470/10000step_number: 0/29 cost:  0.2704499233584026 accuracy:  0.9350313266140017\n",
      "Epoch number: 1471/10000step_number: 0/29 cost:  0.27042589600026445 accuracy:  0.9348951239444293\n",
      "Epoch number: 1472/10000step_number: 0/29 cost:  0.27020938268583816 accuracy:  0.9350313266140017\n",
      "Epoch number: 1473/10000step_number: 0/29 cost:  0.27018644326741564 accuracy:  0.9348951239444293\n",
      "Epoch number: 1474/10000step_number: 0/29 cost:  0.2699650582855583 accuracy:  0.9348951239444293\n",
      "Epoch number: 1475/10000step_number: 0/29 cost:  0.2699446933348013 accuracy:  0.9348951239444293\n",
      "Epoch number: 1476/10000step_number: 0/29 cost:  0.2697172193127358 accuracy:  0.9348951239444293\n",
      "Epoch number: 1477/10000step_number: 0/29 cost:  0.2697057951981827 accuracy:  0.9348951239444293\n",
      "Epoch number: 1478/10000step_number: 0/29 cost:  0.2694847552580407 accuracy:  0.9350313266140017\n",
      "Epoch number: 1479/10000step_number: 0/29 cost:  0.2696472222085629 accuracy:  0.9350313266140017\n",
      "Epoch number: 1480/10000step_number: 0/29 cost:  0.27023832780221346 accuracy:  0.9350313266140017\n",
      "Epoch number: 1481/10000step_number: 0/29 cost:  0.2702759419767668 accuracy:  0.9348951239444293\n",
      "Epoch number: 1482/10000step_number: 0/29 cost:  0.27030038435724507 accuracy:  0.9357123399618632\n",
      "Epoch number: 1483/10000step_number: 0/29 cost:  0.2697798030163957 accuracy:  0.9351675292835739\n",
      "Epoch number: 1484/10000step_number: 0/29 cost:  0.2697248714167794 accuracy:  0.9354399346227186\n",
      "Epoch number: 1485/10000step_number: 0/29 cost:  0.26949359599207673 accuracy:  0.9351675292835739\n",
      "Epoch number: 1486/10000step_number: 0/29 cost:  0.26962047049374827 accuracy:  0.9353037319531463\n",
      "Epoch number: 1487/10000step_number: 0/29 cost:  0.2693257076307319 accuracy:  0.9354399346227186\n",
      "Epoch number: 1488/10000step_number: 0/29 cost:  0.2689315332711276 accuracy:  0.9354399346227186\n",
      "Epoch number: 1489/10000step_number: 0/29 cost:  0.2688954839854271 accuracy:  0.9355761372922909\n",
      "Epoch number: 1490/10000step_number: 0/29 cost:  0.26871311670749837 accuracy:  0.9355761372922909\n",
      "Epoch number: 1491/10000step_number: 0/29 cost:  0.26863470487565755 accuracy:  0.9355761372922909\n",
      "Epoch number: 1492/10000step_number: 0/29 cost:  0.2684347214518691 accuracy:  0.9366657586488695\n",
      "Epoch number: 1493/10000step_number: 0/29 cost:  0.2684284492159908 accuracy:  0.9353037319531463\n",
      "Epoch number: 1494/10000step_number: 0/29 cost:  0.2682191370362073 accuracy:  0.9362571506401526\n",
      "Epoch number: 1495/10000step_number: 0/29 cost:  0.2681695948913648 accuracy:  0.9362571506401526\n",
      "Epoch number: 1496/10000step_number: 0/29 cost:  0.26795376354903994 accuracy:  0.9361209479705802\n",
      "Epoch number: 1497/10000step_number: 0/29 cost:  0.26787182544123017 accuracy:  0.9358485426314356\n",
      "Epoch number: 1498/10000step_number: 0/29 cost:  0.2676172963219587 accuracy:  0.9361209479705802\n",
      "Epoch number: 1499/10000step_number: 0/29 cost:  0.2675098980859655 accuracy:  0.9358485426314356\n",
      "Epoch number: 1500/10000step_number: 0/29 cost:  0.2671978622952563 accuracy:  0.9357123399618632\n",
      "Epoch number: 1501/10000step_number: 0/29 cost:  0.26710563963154427 accuracy:  0.9358485426314356\n",
      "Epoch number: 1502/10000step_number: 0/29 cost:  0.26672166816347476 accuracy:  0.9358485426314356\n",
      "Epoch number: 1503/10000step_number: 0/29 cost:  0.2668541426815682 accuracy:  0.9347589212748569\n",
      "Epoch number: 1504/10000step_number: 0/29 cost:  0.2660588491455688 accuracy:  0.9347589212748569\n",
      "Epoch number: 1505/10000step_number: 0/29 cost:  0.2658915153007822 accuracy:  0.9347589212748569\n",
      "Epoch number: 1506/10000step_number: 0/29 cost:  0.26520809616565705 accuracy:  0.9347589212748569\n",
      "Epoch number: 1507/10000step_number: 0/29 cost:  0.26496068597267114 accuracy:  0.9347589212748569\n",
      "Epoch number: 1508/10000step_number: 0/29 cost:  0.26504199126083916 accuracy:  0.9347589212748569\n",
      "Epoch number: 1509/10000step_number: 0/29 cost:  0.264470634249345 accuracy:  0.9347589212748569\n",
      "Epoch number: 1510/10000step_number: 0/29 cost:  0.26488861579063666 accuracy:  0.9347589212748569\n",
      "Epoch number: 1511/10000step_number: 0/29 cost:  0.26408941577699885 accuracy:  0.9344865159357123\n",
      "Epoch number: 1512/10000step_number: 0/29 cost:  0.26468652812999643 accuracy:  0.9346227186052847\n",
      "Epoch number: 1513/10000step_number: 0/29 cost:  0.26385456423359094 accuracy:  0.9346227186052847\n",
      "Epoch number: 1514/10000step_number: 0/29 cost:  0.26443569248700066 accuracy:  0.9346227186052847\n",
      "Epoch number: 1515/10000step_number: 0/29 cost:  0.26382046141205673 accuracy:  0.9346227186052847\n",
      "Epoch number: 1516/10000step_number: 0/29 cost:  0.26428634809937956 accuracy:  0.9344865159357123\n",
      "Epoch number: 1517/10000step_number: 0/29 cost:  0.2636030389615222 accuracy:  0.9344865159357123\n",
      "Epoch number: 1518/10000step_number: 0/29 cost:  0.2640784038741553 accuracy:  0.9346227186052847\n",
      "Epoch number: 1519/10000step_number: 0/29 cost:  0.2634159257275353 accuracy:  0.9344865159357123\n",
      "Epoch number: 1520/10000step_number: 0/29 cost:  0.26388374204267456 accuracy:  0.9346227186052847\n",
      "Epoch number: 1521/10000step_number: 0/29 cost:  0.2634700621922629 accuracy:  0.9347589212748569\n",
      "Epoch number: 1522/10000step_number: 0/29 cost:  0.2637752897335866 accuracy:  0.9347589212748569\n",
      "Epoch number: 1523/10000step_number: 0/29 cost:  0.2632715272407062 accuracy:  0.9346227186052847\n",
      "Epoch number: 1524/10000step_number: 0/29 cost:  0.26360707544928597 accuracy:  0.9348951239444293\n",
      "Epoch number: 1525/10000step_number: 0/29 cost:  0.26290269606154915 accuracy:  0.9346227186052847\n",
      "Epoch number: 1526/10000step_number: 0/29 cost:  0.26332628856149404 accuracy:  0.9348951239444293\n",
      "Epoch number: 1527/10000step_number: 0/29 cost:  0.2631774263305752 accuracy:  0.9348951239444293\n",
      "Epoch number: 1528/10000step_number: 0/29 cost:  0.2632206175252059 accuracy:  0.9348951239444293\n",
      "Epoch number: 1529/10000step_number: 0/29 cost:  0.26275131804542456 accuracy:  0.9347589212748569\n",
      "Epoch number: 1530/10000step_number: 0/29 cost:  0.26312505977536577 accuracy:  0.9348951239444293\n",
      "Epoch number: 1531/10000step_number: 0/29 cost:  0.2625764088052907 accuracy:  0.9346227186052847\n",
      "Epoch number: 1532/10000step_number: 0/29 cost:  0.26288754853912216 accuracy:  0.9347589212748569\n",
      "Epoch number: 1533/10000step_number: 0/29 cost:  0.26239197147058835 accuracy:  0.9347589212748569\n",
      "Epoch number: 1534/10000step_number: 0/29 cost:  0.26276202847427826 accuracy:  0.9347589212748569\n",
      "Epoch number: 1535/10000step_number: 0/29 cost:  0.26226264556354684 accuracy:  0.9347589212748569\n",
      "Epoch number: 1536/10000step_number: 0/29 cost:  0.2625808052326762 accuracy:  0.9348951239444293\n",
      "Epoch number: 1537/10000step_number: 0/29 cost:  0.26203238652237076 accuracy:  0.9351675292835739\n",
      "Epoch number: 1538/10000step_number: 0/29 cost:  0.26239978545121767 accuracy:  0.9348951239444293\n",
      "Epoch number: 1539/10000step_number: 0/29 cost:  0.26190496327315144 accuracy:  0.9351675292835739\n",
      "Epoch number: 1540/10000step_number: 0/29 cost:  0.26223644445152744 accuracy:  0.9350313266140017\n",
      "Epoch number: 1541/10000step_number: 0/29 cost:  0.26171401401532535 accuracy:  0.9351675292835739\n",
      "Epoch number: 1542/10000step_number: 0/29 cost:  0.2620503293203098 accuracy:  0.9350313266140017\n",
      "Epoch number: 1543/10000step_number: 0/29 cost:  0.2615125392394337 accuracy:  0.9351675292835739\n",
      "Epoch number: 1544/10000step_number: 0/29 cost:  0.2618719469147444 accuracy:  0.9353037319531463\n",
      "Epoch number: 1545/10000step_number: 0/29 cost:  0.2613588225534213 accuracy:  0.9351675292835739\n",
      "Epoch number: 1546/10000step_number: 0/29 cost:  0.26169375347812124 accuracy:  0.9353037319531463\n",
      "Epoch number: 1547/10000step_number: 0/29 cost:  0.2611525875640034 accuracy:  0.9351675292835739\n",
      "Epoch number: 1548/10000step_number: 0/29 cost:  0.26150688500257024 accuracy:  0.9355761372922909\n",
      "Epoch number: 1549/10000step_number: 0/29 cost:  0.26097663519219744 accuracy:  0.9353037319531463\n",
      "Epoch number: 1550/10000step_number: 0/29 cost:  0.26132567610936225 accuracy:  0.9355761372922909\n",
      "Epoch number: 1551/10000step_number: 0/29 cost:  0.26078597297450734 accuracy:  0.9353037319531463\n",
      "Epoch number: 1552/10000step_number: 0/29 cost:  0.2611363726375008 accuracy:  0.9355761372922909\n",
      "Epoch number: 1553/10000step_number: 0/29 cost:  0.2605950613715348 accuracy:  0.9354399346227186\n",
      "Epoch number: 1554/10000step_number: 0/29 cost:  0.26095204998864624 accuracy:  0.9354399346227186\n",
      "Epoch number: 1555/10000step_number: 0/29 cost:  0.2604053600263354 accuracy:  0.9353037319531463\n",
      "Epoch number: 1556/10000step_number: 0/29 cost:  0.26075906479693145 accuracy:  0.9354399346227186\n",
      "Epoch number: 1557/10000step_number: 0/29 cost:  0.26021413030335716 accuracy:  0.9354399346227186\n",
      "Epoch number: 1558/10000step_number: 0/29 cost:  0.2605744084748076 accuracy:  0.9354399346227186\n",
      "Epoch number: 1559/10000step_number: 0/29 cost:  0.26001657304805914 accuracy:  0.9354399346227186\n",
      "Epoch number: 1560/10000step_number: 0/29 cost:  0.2603757322100446 accuracy:  0.9354399346227186\n",
      "Epoch number: 1561/10000step_number: 0/29 cost:  0.2598338157930382 accuracy:  0.9354399346227186\n",
      "Epoch number: 1562/10000step_number: 0/29 cost:  0.2601948254829533 accuracy:  0.9354399346227186\n",
      "Epoch number: 1563/10000step_number: 0/29 cost:  0.25962152211576334 accuracy:  0.9354399346227186\n",
      "Epoch number: 1564/10000step_number: 0/29 cost:  0.25998566777765997 accuracy:  0.9354399346227186\n",
      "Epoch number: 1565/10000step_number: 0/29 cost:  0.2594661731077196 accuracy:  0.9354399346227186\n",
      "Epoch number: 1566/10000step_number: 0/29 cost:  0.2598163601359494 accuracy:  0.9354399346227186\n",
      "Epoch number: 1567/10000step_number: 0/29 cost:  0.2592298707283775 accuracy:  0.9354399346227186\n",
      "Epoch number: 1568/10000step_number: 0/29 cost:  0.2595898284148144 accuracy:  0.9354399346227186\n",
      "Epoch number: 1569/10000step_number: 0/29 cost:  0.2591245599903931 accuracy:  0.9353037319531463\n",
      "Epoch number: 1570/10000step_number: 0/29 cost:  0.25942649729964856 accuracy:  0.9355761372922909\n",
      "Epoch number: 1571/10000step_number: 0/29 cost:  0.2588426364530712 accuracy:  0.9353037319531463\n",
      "Epoch number: 1572/10000step_number: 0/29 cost:  0.2591980541276551 accuracy:  0.9354399346227186\n",
      "Epoch number: 1573/10000step_number: 0/29 cost:  0.25874906449207175 accuracy:  0.9354399346227186\n",
      "Epoch number: 1574/10000step_number: 0/29 cost:  0.25902478856901007 accuracy:  0.9354399346227186\n",
      "Epoch number: 1575/10000step_number: 0/29 cost:  0.25838843432908015 accuracy:  0.9354399346227186\n",
      "Epoch number: 1576/10000step_number: 0/29 cost:  0.2587877151159901 accuracy:  0.9354399346227186\n",
      "Epoch number: 1577/10000step_number: 0/29 cost:  0.2584251579369319 accuracy:  0.9354399346227186\n",
      "Epoch number: 1578/10000step_number: 0/29 cost:  0.258623391107459 accuracy:  0.9355761372922909\n",
      "Epoch number: 1579/10000step_number: 0/29 cost:  0.2579752070454988 accuracy:  0.9354399346227186\n",
      "Epoch number: 1580/10000step_number: 0/29 cost:  0.258407895076846 accuracy:  0.9358485426314356\n",
      "Epoch number: 1581/10000step_number: 0/29 cost:  0.2579744374889153 accuracy:  0.9354399346227186\n",
      "Epoch number: 1582/10000step_number: 0/29 cost:  0.25826092787287447 accuracy:  0.935984745301008\n",
      "Epoch number: 1583/10000step_number: 0/29 cost:  0.2575936861727222 accuracy:  0.9355761372922909\n",
      "Epoch number: 1584/10000step_number: 0/29 cost:  0.25801566830434663 accuracy:  0.9358485426314356\n",
      "Epoch number: 1585/10000step_number: 0/29 cost:  0.2576369870203681 accuracy:  0.9357123399618632\n",
      "Epoch number: 1586/10000step_number: 0/29 cost:  0.25783613699640495 accuracy:  0.9358485426314356\n",
      "Epoch number: 1587/10000step_number: 0/29 cost:  0.2571645456686706 accuracy:  0.9357123399618632\n",
      "Epoch number: 1588/10000step_number: 0/29 cost:  0.25762709206004986 accuracy:  0.935984745301008\n",
      "Epoch number: 1589/10000step_number: 0/29 cost:  0.2571647965443499 accuracy:  0.9357123399618632\n",
      "Epoch number: 1590/10000step_number: 0/29 cost:  0.2574922675080169 accuracy:  0.935984745301008\n",
      "Epoch number: 1591/10000step_number: 0/29 cost:  0.2567797708708233 accuracy:  0.9355761372922909\n",
      "Epoch number: 1592/10000step_number: 0/29 cost:  0.2572329614855876 accuracy:  0.9361209479705802\n",
      "Epoch number: 1593/10000step_number: 0/29 cost:  0.25684002314847865 accuracy:  0.9358485426314356\n",
      "Epoch number: 1594/10000step_number: 0/29 cost:  0.25705360933859456 accuracy:  0.935984745301008\n",
      "Epoch number: 1595/10000step_number: 0/29 cost:  0.25634534636941353 accuracy:  0.935984745301008\n",
      "Epoch number: 1596/10000step_number: 0/29 cost:  0.2568357074600792 accuracy:  0.9362571506401526\n",
      "Epoch number: 1597/10000step_number: 0/29 cost:  0.2563792265485134 accuracy:  0.9361209479705802\n",
      "Epoch number: 1598/10000step_number: 0/29 cost:  0.2567224025573065 accuracy:  0.9361209479705802\n",
      "Epoch number: 1599/10000step_number: 0/29 cost:  0.25594411557453084 accuracy:  0.9362571506401526\n",
      "Epoch number: 1600/10000step_number: 0/29 cost:  0.25645429849670676 accuracy:  0.9362571506401526\n",
      "Epoch number: 1601/10000step_number: 0/29 cost:  0.2561440565489022 accuracy:  0.9362571506401526\n",
      "Epoch number: 1602/10000step_number: 0/29 cost:  0.2562652680215957 accuracy:  0.9362571506401526\n",
      "Epoch number: 1603/10000step_number: 0/29 cost:  0.25568597399665727 accuracy:  0.9362571506401526\n",
      "Epoch number: 1604/10000step_number: 0/29 cost:  0.25614054685296195 accuracy:  0.9361209479705802\n",
      "Epoch number: 1605/10000step_number: 0/29 cost:  0.2553484340935441 accuracy:  0.9363933533097248\n",
      "Epoch number: 1606/10000step_number: 0/29 cost:  0.2558893555964669 accuracy:  0.9363933533097248\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-bea22fa27144>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mNN\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mNeural_Network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m76\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m76\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-43-13f49d9b065b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, y, epoch, X_validation, y_validation)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_propagation_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m                 \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward_propagation_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam_update_parameters_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-13f49d9b065b>\u001b[0m in \u001b[0;36mbackward_propagation_NN\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m         \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"A3\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         \u001b[0mDW3_prime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"A3\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoidPrime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Z3\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#DZ\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[0mDW3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDW3_prime\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"A2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"A3\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-13f49d9b065b>\u001b[0m in \u001b[0;36mcompute_cost\u001b[1;34m(self, AL, Y)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mlogprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m         \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogprobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mcost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#en önemldi model bu Epoch number: 1514/10000step_number: 0/29 cost:  0.26443569248700066 accuracy:  0.9346227186052847 , V7\n",
    "NN= Neural_Network(X_train,y_train,76,76,0.0001,1000)\n",
    "NN.train(X_train,y_train,10000,X_test,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v8\n",
    "from sklearn.metrics import accuracy_score\n",
    "class Neural_Network():   \n",
    "    def __init__(self,X_train,y_train,Number_Dense1,Number_Dense2,learning_rate,batch):\n",
    "        self.X_train=X_train\n",
    "        self.y_train=y_train\n",
    "        self.Number_Dense1=Number_Dense1\n",
    "        self.Number_Dense2=Number_Dense2\n",
    "        self.parameters={}\n",
    "        self.Adam_parameters={}\n",
    "        self.catch={}\n",
    "        self.grads={}\n",
    "        self.learning_rate=learning_rate\n",
    "        self.batch=batch\n",
    "        \n",
    "\n",
    "        \n",
    "    def linear_forward(self,A, W, b):\n",
    "        \n",
    "        Z = np.dot(W, A) + b\n",
    "        cache = (A, W, b)    \n",
    "        return Z, cache\n",
    "    \n",
    "    \n",
    "    def linear_activation_forward(self,A_prev, W, b, activation):       \n",
    "        if activation == \"sigmoid\":\n",
    "            Z, linear_cache  = self.linear_forward(A_prev, W, b)\n",
    "            A, activation_cache = self.sigmoid(Z)\n",
    "        elif activation == \"relu\":\n",
    "            Z, linear_cache = self.linear_forward(A_prev, W, b)\n",
    "            A, activation_cache = self.relu(Z)\n",
    "        cache = (linear_cache, activation_cache)\n",
    "        return A, cache\n",
    "      \n",
    "        print(X_train.shape[0])\n",
    "    def initialize_parameters_and_layer_sizes_NN(self):\n",
    "        parameters={\"weight1\":np.random.randn(self.Number_Dense1,self.X_train.shape[0])*0.01,\n",
    "                    \"bias1\":np.zeros((self.Number_Dense1,1)),\n",
    "                    \"weight2\":np.random.randn(self.Number_Dense2,self.Number_Dense1)*0.01,\n",
    "                    \"bias2\":np.zeros((self.Number_Dense2,1)),\n",
    "                    \"weight3\":np.random.randn(self.y_train.shape[0],self.Number_Dense2)*0.01,\n",
    "                    \"bias3\":np.zeros((self.y_train.shape[0],1))       \n",
    "        }\n",
    "        self.parameters=parameters\n",
    "        \n",
    "    def initialize_parameters_Adam_NN(self):        \n",
    "        parameters={\"weight1_vdw\":np.zeros((self.Number_Dense1,self.X_train.shape[0])),\n",
    "                    \"bias1_vdw\":np.zeros((self.Number_Dense1,1)),\n",
    "                    \"weight2_vdw\":np.zeros((self.Number_Dense2,self.Number_Dense1)),\n",
    "                    \"bias2_vdw\":np.zeros((self.Number_Dense2,1)),\n",
    "                    \"weight3_vdw\":np.zeros((self.y_train.shape[0],self.Number_Dense2)),\n",
    "                    \"bias3_vdw\":np.zeros((self.y_train.shape[0],1)),\n",
    "                    \"weight1_sdw\":np.zeros((self.Number_Dense1,self.X_train.shape[0])),\n",
    "                    \"bias1_sdw\":np.zeros((self.Number_Dense1,1)),\n",
    "                    \"weight2_sdw\":np.zeros((self.Number_Dense2,self.Number_Dense1)),\n",
    "                    \"bias2_sdw\":np.zeros((self.Number_Dense2,1)),\n",
    "                    \"weight3_sdw\":np.zeros((self.y_train.shape[0],self.Number_Dense2)),\n",
    "                    \"bias3_sdw\":np.zeros((self.y_train.shape[0],1))       \n",
    "        }\n",
    "        self.Adam_parameters=parameters\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def Adam_optimizer(self,vdw,epoch,sdw,DW,w,learningRate,epsilon = np.array([pow(10, -8)])):                  \n",
    "        vdw = 0.9 * vdw + (0.1) * DW\n",
    "        sdw = 0.999 * sdw + (0.001) * pow(DW, 2)\n",
    "        vdw_corrected = vdw / (1-pow(0.9, epoch+1))\n",
    "        sdw_corrected = sdw / (1-pow(0.999,epoch+1))\n",
    "        w = w + learningRate * (vdw_corrected / (np.sqrt(sdw_corrected) + epsilon)) #- değiştir\n",
    "        return w,vdw,sdw\n",
    "\n",
    "        \n",
    "    def compute_cost(self,AL, Y): \n",
    "        m = Y.shape[1]\n",
    "        logprobs = np.multiply(np.log(AL),Y) +  np.multiply(np.log(1-AL), (1-Y))\n",
    "        cost = -1/m*np.sum(logprobs)\n",
    "        cost = np.squeeze(cost)\n",
    "        return cost\n",
    "\n",
    "        \n",
    "    def Relu(self,x):\n",
    "        for i in range(x.shape[0]):\n",
    "            for i1 in range(x.shape[1]):\n",
    "                if x[i,i1]<0:\n",
    "                    x[i,i1]=0\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def ReluPrime(self,x):\n",
    "        for i in range(x.shape[0]):\n",
    "            for i1 in range(x.shape[1]):\n",
    "                if(x[i,i1]<0):\n",
    "                     x[i,i1]*=0\n",
    "                else:\n",
    "                    x[i,i1]*=1\n",
    "                \n",
    "        return x\n",
    "    def stable_softmax(self,X):        \n",
    "        exps = np.exp(X - np.max(X))\n",
    "        return exps / np.sum(exps)\n",
    "    def der_tanh(self,X):       \n",
    "        return 1-(np.tanh(X)**2)\n",
    "    \n",
    "    def cross_entropy_loss(self,Y,A3):\n",
    "        E=np.zeros(Y.shape)\n",
    "        \n",
    "        for i in range(Y.shape[0]):\n",
    "            for i1 in range(Y.shape[1]):\n",
    "                if int(Y[i,i1])==1:\n",
    "                    E[i,i1]=-np.log(A3[i,i1])\n",
    "                else:\n",
    "                    E[i,i1]=-np.log(1-A3[i,i1])\n",
    "        \n",
    "    \n",
    "        return np.sum(E)\n",
    "\n",
    "    def forward_propagation_NN(self,X_train):\n",
    "        Z1=np.dot(self.parameters[\"weight1\"],X_train)+self.parameters[\"bias1\"]\n",
    "        A1=np.tanh(Z1)\n",
    "        Z2=np.dot(self.parameters[\"weight2\"],A1)+self.parameters[\"bias2\"]\n",
    "        A2=np.tanh(Z2)\n",
    "        Z3=np.dot(self.parameters[\"weight3\"],A2)+self.parameters[\"bias3\"]       \n",
    "        A3=self.softmax(Z3)\n",
    "    \n",
    "\n",
    "        self.cache={\n",
    "            \"A1\":A1,\n",
    "            \"A2\":A2,\n",
    "            \"A3\":A3,\n",
    "            \"Z1\":Z1,\n",
    "            \"Z2\":Z2,\n",
    "            \"Z3\":Z3}\n",
    "        return A3\n",
    "    \n",
    "    def sigmoid(self,s):\n",
    "        return 1/(1+np.exp(-s))\n",
    "        \n",
    "    def sigmoidPrime(self,s):\n",
    "        return s*(1-s)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    " \n",
    "\n",
    "        \n",
    "    def backward_propagation_NN(self,X,Y):\n",
    "\n",
    "\n",
    "        error=self.compute_cost(self.cache[\"A3\"],Y)\n",
    "        DW3_prime=(self.cache[\"A3\"]-Y) #DZ\n",
    "        DW3=np.dot(DW3_prime,self.cache[\"A2\"].T)/self.cache[\"A3\"].shape[1]\n",
    "        db3=np.sum(DW3_prime,axis=1,keepdims=True)/self.cache[\"A3\"].shape[1]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        DW2_prime=(np.dot(self.parameters[\"weight3\"].T,DW3_prime)*self.der_tanh(self.cache[\"Z2\"]))#76*1000 =\n",
    "        DW2=np.dot(DW2_prime,self.cache[\"A1\"].T)/self.cache[\"A2\"].shape[1] #DW2=76*76=    76*1000,1000*76\n",
    "        db2=np.sum(DW2_prime,axis=1,keepdims=True)/self.cache[\"A2\"].shape[1]\n",
    "\n",
    "        \n",
    "        \n",
    "        DW1_prime=np.dot(self.parameters[\"weight2\"].T,DW2_prime)*self.der_tanh(self.cache[\"Z1\"])\n",
    "        DW1=np.dot(DW1_prime,X.T)/self.cache[\"A1\"].shape[1]\n",
    "        db1=np.sum(DW1_prime,axis=1,keepdims=True)/self.cache[\"A1\"].shape[1]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        self.grads={ \"dweight1\":DW1,\n",
    "              \"dbias1\":db1,\n",
    "              \"dweight2\":DW2,\n",
    "              \"dbias2\":db2,\n",
    "              \"dweight3\":DW3,\n",
    "              \"dbias3\":db3}\n",
    "        return error\n",
    "        \n",
    "            \n",
    "    def softmax(self,X):\n",
    "        exps = np.exp(X)\n",
    "        return exps / np.sum(exps)\n",
    "\n",
    "    def update_parameters_NN(self):\n",
    "        parameter={\"weight1\":self.parameters[\"weight1\"]-(self.learning_rate*self.grads[\"dweight1\"]),\n",
    "                \"weight2\":self.parameters[\"weight2\"]-(self.learning_rate*self.grads[\"dweight2\"]),\n",
    "                   \"weight3\":self.parameters[\"weight3\"]-(self.learning_rate*self.grads[\"dweight3\"]),\n",
    "                \"bias1\":self.parameters[\"bias1\"]-(self.learning_rate*self.grads[\"dbias1\"]),\n",
    "                   \"bias3\":self.parameters[\"bias3\"]-(self.learning_rate*self.grads[\"dbias3\"]),\n",
    "                \"bias2\":self.parameters[\"bias2\"]-(self.learning_rate*self.grads[\"dbias2\"])}\n",
    "        self.parameters=parameter\n",
    "        \n",
    "    def Adam_update_parameters_NN(self,epoch):                      \n",
    "        self.parameters[\"weight1\"],self.Adam_parameters[\"weight1_vdw\"],self.Adam_parameters[\"weight1_sdw\"]=self.Adam_optimizer(self.Adam_parameters[\"weight1_vdw\"],epoch,self.Adam_parameters[\"weight1_sdw\"],self.grads[\"dweight1\"],self.parameters[\"weight1\"],self.learning_rate,np.array([pow(10, -8)]))\n",
    "        self.parameters[\"bias1\"],self.Adam_parameters[\"bias1_vdw\"],self.Adam_parameters[\"bias1_sdw\"]=self.Adam_optimizer(self.Adam_parameters[\"bias1_vdw\"],epoch,self.Adam_parameters[\"bias1_sdw\"],self.grads[\"dbias1\"],self.parameters[\"bias1\"],self.learning_rate,np.array([pow(10, -8)]))\n",
    "        self.parameters[\"weight2\"],self.Adam_parameters[\"weight2_vdw\"],self.Adam_parameters[\"weight2_sdw\"]=self.Adam_optimizer(self.Adam_parameters[\"weight2_vdw\"],epoch,self.Adam_parameters[\"weight2_sdw\"],self.grads[\"dweight2\"],self.parameters[\"weight2\"],self.learning_rate,np.array([pow(10, -8)]))\n",
    "        self.parameters[\"bias2\"],self.Adam_parameters[\"bias2_vdw\"],self.Adam_parameters[\"bias2_sdw\"]=self.Adam_optimizer(self.Adam_parameters[\"bias2_vdw\"],epoch,self.Adam_parameters[\"bias2_sdw\"],self.grads[\"dbias2\"],self.parameters[\"bias2\"],self.learning_rate,np.array([pow(10, -8)]))\n",
    "        self.parameters[\"weight3\"],self.Adam_parameters[\"weight3_vdw\"],self.Adam_parameters[\"weight3_sdw\"]=self.Adam_optimizer(self.Adam_parameters[\"weight3_vdw\"],epoch,self.Adam_parameters[\"weight3_sdw\"],self.grads[\"dweight3\"],self.parameters[\"weight3\"],self.learning_rate,np.array([pow(10, -8)]))\n",
    "        self.parameters[\"bias3\"],self.Adam_parameters[\"bias3_vdw\"],self.Adam_parameters[\"bias3_sdw\"]=self.Adam_optimizer(self.Adam_parameters[\"bias3_vdw\"],epoch,self.Adam_parameters[\"bias3_sdw\"],self.grads[\"dbias3\"],self.parameters[\"bias3\"],self.learning_rate,np.array([pow(10, -8)]))\n",
    "                      \n",
    "        \n",
    "        \n",
    "    def prediction_NN(self,X_test):\n",
    "        \n",
    "        A2=self.forward_propagation_NN(X_test)\n",
    "        print(A2.shape)\n",
    "        Y_prediction=np.zeros((self.batch,5))\n",
    "        for i1 in range(5):\n",
    "            for i in range(self.batch):\n",
    "                if A2[i,i1]<=0.5:\n",
    "                    Y_prediction[i1,i]=0\n",
    "                else:\n",
    "                    Y_prediction[i1,i]=1\n",
    "        return Y_prediction\n",
    "        \n",
    "    def train(self,X,y,epoch,X_validation,y_validation):\n",
    "        \n",
    "        self.initialize_parameters_and_layer_sizes_NN()\n",
    "        self.initialize_parameters_Adam_NN()\n",
    "        step_number=int(X.shape[1]/self.batch)\n",
    "        i1=0\n",
    "        for i1 in range(epoch):\n",
    "            i=0\n",
    "            if i1>0:\n",
    "                print(\"Epoch number: \"+str(i1)+\"/\"+str(epoch)+ \"step_number: \"+str(i)+\"/\"+str(step_number),\"cost: \",error,\"accuracy: \",accuracy_score(NN.forward_propagation_NN(X_test).argmax(axis=0), y_test.argmax(axis=0), normalize=True))\n",
    "\n",
    "            for i in range(step_number):\n",
    "                self.forward_propagation_NN((X[:,i*self.batch:(i+1)*self.batch]))\n",
    "                error=self.backward_propagation_NN(X[:,i*self.batch:(i+1)*self.batch],y[:,i*self.batch:(i+1)*self.batch])\n",
    "                self.Adam_update_parameters_NN(i1)\n",
    "                \n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "rgba(255, 0, 0, 1)",
          "line": {
           "color": "rgb(0,0,0)",
           "width": 1.5
          }
         },
         "name": "KNN",
         "text": [
          "KNN",
          "KNN with PCA"
         ],
         "type": "bar",
         "x": [
          "KNN",
          "KNN with PCA"
         ],
         "y": [
          0.795,
          0.791
         ]
        },
        {
         "marker": {
          "color": "rgba(0, 256, 0, .8)",
          "line": {
           "color": "rgb(0,0,0)",
           "width": 1.5
          }
         },
         "name": "RFC",
         "text": [
          "RFC",
          "RFC with PCA"
         ],
         "type": "bar",
         "x": [
          "RFC",
          "RFC with PCA"
         ],
         "y": [
          0.7532,
          0.7849
         ]
        },
        {
         "marker": {
          "color": "rgba(0, 0, 256, 1)",
          "line": {
           "color": "rgb(0,0,0)",
           "width": 1.5
          }
         },
         "name": "SVC",
         "text": [
          "SVC",
          "SVC with PCA"
         ],
         "type": "bar",
         "x": [
          "SVC",
          "SVC with PCA"
         ],
         "y": [
          0.611277,
          0.8169
         ]
        },
        {
         "marker": {
          "color": "rgba(0, 0, 100, 1)",
          "line": {
           "color": "rgb(0,0,0)",
           "width": 1.5
          }
         },
         "name": "MLP",
         "text": [
          "MLP_with_keras",
          "MLP_our_library"
         ],
         "type": "bar",
         "x": [
          "MLP_with_keras",
          "MLP_our_library"
         ],
         "y": [
          0.9736,
          0.926
         ]
        }
       ],
       "layout": {
        "barmode": "group",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"cb1a3f11-e1f2-47cd-94b7-f3e6edb0c6ba\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"cb1a3f11-e1f2-47cd-94b7-f3e6edb0c6ba\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'cb1a3f11-e1f2-47cd-94b7-f3e6edb0c6ba',\n",
       "                        [{\"marker\": {\"color\": \"rgba(255, 0, 0, 1)\", \"line\": {\"color\": \"rgb(0,0,0)\", \"width\": 1.5}}, \"name\": \"KNN\", \"text\": [\"KNN\", \"KNN with PCA\"], \"type\": \"bar\", \"x\": [\"KNN\", \"KNN with PCA\"], \"y\": [0.795, 0.791]}, {\"marker\": {\"color\": \"rgba(0, 256, 0, .8)\", \"line\": {\"color\": \"rgb(0,0,0)\", \"width\": 1.5}}, \"name\": \"RFC\", \"text\": [\"RFC\", \"RFC with PCA\"], \"type\": \"bar\", \"x\": [\"RFC\", \"RFC with PCA\"], \"y\": [0.7532, 0.7849]}, {\"marker\": {\"color\": \"rgba(0, 0, 256, 1)\", \"line\": {\"color\": \"rgb(0,0,0)\", \"width\": 1.5}}, \"name\": \"SVC\", \"text\": [\"SVC\", \"SVC with PCA\"], \"type\": \"bar\", \"x\": [\"SVC\", \"SVC with PCA\"], \"y\": [0.611277, 0.8169]}, {\"marker\": {\"color\": \"rgba(0, 0, 100, 1)\", \"line\": {\"color\": \"rgb(0,0,0)\", \"width\": 1.5}}, \"name\": \"MLP\", \"text\": [\"MLP_with_keras\", \"MLP_our_library\"], \"type\": \"bar\", \"x\": [\"MLP_with_keras\", \"MLP_our_library\"], \"y\": [0.9736, 0.926]}],\n",
       "                        {\"barmode\": \"group\", \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('cb1a3f11-e1f2-47cd-94b7-f3e6edb0c6ba');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly\n",
    "d1 = {'methods': ['KNN'],'scores':[0.795]}\n",
    "df1=pd.DataFrame(d1)\n",
    "d1 = {'methods': 'KNN with PCA','scores':0.791 }\n",
    "df1=df1.append(d1,ignore_index=True)\n",
    "\n",
    "d2 = {'methods': ['RFC'],'scores':[0.7532]}\n",
    "df2=pd.DataFrame(d2)\n",
    "d2 = {'methods': 'RFC with PCA','scores':0.7849 }\n",
    "df2=df2.append(d2,ignore_index=True)\n",
    "\n",
    "d3 = {'methods': ['SVC'],'scores':[0.611277]}\n",
    "df3=pd.DataFrame(d3)\n",
    "d3 = {'methods': 'SVC with PCA','scores':0.8169 }\n",
    "df3=df3.append(d3,ignore_index=True)\n",
    "\n",
    "d4 = {'methods': ['MLP_with_keras'],'scores':[0.9736]}\n",
    "df4=pd.DataFrame(d4)\n",
    "d4 = {'methods': 'MLP_our_library','scores':0.926\n",
    " }\n",
    "df4=df4.append(d4,ignore_index=True)\n",
    "\n",
    "# prepare data frames\n",
    "\n",
    "# import graph objects as \"go\"\n",
    "import plotly.graph_objs as go\n",
    "# create trace1 \n",
    "trace1 = go.Bar(\n",
    "                x = df1.methods,\n",
    "                y = df1.scores,\n",
    "                name = \"KNN\",\n",
    "                marker = dict(color = 'rgba(255, 0, 0, 1)',\n",
    "                             line=dict(color='rgb(0,0,0)',width=1.5)),\n",
    "                text = df1.methods)\n",
    "trace3 = go.Bar(\n",
    "                x = df2.methods,\n",
    "                y = df2.scores,\n",
    "                name = \"RFC\",\n",
    "                marker = dict(color = 'rgba(0, 256, 0, .8)',\n",
    "                             line=dict(color='rgb(0,0,0)',width=1.5)),\n",
    "                text = df2.methods)\n",
    "# create trace2 \n",
    "trace2 = go.Bar(\n",
    "                x = df3.methods,\n",
    "                y = df3.scores,\n",
    "                name = \"SVC\",\n",
    "                marker = dict(color = 'rgba(0, 0, 256, 1)',\n",
    "                              line=dict(color='rgb(0,0,0)',width=1.5)),\n",
    "                text = df3.methods)\n",
    "trace4 = go.Bar(\n",
    "                x = df4.methods,\n",
    "                y = df4.scores,\n",
    "                name = \"MLP\",\n",
    "                marker = dict(color = 'rgba(0, 0, 100, 1)',\n",
    "                              line=dict(color='rgb(0,0,0)',width=1.5)),\n",
    "                text = df4.methods)\n",
    "data = [trace1,trace3, trace2,trace4]\n",
    "layout = go.Layout(barmode = \"group\")\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch number: 1/10000step_number: 0/29 cost:  3.3277505099348037 accuracy:  0.0\n",
      "Epoch number: 2/10000step_number: 0/29 cost:  3.2313838878892396 accuracy:  1.0\n",
      "Epoch number: 3/10000step_number: 0/29 cost:  3.173625301321641 accuracy:  1.0\n",
      "Epoch number: 4/10000step_number: 0/29 cost:  3.1397287344484828 accuracy:  1.0\n",
      "Epoch number: 5/10000step_number: 0/29 cost:  3.097225336306127 accuracy:  1.0\n",
      "Epoch number: 6/10000step_number: 0/29 cost:  3.042629349180715 accuracy:  1.0\n",
      "Epoch number: 7/10000step_number: 0/29 cost:  2.9904654970816384 accuracy:  1.0\n",
      "Epoch number: 8/10000step_number: 0/29 cost:  2.9475803109788568 accuracy:  1.0\n",
      "Epoch number: 9/10000step_number: 0/29 cost:  2.9132145115713994 accuracy:  1.0\n",
      "Epoch number: 10/10000step_number: 0/29 cost:  2.885008671763536 accuracy:  0.0\n",
      "Epoch number: 11/10000step_number: 0/29 cost:  2.8610868549652633 accuracy:  0.0\n",
      "Epoch number: 12/10000step_number: 0/29 cost:  2.840230043052283 accuracy:  0.0\n",
      "Epoch number: 13/10000step_number: 0/29 cost:  2.821673962325804 accuracy:  0.0\n",
      "Epoch number: 14/10000step_number: 0/29 cost:  2.8049283544345394 accuracy:  0.0\n",
      "Epoch number: 15/10000step_number: 0/29 cost:  2.789663679993928 accuracy:  0.0\n",
      "Epoch number: 16/10000step_number: 0/29 cost:  2.775646323626947 accuracy:  0.0\n",
      "Epoch number: 17/10000step_number: 0/29 cost:  2.762702271770587 accuracy:  0.0\n",
      "Epoch number: 18/10000step_number: 0/29 cost:  2.7506964833323955 accuracy:  0.0\n",
      "Epoch number: 19/10000step_number: 0/29 cost:  2.7395208070480788 accuracy:  0.0\n",
      "Epoch number: 20/10000step_number: 0/29 cost:  2.7290866071214017 accuracy:  0.0\n",
      "Epoch number: 21/10000step_number: 0/29 cost:  2.7193200358026064 accuracy:  0.0\n",
      "Epoch number: 22/10000step_number: 0/29 cost:  2.710158858500432 accuracy:  0.0\n",
      "Epoch number: 23/10000step_number: 0/29 cost:  2.7015502542364644 accuracy:  0.0\n",
      "Epoch number: 24/10000step_number: 0/29 cost:  2.693449265438626 accuracy:  0.0\n",
      "Epoch number: 25/10000step_number: 0/29 cost:  2.6858176570936325 accuracy:  0.0\n",
      "Epoch number: 26/10000step_number: 0/29 cost:  2.678622950876319 accuracy:  0.0\n",
      "Epoch number: 27/10000step_number: 0/29 cost:  2.6718374495815627 accuracy:  0.0\n",
      "Epoch number: 28/10000step_number: 0/29 cost:  2.6654372087185627 accuracy:  0.0\n",
      "Epoch number: 29/10000step_number: 0/29 cost:  2.6594010712656533 accuracy:  0.0\n",
      "Epoch number: 30/10000step_number: 0/29 cost:  2.6537098683434817 accuracy:  0.0\n",
      "Epoch number: 31/10000step_number: 0/29 cost:  2.648345682083369 accuracy:  0.0\n",
      "Epoch number: 32/10000step_number: 0/29 cost:  2.643291155067221 accuracy:  0.0\n",
      "Epoch number: 33/10000step_number: 0/29 cost:  2.638529200446165 accuracy:  0.0\n",
      "Epoch number: 34/10000step_number: 0/29 cost:  2.634043244851166 accuracy:  0.0\n",
      "Epoch number: 35/10000step_number: 0/29 cost:  2.6298174479784455 accuracy:  0.0\n",
      "Epoch number: 36/10000step_number: 0/29 cost:  2.62583631136057 accuracy:  0.0\n",
      "Epoch number: 37/10000step_number: 0/29 cost:  2.6220837031798707 accuracy:  0.0\n",
      "Epoch number: 38/10000step_number: 0/29 cost:  2.6185413752847317 accuracy:  0.0\n",
      "Epoch number: 39/10000step_number: 0/29 cost:  2.615185788817758 accuracy:  0.0\n",
      "Epoch number: 40/10000step_number: 0/29 cost:  2.611985478749527 accuracy:  0.0\n",
      "Epoch number: 41/10000step_number: 0/29 cost:  2.6089071652234836 accuracy:  0.0\n",
      "Epoch number: 42/10000step_number: 0/29 cost:  2.6059258670352925 accuracy:  0.0\n",
      "Epoch number: 43/10000step_number: 0/29 cost:  2.603027153838756 accuracy:  0.0\n",
      "Epoch number: 44/10000step_number: 0/29 cost:  2.600203459775152 accuracy:  0.0\n",
      "Epoch number: 45/10000step_number: 0/29 cost:  2.597448526284358 accuracy:  0.0\n",
      "Epoch number: 46/10000step_number: 0/29 cost:  2.594750552064224 accuracy:  0.0\n",
      "Epoch number: 47/10000step_number: 0/29 cost:  2.5920939907957075 accuracy:  0.0\n",
      "Epoch number: 48/10000step_number: 0/29 cost:  2.589468521135176 accuracy:  0.0\n",
      "Epoch number: 49/10000step_number: 0/29 cost:  2.586871860217643 accuracy:  0.0\n",
      "Epoch number: 50/10000step_number: 0/29 cost:  2.584304912637089 accuracy:  0.0\n",
      "Epoch number: 51/10000step_number: 0/29 cost:  2.58176757930861 accuracy:  0.0\n",
      "Epoch number: 52/10000step_number: 0/29 cost:  2.5792587646376206 accuracy:  0.0\n",
      "Epoch number: 53/10000step_number: 0/29 cost:  2.576773613817287 accuracy:  0.0\n",
      "Epoch number: 54/10000step_number: 0/29 cost:  2.5742963015949454 accuracy:  0.0\n",
      "Epoch number: 55/10000step_number: 0/29 cost:  2.57180463481732 accuracy:  0.0\n",
      "Epoch number: 56/10000step_number: 0/29 cost:  2.569286026497591 accuracy:  0.0\n",
      "Epoch number: 57/10000step_number: 0/29 cost:  2.5667407472699217 accuracy:  0.0\n",
      "Epoch number: 58/10000step_number: 0/29 cost:  2.564173429090699 accuracy:  0.0\n",
      "Epoch number: 59/10000step_number: 0/29 cost:  2.5615897832331354 accuracy:  0.0\n",
      "Epoch number: 60/10000step_number: 0/29 cost:  2.558996574439464 accuracy:  0.0\n",
      "Epoch number: 61/10000step_number: 0/29 cost:  2.556397164656588 accuracy:  0.0\n",
      "Epoch number: 62/10000step_number: 0/29 cost:  2.5537874525448516 accuracy:  0.0\n",
      "Epoch number: 63/10000step_number: 0/29 cost:  2.5511549947951493 accuracy:  0.0\n",
      "Epoch number: 64/10000step_number: 0/29 cost:  2.548480730595019 accuracy:  0.0\n",
      "Epoch number: 65/10000step_number: 0/29 cost:  2.5457478592243388 accuracy:  0.0\n",
      "Epoch number: 66/10000step_number: 0/29 cost:  2.5429504827848044 accuracy:  0.0\n",
      "Epoch number: 67/10000step_number: 0/29 cost:  2.5400921607504374 accuracy:  0.0\n",
      "Epoch number: 68/10000step_number: 0/29 cost:  2.537180265992533 accuracy:  0.0\n",
      "Epoch number: 69/10000step_number: 0/29 cost:  2.5342213920880416 accuracy:  0.0\n",
      "Epoch number: 70/10000step_number: 0/29 cost:  2.531219598148097 accuracy:  0.0\n",
      "Epoch number: 71/10000step_number: 0/29 cost:  2.5281792288287734 accuracy:  0.0\n",
      "Epoch number: 72/10000step_number: 0/29 cost:  2.5251084324214266 accuracy:  0.0\n",
      "Epoch number: 73/10000step_number: 0/29 cost:  2.5220176990713363 accuracy:  0.0\n",
      "Epoch number: 74/10000step_number: 0/29 cost:  2.5189150003711256 accuracy:  0.0\n",
      "Epoch number: 75/10000step_number: 0/29 cost:  2.5158024230172282 accuracy:  0.0\n",
      "Epoch number: 76/10000step_number: 0/29 cost:  2.512675502744733 accuracy:  0.0\n",
      "Epoch number: 77/10000step_number: 0/29 cost:  2.5095281222734687 accuracy:  0.0\n",
      "Epoch number: 78/10000step_number: 0/29 cost:  2.5063600132441253 accuracy:  0.0005448106782892945\n",
      "Epoch number: 79/10000step_number: 0/29 cost:  2.503176736416851 accuracy:  0.004494688095886679\n",
      "Epoch number: 80/10000step_number: 0/29 cost:  2.499984226045896 accuracy:  0.008172160174339417\n",
      "Epoch number: 81/10000step_number: 0/29 cost:  2.4967882716087617 accuracy:  0.01893217107055298\n",
      "Epoch number: 82/10000step_number: 0/29 cost:  2.4935966507640814 accuracy:  0.042222827567420324\n",
      "Epoch number: 83/10000step_number: 0/29 cost:  2.4904152946440217 accuracy:  0.05761372922909289\n",
      "Epoch number: 84/10000step_number: 0/29 cost:  2.487246997461091 accuracy:  0.08567147916099156\n",
      "Epoch number: 85/10000step_number: 0/29 cost:  2.4840954054260247 accuracy:  0.1061018795968401\n",
      "Epoch number: 86/10000step_number: 0/29 cost:  2.4809630541373413 accuracy:  0.12816671206755653\n",
      "Epoch number: 87/10000step_number: 0/29 cost:  2.477846767254592 accuracy:  0.14628166712067556\n",
      "Epoch number: 88/10000step_number: 0/29 cost:  2.47474985284782 accuracy:  0.16044674475619722\n",
      "Epoch number: 89/10000step_number: 0/29 cost:  2.471682815490421 accuracy:  0.1707981476436938\n",
      "Epoch number: 90/10000step_number: 0/29 cost:  2.4686499206975046 accuracy:  0.17965132116589486\n",
      "Epoch number: 91/10000step_number: 0/29 cost:  2.465654969284857 accuracy:  0.1879596840098066\n",
      "Epoch number: 92/10000step_number: 0/29 cost:  2.4627019429410573 accuracy:  0.19926450558430944\n",
      "Epoch number: 93/10000step_number: 0/29 cost:  2.459794778581263 accuracy:  0.2166984472895669\n",
      "Epoch number: 94/10000step_number: 0/29 cost:  2.4569372969043273 accuracy:  0.21942250068101335\n",
      "Epoch number: 95/10000step_number: 0/29 cost:  2.4541332745160283 accuracy:  0.2221465540724598\n",
      "Epoch number: 96/10000step_number: 0/29 cost:  2.4513865068867364 accuracy:  0.22500681013347862\n",
      "Epoch number: 97/10000step_number: 0/29 cost:  2.4487008447962815 accuracy:  0.2267774448379188\n",
      "Epoch number: 98/10000step_number: 0/29 cost:  2.446080237444276 accuracy:  0.2312721329338055\n",
      "Epoch number: 99/10000step_number: 0/29 cost:  2.443528816588643 accuracy:  0.23263415962952874\n",
      "Epoch number: 100/10000step_number: 0/29 cost:  2.4410510155629646 accuracy:  0.23440479433396894\n",
      "Epoch number: 101/10000step_number: 0/29 cost:  2.438651661485318 accuracy:  0.23576682102969218\n",
      "Epoch number: 102/10000step_number: 0/29 cost:  2.4363359778217055 accuracy:  0.23835467175156633\n",
      "Epoch number: 103/10000step_number: 0/29 cost:  2.434109476213383 accuracy:  0.23958049577771726\n",
      "Epoch number: 104/10000step_number: 0/29 cost:  2.4319777356071564 accuracy:  0.24026150912557886\n",
      "Epoch number: 105/10000step_number: 0/29 cost:  2.429946057818996 accuracy:  0.24257695450830835\n",
      "Epoch number: 106/10000step_number: 0/29 cost:  2.4280189882187653 accuracy:  0.242849359847453\n",
      "Epoch number: 107/10000step_number: 0/29 cost:  2.4261997132189146 accuracy:  0.24421138654317626\n",
      "Epoch number: 108/10000step_number: 0/29 cost:  2.4244894860846093 accuracy:  0.24570961590847182\n",
      "Epoch number: 109/10000step_number: 0/29 cost:  2.4228877878113995 accuracy:  0.24639062925633343\n",
      "Epoch number: 110/10000step_number: 0/29 cost:  2.4213938679878555 accuracy:  0.2467992372650504\n",
      "Epoch number: 111/10000step_number: 0/29 cost:  2.4200081791338706 accuracy:  0.24843366929991828\n",
      "Epoch number: 112/10000step_number: 0/29 cost:  2.418731720185467 accuracy:  0.2503405066739308\n",
      "Epoch number: 113/10000step_number: 0/29 cost:  2.417565092877381 accuracy:  0.2503405066739308\n",
      "Epoch number: 114/10000step_number: 0/29 cost:  2.416509348659668 accuracy:  0.25292835739580494\n",
      "Epoch number: 115/10000step_number: 0/29 cost:  2.415563366213169 accuracy:  0.2527921547262326\n",
      "Epoch number: 116/10000step_number: 0/29 cost:  2.4147228552861235 accuracy:  0.25619722146554075\n",
      "Epoch number: 117/10000step_number: 0/29 cost:  2.4139829405640305 accuracy:  0.2576954508308363\n",
      "Epoch number: 118/10000step_number: 0/29 cost:  2.413335834143708 accuracy:  0.2636883682920185\n",
      "Epoch number: 119/10000step_number: 0/29 cost:  2.4127642595817025 accuracy:  0.2683192590574775\n",
      "Epoch number: 120/10000step_number: 0/29 cost:  2.4122540071843517 accuracy:  0.26954508308362846\n",
      "Epoch number: 121/10000step_number: 0/29 cost:  2.4118331691554777 accuracy:  0.27431217651865974\n",
      "Epoch number: 122/10000step_number: 0/29 cost:  2.4114651061798003 accuracy:  0.27839825660582945\n",
      "Epoch number: 123/10000step_number: 0/29 cost:  2.4111284463283718 accuracy:  0.31176791065104875\n",
      "Epoch number: 124/10000step_number: 0/29 cost:  2.410832856095002 accuracy:  0.327022609643149\n",
      "Epoch number: 125/10000step_number: 0/29 cost:  2.41056485206975 accuracy:  0.3407790792699537\n",
      "Epoch number: 126/10000step_number: 0/29 cost:  2.4103611199278094 accuracy:  0.38381912285480796\n",
      "Epoch number: 127/10000step_number: 0/29 cost:  2.4101566440578135 accuracy:  0.4080631980386816\n",
      "Epoch number: 128/10000step_number: 0/29 cost:  2.4099675759713284 accuracy:  0.6357940615636066\n",
      "Epoch number: 129/10000step_number: 0/29 cost:  2.40982039555016 accuracy:  0.9035685099427949\n",
      "Epoch number: 130/10000step_number: 0/29 cost:  2.40970106928328 accuracy:  0.8681558158539907\n",
      "Epoch number: 131/10000step_number: 0/29 cost:  2.4095845608109845 accuracy:  0.8497684554617271\n",
      "Epoch number: 132/10000step_number: 0/29 cost:  2.4094768336108094 accuracy:  0.8278398256605829\n",
      "Epoch number: 133/10000step_number: 0/29 cost:  2.409344322763398 accuracy:  0.8210296921819668\n",
      "Epoch number: 134/10000step_number: 0/29 cost:  2.4092575853807823 accuracy:  0.8120403159901934\n",
      "Epoch number: 135/10000step_number: 0/29 cost:  2.409182719895697 accuracy:  0.8071370198855897\n",
      "Epoch number: 136/10000step_number: 0/29 cost:  2.4090707988117956 accuracy:  0.7978752383546718\n",
      "Epoch number: 137/10000step_number: 0/29 cost:  2.409021517741924 accuracy:  0.7935167529283574\n",
      "Epoch number: 138/10000step_number: 0/29 cost:  2.40900308712378 accuracy:  0.785344592754018\n",
      "Epoch number: 139/10000step_number: 0/29 cost:  2.408904261429509 accuracy:  0.7808499046581313\n",
      "Epoch number: 140/10000step_number: 0/29 cost:  2.408899926307546 accuracy:  0.7782620539362571\n",
      "Epoch number: 141/10000step_number: 0/29 cost:  2.408847125612445 accuracy:  0.7759466085535276\n",
      "Epoch number: 142/10000step_number: 0/29 cost:  2.4087866039526435 accuracy:  0.7715881231272133\n",
      "Epoch number: 143/10000step_number: 0/29 cost:  2.4087590350663732 accuracy:  0.7687278670661944\n",
      "Epoch number: 144/10000step_number: 0/29 cost:  2.408787411068298 accuracy:  0.7672296377008989\n",
      "Epoch number: 145/10000step_number: 0/29 cost:  2.4087410437919097 accuracy:  0.7643693816398801\n",
      "Epoch number: 146/10000step_number: 0/29 cost:  2.408717323428749 accuracy:  0.7590574775265595\n",
      "Epoch number: 147/10000step_number: 0/29 cost:  2.4088454786421774 accuracy:  0.757150640152547\n",
      "Epoch number: 148/10000step_number: 0/29 cost:  2.4087627017666593 accuracy:  0.7515663307000817\n",
      "Epoch number: 149/10000step_number: 0/29 cost:  2.4087710213953795 accuracy:  0.7504767093435031\n",
      "Epoch number: 150/10000step_number: 0/29 cost:  2.408742043856782 accuracy:  0.7485698719694907\n",
      "Epoch number: 151/10000step_number: 0/29 cost:  2.408835966518886 accuracy:  0.7477526559520566\n",
      "Epoch number: 152/10000step_number: 0/29 cost:  2.4088072883592186 accuracy:  0.742032143830019\n",
      "Epoch number: 153/10000step_number: 0/29 cost:  2.408952734283674 accuracy:  0.7450286025606102\n",
      "Epoch number: 154/10000step_number: 0/29 cost:  2.408966405467847 accuracy:  0.7436665758648869\n",
      "Epoch number: 155/10000step_number: 0/29 cost:  2.4089938615699986 accuracy:  0.7371288477254154\n",
      "Epoch number: 156/10000step_number: 0/29 cost:  2.4090409070537744 accuracy:  0.7311359302642332\n",
      "Epoch number: 157/10000step_number: 0/29 cost:  2.40919394097139 accuracy:  0.7232361754290384\n",
      "Epoch number: 158/10000step_number: 0/29 cost:  2.4093054472353295 accuracy:  0.7226913647507491\n",
      "Epoch number: 159/10000step_number: 0/29 cost:  2.409540411637457 accuracy:  0.7252792154726233\n",
      "Epoch number: 160/10000step_number: 0/29 cost:  2.409412701115944 accuracy:  0.7229637700898938\n",
      "Epoch number: 161/10000step_number: 0/29 cost:  2.409660178870168 accuracy:  0.7244619994551893\n",
      "Epoch number: 162/10000step_number: 0/29 cost:  2.4099576587487994 accuracy:  0.7296377008989376\n",
      "Epoch number: 163/10000step_number: 0/29 cost:  2.4102450257368258 accuracy:  0.733996186325252\n",
      "Epoch number: 164/10000step_number: 0/29 cost:  2.410624980370102 accuracy:  0.7348134023426859\n",
      "Epoch number: 165/10000step_number: 0/29 cost:  2.411058535535208 accuracy:  0.7363116317079815\n",
      "Epoch number: 166/10000step_number: 0/29 cost:  2.411246214464793 accuracy:  0.7388994824298556\n",
      "Epoch number: 167/10000step_number: 0/29 cost:  2.4113113450294232 accuracy:  0.7383546717515663\n",
      "Epoch number: 168/10000step_number: 0/29 cost:  2.411386099758708 accuracy:  0.7399891037864342\n",
      "Epoch number: 169/10000step_number: 0/29 cost:  2.4116008375431877 accuracy:  0.7342685916643966\n",
      "Epoch number: 170/10000step_number: 0/29 cost:  2.4118915225679167 accuracy:  0.7397166984472896\n",
      "Epoch number: 171/10000step_number: 0/29 cost:  2.4118075691907737 accuracy:  0.7435303731953147\n",
      "Epoch number: 172/10000step_number: 0/29 cost:  2.4119816509954637 accuracy:  0.7447561972214656\n",
      "Epoch number: 173/10000step_number: 0/29 cost:  2.411858142757318 accuracy:  0.7446199945518932\n",
      "Epoch number: 174/10000step_number: 0/29 cost:  2.4116323342195387 accuracy:  0.742440751838736\n",
      "Epoch number: 175/10000step_number: 0/29 cost:  2.4112961843147636 accuracy:  0.7401253064560065\n",
      "Epoch number: 176/10000step_number: 0/29 cost:  2.411076012864588 accuracy:  0.7417597384908744\n",
      "Epoch number: 177/10000step_number: 0/29 cost:  2.410714996384687 accuracy:  0.7432579678561699\n",
      "Epoch number: 178/10000step_number: 0/29 cost:  2.4104990678122813 accuracy:  0.7435303731953147\n",
      "Epoch number: 179/10000step_number: 0/29 cost:  2.4101732842870063 accuracy:  0.7421683464995914\n",
      "Epoch number: 180/10000step_number: 0/29 cost:  2.4102636615421327 accuracy:  0.7484336692999183\n",
      "Epoch number: 181/10000step_number: 0/29 cost:  2.410057497166719 accuracy:  0.7492508853173522\n",
      "Epoch number: 182/10000step_number: 0/29 cost:  2.4099334034913347 accuracy:  0.7488422773086353\n",
      "Epoch number: 183/10000step_number: 0/29 cost:  2.4100128738010262 accuracy:  0.7504767093435031\n",
      "Epoch number: 184/10000step_number: 0/29 cost:  2.4099983246759704 accuracy:  0.7507491146826478\n",
      "Epoch number: 185/10000step_number: 0/29 cost:  2.4099427604409978 accuracy:  0.7519749387087987\n",
      "Epoch number: 186/10000step_number: 0/29 cost:  2.409832591124254 accuracy:  0.752519749387088\n",
      "Epoch number: 187/10000step_number: 0/29 cost:  2.4097147816629496 accuracy:  0.752928357395805\n",
      "Epoch number: 188/10000step_number: 0/29 cost:  2.4097377578675516 accuracy:  0.7532007627349496\n",
      "Epoch number: 189/10000step_number: 0/29 cost:  2.409627368468886 accuracy:  0.7532007627349496\n",
      "Epoch number: 190/10000step_number: 0/29 cost:  2.410110238968375 accuracy:  0.7546989921002452\n",
      "Epoch number: 191/10000step_number: 0/29 cost:  2.4104178826819385 accuracy:  0.7560610187959684\n",
      "Epoch number: 192/10000step_number: 0/29 cost:  2.410828405738043 accuracy:  0.7568782348134023\n",
      "Epoch number: 193/10000step_number: 0/29 cost:  2.4114850382330717 accuracy:  0.7635521656224462\n",
      "Epoch number: 194/10000step_number: 0/29 cost:  2.411782376652336 accuracy:  0.7635521656224462\n",
      "Epoch number: 195/10000step_number: 0/29 cost:  2.4119654117124707 accuracy:  0.7625987469354399\n",
      "Epoch number: 196/10000step_number: 0/29 cost:  2.4121960673161786 accuracy:  0.7650503949877417\n",
      "Epoch number: 197/10000step_number: 0/29 cost:  2.4122342926589546 accuracy:  0.7601470988831381\n",
      "Epoch number: 198/10000step_number: 0/29 cost:  2.412395611753263 accuracy:  0.7583764641786979\n",
      "Epoch number: 199/10000step_number: 0/29 cost:  2.412574464398564 accuracy:  0.7590574775265595\n",
      "Epoch number: 200/10000step_number: 0/29 cost:  2.4127668679654337 accuracy:  0.7593298828657041\n",
      "Epoch number: 201/10000step_number: 0/29 cost:  2.412903856032125 accuracy:  0.7596022882048488\n",
      "Epoch number: 202/10000step_number: 0/29 cost:  2.4131526898694045 accuracy:  0.7561972214655407\n",
      "Epoch number: 203/10000step_number: 0/29 cost:  2.413361247147602 accuracy:  0.7557886134568238\n",
      "Epoch number: 204/10000step_number: 0/29 cost:  2.413736124160119 accuracy:  0.7563334241351131\n",
      "Epoch number: 205/10000step_number: 0/29 cost:  2.414097506470377 accuracy:  0.7567420321438301\n",
      "Epoch number: 206/10000step_number: 0/29 cost:  2.414656687691007 accuracy:  0.757967856169981\n",
      "Epoch number: 207/10000step_number: 0/29 cost:  2.4147926672254925 accuracy:  0.7496594933260692\n",
      "Epoch number: 208/10000step_number: 0/29 cost:  2.415547337246373 accuracy:  0.7510215200217925\n",
      "Epoch number: 209/10000step_number: 0/29 cost:  2.4160751324750094 accuracy:  0.7514301280305093\n",
      "Epoch number: 210/10000step_number: 0/29 cost:  2.41772548246513 accuracy:  0.7650503949877417\n",
      "Epoch number: 211/10000step_number: 0/29 cost:  2.418451798471225 accuracy:  0.7608281122309998\n",
      "Epoch number: 212/10000step_number: 0/29 cost:  2.4193124689695966 accuracy:  0.7606919095614274\n",
      "Epoch number: 213/10000step_number: 0/29 cost:  2.419807796921824 accuracy:  0.7606919095614274\n",
      "Epoch number: 214/10000step_number: 0/29 cost:  2.420540062066184 accuracy:  0.7549713974393898\n",
      "Epoch number: 215/10000step_number: 0/29 cost:  2.4211454091815527 accuracy:  0.7548351947698175\n",
      "Epoch number: 216/10000step_number: 0/29 cost:  2.4218253955358344 accuracy:  0.7548351947698175\n",
      "Epoch number: 217/10000step_number: 0/29 cost:  2.4224068005332238 accuracy:  0.7549713974393898\n",
      "Epoch number: 218/10000step_number: 0/29 cost:  2.4233977278753684 accuracy:  0.7559248161263961\n",
      "Epoch number: 219/10000step_number: 0/29 cost:  2.4242264855290987 accuracy:  0.757150640152547\n",
      "Epoch number: 220/10000step_number: 0/29 cost:  2.4246054164814037 accuracy:  0.7518387360392264\n",
      "Epoch number: 221/10000step_number: 0/29 cost:  2.425796409305299 accuracy:  0.7534731680740943\n",
      "Epoch number: 222/10000step_number: 0/29 cost:  2.4269117947669527 accuracy:  0.7553800054481068\n",
      "Epoch number: 223/10000step_number: 0/29 cost:  2.4275953737799054 accuracy:  0.7489784799782075\n",
      "Epoch number: 224/10000step_number: 0/29 cost:  2.428924622930843 accuracy:  0.7552438027785344\n",
      "Epoch number: 225/10000step_number: 0/29 cost:  2.4292441951841837 accuracy:  0.7413511304821575\n",
      "Epoch number: 226/10000step_number: 0/29 cost:  2.4309059809145315 accuracy:  0.7493870879869245\n",
      "Epoch number: 227/10000step_number: 0/29 cost:  2.4312992313947626 accuracy:  0.7374012530645601\n",
      "Epoch number: 228/10000step_number: 0/29 cost:  2.432772808190493 accuracy:  0.7406701171342959\n",
      "Epoch number: 229/10000step_number: 0/29 cost:  2.4333835242863895 accuracy:  0.7307273222555162\n",
      "Epoch number: 230/10000step_number: 0/29 cost:  2.4346905620093695 accuracy:  0.7311359302642332\n",
      "Epoch number: 231/10000step_number: 0/29 cost:  2.4355055879566336 accuracy:  0.7145192045764097\n",
      "Epoch number: 232/10000step_number: 0/29 cost:  2.4366729877303914 accuracy:  0.7098883138109507\n",
      "Epoch number: 233/10000step_number: 0/29 cost:  2.4376298624763906 accuracy:  0.6977662762190139\n",
      "Epoch number: 234/10000step_number: 0/29 cost:  2.438719522950249 accuracy:  0.6836011985834922\n",
      "Epoch number: 235/10000step_number: 0/29 cost:  2.4397456942884186 accuracy:  0.6731135930264233\n",
      "Epoch number: 236/10000step_number: 0/29 cost:  2.4408020804284587 accuracy:  0.6510487605557069\n",
      "Epoch number: 237/10000step_number: 0/29 cost:  2.441842556641496 accuracy:  0.6329338055025878\n",
      "Epoch number: 238/10000step_number: 0/29 cost:  2.442879565161469 accuracy:  0.6268046853718333\n",
      "Epoch number: 239/10000step_number: 0/29 cost:  2.443902385127368 accuracy:  0.616998093162626\n",
      "Epoch number: 240/10000step_number: 0/29 cost:  2.444909499041497 accuracy:  0.5913919912830291\n",
      "Epoch number: 241/10000step_number: 0/29 cost:  2.445894130768968 accuracy:  0.5830836284391174\n",
      "Epoch number: 242/10000step_number: 0/29 cost:  2.446853203280347 accuracy:  0.5773631163170798\n",
      "Epoch number: 243/10000step_number: 0/29 cost:  2.447783048226187 accuracy:  0.5704167801688913\n",
      "Epoch number: 244/10000step_number: 0/29 cost:  2.448682547747253 accuracy:  0.5648324707164261\n",
      "Epoch number: 245/10000step_number: 0/29 cost:  2.4495523426409367 accuracy:  0.5529828384636339\n",
      "Epoch number: 246/10000step_number: 0/29 cost:  2.450392930847741 accuracy:  0.5433124489239989\n",
      "Epoch number: 247/10000step_number: 0/29 cost:  2.4512057627093315 accuracy:  0.5358213020975211\n",
      "Epoch number: 248/10000step_number: 0/29 cost:  2.4519916951317717 accuracy:  0.528193952601471\n",
      "Epoch number: 249/10000step_number: 0/29 cost:  2.452752881589148 accuracy:  0.5192045764096976\n",
      "Epoch number: 250/10000step_number: 0/29 cost:  2.4534934027024393 accuracy:  0.4964587305911196\n",
      "Epoch number: 251/10000step_number: 0/29 cost:  2.454222056375077 accuracy:  0.4892399891037864\n",
      "Epoch number: 252/10000step_number: 0/29 cost:  2.454950180064608 accuracy:  0.48637973304276766\n",
      "Epoch number: 253/10000step_number: 0/29 cost:  2.4556730841912406 accuracy:  0.4827022609643149\n",
      "Epoch number: 254/10000step_number: 0/29 cost:  2.4563578689295027 accuracy:  0.4761645328248434\n",
      "Epoch number: 255/10000step_number: 0/29 cost:  2.456993548276673 accuracy:  0.4733042767638246\n",
      "Epoch number: 256/10000step_number: 0/29 cost:  2.457587777158551 accuracy:  0.46622173794606375\n",
      "Epoch number: 257/10000step_number: 0/29 cost:  2.458115773667352 accuracy:  0.45982021247616456\n",
      "Epoch number: 258/10000step_number: 0/29 cost:  2.458541315094709 accuracy:  0.4520566603105421\n",
      "Epoch number: 259/10000step_number: 0/29 cost:  2.4588310976434253 accuracy:  0.4534186870062653\n",
      "Epoch number: 260/10000step_number: 0/29 cost:  2.4589876665372006 accuracy:  0.44756197221465543\n",
      "Epoch number: 261/10000step_number: 0/29 cost:  2.45903715044963 accuracy:  0.4414328520839008\n",
      "Epoch number: 262/10000step_number: 0/29 cost:  2.459014850958348 accuracy:  0.43802778534459275\n",
      "Epoch number: 263/10000step_number: 0/29 cost:  2.458936788996104 accuracy:  0.4374829746663035\n",
      "Epoch number: 264/10000step_number: 0/29 cost:  2.458810638488408 accuracy:  0.43693816398801416\n",
      "Epoch number: 265/10000step_number: 0/29 cost:  2.458636587613577 accuracy:  0.4374829746663035\n",
      "Epoch number: 266/10000step_number: 0/29 cost:  2.4584132540898214 accuracy:  0.4365295559792972\n",
      "Epoch number: 267/10000step_number: 0/29 cost:  2.4581391918030477 accuracy:  0.43666575864886953\n",
      "Epoch number: 268/10000step_number: 0/29 cost:  2.4578153940578176 accuracy:  0.43693816398801416\n",
      "Epoch number: 269/10000step_number: 0/29 cost:  2.4574459601799097 accuracy:  0.43789158267502043\n",
      "Epoch number: 270/10000step_number: 0/29 cost:  2.4570385119375677 accuracy:  0.44088804140561155\n",
      "Epoch number: 271/10000step_number: 0/29 cost:  2.4566028030914264 accuracy:  0.44197766276219014\n",
      "Epoch number: 272/10000step_number: 0/29 cost:  2.4561476693736193 accuracy:  0.4457913375102152\n",
      "Epoch number: 273/10000step_number: 0/29 cost:  2.455677601849295 accuracy:  0.44783437755380007\n",
      "Epoch number: 274/10000step_number: 0/29 cost:  2.4551924228750597 accuracy:  0.4509670389539635\n",
      "Epoch number: 275/10000step_number: 0/29 cost:  2.4546889410478783 accuracy:  0.45137564696268045\n",
      "Epoch number: 276/10000step_number: 0/29 cost:  2.4541592018369958 accuracy:  0.45151184963225277\n",
      "Epoch number: 277/10000step_number: 0/29 cost:  2.453586100721086 accuracy:  0.45260147098883136\n",
      "Epoch number: 278/10000step_number: 0/29 cost:  2.4529406977539026 accuracy:  0.453282484336693\n",
      "Epoch number: 279/10000step_number: 0/29 cost:  2.4521904779082107 accuracy:  0.4535548896758376\n",
      "Epoch number: 280/10000step_number: 0/29 cost:  2.4513155104732904 accuracy:  0.4538272950149823\n",
      "Epoch number: 281/10000step_number: 0/29 cost:  2.4503139281511856 accuracy:  0.45518932171070553\n",
      "Epoch number: 282/10000step_number: 0/29 cost:  2.4491932005519046 accuracy:  0.45641514573685643\n",
      "Epoch number: 283/10000step_number: 0/29 cost:  2.4479584603830244 accuracy:  0.45668755107600106\n",
      "Epoch number: 284/10000step_number: 0/29 cost:  2.4466073985499333 accuracy:  0.457504767093435\n",
      "Epoch number: 285/10000step_number: 0/29 cost:  2.445133472876177 accuracy:  0.4572323617542904\n",
      "Epoch number: 286/10000step_number: 0/29 cost:  2.443518192847029 accuracy:  0.45682375374557344\n",
      "Epoch number: 287/10000step_number: 0/29 cost:  2.4416574734574135 accuracy:  0.4560065377281395\n",
      "Epoch number: 288/10000step_number: 0/29 cost:  2.439292450012438 accuracy:  0.45532552438027785\n",
      "Epoch number: 289/10000step_number: 0/29 cost:  2.4367658835166157 accuracy:  0.45123944429310814\n",
      "Epoch number: 290/10000step_number: 0/29 cost:  2.434686294027021 accuracy:  0.44906020157995097\n",
      "Epoch number: 291/10000step_number: 0/29 cost:  2.432702667827349 accuracy:  0.44742576954508306\n",
      "Epoch number: 292/10000step_number: 0/29 cost:  2.430676072679409 accuracy:  0.44783437755380007\n",
      "Epoch number: 293/10000step_number: 0/29 cost:  2.428588023102156 accuracy:  0.44769817488422775\n",
      "Epoch number: 294/10000step_number: 0/29 cost:  2.4264393461307656 accuracy:  0.448242985562517\n",
      "Epoch number: 295/10000step_number: 0/29 cost:  2.424231792631154 accuracy:  0.448651593571234\n",
      "Epoch number: 296/10000step_number: 0/29 cost:  2.421964526812575 accuracy:  0.4493326069190956\n",
      "Epoch number: 297/10000step_number: 0/29 cost:  2.4196320699307265 accuracy:  0.4496050122582403\n",
      "Epoch number: 298/10000step_number: 0/29 cost:  2.4172246035931813 accuracy:  0.4491964042495233\n",
      "Epoch number: 299/10000step_number: 0/29 cost:  2.4147312260596006 accuracy:  0.4504222282756742\n",
      "Epoch number: 300/10000step_number: 0/29 cost:  2.412145555953145 accuracy:  0.45137564696268045\n",
      "Epoch number: 301/10000step_number: 0/29 cost:  2.4094728318172365 accuracy:  0.45164805230182514\n",
      "Epoch number: 302/10000step_number: 0/29 cost:  2.4067355542191335 accuracy:  0.45246526831925904\n",
      "Epoch number: 303/10000step_number: 0/29 cost:  2.403967560596502 accuracy:  0.453282484336693\n",
      "Epoch number: 304/10000step_number: 0/29 cost:  2.401194959786372 accuracy:  0.4547807137019886\n",
      "Epoch number: 305/10000step_number: 0/29 cost:  2.398424006959418 accuracy:  0.45709615908471807\n",
      "Epoch number: 306/10000step_number: 0/29 cost:  2.3956455198067643 accuracy:  0.45832198311086897\n",
      "Epoch number: 307/10000step_number: 0/29 cost:  2.392844608714857 accuracy:  0.46213565785889404\n",
      "Epoch number: 308/10000step_number: 0/29 cost:  2.3900068489739303 accuracy:  0.46336148188504495\n",
      "Epoch number: 309/10000step_number: 0/29 cost:  2.387121069297423 accuracy:  0.4670389539634977\n",
      "Epoch number: 310/10000step_number: 0/29 cost:  2.3841814271322557 accuracy:  0.46894579133751024\n",
      "Epoch number: 311/10000step_number: 0/29 cost:  2.3811897505566257 accuracy:  0.4719422500681013\n",
      "Epoch number: 312/10000step_number: 0/29 cost:  2.378156825448209 accuracy:  0.4745301007899755\n",
      "Epoch number: 313/10000step_number: 0/29 cost:  2.375099810430998 accuracy:  0.4802506129120131\n",
      "Epoch number: 314/10000step_number: 0/29 cost:  2.372034116980148 accuracy:  0.4931898665213838\n",
      "Epoch number: 315/10000step_number: 0/29 cost:  2.3689627489429377 accuracy:  0.49904658131299373\n",
      "Epoch number: 316/10000step_number: 0/29 cost:  2.3658685279747895 accuracy:  0.5034050667393081\n",
      "Epoch number: 317/10000step_number: 0/29 cost:  2.362715277220572 accuracy:  0.5065377281394715\n",
      "Epoch number: 318/10000step_number: 0/29 cost:  2.3594653664813303 accuracy:  0.5107600108962136\n",
      "Epoch number: 319/10000step_number: 0/29 cost:  2.3560955254348883 accuracy:  0.5192045764096976\n",
      "Epoch number: 320/10000step_number: 0/29 cost:  2.3525925529727396 accuracy:  0.5236992645055843\n",
      "Epoch number: 321/10000step_number: 0/29 cost:  2.3489433965007174 accuracy:  0.5303731953146281\n",
      "Epoch number: 322/10000step_number: 0/29 cost:  2.345127010316177 accuracy:  0.5321438300190684\n",
      "Epoch number: 323/10000step_number: 0/29 cost:  2.341109871553809 accuracy:  0.5321438300190684\n",
      "Epoch number: 324/10000step_number: 0/29 cost:  2.3368651266462446 accuracy:  0.5367747207845274\n",
      "Epoch number: 325/10000step_number: 0/29 cost:  2.3323917131070355 accuracy:  0.5380005448106783\n",
      "Epoch number: 326/10000step_number: 0/29 cost:  2.3277017356958223 accuracy:  0.542495232906565\n",
      "Epoch number: 327/10000step_number: 0/29 cost:  2.3227939516726 accuracy:  0.5566603105420866\n",
      "Epoch number: 328/10000step_number: 0/29 cost:  2.3176610316394832 accuracy:  0.566466902751294\n",
      "Epoch number: 329/10000step_number: 0/29 cost:  2.3123035556319365 accuracy:  0.5719150095341868\n",
      "Epoch number: 330/10000step_number: 0/29 cost:  2.3066779251749647 accuracy:  0.5760010896213565\n",
      "Epoch number: 331/10000step_number: 0/29 cost:  2.3007407160192512 accuracy:  0.5859438845001362\n",
      "Epoch number: 332/10000step_number: 0/29 cost:  2.2944790620438322 accuracy:  0.5794061563606646\n",
      "Epoch number: 333/10000step_number: 0/29 cost:  2.2878926655935077 accuracy:  0.5862162898392809\n",
      "Epoch number: 334/10000step_number: 0/29 cost:  2.280991030964385 accuracy:  0.5968400980659221\n",
      "Epoch number: 335/10000step_number: 0/29 cost:  2.273793232038827 accuracy:  0.6078725143012803\n",
      "Epoch number: 336/10000step_number: 0/29 cost:  2.2662412933433673 accuracy:  0.6133206210841733\n",
      "Epoch number: 337/10000step_number: 0/29 cost:  2.2579325330466804 accuracy:  0.6179515118496323\n",
      "Epoch number: 338/10000step_number: 0/29 cost:  2.2489618547145573 accuracy:  0.6161808771451921\n",
      "Epoch number: 339/10000step_number: 0/29 cost:  2.2406217611069232 accuracy:  0.6212203759193681\n",
      "Epoch number: 340/10000step_number: 0/29 cost:  2.233248869549763 accuracy:  0.6225824026150912\n",
      "Epoch number: 341/10000step_number: 0/29 cost:  2.2262648653464483 accuracy:  0.6204031599019341\n",
      "Epoch number: 342/10000step_number: 0/29 cost:  2.2194919707715717 accuracy:  0.6111413783710161\n",
      "Epoch number: 343/10000step_number: 0/29 cost:  2.21287555439228 accuracy:  0.6112775810405884\n",
      "Epoch number: 344/10000step_number: 0/29 cost:  2.2063689887614957 accuracy:  0.5979297194225007\n",
      "Epoch number: 345/10000step_number: 0/29 cost:  2.199904065761804 accuracy:  0.5969763007354945\n",
      "Epoch number: 346/10000step_number: 0/29 cost:  2.192910027770412 accuracy:  0.5920730046308907\n",
      "Epoch number: 347/10000step_number: 0/29 cost:  2.1839338862326785 accuracy:  0.59847453010079\n",
      "Epoch number: 348/10000step_number: 0/29 cost:  2.1781525961170383 accuracy:  0.5997003541269409\n",
      "Epoch number: 349/10000step_number: 0/29 cost:  2.173398549153552 accuracy:  0.6020157995096704\n",
      "Epoch number: 350/10000step_number: 0/29 cost:  2.167642408815866 accuracy:  0.6041950422228276\n",
      "Epoch number: 351/10000step_number: 0/29 cost:  2.159952820121711 accuracy:  0.6152274584581858\n",
      "Epoch number: 352/10000step_number: 0/29 cost:  2.1551867414674977 accuracy:  0.6383819122854808\n",
      "Epoch number: 353/10000step_number: 0/29 cost:  2.1516932043451287 accuracy:  0.6661672568782349\n",
      "Epoch number: 354/10000step_number: 0/29 cost:  2.14830495842728 accuracy:  0.6771996731135931\n",
      "Epoch number: 355/10000step_number: 0/29 cost:  2.1450176300868655 accuracy:  0.6927267774448379\n",
      "Epoch number: 356/10000step_number: 0/29 cost:  2.1418602462445793 accuracy:  0.7030781803323345\n",
      "Epoch number: 357/10000step_number: 0/29 cost:  2.138826786163417 accuracy:  0.705802233723781\n",
      "Epoch number: 358/10000step_number: 0/29 cost:  2.135884111080231 accuracy:  0.7164260419504223\n",
      "Epoch number: 359/10000step_number: 0/29 cost:  2.1330931615309954 accuracy:  0.7183328793244348\n",
      "Epoch number: 360/10000step_number: 0/29 cost:  2.130396847210535 accuracy:  0.7432579678561699\n",
      "Epoch number: 361/10000step_number: 0/29 cost:  2.127832690087399 accuracy:  0.7777172432579679\n",
      "Epoch number: 362/10000step_number: 0/29 cost:  2.1253782255993254 accuracy:  0.8011441024244075\n",
      "Epoch number: 363/10000step_number: 0/29 cost:  2.123031825886085 accuracy:  0.8198038681558159\n",
      "Epoch number: 364/10000step_number: 0/29 cost:  2.1207851668636493 accuracy:  0.8195314628166712\n",
      "Epoch number: 365/10000step_number: 0/29 cost:  2.118629722310787 accuracy:  0.8166712067556524\n",
      "Epoch number: 366/10000step_number: 0/29 cost:  2.116556612175486 accuracy:  0.8259329882865705\n",
      "Epoch number: 367/10000step_number: 0/29 cost:  2.1145577447678505 accuracy:  0.8228003268864069\n",
      "Epoch number: 368/10000step_number: 0/29 cost:  2.1126261763360126 accuracy:  0.8232089348951239\n",
      "Epoch number: 369/10000step_number: 0/29 cost:  2.1107568012621285 accuracy:  0.8217107055298284\n",
      "Epoch number: 370/10000step_number: 0/29 cost:  2.108947449524195 accuracy:  0.8157177880686461\n",
      "Epoch number: 371/10000step_number: 0/29 cost:  2.1071855779345823 accuracy:  0.8114955053119041\n",
      "Epoch number: 372/10000step_number: 0/29 cost:  2.1054477855002007 accuracy:  0.8086352492508854\n",
      "Epoch number: 373/10000step_number: 0/29 cost:  2.103800015051804 accuracy:  0.8063198038681558\n",
      "Epoch number: 374/10000step_number: 0/29 cost:  2.1021523680456884 accuracy:  0.8151729773903569\n",
      "Epoch number: 375/10000step_number: 0/29 cost:  2.1005557819374907 accuracy:  0.8155815853990738\n",
      "Epoch number: 376/10000step_number: 0/29 cost:  2.0990077816674058 accuracy:  0.8116317079814764\n",
      "Epoch number: 377/10000step_number: 0/29 cost:  2.0974541932992388 accuracy:  0.8129937346771997\n",
      "Epoch number: 378/10000step_number: 0/29 cost:  2.0959827557304163 accuracy:  0.8183056387905203\n",
      "Epoch number: 379/10000step_number: 0/29 cost:  2.094443769723535 accuracy:  0.8230727322255517\n",
      "Epoch number: 380/10000step_number: 0/29 cost:  2.092825733556616 accuracy:  0.8249795695995642\n",
      "Epoch number: 381/10000step_number: 0/29 cost:  2.0908118333889463 accuracy:  0.813538545355489\n",
      "Epoch number: 382/10000step_number: 0/29 cost:  2.0893327678594105 accuracy:  0.7966494143285209\n",
      "Epoch number: 383/10000step_number: 0/29 cost:  2.0883612609050526 accuracy:  0.8005992917461182\n",
      "Epoch number: 384/10000step_number: 0/29 cost:  2.0872758649222343 accuracy:  0.8037319531462817\n",
      "Epoch number: 385/10000step_number: 0/29 cost:  2.086130693853331 accuracy:  0.8075456278943067\n",
      "Epoch number: 386/10000step_number: 0/29 cost:  2.085021807317692 accuracy:  0.813129937346772\n",
      "Epoch number: 387/10000step_number: 0/29 cost:  2.0838969711632984 accuracy:  0.8191228548079542\n",
      "Epoch number: 388/10000step_number: 0/29 cost:  2.082813758215074 accuracy:  0.8218469081994008\n",
      "Epoch number: 389/10000step_number: 0/29 cost:  2.0817333531619595 accuracy:  0.827022609643149\n",
      "Epoch number: 390/10000step_number: 0/29 cost:  2.0806909421863686 accuracy:  0.8335603377826205\n",
      "Epoch number: 391/10000step_number: 0/29 cost:  2.0796604543941313 accuracy:  0.8385998365567965\n",
      "Epoch number: 392/10000step_number: 0/29 cost:  2.078663911703469 accuracy:  0.8433669299918278\n",
      "Epoch number: 393/10000step_number: 0/29 cost:  2.077685046534037 accuracy:  0.8493598474530101\n",
      "Epoch number: 394/10000step_number: 0/29 cost:  2.07673675902841 accuracy:  0.8587578316535004\n",
      "Epoch number: 395/10000step_number: 0/29 cost:  2.0758099168371547 accuracy:  0.864069735766821\n",
      "Epoch number: 396/10000step_number: 0/29 cost:  2.0749114029469102 accuracy:  0.8687006265322801\n",
      "Epoch number: 397/10000step_number: 0/29 cost:  2.0740366076023893 accuracy:  0.8751021520021792\n",
      "Epoch number: 398/10000step_number: 0/29 cost:  2.073188778264138 accuracy:  0.8828657041678016\n",
      "Epoch number: 399/10000step_number: 0/29 cost:  2.07236575837282 accuracy:  0.8906292563334242\n",
      "Epoch number: 400/10000step_number: 0/29 cost:  2.0715688352889865 accuracy:  0.8928084990465813\n",
      "Epoch number: 401/10000step_number: 0/29 cost:  2.0707970003539793 accuracy:  0.8962135657858894\n",
      "Epoch number: 402/10000step_number: 0/29 cost:  2.070050618190718 accuracy:  0.90152546989921\n",
      "Epoch number: 403/10000step_number: 0/29 cost:  2.0693291633982827 accuracy:  0.9024788885862163\n",
      "Epoch number: 404/10000step_number: 0/29 cost:  2.068632621739522 accuracy:  0.9050667393080905\n",
      "Epoch number: 405/10000step_number: 0/29 cost:  2.0679606523719816 accuracy:  0.90738218469082\n",
      "Epoch number: 406/10000step_number: 0/29 cost:  2.0673130876470096 accuracy:  0.9081994007082539\n",
      "Epoch number: 407/10000step_number: 0/29 cost:  2.0666896303653925 accuracy:  0.9005720512122037\n",
      "Epoch number: 408/10000step_number: 0/29 cost:  2.066090022463541 accuracy:  0.901116861890493\n",
      "Epoch number: 409/10000step_number: 0/29 cost:  2.065513936319733 accuracy:  0.9031599019340779\n",
      "Epoch number: 410/10000step_number: 0/29 cost:  2.0649610313888807 accuracy:  0.9039771179515118\n",
      "Epoch number: 411/10000step_number: 0/29 cost:  2.064430918516474 accuracy:  0.9041133206210842\n",
      "Epoch number: 412/10000step_number: 0/29 cost:  2.0639231829995106 accuracy:  0.9041133206210842\n",
      "Epoch number: 413/10000step_number: 0/29 cost:  2.063437378308878 accuracy:  0.9038409152819395\n",
      "Epoch number: 414/10000step_number: 0/29 cost:  2.062973040382573 accuracy:  0.9046581312993734\n",
      "Epoch number: 415/10000step_number: 0/29 cost:  2.062529692488063 accuracy:  0.9041133206210842\n",
      "Epoch number: 416/10000step_number: 0/29 cost:  2.0621068559365874 accuracy:  0.9038409152819395\n",
      "Epoch number: 417/10000step_number: 0/29 cost:  2.061704056579298 accuracy:  0.9026150912557886\n",
      "Epoch number: 418/10000step_number: 0/29 cost:  2.0613208310238877 accuracy:  0.9020702805774993\n",
      "Epoch number: 419/10000step_number: 0/29 cost:  2.0609567294965956 accuracy:  0.9020702805774993\n",
      "Epoch number: 420/10000step_number: 0/29 cost:  2.060611316130803 accuracy:  0.90152546989921\n",
      "Epoch number: 421/10000step_number: 0/29 cost:  2.0602841663801925 accuracy:  0.9008444565513484\n",
      "Epoch number: 422/10000step_number: 0/29 cost:  2.05997486213936 accuracy:  0.9001634432034867\n",
      "Epoch number: 423/10000step_number: 0/29 cost:  2.0596829857378784 accuracy:  0.8983928084990466\n",
      "Epoch number: 424/10000step_number: 0/29 cost:  2.0594081139124127 accuracy:  0.8981204031599019\n",
      "Epoch number: 425/10000step_number: 0/29 cost:  2.0591498132439723 accuracy:  0.8971669844728957\n",
      "Epoch number: 426/10000step_number: 0/29 cost:  2.058907637711456 accuracy:  0.8970307818033233\n",
      "Epoch number: 427/10000step_number: 0/29 cost:  2.058681128736331 accuracy:  0.8963497684554618\n",
      "Epoch number: 428/10000step_number: 0/29 cost:  2.0584698172310825 accuracy:  0.8955325524380278\n",
      "Epoch number: 429/10000step_number: 0/29 cost:  2.0582732271768975 accuracy:  0.8953963497684555\n",
      "Epoch number: 430/10000step_number: 0/29 cost:  2.058090880151825 accuracy:  0.8948515390901661\n",
      "Epoch number: 431/10000step_number: 0/29 cost:  2.0579223005936167 accuracy:  0.8948515390901661\n",
      "Epoch number: 432/10000step_number: 0/29 cost:  2.0577670215800894 accuracy:  0.8949877417597385\n",
      "Epoch number: 433/10000step_number: 0/29 cost:  2.0576245909236897 accuracy:  0.8945791337510215\n",
      "Epoch number: 434/10000step_number: 0/29 cost:  2.0574945771539297 accuracy:  0.8943067284118769\n",
      "Epoch number: 435/10000step_number: 0/29 cost:  2.057376574924799 accuracy:  0.8938981204031599\n",
      "Epoch number: 436/10000step_number: 0/29 cost:  2.057270209454354 accuracy:  0.893489512394443\n",
      "Epoch number: 437/10000step_number: 0/29 cost:  2.0571751398763856 accuracy:  0.892672296377009\n",
      "Epoch number: 438/10000step_number: 0/29 cost:  2.057091061603192 accuracy:  0.8922636883682921\n",
      "Epoch number: 439/10000step_number: 0/29 cost:  2.0570177078278205 accuracy:  0.8922636883682921\n",
      "Epoch number: 440/10000step_number: 0/29 cost:  2.0569548499341748 accuracy:  0.8917188776900027\n",
      "Epoch number: 441/10000step_number: 0/29 cost:  2.0569022959145076 accuracy:  0.8913102696812858\n",
      "Epoch number: 442/10000step_number: 0/29 cost:  2.056859885416793 accuracy:  0.8913102696812858\n",
      "Epoch number: 443/10000step_number: 0/29 cost:  2.0568274808035723 accuracy:  0.8906292563334242\n",
      "Epoch number: 444/10000step_number: 0/29 cost:  2.0568049560853137 accuracy:  0.8902206483247072\n",
      "Epoch number: 445/10000step_number: 0/29 cost:  2.05679218806797 accuracy:  0.8899482429855625\n",
      "Epoch number: 446/10000step_number: 0/29 cost:  2.056789053326026 accuracy:  0.8895396349768455\n",
      "Epoch number: 447/10000step_number: 0/29 cost:  2.0567954302947706 accuracy:  0.8889948242985563\n",
      "Epoch number: 448/10000step_number: 0/29 cost:  2.0568112019492193 accuracy:  0.8889948242985563\n",
      "Epoch number: 449/10000step_number: 0/29 cost:  2.056836254835677 accuracy:  0.8887224189594116\n",
      "Epoch number: 450/10000step_number: 0/29 cost:  2.0568704735623826 accuracy:  0.88804140561155\n",
      "Epoch number: 451/10000step_number: 0/29 cost:  2.056913732796827 accuracy:  0.8877690002724054\n",
      "Epoch number: 452/10000step_number: 0/29 cost:  2.0569658896190894 accuracy:  0.8873603922636883\n",
      "Epoch number: 453/10000step_number: 0/29 cost:  2.057026778255574 accuracy:  0.8865431762462544\n",
      "Epoch number: 454/10000step_number: 0/29 cost:  2.057096207910967 accuracy:  0.8865431762462544\n",
      "Epoch number: 455/10000step_number: 0/29 cost:  2.0571739633408295 accuracy:  0.8866793789158267\n",
      "Epoch number: 456/10000step_number: 0/29 cost:  2.0572598071840194 accuracy:  0.8862707709071098\n",
      "Epoch number: 457/10000step_number: 0/29 cost:  2.057353482889438 accuracy:  0.8859983655679652\n",
      "Epoch number: 458/10000step_number: 0/29 cost:  2.0574547172313675 accuracy:  0.8857259602288204\n",
      "Epoch number: 459/10000step_number: 0/29 cost:  2.0575632217761872 accuracy:  0.8859983655679652\n",
      "Epoch number: 460/10000step_number: 0/29 cost:  2.0576786930821562 accuracy:  0.8859983655679652\n",
      "Epoch number: 461/10000step_number: 0/29 cost:  2.0578008117472035 accuracy:  0.8857259602288204\n",
      "Epoch number: 462/10000step_number: 0/29 cost:  2.0579292405989538 accuracy:  0.8857259602288204\n",
      "Epoch number: 463/10000step_number: 0/29 cost:  2.0580636223570314 accuracy:  0.8859983655679652\n",
      "Epoch number: 464/10000step_number: 0/29 cost:  2.058203577051495 accuracy:  0.8853173522201035\n",
      "Epoch number: 465/10000step_number: 0/29 cost:  2.0583486994242475 accuracy:  0.8853173522201035\n",
      "Epoch number: 466/10000step_number: 0/29 cost:  2.0584985565270943 accuracy:  0.8851811495505312\n",
      "Epoch number: 467/10000step_number: 0/29 cost:  2.058652685790543 accuracy:  0.8849087442113865\n",
      "Epoch number: 468/10000step_number: 0/29 cost:  2.058810593965583 accuracy:  0.8847725415418142\n",
      "Epoch number: 469/10000step_number: 0/29 cost:  2.0589717574561726 accuracy:  0.8846363388722419\n",
      "Epoch number: 470/10000step_number: 0/29 cost:  2.0591356244719488 accuracy:  0.8845001362026695\n",
      "Epoch number: 471/10000step_number: 0/29 cost:  2.0593016189276976 accuracy:  0.8845001362026695\n",
      "Epoch number: 472/10000step_number: 0/29 cost:  2.0594691451763847 accuracy:  0.8840915281939526\n",
      "Epoch number: 473/10000step_number: 0/29 cost:  2.0596375920945316 accuracy:  0.8842277308635249\n",
      "Epoch number: 474/10000step_number: 0/29 cost:  2.059806335451678 accuracy:  0.8846363388722419\n",
      "Epoch number: 475/10000step_number: 0/29 cost:  2.0599747387469747 accuracy:  0.8850449468809589\n",
      "Epoch number: 476/10000step_number: 0/29 cost:  2.0601421536876425 accuracy:  0.8851811495505312\n",
      "Epoch number: 477/10000step_number: 0/29 cost:  2.060307921419452 accuracy:  0.8851811495505312\n",
      "Epoch number: 478/10000step_number: 0/29 cost:  2.060471374884859 accuracy:  0.8851811495505312\n",
      "Epoch number: 479/10000step_number: 0/29 cost:  2.0606318421601335 accuracy:  0.8850449468809589\n",
      "Epoch number: 480/10000step_number: 0/29 cost:  2.0607886506623574 accuracy:  0.8862707709071098\n",
      "Epoch number: 481/10000step_number: 0/29 cost:  2.060941132459499 accuracy:  0.8870879869245437\n",
      "Epoch number: 482/10000step_number: 0/29 cost:  2.061088631195966 accuracy:  0.8873603922636883\n",
      "Epoch number: 483/10000step_number: 0/29 cost:  2.061230511224145 accuracy:  0.8872241895941161\n",
      "Epoch number: 484/10000step_number: 0/29 cost:  2.061366169457951 accuracy:  0.8874965949332607\n",
      "Epoch number: 485/10000step_number: 0/29 cost:  2.061495050306095 accuracy:  0.8869517842549713\n",
      "Epoch number: 486/10000step_number: 0/29 cost:  2.061616663817555 accuracy:  0.8870879869245437\n",
      "Epoch number: 487/10000step_number: 0/29 cost:  2.061730606864491 accuracy:  0.8869517842549713\n",
      "Epoch number: 488/10000step_number: 0/29 cost:  2.0618365867969843 accuracy:  0.8868155815853991\n",
      "Epoch number: 489/10000step_number: 0/29 cost:  2.0619344465721268 accuracy:  0.8866793789158267\n",
      "Epoch number: 490/10000step_number: 0/29 cost:  2.0620241899683434 accuracy:  0.8868155815853991\n",
      "Epoch number: 491/10000step_number: 0/29 cost:  2.0621060052160347 accuracy:  0.8861345682375374\n",
      "Epoch number: 492/10000step_number: 0/29 cost:  2.0621802852238553 accuracy:  0.8861345682375374\n",
      "Epoch number: 493/10000step_number: 0/29 cost:  2.0622476425308776 accuracy:  0.8865431762462544\n",
      "Epoch number: 494/10000step_number: 0/29 cost:  2.062308917167963 accuracy:  0.8865431762462544\n",
      "Epoch number: 495/10000step_number: 0/29 cost:  2.06236517583696 accuracy:  0.8865431762462544\n",
      "Epoch number: 496/10000step_number: 0/29 cost:  2.062417701327253 accuracy:  0.8866793789158267\n",
      "Epoch number: 497/10000step_number: 0/29 cost:  2.0624679719649754 accuracy:  0.8865431762462544\n",
      "Epoch number: 498/10000step_number: 0/29 cost:  2.062517632102125 accuracy:  0.8864069735766821\n",
      "Epoch number: 499/10000step_number: 0/29 cost:  2.0625684560314395 accuracy:  0.8869517842549713\n",
      "Epoch number: 500/10000step_number: 0/29 cost:  2.062622308962916 accuracy:  0.8870879869245437\n",
      "Epoch number: 501/10000step_number: 0/29 cost:  2.062681109457182 accuracy:  0.8873603922636883\n",
      "Epoch number: 502/10000step_number: 0/29 cost:  2.062746797638692 accuracy:  0.8873603922636883\n",
      "Epoch number: 503/10000step_number: 0/29 cost:  2.0628213123901893 accuracy:  0.8872241895941161\n",
      "Epoch number: 504/10000step_number: 0/29 cost:  2.0629065785556144 accuracy:  0.8874965949332607\n",
      "Epoch number: 505/10000step_number: 0/29 cost:  2.0630045022260664 accuracy:  0.8874965949332607\n",
      "Epoch number: 506/10000step_number: 0/29 cost:  2.063116969026386 accuracy:  0.8872241895941161\n",
      "Epoch number: 507/10000step_number: 0/29 cost:  2.063245837798979 accuracy:  0.8870879869245437\n",
      "Epoch number: 508/10000step_number: 0/29 cost:  2.063392921180981 accuracy:  0.8872241895941161\n",
      "Epoch number: 509/10000step_number: 0/29 cost:  2.0635599461532625 accuracy:  0.8874965949332607\n",
      "Epoch number: 510/10000step_number: 0/29 cost:  2.0637484920220923 accuracy:  0.887632797602833\n",
      "Epoch number: 511/10000step_number: 0/29 cost:  2.0639599097998147 accuracy:  0.887632797602833\n",
      "Epoch number: 512/10000step_number: 0/29 cost:  2.0641952337526717 accuracy:  0.8877690002724054\n",
      "Epoch number: 513/10000step_number: 0/29 cost:  2.0644551004813385 accuracy:  0.8877690002724054\n",
      "Epoch number: 514/10000step_number: 0/29 cost:  2.0647396912276745 accuracy:  0.8879052029419776\n",
      "Epoch number: 515/10000step_number: 0/29 cost:  2.065048708706788 accuracy:  0.8879052029419776\n",
      "Epoch number: 516/10000step_number: 0/29 cost:  2.0653813922059263 accuracy:  0.8879052029419776\n",
      "Epoch number: 517/10000step_number: 0/29 cost:  2.065736566772505 accuracy:  0.8881776082811224\n",
      "Epoch number: 518/10000step_number: 0/29 cost:  2.06611271662782 accuracy:  0.8881776082811224\n",
      "Epoch number: 519/10000step_number: 0/29 cost:  2.0665080707378323 accuracy:  0.88804140561155\n",
      "Epoch number: 520/10000step_number: 0/29 cost:  2.0669206894435592 accuracy:  0.8881776082811224\n",
      "Epoch number: 521/10000step_number: 0/29 cost:  2.0673485439444548 accuracy:  0.88804140561155\n",
      "Epoch number: 522/10000step_number: 0/29 cost:  2.067789583845067 accuracy:  0.88804140561155\n",
      "Epoch number: 523/10000step_number: 0/29 cost:  2.068241790931202 accuracy:  0.88804140561155\n",
      "Epoch number: 524/10000step_number: 0/29 cost:  2.0687032194023054 accuracy:  0.8881776082811224\n",
      "Epoch number: 525/10000step_number: 0/29 cost:  2.069172023945216 accuracy:  0.88804140561155\n",
      "Epoch number: 526/10000step_number: 0/29 cost:  2.0696464775048495 accuracy:  0.8879052029419776\n",
      "Epoch number: 527/10000step_number: 0/29 cost:  2.070124980653821 accuracy:  0.8881776082811224\n",
      "Epoch number: 528/10000step_number: 0/29 cost:  2.070606064304543 accuracy:  0.8881776082811224\n",
      "Epoch number: 529/10000step_number: 0/29 cost:  2.0710883872874457 accuracy:  0.8881776082811224\n",
      "Epoch number: 530/10000step_number: 0/29 cost:  2.071570730111627 accuracy:  0.8879052029419776\n",
      "Epoch number: 531/10000step_number: 0/29 cost:  2.0720519860540816 accuracy:  0.887632797602833\n",
      "Epoch number: 532/10000step_number: 0/29 cost:  2.072531150586323 accuracy:  0.8877690002724054\n",
      "Epoch number: 533/10000step_number: 0/29 cost:  2.0730073100246362 accuracy:  0.8879052029419776\n",
      "Epoch number: 534/10000step_number: 0/29 cost:  2.0734796301610428 accuracy:  0.8877690002724054\n",
      "Epoch number: 535/10000step_number: 0/29 cost:  2.073947345478956 accuracy:  0.88804140561155\n",
      "Epoch number: 536/10000step_number: 0/29 cost:  2.074409749372715 accuracy:  0.88804140561155\n",
      "Epoch number: 537/10000step_number: 0/29 cost:  2.0748661855815045 accuracy:  0.8879052029419776\n",
      "Epoch number: 538/10000step_number: 0/29 cost:  2.0753160408418725 accuracy:  0.8877690002724054\n",
      "Epoch number: 539/10000step_number: 0/29 cost:  2.0757587385995757 accuracy:  0.887632797602833\n",
      "Epoch number: 540/10000step_number: 0/29 cost:  2.0761937335386302 accuracy:  0.8877690002724054\n",
      "Epoch number: 541/10000step_number: 0/29 cost:  2.0766205066957966 accuracy:  0.887632797602833\n",
      "Epoch number: 542/10000step_number: 0/29 cost:  2.0770385610060282 accuracy:  0.8874965949332607\n",
      "Epoch number: 543/10000step_number: 0/29 cost:  2.0774474172153137 accuracy:  0.8877690002724054\n",
      "Epoch number: 544/10000step_number: 0/29 cost:  2.077846610153818 accuracy:  0.8877690002724054\n",
      "Epoch number: 545/10000step_number: 0/29 cost:  2.0782356853691764 accuracy:  0.88804140561155\n",
      "Epoch number: 546/10000step_number: 0/29 cost:  2.078614196097545 accuracy:  0.88804140561155\n",
      "Epoch number: 547/10000step_number: 0/29 cost:  2.0789817005375735 accuracy:  0.8923998910378643\n",
      "Epoch number: 548/10000step_number: 0/29 cost:  2.079337759445054 accuracy:  0.8909016616725688\n",
      "Epoch number: 549/10000step_number: 0/29 cost:  2.079681934274195 accuracy:  0.891037864342141\n",
      "Epoch number: 550/10000step_number: 0/29 cost:  2.0800137865275103 accuracy:  0.891037864342141\n",
      "Epoch number: 551/10000step_number: 0/29 cost:  2.080332879387495 accuracy:  0.8906292563334242\n",
      "Epoch number: 552/10000step_number: 0/29 cost:  2.0806387819650376 accuracy:  0.891037864342141\n",
      "Epoch number: 553/10000step_number: 0/29 cost:  2.080931072726023 accuracy:  0.8909016616725688\n",
      "Epoch number: 554/10000step_number: 0/29 cost:  2.081209332224463 accuracy:  0.8909016616725688\n",
      "Epoch number: 555/10000step_number: 0/29 cost:  2.0814731146354233 accuracy:  0.8909016616725688\n",
      "Epoch number: 556/10000step_number: 0/29 cost:  2.0817219045604505 accuracy:  0.891037864342141\n",
      "Epoch number: 557/10000step_number: 0/29 cost:  2.081955087773232 accuracy:  0.891446472350858\n",
      "Epoch number: 558/10000step_number: 0/29 cost:  2.0821719556317158 accuracy:  0.8903568509942795\n",
      "Epoch number: 559/10000step_number: 0/29 cost:  2.0823717311671324 accuracy:  0.8904930536638518\n",
      "Epoch number: 560/10000step_number: 0/29 cost:  2.0825536017817843 accuracy:  0.8903568509942795\n",
      "Epoch number: 561/10000step_number: 0/29 cost:  2.082716761713514 accuracy:  0.8902206483247072\n",
      "Epoch number: 562/10000step_number: 0/29 cost:  2.082860460113749 accuracy:  0.8900844456551349\n",
      "Epoch number: 563/10000step_number: 0/29 cost:  2.0829840277869254 accuracy:  0.8900844456551349\n",
      "Epoch number: 564/10000step_number: 0/29 cost:  2.0830868609024527 accuracy:  0.8904930536638518\n",
      "Epoch number: 565/10000step_number: 0/29 cost:  2.083168369803201 accuracy:  0.8898120403159901\n",
      "Epoch number: 566/10000step_number: 0/29 cost:  2.0832279189975655 accuracy:  0.8898120403159901\n",
      "Epoch number: 567/10000step_number: 0/29 cost:  2.083264781298922 accuracy:  0.8899482429855625\n",
      "Epoch number: 568/10000step_number: 0/29 cost:  2.0832781119109995 accuracy:  0.8899482429855625\n",
      "Epoch number: 569/10000step_number: 0/29 cost:  2.0832669485468878 accuracy:  0.8899482429855625\n",
      "Epoch number: 570/10000step_number: 0/29 cost:  2.0832302609350197 accuracy:  0.8899482429855625\n",
      "Epoch number: 571/10000step_number: 0/29 cost:  2.0831670562159084 accuracy:  0.8900844456551349\n",
      "Epoch number: 572/10000step_number: 0/29 cost:  2.0830765105291467 accuracy:  0.8902206483247072\n",
      "Epoch number: 573/10000step_number: 0/29 cost:  2.082958086679515 accuracy:  0.8900844456551349\n",
      "Epoch number: 574/10000step_number: 0/29 cost:  2.082811608499622 accuracy:  0.8899482429855625\n",
      "Epoch number: 575/10000step_number: 0/29 cost:  2.082637278587232 accuracy:  0.8900844456551349\n",
      "Epoch number: 576/10000step_number: 0/29 cost:  2.0824356428981003 accuracy:  0.8903568509942795\n",
      "Epoch number: 577/10000step_number: 0/29 cost:  2.0822075202150487 accuracy:  0.8903568509942795\n",
      "Epoch number: 578/10000step_number: 0/29 cost:  2.081953920884261 accuracy:  0.8902206483247072\n",
      "Epoch number: 579/10000step_number: 0/29 cost:  2.0816759742753916 accuracy:  0.8896758376464179\n",
      "Epoch number: 580/10000step_number: 0/29 cost:  2.0813748733680097 accuracy:  0.8896758376464179\n",
      "Epoch number: 581/10000step_number: 0/29 cost:  2.081051835324929 accuracy:  0.8896758376464179\n",
      "Epoch number: 582/10000step_number: 0/29 cost:  2.080708072627617 accuracy:  0.8902206483247072\n",
      "Epoch number: 583/10000step_number: 0/29 cost:  2.0803447698671267 accuracy:  0.8898120403159901\n",
      "Epoch number: 584/10000step_number: 0/29 cost:  2.079963064184511 accuracy:  0.8902206483247072\n",
      "Epoch number: 585/10000step_number: 0/29 cost:  2.079564030315343 accuracy:  0.8892672296377009\n",
      "Epoch number: 586/10000step_number: 0/29 cost:  2.0791486728885675 accuracy:  0.8892672296377009\n",
      "Epoch number: 587/10000step_number: 0/29 cost:  2.078717928705194 accuracy:  0.8892672296377009\n",
      "Epoch number: 588/10000step_number: 0/29 cost:  2.0782726804455423 accuracy:  0.8894034323072733\n",
      "Epoch number: 589/10000step_number: 0/29 cost:  2.0778137811803092 accuracy:  0.8873603922636883\n",
      "Epoch number: 590/10000step_number: 0/29 cost:  2.0773420868320467 accuracy:  0.8869517842549713\n",
      "Epoch number: 591/10000step_number: 0/29 cost:  2.0768584919494937 accuracy:  0.8868155815853991\n",
      "Epoch number: 592/10000step_number: 0/29 cost:  2.0763639632456896 accuracy:  0.8869517842549713\n",
      "Epoch number: 593/10000step_number: 0/29 cost:  2.075859565445131 accuracy:  0.8870879869245437\n",
      "Epoch number: 594/10000step_number: 0/29 cost:  2.075346474853577 accuracy:  0.8869517842549713\n",
      "Epoch number: 595/10000step_number: 0/29 cost:  2.0748259770872672 accuracy:  0.8872241895941161\n",
      "Epoch number: 596/10000step_number: 0/29 cost:  2.0742994455177843 accuracy:  0.8859983655679652\n",
      "Epoch number: 597/10000step_number: 0/29 cost:  2.0737682945582523 accuracy:  0.8850449468809589\n",
      "Epoch number: 598/10000step_number: 0/29 cost:  2.0732338947635616 accuracy:  0.8840915281939526\n",
      "Epoch number: 599/10000step_number: 0/29 cost:  2.0726974245949124 accuracy:  0.8835467175156633\n",
      "Epoch number: 600/10000step_number: 0/29 cost:  2.072159631013271 accuracy:  0.8836829201852356\n",
      "Epoch number: 601/10000step_number: 0/29 cost:  2.0716205380083994 accuracy:  0.8836829201852356\n",
      "Epoch number: 602/10000step_number: 0/29 cost:  2.0710793602557693 accuracy:  0.8832743121765186\n",
      "Epoch number: 603/10000step_number: 0/29 cost:  2.070535025060997 accuracy:  0.8831381095069464\n",
      "Epoch number: 604/10000step_number: 0/29 cost:  2.0699871105531904 accuracy:  0.8824570961590847\n",
      "Epoch number: 605/10000step_number: 0/29 cost:  2.0694362205379067 accuracy:  0.8823208934895124\n",
      "Epoch number: 606/10000step_number: 0/29 cost:  2.0688835327080612 accuracy:  0.8835467175156633\n",
      "Epoch number: 607/10000step_number: 0/29 cost:  2.0683302650426088 accuracy:  0.8832743121765186\n",
      "Epoch number: 608/10000step_number: 0/29 cost:  2.0677773483963837 accuracy:  0.8835467175156633\n",
      "Epoch number: 609/10000step_number: 0/29 cost:  2.067225182992703 accuracy:  0.8836829201852356\n",
      "Epoch number: 610/10000step_number: 0/29 cost:  2.066673718701994 accuracy:  0.883001906837374\n",
      "Epoch number: 611/10000step_number: 0/29 cost:  2.0661226763451856 accuracy:  0.883410514846091\n",
      "Epoch number: 612/10000step_number: 0/29 cost:  2.0655716438297804 accuracy:  0.883410514846091\n",
      "Epoch number: 613/10000step_number: 0/29 cost:  2.065020123103043 accuracy:  0.8828657041678016\n",
      "Epoch number: 614/10000step_number: 0/29 cost:  2.0644675695106534 accuracy:  0.8823208934895124\n",
      "Epoch number: 615/10000step_number: 0/29 cost:  2.063913413375586 accuracy:  0.8795968400980659\n",
      "Epoch number: 616/10000step_number: 0/29 cost:  2.063357076201621 accuracy:  0.8801416507763552\n",
      "Epoch number: 617/10000step_number: 0/29 cost:  2.0627979838473687 accuracy:  0.8804140561154998\n",
      "Epoch number: 618/10000step_number: 0/29 cost:  2.0622355767512874 accuracy:  0.8804140561154998\n",
      "Epoch number: 619/10000step_number: 0/29 cost:  2.061669319342588 accuracy:  0.8801416507763552\n",
      "Epoch number: 620/10000step_number: 0/29 cost:  2.0610987088382067 accuracy:  0.8801416507763552\n",
      "Epoch number: 621/10000step_number: 0/29 cost:  2.0605232836487892 accuracy:  0.8801416507763552\n",
      "Epoch number: 622/10000step_number: 0/29 cost:  2.059942631616033 accuracy:  0.8798692454372106\n",
      "Epoch number: 623/10000step_number: 0/29 cost:  2.0593563979031884 accuracy:  0.8800054481067829\n",
      "Epoch number: 624/10000step_number: 0/29 cost:  2.058764292198892 accuracy:  0.8795968400980659\n",
      "Epoch number: 625/10000step_number: 0/29 cost:  2.0581660947024694 accuracy:  0.8785072187414873\n",
      "Epoch number: 626/10000step_number: 0/29 cost:  2.057561660259861 accuracy:  0.8786434214110597\n",
      "Epoch number: 627/10000step_number: 0/29 cost:  2.056950920080033 accuracy:  0.877962408063198\n",
      "Epoch number: 628/10000step_number: 0/29 cost:  2.0563338805648903 accuracy:  0.869517842549714\n",
      "Epoch number: 629/10000step_number: 0/29 cost:  2.055710618865451 accuracy:  0.8696540452192864\n",
      "Epoch number: 630/10000step_number: 0/29 cost:  2.0550812749285643 accuracy:  0.8704712612367203\n",
      "Epoch number: 631/10000step_number: 0/29 cost:  2.054446040274097 accuracy:  0.8710160719150095\n",
      "Epoch number: 632/10000step_number: 0/29 cost:  2.0538051445646666 accuracy:  0.869517842549714\n",
      "Epoch number: 633/10000step_number: 0/29 cost:  2.0531588416535844 accuracy:  0.8693816398801416\n",
      "Epoch number: 634/10000step_number: 0/29 cost:  2.052507396643775 accuracy:  0.869926450558431\n",
      "Epoch number: 635/10000step_number: 0/29 cost:  2.0518510748243095 accuracy:  0.8697902478888586\n",
      "Epoch number: 636/10000step_number: 0/29 cost:  2.0511901329359015 accuracy:  0.869926450558431\n",
      "Epoch number: 637/10000step_number: 0/29 cost:  2.0505248131519065 accuracy:  0.8700626532280032\n",
      "Epoch number: 638/10000step_number: 0/29 cost:  2.049855339888719 accuracy:  0.8693816398801416\n",
      "Epoch number: 639/10000step_number: 0/29 cost:  2.0491819189121134 accuracy:  0.869109234540997\n",
      "Epoch number: 640/10000step_number: 0/29 cost:  2.048504737677669 accuracy:  0.8688368292018523\n",
      "Epoch number: 641/10000step_number: 0/29 cost:  2.0478239658819755 accuracy:  0.869109234540997\n",
      "Epoch number: 642/10000step_number: 0/29 cost:  2.047139755719659 accuracy:  0.8697902478888586\n",
      "Epoch number: 643/10000step_number: 0/29 cost:  2.0464522419185216 accuracy:  0.8697902478888586\n",
      "Epoch number: 644/10000step_number: 0/29 cost:  2.0457615419365496 accuracy:  0.869926450558431\n",
      "Epoch number: 645/10000step_number: 0/29 cost:  2.0450677567042668 accuracy:  0.8704712612367203\n",
      "Epoch number: 646/10000step_number: 0/29 cost:  2.0443709721078935 accuracy:  0.8706074639062925\n",
      "Epoch number: 647/10000step_number: 0/29 cost:  2.043671261157081 accuracy:  0.8706074639062925\n",
      "Epoch number: 648/10000step_number: 0/29 cost:  2.0429686865334924 accuracy:  0.8708798692454373\n",
      "Epoch number: 649/10000step_number: 0/29 cost:  2.0422633030293915 accuracy:  0.8711522745845819\n",
      "Epoch number: 650/10000step_number: 0/29 cost:  2.0415551593344823 accuracy:  0.8710160719150095\n",
      "Epoch number: 651/10000step_number: 0/29 cost:  2.0408442987757542 accuracy:  0.8710160719150095\n",
      "Epoch number: 652/10000step_number: 0/29 cost:  2.0401307589446396 accuracy:  0.8712884772541541\n",
      "Epoch number: 653/10000step_number: 0/29 cost:  2.039414570547231 accuracy:  0.8701988558975756\n",
      "Epoch number: 654/10000step_number: 0/29 cost:  2.0386957561144254 accuracy:  0.8704712612367203\n",
      "Epoch number: 655/10000step_number: 0/29 cost:  2.0379743292479744 accuracy:  0.8708798692454373\n",
      "Epoch number: 656/10000step_number: 0/29 cost:  2.037250294787776 accuracy:  0.8719694906020158\n",
      "Epoch number: 657/10000step_number: 0/29 cost:  2.0365236497642596 accuracy:  0.8718332879324435\n",
      "Epoch number: 658/10000step_number: 0/29 cost:  2.035794384520152 accuracy:  0.8721056932715882\n",
      "Epoch number: 659/10000step_number: 0/29 cost:  2.0350624832675126 accuracy:  0.8712884772541541\n",
      "Epoch number: 660/10000step_number: 0/29 cost:  2.0343279237150576 accuracy:  0.8712884772541541\n",
      "Epoch number: 661/10000step_number: 0/29 cost:  2.033590676036792 accuracy:  0.8718332879324435\n",
      "Epoch number: 662/10000step_number: 0/29 cost:  2.032850701923681 accuracy:  0.8726505039498774\n",
      "Epoch number: 663/10000step_number: 0/29 cost:  2.0321079544668827 accuracy:  0.872922909289022\n",
      "Epoch number: 664/10000step_number: 0/29 cost:  2.0313623792133346 accuracy:  0.8731953146281667\n",
      "Epoch number: 665/10000step_number: 0/29 cost:  2.0306139162053713 accuracy:  0.8737401253064561\n",
      "Epoch number: 666/10000step_number: 0/29 cost:  2.029862502446967 accuracy:  0.8737401253064561\n",
      "Epoch number: 667/10000step_number: 0/29 cost:  2.0291080741479446 accuracy:  0.8730591119585944\n",
      "Epoch number: 668/10000step_number: 0/29 cost:  2.0283505682505343 accuracy:  0.8730591119585944\n",
      "Epoch number: 669/10000step_number: 0/29 cost:  2.0275899230305745 accuracy:  0.872922909289022\n",
      "Epoch number: 670/10000step_number: 0/29 cost:  2.026826077863778 accuracy:  0.87455734132389\n",
      "Epoch number: 671/10000step_number: 0/29 cost:  2.026058972454209 accuracy:  0.874965949332607\n",
      "Epoch number: 672/10000step_number: 0/29 cost:  2.0252885458879253 accuracy:  0.8756469626804685\n",
      "Epoch number: 673/10000step_number: 0/29 cost:  2.0245147358133764 accuracy:  0.8718332879324435\n",
      "Epoch number: 674/10000step_number: 0/29 cost:  2.0237374779204904 accuracy:  0.8708798692454373\n",
      "Epoch number: 675/10000step_number: 0/29 cost:  2.022956705757934 accuracy:  0.8701988558975756\n",
      "Epoch number: 676/10000step_number: 0/29 cost:  2.02217235083297 accuracy:  0.8704712612367203\n",
      "Epoch number: 677/10000step_number: 0/29 cost:  2.0213843428888647 accuracy:  0.8706074639062925\n",
      "Epoch number: 678/10000step_number: 0/29 cost:  2.0205926102448974 accuracy:  0.8703350585671479\n",
      "Epoch number: 679/10000step_number: 0/29 cost:  2.0197970801153957 accuracy:  0.8701988558975756\n",
      "Epoch number: 680/10000step_number: 0/29 cost:  2.018997678908292 accuracy:  0.869926450558431\n",
      "Epoch number: 681/10000step_number: 0/29 cost:  2.0181943326412912 accuracy:  0.869926450558431\n",
      "Epoch number: 682/10000step_number: 0/29 cost:  2.0173869677758782 accuracy:  0.8697902478888586\n",
      "Epoch number: 683/10000step_number: 0/29 cost:  2.01657551290737 accuracy:  0.869926450558431\n",
      "Epoch number: 684/10000step_number: 0/29 cost:  2.0157599018186927 accuracy:  0.869926450558431\n",
      "Epoch number: 685/10000step_number: 0/29 cost:  2.0149400783601235 accuracy:  0.869926450558431\n",
      "Epoch number: 686/10000step_number: 0/29 cost:  2.0141160033558223 accuracy:  0.8704712612367203\n",
      "Epoch number: 687/10000step_number: 0/29 cost:  2.013287663057853 accuracy:  0.8707436665758649\n",
      "Epoch number: 688/10000step_number: 0/29 cost:  2.0124550773252987 accuracy:  0.8710160719150095\n",
      "Epoch number: 689/10000step_number: 0/29 cost:  2.011618303710618 accuracy:  0.8711522745845819\n",
      "Epoch number: 690/10000step_number: 0/29 cost:  2.0107774318062184 accuracy:  0.8711522745845819\n",
      "Epoch number: 691/10000step_number: 0/29 cost:  2.009932562509689 accuracy:  0.8721056932715882\n",
      "Epoch number: 692/10000step_number: 0/29 cost:  2.0090837714052876 accuracy:  0.8722418959411604\n",
      "Epoch number: 693/10000step_number: 0/29 cost:  2.0082310636240677 accuracy:  0.8721056932715882\n",
      "Epoch number: 694/10000step_number: 0/29 cost:  2.007374334162333 accuracy:  0.8726505039498774\n",
      "Epoch number: 695/10000step_number: 0/29 cost:  2.0065133465115457 accuracy:  0.8727867066194498\n",
      "Epoch number: 696/10000step_number: 0/29 cost:  2.005647733382224 accuracy:  0.8723780986107328\n",
      "Epoch number: 697/10000step_number: 0/29 cost:  2.004777013433832 accuracy:  0.8723780986107328\n",
      "Epoch number: 698/10000step_number: 0/29 cost:  2.0039006148051484 accuracy:  0.8654317624625443\n",
      "Epoch number: 699/10000step_number: 0/29 cost:  2.003017902065247 accuracy:  0.8624353037319531\n",
      "Epoch number: 700/10000step_number: 0/29 cost:  2.002128216915652 accuracy:  0.8625715064015255\n",
      "Epoch number: 701/10000step_number: 0/29 cost:  2.001230965334392 accuracy:  0.8628439117406701\n",
      "Epoch number: 702/10000step_number: 0/29 cost:  2.000325816406336 accuracy:  0.8627077090710978\n",
      "Epoch number: 703/10000step_number: 0/29 cost:  1.999413105415862 accuracy:  0.8625715064015255\n",
      "Epoch number: 704/10000step_number: 0/29 cost:  1.9984944782061498 accuracy:  0.8625715064015255\n",
      "Epoch number: 705/10000step_number: 0/29 cost:  1.9975735213698942 accuracy:  0.8625715064015255\n",
      "Epoch number: 706/10000step_number: 0/29 cost:  1.996655650512243 accuracy:  0.8627077090710978\n",
      "Epoch number: 707/10000step_number: 0/29 cost:  1.9957466783615991 accuracy:  0.8622991010623808\n",
      "Epoch number: 708/10000step_number: 0/29 cost:  1.994850839078466 accuracy:  0.8620266957232362\n",
      "Epoch number: 709/10000step_number: 0/29 cost:  1.993969787630385 accuracy:  0.8582130209752111\n",
      "Epoch number: 710/10000step_number: 0/29 cost:  1.9931027021782155 accuracy:  0.8571233996186325\n",
      "Epoch number: 711/10000step_number: 0/29 cost:  1.992246540182293 accuracy:  0.8567147916099156\n",
      "Epoch number: 712/10000step_number: 0/29 cost:  1.9913963788981168 accuracy:  0.8569871969490602\n",
      "Epoch number: 713/10000step_number: 0/29 cost:  1.9905463983629539 accuracy:  0.8578044129664941\n",
      "Epoch number: 714/10000step_number: 0/29 cost:  1.98969123127573 accuracy:  0.8582130209752111\n",
      "Epoch number: 715/10000step_number: 0/29 cost:  1.988826804083525 accuracy:  0.8582130209752111\n",
      "Epoch number: 716/10000step_number: 0/29 cost:  1.9879503995758483 accuracy:  0.8531735222010352\n",
      "Epoch number: 717/10000step_number: 0/29 cost:  1.987060365526093 accuracy:  0.8515390901661672\n",
      "Epoch number: 718/10000step_number: 0/29 cost:  1.9861558276094955 accuracy:  0.8518114955053119\n",
      "Epoch number: 719/10000step_number: 0/29 cost:  1.985236465780669 accuracy:  0.8518114955053119\n",
      "Epoch number: 720/10000step_number: 0/29 cost:  1.9843023525398766 accuracy:  0.8515390901661672\n",
      "Epoch number: 721/10000step_number: 0/29 cost:  1.9833538482591135 accuracy:  0.850994279487878\n",
      "Epoch number: 722/10000step_number: 0/29 cost:  1.9823915056435457 accuracy:  0.8499046581312993\n",
      "Epoch number: 723/10000step_number: 0/29 cost:  1.9814159477919089 accuracy:  0.8497684554617271\n",
      "Epoch number: 724/10000step_number: 0/29 cost:  1.9804277369833878 accuracy:  0.8500408608008717\n",
      "Epoch number: 725/10000step_number: 0/29 cost:  1.9794272744052233 accuracy:  0.8499046581312993\n",
      "Epoch number: 726/10000step_number: 0/29 cost:  1.9784147573117925 accuracy:  0.8496322527921547\n",
      "Epoch number: 727/10000step_number: 0/29 cost:  1.9773901933931297 accuracy:  0.8496322527921547\n",
      "Epoch number: 728/10000step_number: 0/29 cost:  1.9763534480309428 accuracy:  0.8490874421138654\n",
      "Epoch number: 729/10000step_number: 0/29 cost:  1.9753042912986523 accuracy:  0.8484064287660038\n",
      "Epoch number: 730/10000step_number: 0/29 cost:  1.9742424238829492 accuracy:  0.8481340234268592\n",
      "Epoch number: 731/10000step_number: 0/29 cost:  1.973167480357924 accuracy:  0.8478616180877145\n",
      "Epoch number: 732/10000step_number: 0/29 cost:  1.9720790174102167 accuracy:  0.8474530100789975\n",
      "Epoch number: 733/10000step_number: 0/29 cost:  1.9709764939157937 accuracy:  0.8473168074094253\n",
      "Epoch number: 734/10000step_number: 0/29 cost:  1.9698592472950087 accuracy:  0.8466357940615636\n",
      "Epoch number: 735/10000step_number: 0/29 cost:  1.9687264693806301 accuracy:  0.8466357940615636\n",
      "Epoch number: 736/10000step_number: 0/29 cost:  1.9675771842071006 accuracy:  0.8464995913919913\n",
      "Epoch number: 737/10000step_number: 0/29 cost:  1.966410228374213 accuracy:  0.845546172704985\n",
      "Epoch number: 738/10000step_number: 0/29 cost:  1.9652242317925126 accuracy:  0.8456823753745574\n",
      "Epoch number: 739/10000step_number: 0/29 cost:  1.964017594569413 accuracy:  0.8454099700354127\n",
      "Epoch number: 740/10000step_number: 0/29 cost:  1.9627884564656746 accuracy:  0.8387360392263689\n",
      "Epoch number: 741/10000step_number: 0/29 cost:  1.9615346578457524 accuracy:  0.8383274312176519\n",
      "Epoch number: 742/10000step_number: 0/29 cost:  1.9602536928256586 accuracy:  0.8380550258785072\n",
      "Epoch number: 743/10000step_number: 0/29 cost:  1.9589426552819873 accuracy:  0.8380550258785072\n",
      "Epoch number: 744/10000step_number: 0/29 cost:  1.9575981772187998 accuracy:  0.8377826205393626\n",
      "Epoch number: 745/10000step_number: 0/29 cost:  1.9562163575863096 accuracy:  0.8377826205393626\n",
      "Epoch number: 746/10000step_number: 0/29 cost:  1.9547926783549225 accuracy:  0.8377826205393626\n",
      "Epoch number: 747/10000step_number: 0/29 cost:  1.9533219035698393 accuracy:  0.8381912285480796\n",
      "Epoch number: 748/10000step_number: 0/29 cost:  1.9517979563462318 accuracy:  0.837101607191501\n",
      "Epoch number: 749/10000step_number: 0/29 cost:  1.9502137684788774 accuracy:  0.8353309724870608\n",
      "Epoch number: 750/10000step_number: 0/29 cost:  1.9485610979212884 accuracy:  0.8293380550258785\n",
      "Epoch number: 751/10000step_number: 0/29 cost:  1.946830311712112 accuracy:  0.8290656496867339\n",
      "Epoch number: 752/10000step_number: 0/29 cost:  1.9450101377517113 accuracy:  0.8271588123127214\n",
      "Epoch number: 753/10000step_number: 0/29 cost:  1.9430874015014479 accuracy:  0.8248433669299918\n",
      "Epoch number: 754/10000step_number: 0/29 cost:  1.9410467890680316 accuracy:  0.8229365295559793\n",
      "Epoch number: 755/10000step_number: 0/29 cost:  1.9388707251485948 accuracy:  0.8170798147643694\n",
      "Epoch number: 756/10000step_number: 0/29 cost:  1.9365395323926424 accuracy:  0.8153091800599291\n",
      "Epoch number: 757/10000step_number: 0/29 cost:  1.9340321459591845 accuracy:  0.8128575320076273\n",
      "Epoch number: 758/10000step_number: 0/29 cost:  1.931327748234784 accuracy:  0.8112230999727594\n",
      "Epoch number: 759/10000step_number: 0/29 cost:  1.9284086240567755 accuracy:  0.8057749931898666\n",
      "Epoch number: 760/10000step_number: 0/29 cost:  1.9252640766402833 accuracy:  0.8042767638245709\n",
      "Epoch number: 761/10000step_number: 0/29 cost:  1.9218942691684275 accuracy:  0.8018251157722691\n",
      "Epoch number: 762/10000step_number: 0/29 cost:  1.9183118727472481 accuracy:  0.7973304276763824\n",
      "Epoch number: 763/10000step_number: 0/29 cost:  1.9145396360760265 accuracy:  0.7939253609370743\n",
      "Epoch number: 764/10000step_number: 0/29 cost:  1.9106040801923256 accuracy:  0.7906564968673386\n",
      "Epoch number: 765/10000step_number: 0/29 cost:  1.9065280477517081 accuracy:  0.7873876327976028\n",
      "Epoch number: 766/10000step_number: 0/29 cost:  1.9023255228703184 accuracy:  0.784935984745301\n",
      "Epoch number: 767/10000step_number: 0/29 cost:  1.8980004354681668 accuracy:  0.7834377553800055\n",
      "Epoch number: 768/10000step_number: 0/29 cost:  1.893548698371466 accuracy:  0.7777172432579679\n",
      "Epoch number: 769/10000step_number: 0/29 cost:  1.8889614923090452 accuracy:  0.7724053391446473\n",
      "Epoch number: 770/10000step_number: 0/29 cost:  1.8842282656244225 accuracy:  0.7665486243530373\n",
      "Epoch number: 771/10000step_number: 0/29 cost:  1.8793389810175791 accuracy:  0.7631435576137292\n",
      "Epoch number: 772/10000step_number: 0/29 cost:  1.8742858775145743 accuracy:  0.7602833015527104\n",
      "Epoch number: 773/10000step_number: 0/29 cost:  1.869065439727897 accuracy:  0.7546989921002452\n",
      "Epoch number: 774/10000step_number: 0/29 cost:  1.8636811623496456 accuracy:  0.7448923998910378\n",
      "Epoch number: 775/10000step_number: 0/29 cost:  1.8581449820691633 accuracy:  0.7265050394987742\n",
      "Epoch number: 776/10000step_number: 0/29 cost:  1.8524736082867472 accuracy:  0.7071642604195042\n",
      "Epoch number: 777/10000step_number: 0/29 cost:  1.8466844709690504 accuracy:  0.6882320893489512\n",
      "Epoch number: 778/10000step_number: 0/29 cost:  1.8407958939752038 accuracy:  0.6551348406428766\n",
      "Epoch number: 779/10000step_number: 0/29 cost:  1.834826908996825 accuracy:  0.6240806319803868\n",
      "Epoch number: 780/10000step_number: 0/29 cost:  1.8287967719099207 accuracy:  0.5832198311086897\n",
      "Epoch number: 781/10000step_number: 0/29 cost:  1.8227255193206064 accuracy:  0.5488967583764642\n",
      "Epoch number: 782/10000step_number: 0/29 cost:  1.8166335416757948 accuracy:  0.5076273494960502\n",
      "Epoch number: 783/10000step_number: 0/29 cost:  1.810539884645245 accuracy:  0.4591391991283029\n",
      "Epoch number: 784/10000step_number: 0/29 cost:  1.8044609193030128 accuracy:  0.39430672841187686\n",
      "Epoch number: 785/10000step_number: 0/29 cost:  1.7984095709016996 accuracy:  0.3466357940615636\n",
      "Epoch number: 786/10000step_number: 0/29 cost:  1.7923946596621505 accuracy:  0.3124489239989104\n",
      "Epoch number: 787/10000step_number: 0/29 cost:  1.7864206733242531 accuracy:  0.2869790247888859\n",
      "Epoch number: 788/10000step_number: 0/29 cost:  1.780488147921546 accuracy:  0.27036229910106235\n",
      "Epoch number: 789/10000step_number: 0/29 cost:  1.7745943211363189 accuracy:  0.24829746663034596\n",
      "Epoch number: 790/10000step_number: 0/29 cost:  1.7687339965131428 accuracy:  0.24175973849087443\n",
      "Epoch number: 791/10000step_number: 0/29 cost:  1.7629007570975233 accuracy:  0.22936529555979296\n",
      "Epoch number: 792/10000step_number: 0/29 cost:  1.757087770266674 accuracy:  0.22350858076818306\n",
      "Epoch number: 793/10000step_number: 0/29 cost:  1.7512879624542257 accuracy:  0.21819667665486245\n",
      "Epoch number: 794/10000step_number: 0/29 cost:  1.7454944090671147 accuracy:  0.21547262326341596\n",
      "Epoch number: 795/10000step_number: 0/29 cost:  1.739700666278606 accuracy:  0.21560882593298827\n",
      "Epoch number: 796/10000step_number: 0/29 cost:  1.73390174144581 accuracy:  0.21411059656769274\n",
      "Epoch number: 797/10000step_number: 0/29 cost:  1.7280954642355155 accuracy:  0.2128847725415418\n",
      "Epoch number: 798/10000step_number: 0/29 cost:  1.722285150128001 accuracy:  0.21043312448923998\n",
      "Epoch number: 799/10000step_number: 0/29 cost:  1.7164871741274914 accuracy:  0.20839008444565513\n",
      "Epoch number: 800/10000step_number: 0/29 cost:  1.7107479740597729 accuracy:  0.20689185508035957\n",
      "Epoch number: 801/10000step_number: 0/29 cost:  1.7051810721895937 accuracy:  0.2048488150367747\n",
      "Epoch number: 802/10000step_number: 0/29 cost:  1.699767702498103 accuracy:  0.20266957232361754\n",
      "Epoch number: 803/10000step_number: 0/29 cost:  1.6941762484852552 accuracy:  0.19531462816671208\n",
      "Epoch number: 804/10000step_number: 0/29 cost:  1.6884255744932966 accuracy:  0.1921819667665486\n",
      "Epoch number: 805/10000step_number: 0/29 cost:  1.6826119118538776 accuracy:  0.19000272405339144\n",
      "Epoch number: 806/10000step_number: 0/29 cost:  1.6767713912245077 accuracy:  0.18646145464451103\n",
      "Epoch number: 807/10000step_number: 0/29 cost:  1.6709111570013082 accuracy:  0.18319259057477527\n",
      "Epoch number: 808/10000step_number: 0/29 cost:  1.6650475567204772 accuracy:  0.1752928357395805\n",
      "Epoch number: 809/10000step_number: 0/29 cost:  1.6591919540119826 accuracy:  0.17147916099155544\n",
      "Epoch number: 810/10000step_number: 0/29 cost:  1.6533501385463232 accuracy:  0.1672568782348134\n",
      "Epoch number: 811/10000step_number: 0/29 cost:  1.6475344340340552 accuracy:  0.16466902751293924\n",
      "Epoch number: 812/10000step_number: 0/29 cost:  1.641755463912904 accuracy:  0.1596295287387633\n",
      "Epoch number: 813/10000step_number: 0/29 cost:  1.6360167810653148 accuracy:  0.15894851539090166\n",
      "Epoch number: 814/10000step_number: 0/29 cost:  1.6303198118862656 accuracy:  0.15445382729501497\n",
      "Epoch number: 815/10000step_number: 0/29 cost:  1.624662167106361 accuracy:  0.1529555979297194\n",
      "Epoch number: 816/10000step_number: 0/29 cost:  1.6190353793920294 accuracy:  0.15254698992100246\n",
      "Epoch number: 817/10000step_number: 0/29 cost:  1.6134289251085379 accuracy:  0.1510487605557069\n",
      "Epoch number: 818/10000step_number: 0/29 cost:  1.6078346102673637 accuracy:  0.14927812585126668\n",
      "Epoch number: 819/10000step_number: 0/29 cost:  1.602251149847103 accuracy:  0.1464178697902479\n",
      "Epoch number: 820/10000step_number: 0/29 cost:  1.5966856573270933 accuracy:  0.14205938436393353\n",
      "Epoch number: 821/10000step_number: 0/29 cost:  1.5911462798611935 accuracy:  0.13865431762462543\n",
      "Epoch number: 822/10000step_number: 0/29 cost:  1.5856363313609498 accuracy:  0.13524925088531736\n",
      "Epoch number: 823/10000step_number: 0/29 cost:  1.5801557657045906 accuracy:  0.1321165894851539\n",
      "Epoch number: 824/10000step_number: 0/29 cost:  1.5747016973958257 accuracy:  0.126259874693544\n",
      "Epoch number: 825/10000step_number: 0/29 cost:  1.5692569043367557 accuracy:  0.11836011985834922\n",
      "Epoch number: 826/10000step_number: 0/29 cost:  1.563770467778976 accuracy:  0.11277581040588396\n",
      "Epoch number: 827/10000step_number: 0/29 cost:  1.558159806638943 accuracy:  0.10365023154453827\n",
      "Epoch number: 828/10000step_number: 0/29 cost:  1.5523724235701635 accuracy:  0.098065922092073\n",
      "Epoch number: 829/10000step_number: 0/29 cost:  1.546399446962676 accuracy:  0.09220920730046309\n",
      "Epoch number: 830/10000step_number: 0/29 cost:  1.5402633179509653 accuracy:  0.08580768183056388\n",
      "Epoch number: 831/10000step_number: 0/29 cost:  1.5340113135681963 accuracy:  0.0807681830563879\n",
      "Epoch number: 832/10000step_number: 0/29 cost:  1.5276826994849766 accuracy:  0.07872514301280305\n",
      "Epoch number: 833/10000step_number: 0/29 cost:  1.5213058341592947 accuracy:  0.07763552165622446\n",
      "Epoch number: 834/10000step_number: 0/29 cost:  1.5149067810980918 accuracy:  0.07709071097793517\n",
      "Epoch number: 835/10000step_number: 0/29 cost:  1.5085011330800793 accuracy:  0.07654590029964588\n",
      "Epoch number: 836/10000step_number: 0/29 cost:  1.5020942939620567 accuracy:  0.07600108962135659\n",
      "Epoch number: 837/10000step_number: 0/29 cost:  1.495689242530914 accuracy:  0.07559248161263961\n",
      "Epoch number: 838/10000step_number: 0/29 cost:  1.4892865434388107 accuracy:  0.07559248161263961\n",
      "Epoch number: 839/10000step_number: 0/29 cost:  1.482880227556085 accuracy:  0.0738218469081994\n",
      "Epoch number: 840/10000step_number: 0/29 cost:  1.4764530203943749 accuracy:  0.06796513211658949\n",
      "Epoch number: 841/10000step_number: 0/29 cost:  1.4699835752003527 accuracy:  0.06837374012530646\n",
      "Epoch number: 842/10000step_number: 0/29 cost:  1.4634601416567856 accuracy:  0.06633070008172161\n",
      "Epoch number: 843/10000step_number: 0/29 cost:  1.4568549522796759 accuracy:  0.06551348406428766\n",
      "Epoch number: 844/10000step_number: 0/29 cost:  1.4501368443894858 accuracy:  0.06469626804685372\n",
      "Epoch number: 845/10000step_number: 0/29 cost:  1.4431991557001147 accuracy:  0.06415145736856442\n",
      "Epoch number: 846/10000step_number: 0/29 cost:  1.4359605702021465 accuracy:  0.06360664669027513\n",
      "Epoch number: 847/10000step_number: 0/29 cost:  1.4295095522519823 accuracy:  0.06306183601198584\n",
      "Epoch number: 848/10000step_number: 0/29 cost:  1.4229919571350207 accuracy:  0.061836011985834924\n",
      "Epoch number: 849/10000step_number: 0/29 cost:  1.4157052136332369 accuracy:  0.0611549986379733\n",
      "Epoch number: 850/10000step_number: 0/29 cost:  1.4064313017056866 accuracy:  0.06020157995096704\n",
      "Epoch number: 851/10000step_number: 0/29 cost:  1.3986182905649125 accuracy:  0.05992917461182239\n",
      "Epoch number: 852/10000step_number: 0/29 cost:  1.3906079213462792 accuracy:  0.05911195859438845\n",
      "Epoch number: 853/10000step_number: 0/29 cost:  1.383751347153699 accuracy:  0.05734132388994824\n",
      "Epoch number: 854/10000step_number: 0/29 cost:  1.3761506237524719 accuracy:  0.05706891855080359\n",
      "Epoch number: 855/10000step_number: 0/29 cost:  1.3701853278739728 accuracy:  0.0565241078725143\n",
      "Epoch number: 856/10000step_number: 0/29 cost:  1.3625054412289297 accuracy:  0.05543448651593571\n",
      "Epoch number: 857/10000step_number: 0/29 cost:  1.3582643818354827 accuracy:  0.054344865159357124\n",
      "Epoch number: 858/10000step_number: 0/29 cost:  1.3491392120620107 accuracy:  0.053391446472350855\n",
      "Epoch number: 859/10000step_number: 0/29 cost:  1.347994921656736 accuracy:  0.046036502315445385\n",
      "Epoch number: 860/10000step_number: 0/29 cost:  1.3378275463607838 accuracy:  0.046036502315445385\n",
      "Epoch number: 861/10000step_number: 0/29 cost:  1.3360724010438203 accuracy:  0.04562789430672841\n",
      "Epoch number: 862/10000step_number: 0/29 cost:  1.3269266879425887 accuracy:  0.04576409697630074\n",
      "Epoch number: 863/10000step_number: 0/29 cost:  1.3213005075173225 accuracy:  0.04535548896758376\n",
      "Epoch number: 864/10000step_number: 0/29 cost:  1.314023460575007 accuracy:  0.04467447561972215\n",
      "Epoch number: 865/10000step_number: 0/29 cost:  1.3101501909254802 accuracy:  0.04399346227186053\n",
      "Epoch number: 866/10000step_number: 0/29 cost:  1.3026423837508436 accuracy:  0.04372105693271588\n",
      "Epoch number: 867/10000step_number: 0/29 cost:  1.2997407161634682 accuracy:  0.04372105693271588\n",
      "Epoch number: 868/10000step_number: 0/29 cost:  1.291435780470249 accuracy:  0.04304004358485426\n",
      "Epoch number: 869/10000step_number: 0/29 cost:  1.2879994118706486 accuracy:  0.04099700354126941\n",
      "Epoch number: 870/10000step_number: 0/29 cost:  1.2800775343705544 accuracy:  0.04058839553255244\n",
      "Epoch number: 871/10000step_number: 0/29 cost:  1.276377103056772 accuracy:  0.03963497684554617\n",
      "Epoch number: 872/10000step_number: 0/29 cost:  1.2684278865515735 accuracy:  0.03949877417597385\n",
      "Epoch number: 873/10000step_number: 0/29 cost:  1.2648986457087452 accuracy:  0.037591936801961316\n",
      "Epoch number: 874/10000step_number: 0/29 cost:  1.2568571547142233 accuracy:  0.03595750476709343\n",
      "Epoch number: 875/10000step_number: 0/29 cost:  1.2534245197994007 accuracy:  0.03514028874965949\n",
      "Epoch number: 876/10000step_number: 0/29 cost:  1.245137096252869 accuracy:  0.03405066739308091\n",
      "Epoch number: 877/10000step_number: 0/29 cost:  1.2420621876177207 accuracy:  0.0322800326886407\n",
      "Epoch number: 878/10000step_number: 0/29 cost:  1.23380904500266 accuracy:  0.03010078997548352\n",
      "Epoch number: 879/10000step_number: 0/29 cost:  1.2317101485168953 accuracy:  0.028330155271043312\n",
      "Epoch number: 880/10000step_number: 0/29 cost:  1.2238571978663964 accuracy:  0.026559520566603104\n",
      "Epoch number: 881/10000step_number: 0/29 cost:  1.2233649419348065 accuracy:  0.024925088531735223\n",
      "Epoch number: 882/10000step_number: 0/29 cost:  1.2142900695425067 accuracy:  0.020430400435848543\n",
      "Epoch number: 883/10000step_number: 0/29 cost:  1.2170216176512452 accuracy:  0.015663307000817216\n",
      "Epoch number: 884/10000step_number: 0/29 cost:  1.2139927068220489 accuracy:  0.007491146826477799\n",
      "Epoch number: 885/10000step_number: 0/29 cost:  1.2260843337994272 accuracy:  0.0029964587305911197\n",
      "Epoch number: 886/10000step_number: 0/29 cost:  1.237615364881728 accuracy:  0.00040860800871697086\n",
      "Epoch number: 887/10000step_number: 0/29 cost:  1.2864350930726811 accuracy:  0.0\n",
      "Epoch number: 888/10000step_number: 0/29 cost:  1.3117669659661415 accuracy:  0.0\n",
      "Epoch number: 889/10000step_number: 0/29 cost:  1.3173462803567568 accuracy:  0.0\n",
      "Epoch number: 890/10000step_number: 0/29 cost:  1.291622565854067 accuracy:  0.0\n",
      "Epoch number: 891/10000step_number: 0/29 cost:  1.281162459762939 accuracy:  0.0\n",
      "Epoch number: 892/10000step_number: 0/29 cost:  1.2790339376985638 accuracy:  0.0\n",
      "Epoch number: 893/10000step_number: 0/29 cost:  1.2711833566600297 accuracy:  0.0\n",
      "Epoch number: 894/10000step_number: 0/29 cost:  1.2600245060360062 accuracy:  0.0\n",
      "Epoch number: 895/10000step_number: 0/29 cost:  1.2612570228947797 accuracy:  0.0\n",
      "Epoch number: 896/10000step_number: 0/29 cost:  1.2545142909564833 accuracy:  0.0\n",
      "Epoch number: 897/10000step_number: 0/29 cost:  1.2485702979089954 accuracy:  0.0\n",
      "Epoch number: 898/10000step_number: 0/29 cost:  1.2418825488641165 accuracy:  0.0\n",
      "Epoch number: 899/10000step_number: 0/29 cost:  1.241484022709306 accuracy:  0.0\n",
      "Epoch number: 900/10000step_number: 0/29 cost:  1.2305960308512671 accuracy:  0.0\n",
      "Epoch number: 901/10000step_number: 0/29 cost:  1.2311942093443629 accuracy:  0.0\n",
      "Epoch number: 902/10000step_number: 0/29 cost:  1.2207798044689697 accuracy:  0.0\n",
      "Epoch number: 903/10000step_number: 0/29 cost:  1.2215147952164485 accuracy:  0.0\n",
      "Epoch number: 904/10000step_number: 0/29 cost:  1.2109560116939013 accuracy:  0.0\n",
      "Epoch number: 905/10000step_number: 0/29 cost:  1.2118544651283718 accuracy:  0.0\n",
      "Epoch number: 906/10000step_number: 0/29 cost:  1.2011310926215448 accuracy:  0.0\n",
      "Epoch number: 907/10000step_number: 0/29 cost:  1.2031524945483958 accuracy:  0.0\n",
      "Epoch number: 908/10000step_number: 0/29 cost:  1.191159480849531 accuracy:  0.0\n",
      "Epoch number: 909/10000step_number: 0/29 cost:  1.1941996784537383 accuracy:  0.0\n",
      "Epoch number: 910/10000step_number: 0/29 cost:  1.1819016555513127 accuracy:  0.0\n",
      "Epoch number: 911/10000step_number: 0/29 cost:  1.1848410028806902 accuracy:  0.0\n",
      "Epoch number: 912/10000step_number: 0/29 cost:  1.1727168704474649 accuracy:  0.0\n",
      "Epoch number: 913/10000step_number: 0/29 cost:  1.1758236302265759 accuracy:  0.0\n",
      "Epoch number: 914/10000step_number: 0/29 cost:  1.1634211877082088 accuracy:  0.0\n",
      "Epoch number: 915/10000step_number: 0/29 cost:  1.1672011968056333 accuracy:  0.0\n",
      "Epoch number: 916/10000step_number: 0/29 cost:  1.1542344977905745 accuracy:  0.0\n",
      "Epoch number: 917/10000step_number: 0/29 cost:  1.158865759423791 accuracy:  0.0\n",
      "Epoch number: 918/10000step_number: 0/29 cost:  1.145244068996351 accuracy:  0.0\n",
      "Epoch number: 919/10000step_number: 0/29 cost:  1.150718450733852 accuracy:  0.0\n",
      "Epoch number: 920/10000step_number: 0/29 cost:  1.1370390336458465 accuracy:  0.0\n",
      "Epoch number: 921/10000step_number: 0/29 cost:  1.142499894234068 accuracy:  0.0\n",
      "Epoch number: 922/10000step_number: 0/29 cost:  1.1290249479980885 accuracy:  0.0\n",
      "Epoch number: 923/10000step_number: 0/29 cost:  1.1346806376536998 accuracy:  0.0\n",
      "Epoch number: 924/10000step_number: 0/29 cost:  1.1213922234913156 accuracy:  0.0\n",
      "Epoch number: 925/10000step_number: 0/29 cost:  1.1270724045217617 accuracy:  0.0\n",
      "Epoch number: 926/10000step_number: 0/29 cost:  1.1138827026590783 accuracy:  0.0\n",
      "Epoch number: 927/10000step_number: 0/29 cost:  1.1195289904518582 accuracy:  0.0\n",
      "Epoch number: 928/10000step_number: 0/29 cost:  1.106613520335528 accuracy:  0.0\n",
      "Epoch number: 929/10000step_number: 0/29 cost:  1.1120452212076408 accuracy:  0.0\n",
      "Epoch number: 930/10000step_number: 0/29 cost:  1.0991532567496978 accuracy:  0.0\n",
      "Epoch number: 931/10000step_number: 0/29 cost:  1.1043249252187868 accuracy:  0.0\n",
      "Epoch number: 932/10000step_number: 0/29 cost:  1.092973729631322 accuracy:  0.0\n",
      "Epoch number: 933/10000step_number: 0/29 cost:  1.0973003836740145 accuracy:  0.0\n",
      "Epoch number: 934/10000step_number: 0/29 cost:  1.0875964283896984 accuracy:  0.0\n",
      "Epoch number: 935/10000step_number: 0/29 cost:  1.0911609688443835 accuracy:  0.0\n",
      "Epoch number: 936/10000step_number: 0/29 cost:  1.0818385743711787 accuracy:  0.0\n",
      "Epoch number: 937/10000step_number: 0/29 cost:  1.084963084548311 accuracy:  0.0\n",
      "Epoch number: 938/10000step_number: 0/29 cost:  1.0762017546793892 accuracy:  0.0\n",
      "Epoch number: 939/10000step_number: 0/29 cost:  1.078501556972317 accuracy:  0.0\n",
      "Epoch number: 940/10000step_number: 0/29 cost:  1.0693412482923663 accuracy:  0.0\n",
      "Epoch number: 941/10000step_number: 0/29 cost:  1.0724966724469145 accuracy:  0.0\n",
      "Epoch number: 942/10000step_number: 0/29 cost:  1.0639773369594592 accuracy:  0.0\n",
      "Epoch number: 943/10000step_number: 0/29 cost:  1.065997308120856 accuracy:  0.0\n",
      "Epoch number: 944/10000step_number: 0/29 cost:  1.0573247652590656 accuracy:  0.0\n",
      "Epoch number: 945/10000step_number: 0/29 cost:  1.0603391320142062 accuracy:  0.0\n",
      "Epoch number: 946/10000step_number: 0/29 cost:  1.0516478435006045 accuracy:  0.0\n",
      "Epoch number: 947/10000step_number: 0/29 cost:  1.0535100276675708 accuracy:  0.0\n",
      "Epoch number: 948/10000step_number: 0/29 cost:  1.0452040075965738 accuracy:  0.0\n",
      "Epoch number: 949/10000step_number: 0/29 cost:  1.0488826894172774 accuracy:  0.0\n",
      "Epoch number: 950/10000step_number: 0/29 cost:  1.0402396781862082 accuracy:  0.0\n",
      "Epoch number: 951/10000step_number: 0/29 cost:  1.0416619663323081 accuracy:  0.0\n",
      "Epoch number: 952/10000step_number: 0/29 cost:  1.0311617294749071 accuracy:  0.0\n",
      "Epoch number: 953/10000step_number: 0/29 cost:  1.036459021915802 accuracy:  0.0\n",
      "Epoch number: 954/10000step_number: 0/29 cost:  1.0250727462524776 accuracy:  0.0\n",
      "Epoch number: 955/10000step_number: 0/29 cost:  1.0316578333913782 accuracy:  0.0\n",
      "Epoch number: 956/10000step_number: 0/29 cost:  1.0181781718998943 accuracy:  0.0\n",
      "Epoch number: 957/10000step_number: 0/29 cost:  1.0226620623038074 accuracy:  0.0\n",
      "Epoch number: 958/10000step_number: 0/29 cost:  1.0140615483130173 accuracy:  0.0\n",
      "Epoch number: 959/10000step_number: 0/29 cost:  1.0201037973648113 accuracy:  0.0\n",
      "Epoch number: 960/10000step_number: 0/29 cost:  1.0090423466267808 accuracy:  0.0\n",
      "Epoch number: 961/10000step_number: 0/29 cost:  1.0136139061100955 accuracy:  0.0\n",
      "Epoch number: 962/10000step_number: 0/29 cost:  1.0067309569335159 accuracy:  0.0\n",
      "Epoch number: 963/10000step_number: 0/29 cost:  1.0089233193509641 accuracy:  0.0\n",
      "Epoch number: 964/10000step_number: 0/29 cost:  1.0006886293180015 accuracy:  0.0\n",
      "Epoch number: 965/10000step_number: 0/29 cost:  1.0051678488383335 accuracy:  0.0\n",
      "Epoch number: 966/10000step_number: 0/29 cost:  0.9940357191037996 accuracy:  0.0\n",
      "Epoch number: 967/10000step_number: 0/29 cost:  0.9939960432769647 accuracy:  0.0\n",
      "Epoch number: 968/10000step_number: 0/29 cost:  0.988440338792997 accuracy:  0.0\n",
      "Epoch number: 969/10000step_number: 0/29 cost:  0.9967255534912587 accuracy:  0.0\n",
      "Epoch number: 970/10000step_number: 0/29 cost:  0.9830190958845793 accuracy:  0.0\n",
      "Epoch number: 971/10000step_number: 0/29 cost:  0.9836978775888259 accuracy:  0.0\n",
      "Epoch number: 972/10000step_number: 0/29 cost:  0.9789516166139174 accuracy:  0.0\n",
      "Epoch number: 973/10000step_number: 0/29 cost:  0.9779785941001804 accuracy:  0.0\n",
      "Epoch number: 974/10000step_number: 0/29 cost:  0.9740915201166191 accuracy:  0.0\n",
      "Epoch number: 975/10000step_number: 0/29 cost:  0.9739272133217765 accuracy:  0.0\n",
      "Epoch number: 976/10000step_number: 0/29 cost:  0.9675137437695297 accuracy:  0.0\n",
      "Epoch number: 977/10000step_number: 0/29 cost:  0.9670413156967198 accuracy:  0.0\n",
      "Epoch number: 978/10000step_number: 0/29 cost:  0.9620614801348272 accuracy:  0.0\n",
      "Epoch number: 979/10000step_number: 0/29 cost:  0.9616444538144862 accuracy:  0.0\n",
      "Epoch number: 980/10000step_number: 0/29 cost:  0.956021234923174 accuracy:  0.0\n",
      "Epoch number: 981/10000step_number: 0/29 cost:  0.9555347017291043 accuracy:  0.0\n",
      "Epoch number: 982/10000step_number: 0/29 cost:  0.9506564320361801 accuracy:  0.0\n",
      "Epoch number: 983/10000step_number: 0/29 cost:  0.9499265927081556 accuracy:  0.0\n",
      "Epoch number: 984/10000step_number: 0/29 cost:  0.9450870358075241 accuracy:  0.0\n",
      "Epoch number: 985/10000step_number: 0/29 cost:  0.9442761993538431 accuracy:  0.0\n",
      "Epoch number: 986/10000step_number: 0/29 cost:  0.9399087194740691 accuracy:  0.0\n",
      "Epoch number: 987/10000step_number: 0/29 cost:  0.9389393449683827 accuracy:  0.0\n",
      "Epoch number: 988/10000step_number: 0/29 cost:  0.9349971196332071 accuracy:  0.0\n",
      "Epoch number: 989/10000step_number: 0/29 cost:  0.9340347481524423 accuracy:  0.0\n",
      "Epoch number: 990/10000step_number: 0/29 cost:  0.9306328801114662 accuracy:  0.0\n",
      "Epoch number: 991/10000step_number: 0/29 cost:  0.9295913140723856 accuracy:  0.0\n",
      "Epoch number: 992/10000step_number: 0/29 cost:  0.9264853365781239 accuracy:  0.0\n",
      "Epoch number: 993/10000step_number: 0/29 cost:  0.9251830693247868 accuracy:  0.0\n",
      "Epoch number: 994/10000step_number: 0/29 cost:  0.9223404159786078 accuracy:  0.0\n",
      "Epoch number: 995/10000step_number: 0/29 cost:  0.9209393348016428 accuracy:  0.0\n",
      "Epoch number: 996/10000step_number: 0/29 cost:  0.9181915053054003 accuracy:  0.0\n",
      "Epoch number: 997/10000step_number: 0/29 cost:  0.916500202642191 accuracy:  0.0\n",
      "Epoch number: 998/10000step_number: 0/29 cost:  0.9131759256013441 accuracy:  0.0\n",
      "Epoch number: 999/10000step_number: 0/29 cost:  0.9113407844773265 accuracy:  0.0\n",
      "Epoch number: 1000/10000step_number: 0/29 cost:  0.907888781364006 accuracy:  0.0\n",
      "Epoch number: 1001/10000step_number: 0/29 cost:  0.9063376380381665 accuracy:  0.0\n",
      "Epoch number: 1002/10000step_number: 0/29 cost:  0.9029297590034825 accuracy:  0.0\n",
      "Epoch number: 1003/10000step_number: 0/29 cost:  0.9015350489851565 accuracy:  0.0\n",
      "Epoch number: 1004/10000step_number: 0/29 cost:  0.8981444451083055 accuracy:  0.0\n",
      "Epoch number: 1005/10000step_number: 0/29 cost:  0.896703597041926 accuracy:  0.0\n",
      "Epoch number: 1006/10000step_number: 0/29 cost:  0.8933674651834683 accuracy:  0.0\n",
      "Epoch number: 1007/10000step_number: 0/29 cost:  0.8918206046950412 accuracy:  0.0\n",
      "Epoch number: 1008/10000step_number: 0/29 cost:  0.8885694307996687 accuracy:  0.0\n",
      "Epoch number: 1009/10000step_number: 0/29 cost:  0.8869414390246639 accuracy:  0.0\n",
      "Epoch number: 1010/10000step_number: 0/29 cost:  0.883811896347706 accuracy:  0.0\n",
      "Epoch number: 1011/10000step_number: 0/29 cost:  0.8820857199020267 accuracy:  0.0\n",
      "Epoch number: 1012/10000step_number: 0/29 cost:  0.8790855717913314 accuracy:  0.0\n",
      "Epoch number: 1013/10000step_number: 0/29 cost:  0.8772735421114971 accuracy:  0.0\n",
      "Epoch number: 1014/10000step_number: 0/29 cost:  0.8743654334836155 accuracy:  0.0\n",
      "Epoch number: 1015/10000step_number: 0/29 cost:  0.872474399437325 accuracy:  0.0\n",
      "Epoch number: 1016/10000step_number: 0/29 cost:  0.8696240287204876 accuracy:  0.0\n",
      "Epoch number: 1017/10000step_number: 0/29 cost:  0.8676813436374009 accuracy:  0.0\n",
      "Epoch number: 1018/10000step_number: 0/29 cost:  0.8648724859779753 accuracy:  0.0\n",
      "Epoch number: 1019/10000step_number: 0/29 cost:  0.862918189687086 accuracy:  0.0\n",
      "Epoch number: 1020/10000step_number: 0/29 cost:  0.8601303818992349 accuracy:  0.0\n",
      "Epoch number: 1021/10000step_number: 0/29 cost:  0.8581960289880519 accuracy:  0.0\n",
      "Epoch number: 1022/10000step_number: 0/29 cost:  0.8554060526296203 accuracy:  0.0\n",
      "Epoch number: 1023/10000step_number: 0/29 cost:  0.8535124225986753 accuracy:  0.0\n",
      "Epoch number: 1024/10000step_number: 0/29 cost:  0.8507005232045878 accuracy:  0.0\n",
      "Epoch number: 1025/10000step_number: 0/29 cost:  0.8488563933465992 accuracy:  0.0\n",
      "Epoch number: 1026/10000step_number: 0/29 cost:  0.846003104461458 accuracy:  0.0\n",
      "Epoch number: 1027/10000step_number: 0/29 cost:  0.8442045896721261 accuracy:  0.0\n",
      "Epoch number: 1028/10000step_number: 0/29 cost:  0.8412965562677569 accuracy:  0.0\n",
      "Epoch number: 1029/10000step_number: 0/29 cost:  0.8395275793761185 accuracy:  0.0\n",
      "Epoch number: 1030/10000step_number: 0/29 cost:  0.8365665010857516 accuracy:  0.0\n",
      "Epoch number: 1031/10000step_number: 0/29 cost:  0.8348024473179004 accuracy:  0.0\n",
      "Epoch number: 1032/10000step_number: 0/29 cost:  0.8318054113511808 accuracy:  0.0\n",
      "Epoch number: 1033/10000step_number: 0/29 cost:  0.8300234230970146 accuracy:  0.0\n",
      "Epoch number: 1034/10000step_number: 0/29 cost:  0.8270122840421547 accuracy:  0.0\n",
      "Epoch number: 1035/10000step_number: 0/29 cost:  0.8252035211436843 accuracy:  0.0\n",
      "Epoch number: 1036/10000step_number: 0/29 cost:  0.8221929661122107 accuracy:  0.0\n",
      "Epoch number: 1037/10000step_number: 0/29 cost:  0.8203651554302107 accuracy:  0.0\n",
      "Epoch number: 1038/10000step_number: 0/29 cost:  0.8173608018845274 accuracy:  0.0\n",
      "Epoch number: 1039/10000step_number: 0/29 cost:  0.8155286587768804 accuracy:  0.0\n",
      "Epoch number: 1040/10000step_number: 0/29 cost:  0.8125336062869096 accuracy:  0.0\n",
      "Epoch number: 1041/10000step_number: 0/29 cost:  0.8107078523381147 accuracy:  0.0\n",
      "Epoch number: 1042/10000step_number: 0/29 cost:  0.8077290547827842 accuracy:  0.0\n",
      "Epoch number: 1043/10000step_number: 0/29 cost:  0.8059115123986315 accuracy:  0.0\n",
      "Epoch number: 1044/10000step_number: 0/29 cost:  0.8029613870824184 accuracy:  0.0\n",
      "Epoch number: 1045/10000step_number: 0/29 cost:  0.8011461501534098 accuracy:  0.0\n",
      "Epoch number: 1046/10000step_number: 0/29 cost:  0.7982397975987663 accuracy:  0.0\n",
      "Epoch number: 1047/10000step_number: 0/29 cost:  0.7964177383338806 accuracy:  0.0\n",
      "Epoch number: 1048/10000step_number: 0/29 cost:  0.7935688304149014 accuracy:  0.0\n",
      "Epoch number: 1049/10000step_number: 0/29 cost:  0.7917316623947409 accuracy:  0.0\n",
      "Epoch number: 1050/10000step_number: 0/29 cost:  0.7889503068716497 accuracy:  0.0\n",
      "Epoch number: 1051/10000step_number: 0/29 cost:  0.787091623187809 accuracy:  0.0\n",
      "Epoch number: 1052/10000step_number: 0/29 cost:  0.7843850433312203 accuracy:  0.0\n",
      "Epoch number: 1053/10000step_number: 0/29 cost:  0.7824992788205452 accuracy:  0.0\n",
      "Epoch number: 1054/10000step_number: 0/29 cost:  0.7798735045039242 accuracy:  0.0\n",
      "Epoch number: 1055/10000step_number: 0/29 cost:  0.777955547647889 accuracy:  0.0\n",
      "Epoch number: 1056/10000step_number: 0/29 cost:  0.7754162902293381 accuracy:  0.0\n",
      "Epoch number: 1057/10000step_number: 0/29 cost:  0.7734625564366163 accuracy:  0.0\n",
      "Epoch number: 1058/10000step_number: 0/29 cost:  0.7710151176970395 accuracy:  0.0\n",
      "Epoch number: 1059/10000step_number: 0/29 cost:  0.7690245921471696 accuracy:  0.00027240533914464724\n",
      "Epoch number: 1060/10000step_number: 0/29 cost:  0.7666735529606199 accuracy:  0.00027240533914464724\n",
      "Epoch number: 1061/10000step_number: 0/29 cost:  0.7646473306601845 accuracy:  0.00040860800871697086\n",
      "Epoch number: 1062/10000step_number: 0/29 cost:  0.7623963782951856 accuracy:  0.00040860800871697086\n",
      "Epoch number: 1063/10000step_number: 0/29 cost:  0.7603357434829037 accuracy:  0.00040860800871697086\n",
      "Epoch number: 1064/10000step_number: 0/29 cost:  0.7581878770848886 accuracy:  0.00040860800871697086\n",
      "Epoch number: 1065/10000step_number: 0/29 cost:  0.7560929936593416 accuracy:  0.00040860800871697086\n",
      "Epoch number: 1066/10000step_number: 0/29 cost:  0.754051006786019 accuracy:  0.00040860800871697086\n",
      "Epoch number: 1067/10000step_number: 0/29 cost:  0.7519235529450197 accuracy:  0.00040860800871697086\n",
      "Epoch number: 1068/10000step_number: 0/29 cost:  0.7499882560157924 accuracy:  0.00040860800871697086\n",
      "Epoch number: 1069/10000step_number: 0/29 cost:  0.747834656925215 accuracy:  0.0005448106782892945\n",
      "Epoch number: 1070/10000step_number: 0/29 cost:  0.7460013708379282 accuracy:  0.0005448106782892945\n",
      "Epoch number: 1071/10000step_number: 0/29 cost:  0.7438261155702203 accuracy:  0.000681013347861618\n",
      "Epoch number: 1072/10000step_number: 0/29 cost:  0.7420866446704083 accuracy:  0.000681013347861618\n",
      "Epoch number: 1073/10000step_number: 0/29 cost:  0.7398859547079518 accuracy:  0.0008172160174339417\n",
      "Epoch number: 1074/10000step_number: 0/29 cost:  0.7382449195923063 accuracy:  0.0008172160174339417\n",
      "Epoch number: 1075/10000step_number: 0/29 cost:  0.7360284020100919 accuracy:  0.0009534186870062653\n",
      "Epoch number: 1076/10000step_number: 0/29 cost:  0.7345286729349567 accuracy:  0.0009534186870062653\n",
      "Epoch number: 1077/10000step_number: 0/29 cost:  0.7323297427279315 accuracy:  0.0012258240261509125\n",
      "Epoch number: 1078/10000step_number: 0/29 cost:  0.7310519241924195 accuracy:  0.0012258240261509125\n",
      "Epoch number: 1079/10000step_number: 0/29 cost:  0.7288456550328624 accuracy:  0.0012258240261509125\n",
      "Epoch number: 1080/10000step_number: 0/29 cost:  0.727832526960289 accuracy:  0.0012258240261509125\n",
      "Epoch number: 1081/10000step_number: 0/29 cost:  0.7254955721525729 accuracy:  0.0012258240261509125\n",
      "Epoch number: 1082/10000step_number: 0/29 cost:  0.7245327103088074 accuracy:  0.0012258240261509125\n",
      "Epoch number: 1083/10000step_number: 0/29 cost:  0.7221331619614184 accuracy:  0.0016344320348678834\n",
      "Epoch number: 1084/10000step_number: 0/29 cost:  0.7208034915441275 accuracy:  0.0014982293652955599\n",
      "Epoch number: 1085/10000step_number: 0/29 cost:  0.7185351860477213 accuracy:  0.002179242713157178\n",
      "Epoch number: 1086/10000step_number: 0/29 cost:  0.7167113355863589 accuracy:  0.002179242713157178\n",
      "Epoch number: 1087/10000step_number: 0/29 cost:  0.7149571734902366 accuracy:  0.0025878507218741486\n",
      "Epoch number: 1088/10000step_number: 0/29 cost:  0.7126920228912699 accuracy:  0.002451648052301825\n",
      "Epoch number: 1089/10000step_number: 0/29 cost:  0.711357119006789 accuracy:  0.0025878507218741486\n",
      "Epoch number: 1090/10000step_number: 0/29 cost:  0.7087125567346526 accuracy:  0.0025878507218741486\n",
      "Epoch number: 1091/10000step_number: 0/29 cost:  0.7065977599481571 accuracy:  0.002860256061018796\n",
      "Epoch number: 1092/10000step_number: 0/29 cost:  0.7040832459178663 accuracy:  0.002860256061018796\n",
      "Epoch number: 1093/10000step_number: 0/29 cost:  0.7021093664762958 accuracy:  0.0029964587305911197\n",
      "Epoch number: 1094/10000step_number: 0/29 cost:  0.6993531871454667 accuracy:  0.0031326614001634433\n",
      "Epoch number: 1095/10000step_number: 0/29 cost:  0.6961943195739889 accuracy:  0.003268864069735767\n",
      "Epoch number: 1096/10000step_number: 0/29 cost:  0.6853850828931093 accuracy:  0.003268864069735767\n",
      "Epoch number: 1097/10000step_number: 0/29 cost:  0.6789517567735044 accuracy:  0.003949877417597385\n",
      "Epoch number: 1098/10000step_number: 0/29 cost:  0.6751472338037113 accuracy:  0.003949877417597385\n",
      "Epoch number: 1099/10000step_number: 0/29 cost:  0.6723188959677255 accuracy:  0.003949877417597385\n",
      "Epoch number: 1100/10000step_number: 0/29 cost:  0.6693304987290232 accuracy:  0.003949877417597385\n",
      "Epoch number: 1101/10000step_number: 0/29 cost:  0.6663424845284563 accuracy:  0.004086080087169709\n",
      "Epoch number: 1102/10000step_number: 0/29 cost:  0.663886358958628 accuracy:  0.004222282756742032\n",
      "Epoch number: 1103/10000step_number: 0/29 cost:  0.6611486517429562 accuracy:  0.004222282756742032\n",
      "Epoch number: 1104/10000step_number: 0/29 cost:  0.6587952254611271 accuracy:  0.004494688095886679\n",
      "Epoch number: 1105/10000step_number: 0/29 cost:  0.6564553517367818 accuracy:  0.004767093435031327\n",
      "Epoch number: 1106/10000step_number: 0/29 cost:  0.6540670749766864 accuracy:  0.00490329610460365\n",
      "Epoch number: 1107/10000step_number: 0/29 cost:  0.6518718816607261 accuracy:  0.005175701443748297\n",
      "Epoch number: 1108/10000step_number: 0/29 cost:  0.649629609120413 accuracy:  0.005311904113320621\n",
      "Epoch number: 1109/10000step_number: 0/29 cost:  0.6475685537354797 accuracy:  0.005311904113320621\n",
      "Epoch number: 1110/10000step_number: 0/29 cost:  0.6459246359000186 accuracy:  0.005448106782892944\n",
      "Epoch number: 1111/10000step_number: 0/29 cost:  0.6434729107177874 accuracy:  0.005584309452465268\n",
      "Epoch number: 1112/10000step_number: 0/29 cost:  0.6406684345302294 accuracy:  0.005584309452465268\n",
      "Epoch number: 1113/10000step_number: 0/29 cost:  0.6387266869260328 accuracy:  0.0058567147916099155\n",
      "Epoch number: 1114/10000step_number: 0/29 cost:  0.6365139881030207 accuracy:  0.006129120130754563\n",
      "Epoch number: 1115/10000step_number: 0/29 cost:  0.6342168533110271 accuracy:  0.006265322800326887\n",
      "Epoch number: 1116/10000step_number: 0/29 cost:  0.6321052543510267 accuracy:  0.00640152546989921\n",
      "Epoch number: 1117/10000step_number: 0/29 cost:  0.6299090212521009 accuracy:  0.006265322800326887\n",
      "Epoch number: 1118/10000step_number: 0/29 cost:  0.6277630610683309 accuracy:  0.006673930809043857\n",
      "Epoch number: 1119/10000step_number: 0/29 cost:  0.6256389042028544 accuracy:  0.006946336148188505\n",
      "Epoch number: 1120/10000step_number: 0/29 cost:  0.6235072063870095 accuracy:  0.007082538817760828\n",
      "Epoch number: 1121/10000step_number: 0/29 cost:  0.6214181206843941 accuracy:  0.007218741487333152\n",
      "Epoch number: 1122/10000step_number: 0/29 cost:  0.6193283132852759 accuracy:  0.007354944156905475\n",
      "Epoch number: 1123/10000step_number: 0/29 cost:  0.617259505542949 accuracy:  0.007627349496050122\n",
      "Epoch number: 1124/10000step_number: 0/29 cost:  0.6152090423939243 accuracy:  0.007763552165622446\n",
      "Epoch number: 1125/10000step_number: 0/29 cost:  0.6131690206870811 accuracy:  0.00830836284391174\n",
      "Epoch number: 1126/10000step_number: 0/29 cost:  0.6111477594399733 accuracy:  0.008172160174339417\n",
      "Epoch number: 1127/10000step_number: 0/29 cost:  0.6091391842210584 accuracy:  0.008172160174339417\n",
      "Epoch number: 1128/10000step_number: 0/29 cost:  0.6071443240932763 accuracy:  0.00830836284391174\n",
      "Epoch number: 1129/10000step_number: 0/29 cost:  0.6051637480467774 accuracy:  0.008444565513484064\n",
      "Epoch number: 1130/10000step_number: 0/29 cost:  0.603195032034805 accuracy:  0.008444565513484064\n",
      "Epoch number: 1131/10000step_number: 0/29 cost:  0.6012394612826295 accuracy:  0.008444565513484064\n",
      "Epoch number: 1132/10000step_number: 0/29 cost:  0.599296005343331 accuracy:  0.008444565513484064\n",
      "Epoch number: 1133/10000step_number: 0/29 cost:  0.5973643782587053 accuracy:  0.008580768183056389\n",
      "Epoch number: 1134/10000step_number: 0/29 cost:  0.5954448647932759 accuracy:  0.008853173522201035\n",
      "Epoch number: 1135/10000step_number: 0/29 cost:  0.5935369636998105 accuracy:  0.009125578861345683\n",
      "Epoch number: 1136/10000step_number: 0/29 cost:  0.5916410059559681 accuracy:  0.009397984200490329\n",
      "Epoch number: 1137/10000step_number: 0/29 cost:  0.5897572200787021 accuracy:  0.009670389539634977\n",
      "Epoch number: 1138/10000step_number: 0/29 cost:  0.5878859650334519 accuracy:  0.0098065922092073\n",
      "Epoch number: 1139/10000step_number: 0/29 cost:  0.5860280600941141 accuracy:  0.009942794878779623\n",
      "Epoch number: 1140/10000step_number: 0/29 cost:  0.5841843295730514 accuracy:  0.009942794878779623\n",
      "Epoch number: 1141/10000step_number: 0/29 cost:  0.5823558205964122 accuracy:  0.010215200217924271\n",
      "Epoch number: 1142/10000step_number: 0/29 cost:  0.5805435715640853 accuracy:  0.010351402887496594\n",
      "Epoch number: 1143/10000step_number: 0/29 cost:  0.5787483180738058 accuracy:  0.010896213565785889\n",
      "Epoch number: 1144/10000step_number: 0/29 cost:  0.5769704135329644 accuracy:  0.011032416235358214\n",
      "Epoch number: 1145/10000step_number: 0/29 cost:  0.5752096475501672 accuracy:  0.011168618904930537\n",
      "Epoch number: 1146/10000step_number: 0/29 cost:  0.5734653518089708 accuracy:  0.011168618904930537\n",
      "Epoch number: 1147/10000step_number: 0/29 cost:  0.571736689993371 accuracy:  0.011168618904930537\n",
      "Epoch number: 1148/10000step_number: 0/29 cost:  0.5700229510050238 accuracy:  0.011168618904930537\n",
      "Epoch number: 1149/10000step_number: 0/29 cost:  0.5683238405040344 accuracy:  0.011849632252792154\n",
      "Epoch number: 1150/10000step_number: 0/29 cost:  0.5666396133248449 accuracy:  0.012666848270226096\n",
      "Epoch number: 1151/10000step_number: 0/29 cost:  0.5649710536572573 accuracy:  0.013484064287660039\n",
      "Epoch number: 1152/10000step_number: 0/29 cost:  0.5633193637680841 accuracy:  0.013484064287660039\n",
      "Epoch number: 1153/10000step_number: 0/29 cost:  0.561685954479907 accuracy:  0.013620266957232362\n",
      "Epoch number: 1154/10000step_number: 0/29 cost:  0.5600721848053347 accuracy:  0.01389267229637701\n",
      "Epoch number: 1155/10000step_number: 0/29 cost:  0.5584790973753424 accuracy:  0.01389267229637701\n",
      "Epoch number: 1156/10000step_number: 0/29 cost:  0.5569071976523554 accuracy:  0.014028874965949333\n",
      "Epoch number: 1157/10000step_number: 0/29 cost:  0.5553563497915166 accuracy:  0.014028874965949333\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-7563b55d50d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mNN1_\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mNeural_Network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m76\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m76\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#v7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0ma1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNN1_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32melif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-e0e668b8ba66>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, y, epoch, X_test, y_test)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_propagation_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m                 \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward_propagation_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam_update_parameters_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_propagation_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-e0e668b8ba66>\u001b[0m in \u001b[0;36mbackward_propagation_NN\u001b[1;34m(self, X, Y)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mDW2_prime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"weight3\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDW3_prime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mder_tanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Z2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#76*1000 =\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mDW2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDW2_prime\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"A1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"A2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m#DW2=76*76=    76*1000,1000*76\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[0mdb2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDW2_prime\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"A2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-41-e0e668b8ba66>\u001b[0m in \u001b[0;36mder_tanh\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mder_tanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "XX=X.values\n",
    "YY=target_cate.values\n",
    "X_=XX\n",
    "Y_=YY\n",
    "a=kf.split(X_)\n",
    "from sklearn.model_selection import KFold \n",
    "kf = KFold(n_splits=5,  random_state=None)\n",
    "\n",
    "\n",
    "i=0\n",
    "for train_index, test_index in kf.split(X_):    \n",
    "    X_train, X_test = X_[train_index], X_[test_index] \n",
    "    y_train, y_test = Y_[train_index], Y_[test_index]\n",
    "    X_train=X_train.T\n",
    "    X_test=X_test.T\n",
    "    y_train=y_train.T\n",
    "    y_test=y_test.T\n",
    "    if(i%5==0):\n",
    "        NN1_= Neural_Network(X_train,y_train,76,76,0.0001,1000) #v7\n",
    "        a1=NN1_.train(X_train,y_train,10000,X_test1,y_test1)\n",
    "        i=i+1\n",
    "    elif(i%5==1):\n",
    "        NN2= Neural_Network(X_train,y_train,76,76,0.0001,1000) #v7\n",
    "        a2=NN1.train(X_train,y_train,10000,X_test1,y_test1)\n",
    "        i=i+1\n",
    "    elif(i%5==2):\n",
    "        NN3= Neural_Network(X_train,y_train,76,76,0.0001,1000) #v7\n",
    "        a3=NN1.train(X_train,y_train,10000,X_test1,y_test1)\n",
    "        i=i+1\n",
    "    elif(i%5==3):\n",
    "        NN4= Neural_Network(X_train,y_train,76,76,0.0001,1000) #v7\n",
    "        a4=NN1.train(X_train,y_train,10000,X_test1,y_test1)\n",
    "        i=i+1\n",
    "    else:\n",
    "        NN5= Neural_Network(X_train,y_train,76,76,0.0001,1000) #v7\n",
    "        a5=NN1.train(X_train,y_train,10000,X_test1,y_test1)\n",
    "        i=i+1\n",
    "print(\"SONUC!\",\"cost: \",(a1[1]+a2[1]+a3[1]+a4[1]+a5[1])/5,\"accuracy: \",(a1[0]+a2[0]+a3[0]+a4[0]+a5[0])/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "kf = KFold(n_splits=5,  random_state=None)\n",
    "NN1= Neural_Network(X_train1,y_train1,76,76,0.0001,1000) #v7\n",
    "NN2= Neural_Network(X_train2,y_train2,76,76,0.0001,1000) #v7\n",
    "NN3= Neural_Network(X_train3,y_train3,76,76,0.0001,1000) #v7\n",
    "NN4= Neural_Network(X_train4,y_train4,76,76,0.0001,1000) #v7\n",
    "NN5= Neural_Network(X_train5,y_train5,76,76,0.0001,1000) #v7\n",
    "i1=0\n",
    "while i1<1000:\n",
    "    \n",
    "    a1=NN1.train(X_train1,y_train1,10000,X_test1,y_test1)\n",
    "    print(a1[0])\n",
    "    a2=NN2.train(X_train2,y_train2,10000,X_test2,y_test2)\n",
    "    print(a2[0])\n",
    "    a3=NN3.train(X_train3,y_train3,10000,X_test3,y_test3)\n",
    "    print(a3[0])\n",
    "    a4=NN4.train(X_train4,y_train4,10000,X_test4,y_test4)\n",
    "    print(a4[0])\n",
    "    a5=NN5.train(X_train5,y_train5,10000,X_test5,y_test5)\n",
    "    print(a5[0])\n",
    "    print(\"SONUC!\",\"cost: \",(a1[1]+a2[1]+a3[1]+a4[1]+a5[1])/5,\"accuracy: \",(a1[0]+a2[0]+a3[0]+a4[0]+a5[0])/5)\n",
    "    i1=i1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "0.13989919629478273\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 0/1000 cost:  3.5244260350216097 accuracy:  0.5996185805748535\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 1/1000 cost:  3.5917065157025108 accuracy:  0.571638741315897\n",
      "0.0\n",
      "0.08008716970852629\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 2/1000 cost:  3.501094893939608 accuracy:  0.39471243462281136\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 3/1000 cost:  3.404462107425041 accuracy:  0.3664645167462119\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.8026154474867184\n",
      "Epoch number: 4/1000 cost:  3.4857965428542053 accuracy:  0.34967988012532353\n",
      "1.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 5/1000 cost:  3.3982771606175968 accuracy:  0.578695000681106\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 6/1000 cost:  3.4660290646786387 accuracy:  0.18248195068791717\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.05421604686010081\n",
      "0.08759024656041411\n",
      "Epoch number: 7/1000 cost:  3.3860031321111577 accuracy:  0.028361258684102986\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.13989919629478273\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 8/1000 cost:  3.4778429847160792 accuracy:  0.41863724525731394\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 9/1000 cost:  3.493860151360373 accuracy:  0.18915679062797983\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 10/1000 cost:  3.5922191812950492 accuracy:  0.0\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 11/1000 cost:  3.5852684643532404 accuracy:  0.3611769513690233\n",
      "1.0\n",
      "0.0\n",
      "0.13989919629478273\n",
      "0.05421604686010081\n",
      "0.0\n",
      "Epoch number: 12/1000 cost:  3.4591274924789355 accuracy:  0.23882304863097667\n",
      "1.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 13/1000 cost:  3.4283919287200697 accuracy:  0.37202016074104344\n",
      "0.0\n",
      "0.08008716970852629\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 14/1000 cost:  3.3467427926998887 accuracy:  0.2226922738817679\n",
      "1.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 15/1000 cost:  3.5336616202579223 accuracy:  0.37202016074104344\n",
      "1.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 16/1000 cost:  3.5408439578897557 accuracy:  0.5545021114289606\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.08541070698814876\n",
      "Epoch number: 17/1000 cost:  3.5386626284123444 accuracy:  0.39022149808390433\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 18/1000 cost:  3.5340572713727547 accuracy:  0.35450211142896065\n",
      "0.0\n",
      "0.9197766276219014\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 19/1000 cost:  3.5340713600281317 accuracy:  0.39063016546444296\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 20/1000 cost:  3.4658377511777383 accuracy:  0.5906574059983574\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 21/1000 cost:  3.484335269868339 accuracy:  0.18398256605829474\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.05421604686010081\n",
      "0.9124097534395859\n",
      "Epoch number: 22/1000 cost:  3.5462198830552665 accuracy:  0.3773077261182321\n",
      "1.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.08759024656041411\n",
      "Epoch number: 23/1000 cost:  3.4141239342538063 accuracy:  0.3895382100531263\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.13989919629478273\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 24/1000 cost:  3.5880766282222005 accuracy:  0.5836011466331483\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 25/1000 cost:  3.578849962438787 accuracy:  0.7276414681152351\n",
      "0.0\n",
      "0.0\n",
      "0.13989919629478273\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 26/1000 cost:  3.3246953370526517 accuracy:  0.23465467919901922\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.13989919629478273\n",
      "0.05421604686010081\n",
      "0.08759024656041411\n",
      "Epoch number: 27/1000 cost:  3.445440819601975 accuracy:  0.24032366400135427\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 28/1000 cost:  3.5302581652447573 accuracy:  0.5664645167462119\n",
      "0.0\n",
      "0.0\n",
      "0.13989919629478273\n",
      "0.05421604686010081\n",
      "0.08759024656041411\n",
      "Epoch number: 29/1000 cost:  3.431804011415619 accuracy:  0.056341097943059526\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 30/1000 cost:  3.3492414902036236 accuracy:  0.17202016074104345\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 31/1000 cost:  3.583891154663475 accuracy:  0.745159517427318\n",
      "0.0\n",
      "0.0\n",
      "0.13989919629478273\n",
      "0.054079825636834215\n",
      "0.0\n",
      "Epoch number: 32/1000 cost:  3.46101632863391 accuracy:  0.03879580438632339\n",
      "0.0\n",
      "0.0\n",
      "0.13989919629478273\n",
      "0.05421604686010081\n",
      "0.0\n",
      "Epoch number: 33/1000 cost:  3.4750621060996627 accuracy:  0.03882304863097671\n",
      "1.0\n",
      "0.23277036229910106\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 34/1000 cost:  3.5408156788302483 accuracy:  0.6077310238288435\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 35/1000 cost:  3.5570057002482884 accuracy:  0.5556213073741917\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 36/1000 cost:  3.421151926756989 accuracy:  0.18248195068791717\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 37/1000 cost:  3.5259278877251803 accuracy:  0.18915679062797983\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 38/1000 cost:  3.445928619097228 accuracy:  0.371638741315897\n",
      "1.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 39/1000 cost:  3.4911349366151407 accuracy:  0.5611769513690232\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.08759024656041411\n",
      "Epoch number: 40/1000 cost:  3.436595784026116 accuracy:  0.18953821005312627\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.13989919629478273\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 41/1000 cost:  3.405191444081516 accuracy:  0.5836011466331483\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 42/1000 cost:  3.4763968465084103 accuracy:  0.3824819506879172\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 43/1000 cost:  3.504682879719399 accuracy:  0.35450211142896065\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 44/1000 cost:  3.456249993910246 accuracy:  0.20667483994006264\n",
      "1.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.05421604686010081\n",
      "0.9124097534395859\n",
      "Epoch number: 45/1000 cost:  3.5155454456723434 accuracy:  0.5653453208009808\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.05421604686010081\n",
      "0.08759024656041411\n",
      "Epoch number: 46/1000 cost:  3.4230475291275004 accuracy:  0.22836125868410298\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 47/1000 cost:  3.48491818178844 accuracy:  0.3664645167462119\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 48/1000 cost:  3.5207244545852276 accuracy:  0.5906574059983574\n",
      "0.0\n",
      "0.08008716970852629\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 49/1000 cost:  3.5008853901460455 accuracy:  0.2051742245696851\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 50/1000 cost:  3.6581004301824995 accuracy:  0.5664645167462119\n",
      "1.0\n",
      "0.08008716970852629\n",
      "0.0\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 51/1000 cost:  3.4907984069594264 accuracy:  0.3984993846296224\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 52/1000 cost:  3.414083349794434 accuracy:  0.0\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 53/1000 cost:  3.391606152020595 accuracy:  0.17202016074104345\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 54/1000 cost:  3.480979257417821 accuracy:  0.3786950006811061\n",
      "1.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 55/1000 cost:  3.6330221157620715 accuracy:  0.5545021114289606\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.8599645824819507\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 56/1000 cost:  3.4695036779007595 accuracy:  0.555975482554685\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 57/1000 cost:  3.5292473177261967 accuracy:  0.5436589020569405\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 58/1000 cost:  3.383757809807482 accuracy:  0.3906574059983574\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 59/1000 cost:  3.506121447964668 accuracy:  0.5384846774872554\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 60/1000 cost:  3.4191601680079593 accuracy:  0.4066748399400626\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 61/1000 cost:  3.449123118558338 accuracy:  0.18915679062797983\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 62/1000 cost:  3.489329232179016 accuracy:  0.3664645167462119\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.05421604686010081\n",
      "0.08759024656041411\n",
      "Epoch number: 63/1000 cost:  3.2852679143634953 accuracy:  0.22836125868410298\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 64/1000 cost:  3.474496326302385 accuracy:  0.7556213073741918\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.07533033646642147\n",
      "Epoch number: 65/1000 cost:  3.5627438775792166 accuracy:  0.5882054239795589\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 66/1000 cost:  3.4402257723403658 accuracy:  0.17202016074104345\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 67/1000 cost:  3.422829750161717 accuracy:  0.371638741315897\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.8601008037052172\n",
      "0.05421604686010081\n",
      "0.0\n",
      "Epoch number: 68/1000 cost:  3.472944886383856 accuracy:  0.36684593617135836\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 69/1000 cost:  3.450343441391051 accuracy:  0.18248195068791717\n",
      "0.0\n",
      "0.08008716970852629\n",
      "0.13989919629478273\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 70/1000 cost:  3.4934114792304802 accuracy:  0.0439972732006618\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 71/1000 cost:  3.4362933292327695 accuracy:  0.20667483994006264\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 72/1000 cost:  3.3480160958285636 accuracy:  0.17202016074104345\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.05421604686010081\n",
      "0.9124097534395859\n",
      "Epoch number: 73/1000 cost:  3.583158416509176 accuracy:  0.5773077261182321\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 74/1000 cost:  3.535568249977569 accuracy:  0.18915679062797983\n",
      "1.0\n",
      "0.08008716970852629\n",
      "0.13989919629478273\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 75/1000 cost:  3.4911289896310267 accuracy:  0.6156360145165587\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 76/1000 cost:  3.481149581210822 accuracy:  0.35450211142896065\n",
      "0.0\n",
      "0.40111686189049306\n",
      "0.13989919629478273\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 77/1000 cost:  3.558367235404796 accuracy:  0.2906851623249723\n",
      "0.0\n",
      "0.08008716970852629\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 78/1000 cost:  3.589678166776918 accuracy:  0.5596763359986457\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 79/1000 cost:  3.5359387614152076 accuracy:  0.37313935668627457\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.08759024656041411\n",
      "Epoch number: 80/1000 cost:  3.455199597609037 accuracy:  0.5735207761114209\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.05421604686010081\n",
      "0.9124097534395859\n",
      "Epoch number: 81/1000 cost:  3.446520612681899 accuracy:  0.3653453208009808\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 82/1000 cost:  3.6005353092936376 accuracy:  0.9276414681152352\n",
      "0.0\n",
      "0.08008716970852629\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 83/1000 cost:  3.367233515480126 accuracy:  0.01601743394170526\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 84/1000 cost:  3.4010937451930623 accuracy:  0.37313935668627457\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.08759024656041411\n",
      "Epoch number: 85/1000 cost:  3.3499781792361434 accuracy:  0.017518049312082822\n",
      "1.0\n",
      "0.0\n",
      "0.13989919629478273\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 86/1000 cost:  3.583529459079365 accuracy:  0.5996185805748535\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 87/1000 cost:  3.519576246623754 accuracy:  0.5731393566862746\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 88/1000 cost:  3.4387072884810395 accuracy:  0.3611769513690233\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.047132543250238385\n",
      "0.0\n",
      "0.08759024656041411\n",
      "Epoch number: 89/1000 cost:  3.4091890664104936 accuracy:  0.41092712402042525\n",
      "0.0\n",
      "0.0\n",
      "0.13989919629478273\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 90/1000 cost:  3.452062703084857 accuracy:  0.2104617899468737\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.05421604686010081\n",
      "0.0\n",
      "Epoch number: 91/1000 cost:  3.452808361529068 accuracy:  0.21084320937202014\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 92/1000 cost:  3.4792757574455804 accuracy:  0.18398256605829474\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 93/1000 cost:  3.5580169603722935 accuracy:  0.545159517427318\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.0\n",
      "0.08759024656041411\n",
      "Epoch number: 94/1000 cost:  3.4260377488222304 accuracy:  0.40150061537037757\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 95/1000 cost:  3.5584614261335274 accuracy:  0.545159517427318\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 96/1000 cost:  3.5634214058787257 accuracy:  0.7626775667394008\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.05421604686010081\n",
      "0.9124097534395859\n",
      "Epoch number: 97/1000 cost:  3.5337098993843457 accuracy:  0.3653453208009808\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 98/1000 cost:  3.5504927089731324 accuracy:  0.5556213073741917\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 99/1000 cost:  3.5587885571289606 accuracy:  0.17202016074104345\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.08759024656041411\n",
      "Epoch number: 100/1000 cost:  3.2816031023489685 accuracy:  0.017518049312082822\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.0\n",
      "0.08759024656041411\n",
      "Epoch number: 101/1000 cost:  3.2980245208323735 accuracy:  0.40150061537037757\n",
      "1.0\n",
      "0.08008716970852629\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 102/1000 cost:  3.4873676267727083 accuracy:  0.4051742245696851\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 103/1000 cost:  3.5065716572247645 accuracy:  0.5436589020569405\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 104/1000 cost:  3.5114765395110217 accuracy:  0.35450211142896065\n",
      "1.0\n",
      "0.0\n",
      "0.001770875902465604\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 105/1000 cost:  3.4527871033459063 accuracy:  0.2003541751804931\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 106/1000 cost:  3.4350051213776376 accuracy:  0.7384846774872553\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.0\n",
      "0.08759024656041411\n",
      "Epoch number: 107/1000 cost:  3.5633413994152887 accuracy:  0.40150061537037757\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.05421604686010081\n",
      "0.08759024656041411\n",
      "Epoch number: 108/1000 cost:  3.429015275948621 accuracy:  0.22836125868410298\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.0\n",
      "0.08759024656041411\n",
      "Epoch number: 109/1000 cost:  3.3842527719319664 accuracy:  0.40150061537037757\n",
      "1.0\n",
      "0.08008716970852629\n",
      "0.8601008037052172\n",
      "0.05612314398583299\n",
      "0.9124097534395859\n",
      "Epoch number: 110/1000 cost:  3.614029202709941 accuracy:  0.5817441741678324\n",
      "1.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 111/1000 cost:  3.5425900235584833 accuracy:  0.5611769513690232\n",
      "1.0\n",
      "0.08008716970852629\n",
      "0.0\n",
      "0.0\n",
      "0.8442991418062934\n",
      "Epoch number: 112/1000 cost:  3.4809736318628355 accuracy:  0.384877262302964\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 113/1000 cost:  3.556465662077552 accuracy:  0.745159517427318\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 114/1000 cost:  3.6451145158231624 accuracy:  0.7556213073741918\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 115/1000 cost:  3.4997496392931615 accuracy:  0.18398256605829474\n",
      "1.0\n",
      "0.9156905475347317\n",
      "0.0\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 116/1000 cost:  3.5687589467728715 accuracy:  0.5656200601948635\n",
      "1.0\n",
      "0.08008716970852629\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 117/1000 cost:  3.4891076364886415 accuracy:  0.5947124346228113\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 118/1000 cost:  3.6133940592264224 accuracy:  0.545159517427318\n",
      "0.0\n",
      "0.0\n",
      "0.13989919629478273\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 119/1000 cost:  3.4490761024772105 accuracy:  0.027979839258956547\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.13989919629478273\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 120/1000 cost:  3.536495662254507 accuracy:  0.41863724525731394\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 121/1000 cost:  3.3905295504555064 accuracy:  0.17202016074104345\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.05421604686010081\n",
      "0.9124097534395859\n",
      "Epoch number: 122/1000 cost:  3.474923086119072 accuracy:  0.19332516005993733\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 123/1000 cost:  3.5277011961381333 accuracy:  0.745159517427318\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 124/1000 cost:  3.400029146006024 accuracy:  0.35450211142896065\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 125/1000 cost:  3.5002364098875693 accuracy:  0.371638741315897\n",
      "0.0\n",
      "0.08008716970852629\n",
      "0.0\n",
      "0.05421604686010081\n",
      "0.9124097534395859\n",
      "Epoch number: 126/1000 cost:  3.346691266006316 accuracy:  0.2093425940016426\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.05421604686010081\n",
      "0.0\n",
      "Epoch number: 127/1000 cost:  3.5941717859791256 accuracy:  0.39482577543031494\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 128/1000 cost:  3.4397689359289965 accuracy:  0.17202016074104345\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.08759024656041411\n",
      "Epoch number: 129/1000 cost:  3.4055572101681646 accuracy:  0.017518049312082822\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 130/1000 cost:  3.5733299927161775 accuracy:  0.5626775667394008\n",
      "1.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.08759024656041411\n",
      "Epoch number: 131/1000 cost:  3.5244508555271032 accuracy:  0.3895382100531263\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 132/1000 cost:  3.4557134581951097 accuracy:  0.20667483994006264\n",
      "1.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 133/1000 cost:  3.6158541032817113 accuracy:  0.7436589020569404\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 134/1000 cost:  3.4297681048656044 accuracy:  0.18248195068791717\n",
      "0.0\n",
      "0.08008716970852629\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 135/1000 cost:  3.5528313146317365 accuracy:  0.5596763359986457\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.05421604686010081\n",
      "0.0\n",
      "Epoch number: 136/1000 cost:  3.4583376413458615 accuracy:  0.01084320937202016\n",
      "0.0\n",
      "0.0\n",
      "0.13989919629478273\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 137/1000 cost:  3.3624070972480324 accuracy:  0.2104617899468737\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 138/1000 cost:  3.535966002175639 accuracy:  0.37313935668627457\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.05421604686010081\n",
      "0.0\n",
      "Epoch number: 139/1000 cost:  3.4781898393349993 accuracy:  0.39482577543031494\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 140/1000 cost:  3.519116677094325 accuracy:  0.371638741315897\n",
      "1.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 141/1000 cost:  3.4089478030811216 accuracy:  0.37202016074104344\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 142/1000 cost:  3.505811235678832 accuracy:  0.5436589020569405\n",
      "0.0\n",
      "0.5844456551348406\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 143/1000 cost:  3.5119538338509813 accuracy:  0.48852787234286515\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.05421604686010081\n",
      "0.08759024656041411\n",
      "Epoch number: 144/1000 cost:  3.35721860140225 accuracy:  0.20038141942514645\n",
      "1.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.05421604686010081\n",
      "0.0\n",
      "Epoch number: 145/1000 cost:  3.491724751933159 accuracy:  0.3828633701130636\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 146/1000 cost:  3.4734256040446616 accuracy:  0.371638741315897\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 147/1000 cost:  3.4513786397395405 accuracy:  0.371638741315897\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 148/1000 cost:  3.513023362401185 accuracy:  0.3611769513690233\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 149/1000 cost:  3.4545072983866874 accuracy:  0.371638741315897\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.0\n",
      "0.08759024656041411\n",
      "Epoch number: 150/1000 cost:  3.4182576914542637 accuracy:  0.18953821005312627\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.9457839531398992\n",
      "0.0\n",
      "Epoch number: 151/1000 cost:  3.5833508753499417 accuracy:  0.3891567906279798\n",
      "1.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 152/1000 cost:  3.4901319654531875 accuracy:  0.5664645167462119\n",
      "0.0\n",
      "0.0\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.08759024656041411\n",
      "Epoch number: 153/1000 cost:  3.4837049705753365 accuracy:  0.3786950006811061\n",
      "0.8493598474530101\n",
      "0.9199128302914737\n",
      "0.8601008037052172\n",
      "0.9457839531398992\n",
      "0.9124097534395859\n",
      "Epoch number: 154/1000 cost:  3.6636178338256733 accuracy:  0.8975134376058372\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.13989919629478273\n",
      "0.0\n",
      "0.0\n",
      "Epoch number: 155/1000 cost:  3.4137402150392715 accuracy:  0.2119624053172513\n",
      "0.0\n",
      "0.9199128302914737\n",
      "0.0\n",
      "0.0\n",
      "0.9124097534395859\n",
      "Epoch number: 156/1000 cost:  3.4050435249578763 accuracy:  0.3664645167462119\n",
      "0.0\n",
      "0.39689457913375104\n",
      "0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-48cf096fdec6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0ma3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNN3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0ma4\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNN4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma4\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0ma5\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNN5\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_test5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-a647f42ca101>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, y, epoch, X_test, y_test)\u001b[0m\n\u001b[0;32m    161\u001b[0m                 \u001b[0merror\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward_propagation_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam_update_parameters_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_propagation_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-a647f42ca101>\u001b[0m in \u001b[0;36mforward_propagation_NN\u001b[1;34m(self, X_train)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward_propagation_NN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mZ1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"weight1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bias1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mA1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[0mZ2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"weight2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mA1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bias2\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mA2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "kf = KFold(n_splits=5,  random_state=None)\n",
    "NN1= Neural_Network(X_train1,y_train1,76,76,0.0001,1000) #v7\n",
    "NN2= Neural_Network(X_train2,y_train2,76,76,0.0001,1000) #v7\n",
    "NN3= Neural_Network(X_train3,y_train3,76,76,0.0001,1000) #v7\n",
    "NN4= Neural_Network(X_train4,y_train4,76,76,0.0001,1000) #v7\n",
    "NN5= Neural_Network(X_train5,y_train5,76,76,0.0001,1000) #v7\n",
    "i1=0\n",
    "while i1<1000:\n",
    "    a1=NN1.train(X_train1,y_train1,10000,X_test1,y_test1)\n",
    "    print(a1[0])\n",
    "    a2=NN2.train(X_train2,y_train2,10000,X_test2,y_test2)\n",
    "    print(a2[0])\n",
    "    a3=NN3.train(X_train3,y_train3,10000,X_test3,y_test3)\n",
    "    print(a3[0])\n",
    "    a4=NN4.train(X_train4,y_train4,10000,X_test4,y_test4)\n",
    "    print(a4[0])\n",
    "    a5=NN5.train(X_train5,y_train5,10000,X_test5,y_test5)\n",
    "    print(a5[0])\n",
    "    print(\"Epoch number: \"+str(i1)+\"/\"+\"1000\",\"cost: \",(a1[1]+a2[1]+a3[1]+a4[1]+a5[1])/5,\"accuracy: \",(a1[0]+a2[0]+a3[0]+a4[0]+a5[0])/5)\n",
    "    i1=i1+1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
